<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>lyyyuna 的小花园</title>
  <id>https://www.lyyyuna.com</id>
  <updated>2026-01-21T10:28:30+08:00</updated>
  <subtitle>动静中之动</subtitle>
  <link href="https://www.lyyyuna.com"></link>
  <author>
    <name>lyyyuna</name>
    <email>lyyyuna@outlook.com</email>
  </author>
  <entry>
    <title>20260121</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2026/01/21/diary13/</id>
    <content type="html">&lt;p&gt;我们会说一个人非理性表现的时候是“失了魂”，仿佛此刻这个人被夺舍，已经和大家熟知的朋友完全断了联系。&lt;/p&gt;&#xA;&lt;p&gt;那什么才是一个完整状态的人呢？人没睡好，没休息好，情绪没控制好，喝了酒，吃了药，打了麻药。。。生活中人几乎不会处于 100% 理性的状态。&lt;/p&gt;&#xA;&lt;p&gt;追求完整状态就是成仙吗？那和机器人有什么区别？&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2026/01/21/diary13/" rel="alternate"></link>
    <summary type="html">完整状态的人</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>20251223</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/12/23/diary12/</id>
    <content type="html">&lt;p&gt;从上一篇文章的角度看，我对 AI 对初学者和基础不牢的人的影响持悲观态度，但对我自己不是。&lt;/p&gt;&#xA;&lt;p&gt;我一直认为，能用时间解决的问题都不算问题，需要精心设计思考而不得的问题，才值得人投入精力。现在有可以 AI 解决时间问题，那自然是极好的。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/12/23/diary12/" rel="alternate"></link>
    <summary type="html">人生苦短，快用 AI？</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Robot Framework 新版教程 - 创建测试套件</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/12/19/robotframework-new-tutorial-create-test-suites/</id>
    <content type="html">&lt;p&gt;Robot Framework 的测试用例创建于测试用例文件中，这些文件可以组织到不同的目录中。这些文件和目录共同构成了一个分层的测试套件结构。在创建任务时，这些概念同样适用，但使用的术语有所不同。&lt;/p&gt;&#xA;&lt;h2&gt;套件文件&lt;/h2&gt;&#xA;&lt;p&gt;Robot Framework 的测试用例在套件文件（也称为测试用例文件）的测试用例部分中创建。这样的文件会自动将其包含的所有测试用例构成一个测试套件。文件中可以包含的测试用例数量没有上限，但建议少于十个，除非使用数据驱动的方法——在此方法中，一个测试用例仅包含一个高层级的关键字。&lt;/p&gt;&#xA;&lt;p&gt;在设置部分中，可以使用以下配置来自定义套件：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Name：用于设置自定义的套件名称。默认名称基于文件或目录名生成。&lt;/li&gt;&#xA;&lt;li&gt;Documentation：用于指定套件的说明文档。&lt;/li&gt;&#xA;&lt;li&gt;Metadata：用于以名称-值对的形式设置自由的套件元数据。&lt;/li&gt;&#xA;&lt;li&gt;Suite Setup, Suite Teardown：指定套件的初始化和清理操作。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;套件目录&lt;/h2&gt;&#xA;&lt;p&gt;测试用例文件可以按目录组织，这些目录会形成更高级别的测试套件。由目录创建的测试套件本身不能直接包含任何测试用例，而是包含其他带有测试用例的套件。这些目录还可以进一步放入其他目录中，从而形成更高级别的套件。目录结构没有限制，因此可以根据需要灵活组织测试用例。&lt;/p&gt;&#xA;&lt;p&gt;当执行一个测试目录时，会递归处理其中的文件和目录，具体规则如下：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;名称以点号（&lt;code&gt;.&lt;/code&gt;）或下划线（&lt;code&gt;_&lt;/code&gt;）开头的文件和目录将被忽略。&lt;/li&gt;&#xA;&lt;li&gt;名为 CVS 的目录将被忽略（区分大小写）。&lt;/li&gt;&#xA;&lt;li&gt;支持格式的文件会被处理。&lt;/li&gt;&#xA;&lt;li&gt;其他文件将被忽略。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;如果被处理的文件或目录中未包含任何测试用例，系统会静默忽略（仅向系统日志写入一条消息），并继续执行后续处理。&lt;/p&gt;&#xA;&lt;h3&gt;套件初始化文件&lt;/h3&gt;&#xA;&lt;p&gt;通过目录创建的测试套件可以拥有与通过测试用例文件创建的套件类似的设置。由于目录本身无法包含这类信息，因此必须将其放置在一个特殊的测试套件初始化文件中。初始化文件的名称必须始终采用 &lt;code&gt;__init__.ext&lt;/code&gt; 格式，其中扩展名必须是支持的测试文件格式之一（通常是 &lt;code&gt;__init__.robot&lt;/code&gt;）。该命名格式借鉴自 Python，在这种命名方式下，文件表示该目录是一个模块。&lt;/p&gt;&#xA;&lt;p&gt;从 Robot Framework 6.1 开始，也可以通过提供多个路径，在开始测试执行时为自动创建的套件定义一个套件初始化文件。&lt;/p&gt;&#xA;&lt;p&gt;初始化文件的结构和语法与测试用例文件相同，但它们不能包含测试用例部分，并且不支持所有设置。在初始化文件中创建或导入的变量和关键字，在较低层级的测试套件中不可用。如果需要共享变量或关键字，可以将它们放入资源文件中，该资源文件既可以被初始化文件导入，也可以被测试用例文件导入。&lt;/p&gt;&#xA;&lt;p&gt;初始化文件的主要用途是类似于套件文件，指定与测试套件相关的设置，但也可以设置一些与测试用例相关的设置。以下将说明如何在初始化文件中使用不同的设置。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;Name&lt;/code&gt;, &lt;code&gt;Documentation&lt;/code&gt;, &lt;code&gt;Metadata&lt;/code&gt;, &lt;code&gt;Suite Setup&lt;/code&gt;, &lt;code&gt;Suite Teardown&lt;/code&gt;。这些套件专有的设置在套件初始化文件中的使用方式与在套件文件中完全相同。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Test Tags&lt;/code&gt;。指定的标签会无条件地递归设置到此目录包含的所有套件文件中的所有测试中。此功能为 Robot Framework 6.1 的新增特性。在旧版本中需要使用已弃用的 &lt;code&gt;Force Tags&lt;/code&gt; 设置。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Test Setup&lt;/code&gt;, &lt;code&gt;Test Teardown&lt;/code&gt;, &lt;code&gt;Test Timeout&lt;/code&gt;。为此目录包含的所有测试用例设置测试初始化/清理或测试超时的默认值。可在更低层级中覆盖此设置。请注意，用作初始化和清理的关键字必须在用到它们的测试用例文件中可用，仅在初始化文件中定义关键字是不够的。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Task Setup&lt;/code&gt;, &lt;code&gt;Task Teardown&lt;/code&gt;, &lt;code&gt;Task Tags&lt;/code&gt;, &lt;code&gt;Task Timeout&lt;/code&gt;。分别为 &lt;code&gt;Test Setup&lt;/code&gt;、&lt;code&gt;Test Teardown&lt;/code&gt;、&lt;code&gt;Test Tags&lt;/code&gt; 和 &lt;code&gt;Test Timeout&lt;/code&gt; 的别名，可用于创建任务（而非测试）时。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Default Tags&lt;/code&gt;, &lt;code&gt;Test Template&lt;/code&gt;。初始化文件中不支持这些设置。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Settings ***&#xA;Documentation    Example suite&#xA;Suite Setup      Do Something    ${MESSAGE}&#xA;Test Tags        example&#xA;Library          SomeLibrary&#xA;&#xA;*** Variables ***&#xA;${MESSAGE}       Hello, world!&#xA;&#xA;*** Keywords ***&#xA;Do Something&#xA;    [Arguments]    ${args}&#xA;    Some Keyword    ${arg}&#xA;    Another Keyword&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;套件名称&lt;/h2&gt;&#xA;&lt;p&gt;默认情况下，测试套件的名称基于文件或目录的名称生成。生成规则为：忽略扩展名，将可能存在的下划线替换为空格，并将完全小写的名称转换为首字母大写形式。例如，&lt;code&gt;some_tests.robot&lt;/code&gt; 会变为 &lt;strong&gt;Some Tests&lt;/strong&gt;，&lt;code&gt;My_test_directory&lt;/code&gt; 会变为 &lt;strong&gt;My test directory&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;文件或目录名可以包含一个前缀，用于控制套件的执行顺序。前缀与基本名称之间由两个下划线分隔。在构建实际的测试套件名称时，前缀及下划线均会被移除。例如，文件 &lt;code&gt;01__some_tests.robot&lt;/code&gt; 和 &lt;code&gt;02__more_tests.robot&lt;/code&gt; 会分别创建测试套件 &lt;strong&gt;Some Tests&lt;/strong&gt; 和 &lt;strong&gt;More Tests&lt;/strong&gt;，且前者会先于后者执行。&lt;/p&gt;&#xA;&lt;p&gt;从 Robot Framework 6.1 开始，还可以通过在设置区（Setting section）使用 &lt;strong&gt;Name&lt;/strong&gt; 设置项来为套件指定自定义名称：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Settings ***&#xA;Name            Custom suite name&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;顶层套件的名称可以通过命令行中的 &lt;code&gt;--name&lt;/code&gt; 选项进行覆盖。&lt;/p&gt;&#xA;&lt;h2&gt;套件文档&lt;/h2&gt;&#xA;&lt;p&gt;测试套件的文档通过 Settings 部分中的 &lt;strong&gt;Documentation&lt;/strong&gt; 设置项进行设置。该设置项既可用于套件文件，也可用于套件初始化文件。套件文档在显示位置和创建方式上与测试用例文档具有完全相同的特性。有关语法的详细信息，请参阅&lt;a href=&#34;https://robotframework.org/robotframework/latest/RobotFrameworkUserGuide.html#documentation-formatting&#34;&gt;文档格式化附录&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Settings ***&#xA;Documentation    An example suite documentation with *some* _formatting_.&#xA;...              Long documentation can be split into multiple lines.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;顶层套件的文档可以通过命令行中的 &lt;code&gt;--doc&lt;/code&gt; 选项进行覆盖。&lt;/p&gt;&#xA;&lt;h2&gt;测试套件的自由元数据&lt;/h2&gt;&#xA;&lt;p&gt;除了文档之外，测试套件还可以拥有自由元数据。这些元数据在 Settings 部分通过 &lt;strong&gt;Metadata&lt;/strong&gt; 设置项以“名称-值”对的形式进行定义，其展示方式与文档类似，会在报告和日志中呈现。&lt;/p&gt;&#xA;&lt;p&gt;元数据的名称是提供给 &lt;strong&gt;Metadata&lt;/strong&gt; 设置项的第一个参数，其余参数则指定其值。元数据的值处理方式与文档类似，这意味着它支持 HTML 格式和变量，并且较长的值可以拆分成多行。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-makrdown&#34;&gt;*** Settings ***&#xA;Metadata        Version            2.0&#xA;Metadata        Robot Framework    http://robotframework.org&#xA;Metadata        Platform           ${PLATFORM}&#xA;Metadata        Longer Value&#xA;...             Longer metadata values can be split into multiple&#xA;...             rows. Also *simple* _formatting_ is supported.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;顶层套件的自由元数据可以通过命令行中的 &lt;code&gt;--metadata&lt;/code&gt; 选项进行设置。&lt;/p&gt;&#xA;&lt;h2&gt;套件的初始化和清理&lt;/h2&gt;&#xA;&lt;p&gt;不仅测试用例可以设置初始化和清理，测试套件同样可以拥有初始化和清理步骤。套件初始化 会在执行该套件内任何测试用例或子测试套件之前运行，而 套件清理 则在它们之后执行。所有测试套件均可设置初始化和清理；对于通过目录创建的套件，必须在套件初始化文件中进行配置。&lt;/p&gt;&#xA;&lt;p&gt;与测试用例类似，套件的初始化和清理也是关键字，并且可以接受参数。它们分别在 Settings 部分通过 &lt;code&gt;Suite Setup&lt;/code&gt; 和 &lt;code&gt;Suite Teardown&lt;/code&gt; 设置项进行定义。关键字名称及可能的参数位于设置名称之后的列中。&lt;/p&gt;&#xA;&lt;p&gt;如果套件初始化失败，则该套件及其所有子套件中的所有测试用例将立即被标记为失败状态，并且实际不会被执行。这使得套件初始化非常适合用于检查运行测试用例前必须满足的前提条件。&lt;/p&gt;&#xA;&lt;p&gt;套件清理通常用于在所有测试用例执行完毕后进行清理工作。即使同一套件的初始化失败，清理步骤仍会执行。如果套件清理失败，则无论测试用例的原始执行状态如何，套件中的所有测试用例都将被标记为失败。需要注意的是，即使套件清理中的某个关键字执行失败，后续的所有关键字仍会继续执行。&lt;/p&gt;&#xA;&lt;p&gt;作为初始化或清理执行的关键字名称可以是变量。这使得可以通过命令行将关键字名称作为变量传入，从而实现在不同环境下使用不同的初始化或清理步骤。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/12/19/robotframework-new-tutorial-create-test-suites/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Robot Framework 新版教程 - 创建任务</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/12/18/robotframework-new-tutorial-create-tasks/</id>
    <content type="html">&lt;p&gt;除了测试自动化，Robot Framework 还可用于其他自动化场景，例如机器人流程自动化（RPA）。虽然这一功能始终可行，但直到 Robot Framework 3.1 版本才正式扩展了对非测试类自动化任务的支持。在大多数情况下，创建任务的流程与创建测试几乎完全相同，唯一的实质区别在于术语体系。与测试用例类似，任务同样可以通过套件形式进行结构化组织。&lt;/p&gt;&#xA;&lt;h2&gt;任务语法&lt;/h2&gt;&#xA;&lt;p&gt;任务的创建基于已有的关键字，这与创建测试用例的方式完全相同，并且任务的语法总体上与测试用例的语法一致。主要的区别在于，任务是在&amp;quot;任务&amp;quot;部分而非&amp;quot;测试用例&amp;quot;部分创建的：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Tasks ***&#xA;Process invoice&#xA;    Read information from PDF&#xA;    Validate information&#xA;    Submit information to backend system&#xA;    Validate information is visible in web UI&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;注意：在同一文件中同时包含测试和任务是错误的。&lt;/p&gt;&#xA;&lt;h2&gt;任务相关配置设置&lt;/h2&gt;&#xA;&lt;p&gt;任务部分可使用的配置设置与测试用例部分完全相同。在设置部分，可以使用 &lt;code&gt;Task Setup&lt;/code&gt;、&lt;code&gt;Task Teardown&lt;/code&gt;、&lt;code&gt;Task Template&lt;/code&gt; 和 &lt;code&gt;Task Timeout&lt;/code&gt;，以替代相应的测试变体（如 &lt;code&gt;Test Setup&lt;/code&gt;、&lt;code&gt;Test Teardown&lt;/code&gt; 等）。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/12/18/robotframework-new-tutorial-create-tasks/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>20251216</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/12/16/diary11/</id>
    <content type="html">&lt;p&gt;去年的智能编程给我感觉还只是高级一点的智能补全，但今年开始的 &lt;code&gt;vibe coding&lt;/code&gt; 后，很多就改变了。每次想做个项目，改个功能，都是把需求写成文档，让 AI 自己去设计结构、梳理逻辑、构建工程、编写代码，我俨然成了一个“项目经理”。&lt;/p&gt;&#xA;&lt;p&gt;这是好的么？这里可以探讨一下。&lt;/p&gt;&#xA;&lt;p&gt;我过去几年一直关注着编程语言的发展，可 &lt;code&gt;vibe coding&lt;/code&gt; 后，语言的特性似乎不重要了，还发不发展 GC？还继续引入更多的函数式编程概念？对每一个使用 AI 的程序员来说，这些玩意本来就费脑，现在更不需要关注，AI 会帮你解决“一切”。&lt;/p&gt;&#xA;&lt;p&gt;编程语言的发展，本质上是帮助人理解机器，用更高级更抽象的语言来表达。有了 AI，你还需要这些抽象吗？我敢肯定，AI 编程早 10 年出现的话，现在大家肯定都用 Java 来作为工作语言。&lt;/p&gt;&#xA;&lt;p&gt;可我总觉得，编程语言还远未进化到一个终极形态，各个编程语言还有很多自身的缺陷需要解决。可 AI 却有一种要把这一自然发展的进程给戛然而止的态势。&lt;/p&gt;&#xA;&lt;p&gt;大佬总说，“AI 时代，人人都是产品经理”。可我想说，AI 不会提升你的抽象技术能力，用了 AI 你大概率会陷入技术停滞。&lt;/p&gt;&#xA;&lt;p&gt;这其实是一个可以预见的现象。大家观察一下，那些从一线码农转变成技术 leader/项目管理员的人，是不是大部分脑子里塞的都是陈旧的技术？因为对于他们来说，用那些过时的技术，指挥手下的人，完全可以应付日常工作。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/12/16/diary11/" rel="alternate"></link>
    <summary type="html">AI 让编程语言的发展陷入停滞？</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Siril 教程：天文摄影中的图像堆栈与处理</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/12/05/siril-tutorial/</id>
    <content type="html">&lt;p&gt;天文摄影让我们能够捕捉夜空之美，但由于长曝光时间和低光条件，单张图像往往包含噪声且缺乏细节。为了克服这一问题，天文摄影师使用一种称为图像堆栈的技术。通过组合同一场景的多张图像，我们可以增强信噪比并揭示更多天体细节。&lt;/p&gt;&#xA;&lt;p&gt;在本指南中，我将带你了解使用 Siril 堆栈天文摄影图像的过程，Siril 是一款专为天文图像处理设计的功能强大的免费软件。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/46.png&#34; alt=&#34;堆栈后的 M31 仙女座星系&#34;&gt;&lt;/p&gt;&#xA;&lt;h2&gt;为什么使用 Siril？&lt;/h2&gt;&#xA;&lt;p&gt;Siril 是一款专为天文摄影图像叠加而设计的软件，提供一系列强大的工具，能满足高质量天文图像处理的需求。其核心功能包括精密的对齐与校准工具，可修正由大气和光学因素引起的偏移与畸变，从而生成清晰准确的叠加图像。Siril 的叠加算法在弱光天文摄影中能有效抑制噪点，同时保留精细细节，呈现出明亮生动的画面。此外，Siril 还提供背景提取、色彩校准与测光色偏校正功能，能增强天体的自然色彩。该软件同时支持自动化流程与手动调控，兼顾从新手到高阶用户的不同需求。作为一款免费开源工具，Siril 持续保持更新，是天文学爱好者强大且易用的理想选择。&lt;/p&gt;&#xA;&lt;h2&gt;安装 Siril&lt;/h2&gt;&#xA;&lt;p&gt;你可以从 &lt;a href=&#34;https://siril.org&#34;&gt;siril.org&lt;/a&gt; 下载安装最新的 Siril。&lt;/p&gt;&#xA;&lt;h2&gt;前置条件&lt;/h2&gt;&#xA;&lt;p&gt;进行图像叠加处理时，您需要准备一组针对同一天体或相同天区的多张图像。请确保这些图像在相似的拍摄条件和一致的参数设置下获得，以实现最佳的叠加效果。您使用的图像数量越多，最终成像质量越好，因为叠加处理能有效抑制噪点并增强细节表现。&lt;/p&gt;&#xA;&lt;h2&gt;实践天文摄影图像堆栈&lt;/h2&gt;&#xA;&lt;p&gt;你可以从以下资源下载用于天文摄影图像叠加的练习素材，以获得实际操作经验：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://astropix.com&#34;&gt;Astropix&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://astrobackyard.com&#34;&gt;AstroBackyard&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这些资源提供了出色的数据集，可供您练习图像叠加与后期处理技巧。&lt;/p&gt;&#xA;&lt;h2&gt;图像校准&lt;/h2&gt;&#xA;&lt;p&gt;本部分将说明如何在 Siril 中为图像叠加整理文件。&lt;/p&gt;&#xA;&lt;h3&gt;在 Siril 中组织图像文件以进行堆栈&lt;/h3&gt;&#xA;&lt;p&gt;在使用 Siril 处理天文摄影图像前，妥善整理文件至关重要。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;首先，以你处理的天体或星团名称创建一个主目录。（例如：M31 - 仙女座星系）&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/one.png&#34; alt=&#34;创建主目录&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;在该目录内，创建四个子文件夹：lights、darks、biases 和 flats。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/two.png&#34; alt=&#34;创建子目录&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Lights&lt;/strong&gt;：将所有目标天体的原始图像（计划用于叠加的图片）放入 lights 文件夹。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Darks&lt;/strong&gt;：将暗场图像放置于此，用于校正传感器噪声。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Biases&lt;/strong&gt;：将偏置场图像添加到此文件夹，以校正读取噪声。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Flats&lt;/strong&gt;：存储平场图像，用于校正传感器暗角或灰尘影响。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;在此步骤中，我们仅将亮场文件（原始图像）放入 lights 文件夹。本指南将仅使用这些亮场图像进行操作。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/three.png&#34; alt=&#34;放置光学文件&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：这些目录至关重要，因为 Siril 的内置脚本依赖它们来执行叠加流程。如果未正确创建这些目录并放入对应的图像文件，脚本将无法运行，您会遇到错误。遵循此结构能确保叠加工作流程顺利进行。&lt;/p&gt;&#xA;&lt;h2&gt;启动 Siril&lt;/h2&gt;&#xA;&lt;h3&gt;设置工作区&lt;/h3&gt;&#xA;&lt;p&gt;默认情况下，Siril 启动时的工作目录可能与您存储图像的目录不同。为确保 Siril 能够访问您的图像并正确执行叠加操作，请按以下步骤更改工作目录：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;打开 Siril：在您的计算机上启动 Siril。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/four.png&#34; alt=&#34;打开 Siril&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;要更改 Siril 中的当前工作目录，请点击窗口左上角的&lt;strong&gt;主页&lt;/strong&gt;图标。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/five~2.png&#34; alt=&#34;主页图标位置&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;此操作将打开文件浏览器，您可以导航至并选择存储图像文件的目录。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/seven~2.png&#34; alt=&#34;文件浏览器界面&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;4&#34;&gt;&#xA;&lt;li&gt;导航至包含 lights、darks、flats 和 biases 文件夹的目录后，点击&lt;strong&gt;打开&lt;/strong&gt;，将此目录设为 Siril 的工作目录。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/eight~2.png&#34; alt=&#34;确认目录选择&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;现在，Siril 已设置为在指定目录中处理图像。您可以通过查看 Siril 窗口左上角显示的当前工作目录路径来确认这一点。&lt;/p&gt;&#xA;&lt;h3&gt;安装脚本&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;点击 Siril 窗口右上角的&lt;strong&gt;三横线菜单&lt;/strong&gt;图标。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/nine~2.png&#34; alt=&#34;三横线菜单图标&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;点击&lt;strong&gt;获取脚本&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/ten~2.png&#34; alt=&#34;Get Scripts 选项&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;点击后，系统将跳转至 Siril 的官方文档页面。在该页面的&lt;strong&gt;获取更多脚本&lt;/strong&gt;章节下找到 &lt;a href=&#34;https://gitlab.com/free-astro/siril-scripts&#34;&gt;GitLab&lt;/a&gt; 链接并点击进入。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/111.png&#34; alt=&#34;GitLab 链接&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;4&#34;&gt;&#xA;&lt;li&gt;点击 &lt;strong&gt;preprocessing&lt;/strong&gt; 目录。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/122.png&#34; alt=&#34;Preprocessing 选择&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;5&#34;&gt;&#xA;&lt;li&gt;点击 &lt;strong&gt;OSC_Preprocessing_WithoutDBF.ssf&lt;/strong&gt; 文件。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/13.png&#34; alt=&#34;OSC_Preprocessing_WithoutDBF.ssf 脚本&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：我们将下载 &lt;strong&gt;OSC_Preprocessing_WithoutDBF.ssf&lt;/strong&gt; 脚本，因为本教程仅使用亮场图像进行处理。&lt;/p&gt;&#xA;&lt;ol start=&#34;6&#34;&gt;&#xA;&lt;li&gt;下载 &lt;strong&gt;OSC_Preprocessing_WithoutDBF.ssf&lt;/strong&gt; 脚本文件。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/144.png&#34; alt=&#34;下载脚本&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;下载脚本后，请将其放置在以下目录中：&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;/This PC/Local Disk (C:)/Program Files/Siril/scripts/&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;一旦脚本正确安装并放置在正确的目录中，你就可以开始在 Siril 中进行堆栈工作流程了。&lt;/p&gt;&#xA;&lt;h3&gt;图像堆栈&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;点击顶部菜单中的&lt;strong&gt;脚本&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/15~2.png&#34; alt=&#34;Scripts 菜单&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;从可用脚本列表中选择 &lt;strong&gt;OSC_Preprocessing_WithoutDBF&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/16~2.png&#34; alt=&#34;选择脚本&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;点击&lt;strong&gt;运行&lt;/strong&gt;以执行该脚本。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/17~2.png&#34; alt=&#34;Run 按钮&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;4&#34;&gt;&#xA;&lt;li&gt;等待脚本执行完成。你可以在控制台窗口中查看执行进度。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/18~2.png&#34; alt=&#34;控制台进度窗口&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;最终叠加完成的图像将保存在名为 &lt;strong&gt;M31&lt;/strong&gt; 的主目录中。&lt;/p&gt;&#xA;&lt;ol start=&#34;5&#34;&gt;&#xA;&lt;li&gt;要打开最终叠加图像，请点击顶部菜单中的&lt;strong&gt;打开&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/19~2.png&#34; alt=&#34;Open 菜单选项&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;最终叠加完成的图像将命名为 &lt;strong&gt;result.fit&lt;/strong&gt;，并以 FITS 格式保存。&lt;/p&gt;&#xA;&lt;ol start=&#34;6&#34;&gt;&#xA;&lt;li&gt;选择 &lt;strong&gt;result.fit&lt;/strong&gt; 文件，然后点击底部的&lt;strong&gt;打开&lt;/strong&gt;按钮以加载图像。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/20~2.png&#34; alt=&#34;选择 result.fit 文件&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;7&#34;&gt;&#xA;&lt;li&gt;这是 M31 原始叠加图像在&lt;strong&gt;线性视图&lt;/strong&gt;下的显示效果。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/21~2.png&#34; alt=&#34;原始堆栈图像显示&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;8&#34;&gt;&#xA;&lt;li&gt;要从&amp;quot;线性&amp;quot;视图切换到&amp;quot;自动拉伸&amp;quot;视图，只需点击&lt;strong&gt;线性&lt;/strong&gt;按钮，然后选择&lt;strong&gt;自动拉伸&lt;/strong&gt;以调整图像显示效果。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/22~2.png&#34; alt=&#34;Linear 到 Autostretch 切换&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/23~2.png&#34; alt=&#34;Autostretch 视图&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：自动拉伸会对图像数据进行临时拉伸，使微弱细节更易见，但不会永久改变原始数据。这在对叠加图像进行进一步后处理前，用于预览非常有用。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/24~2.png&#34; alt=&#34;Autostretch 结果&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：对叠加图像应用自动拉伸后，你可能会注意到绿色噪点。这很常见，可以在后续处理中进行校正。&lt;/p&gt;&#xA;&lt;ol start=&#34;9&#34;&gt;&#xA;&lt;li&gt;要切换到&lt;strong&gt;直方图视图&lt;/strong&gt;，请从视图选项中选择&lt;strong&gt;直方图&lt;/strong&gt;。切换到直方图视图可以让您更精细地控制图像的色调范围，从而更好地观察细节和调整曝光。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/26~2.png&#34; alt=&#34;直方图视图&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;在直方图视图中，您可以看到图像像素值的分布情况。该视图有助于调整亮度和对比度。&lt;/p&gt;&#xA;&lt;h2&gt;背景提取&lt;/h2&gt;&#xA;&lt;p&gt;背景提取是天文学图像处理中至关重要的一步。它有助于去除图像中不需要的背景噪声或背景亮度变化，让天体目标更加清晰地显现出来。在本节中，我们将详细介绍在 Siril 中执行背景提取的步骤。&lt;/p&gt;&#xA;&lt;p&gt;在开始后处理之前，首先需要裁剪掉在直方图视图中可见的图像边缘的畸变和噪声。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;要进行裁剪，请在图像上&lt;strong&gt;左键单击&lt;/strong&gt;，拖动鼠标框选您希望保留的区域，然后&lt;strong&gt;右键单击&lt;/strong&gt;并选择&lt;strong&gt;裁剪&lt;/strong&gt;以应用更改。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/27~3.png&#34; alt=&#34;裁剪工具界面&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;裁剪完成后，请切换回&lt;strong&gt;自动拉伸&lt;/strong&gt;视图以增强图像可见度，然后开始&lt;strong&gt;背景提取&lt;/strong&gt;流程。&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;导航至&lt;strong&gt;图像处理&lt;/strong&gt;菜单。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Siril 中的背景提取是一个帮助去除天文图像中不需要的背景噪声或亮度变化的过程。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/28.png&#34; alt=&#34;Image Processing 菜单&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;选择&lt;strong&gt;背景提取&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/29.png&#34; alt=&#34;Background Extraction 选择&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;4&#34;&gt;&#xA;&lt;li&gt;点击&lt;strong&gt;生成样本&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/33.png&#34; alt=&#34;生成采样点&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：Siril 利用这些样本来估计背景强度以及由光污染或传感器噪声等因素引起的亮度梯度。选择样本后，Siril 会从图像中减去估算出的背景模型，从而获得更干净、更均匀的背景。&lt;/p&gt;&#xA;&lt;ol start=&#34;5&#34;&gt;&#xA;&lt;li&gt;为确保背景提取的准确性，请&lt;strong&gt;右键单击&lt;/strong&gt;删除任何离明亮恒星或天体过近的样本。这有助于避免图像中天体的干扰，确保只对背景进行建模。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/30.png&#34; alt=&#34;在亮星附近移除采样点&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;6&#34;&gt;&#xA;&lt;li&gt;点击&lt;strong&gt;计算背景&lt;/strong&gt;以完成此步骤，然后点击&lt;strong&gt;应用&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/31.png&#34; alt=&#34;计算背景并应用&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;应用背景提取后，您将注意到图像质量有显著提升。背景噪声和亮度变化将减少，使天体目标更加清晰地凸显出来。&lt;/p&gt;&#xA;&lt;h2&gt;测光色彩校准&lt;/h2&gt;&#xA;&lt;p&gt;在天文摄影图像叠加中，测光色彩校准对于校正由光污染、传感器特性及不同曝光条件等因素引起的色彩失衡至关重要。在 Siril 中，此过程通过调整叠加图像的色彩，使其与天体的真实色彩相匹配，从而确保结果准确且自然。Siril 通过分析图像中恒星及其他天体的色彩，并调整红、绿、蓝通道以消除任何不必要的色偏来实现这一校准。这项校准对于生成科学准确且视觉一致的图像至关重要，尤其是在叠加多帧具有不同色彩偏差的图像时。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;要进行测光色彩校准，请点击&lt;strong&gt;色彩校准&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/50.png&#34; alt=&#34;Color Calibration 菜单&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;选择&lt;strong&gt;测光色彩校准&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/51.png&#34; alt=&#34;Photometric Color Calibration&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;随后将弹出一个窗口，您需要输入星表编号以匹配对应的赤经与赤纬坐标。若您使用望远镜拍摄，坐标信息通常会&lt;strong&gt;自动显示&lt;/strong&gt;；若使用数码单反相机拍摄，坐标值&lt;strong&gt;默认可能为零&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;对于 M31（仙女座星系）图像进行校准时，其星表编号为 &lt;strong&gt;NGC 224&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/52.png&#34; alt=&#34;输入星表编号窗口&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;你可以从多种星表（如 VizieR、SIMBAD 或 CDS）中选择，以确保坐标与正确的星表条目匹配。&lt;/p&gt;&#xA;&lt;p&gt;为提高校准精度，请补充输入望远镜的&lt;strong&gt;焦距&lt;/strong&gt;和&lt;strong&gt;像素尺寸&lt;/strong&gt;。这些参数有助于根据您的设备配置优化测光校正效果。&lt;/p&gt;&#xA;&lt;p&gt;填写完所有必要信息后，点击&lt;strong&gt;确定&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;h2&gt;去除绿色噪点&lt;/h2&gt;&#xA;&lt;p&gt;绿色噪点是天文摄影图像中常见的问题，尤其在使用某些相机或传感器时更为明显。它表现为图像中出现绿色调或色偏，会影响最终图像的整体质量和色彩准确性。去除绿色噪点对于获得更均衡、自然的图像至关重要。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果图像中仍存在绿色噪点，请点击&lt;strong&gt;去除绿色噪点&lt;/strong&gt;将其消除。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/34.png&#34; alt=&#34;Remove green noise 选项&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;保持默认选项不变，直接点击&lt;strong&gt;应用&lt;/strong&gt;即可。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/35.png&#34; alt=&#34;Remove green noise 设置&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/36.png&#34; alt=&#34;去噪后的结果&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;去除绿色噪点后，图像变得更干净，色彩也更均衡了。&lt;/p&gt;&#xA;&lt;h2&gt;图像拉伸&lt;/h2&gt;&#xA;&lt;p&gt;图像拉伸是天文学图像处理中至关重要的一步。它能增强叠加图像中微弱细节和色彩的可见度，使图像更具视觉吸引力。在本节中，我们将详细介绍有效拉伸图像的步骤。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;将视图切换为&lt;strong&gt;线性视图&lt;/strong&gt;，然后点击&lt;strong&gt;直方图变换&lt;/strong&gt;对图像进行拉伸。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/40.png&#34; alt=&#34;Histogram Transformation&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;点击 &lt;strong&gt;clip(%)&lt;/strong&gt; 上方的图标，应用自动拉伸算法。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/41.png&#34; alt=&#34;Autostretch 算法图标&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;选择 &lt;strong&gt;Asinh&lt;/strong&gt; 变换。此调整将增强图像中的细节表现。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/37.png&#34; alt=&#34;Asinh 变换选择&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;4&#34;&gt;&#xA;&lt;li&gt;将&lt;strong&gt;拉伸因子&lt;/strong&gt;调整至最大值，以增强图像的对比度和细节。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/38.png&#34; alt=&#34;拉伸因子调整&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;5&#34;&gt;&#xA;&lt;li&gt;点击&lt;strong&gt;应用&lt;/strong&gt;以使更改生效。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;应用色彩调整&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;点击&lt;strong&gt;色彩饱和度&lt;/strong&gt;选项，以增强图像中色彩的生动度。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/42.png&#34; alt=&#34;Color Saturation 选项&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;选择&lt;strong&gt;全局&lt;/strong&gt;，以使用多种色彩调整选项。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;选定所需的色彩选项后，通过调整&lt;strong&gt;数量&lt;/strong&gt;滑块来增加色彩饱和度。点击&lt;strong&gt;应用&lt;/strong&gt;以确认并应用更改，从而提升图像的色彩活力。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/43.png&#34; alt=&#34;色彩饱和度调整&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/46.png&#34; alt=&#34;色彩饱和度调整&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这是最终叠加图像的处理结果。你可以使用各类照片编辑软件进一步微调和增强，以进行更多调整与优化。&lt;/p&gt;&#xA;&lt;ol start=&#34;4&#34;&gt;&#xA;&lt;li&gt;点击右上角的&lt;strong&gt;保存&lt;/strong&gt;或&lt;strong&gt;下载&lt;/strong&gt;选项，以保存最终结果图像。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/47.png&#34; alt=&#34;保存/下载按钮&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;5&#34;&gt;&#xA;&lt;li&gt;保存图像时，你可以根据需求选择不同的文件格式。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/imgrrr/%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E7%8C%8E%E6%88%B7%E5%BA%A7/49.png&#34; alt=&#34;文件格式选择&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;6&#34;&gt;&#xA;&lt;li&gt;点击&lt;strong&gt;保存&lt;/strong&gt;以下载最终图像。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;结论&lt;/h2&gt;&#xA;&lt;p&gt;总的来说，Siril 对于天文摄影师而言是一款极其强大的工具，它提供了一系列功能，使图像叠加和校准等复杂任务变得更为简易。其通过多种脚本实现的自动化支持尤为突出，能为您节省大量时间和精力，尤其是在处理大量图像时。然而，要获得最佳效果，仍需在掌握工作流程上投入一定的耐心与实践。&lt;/p&gt;&#xA;&lt;p&gt;需要注意的是，本指南专为使用望远镜进行天文摄影的初学者设计，并未涵盖更高级的技术，例如广义双曲拉伸变换、反卷积、降噪，或像 StarNet 这类高级星点处理工具。&lt;/p&gt;&#xA;&lt;p&gt;若您希望深入了解这些领域，我强烈推荐您访问 &lt;a href=&#34;https://www.youtube.com/@DeepSpaceAstro&#34;&gt;Deep Space Astro&lt;/a&gt; 的 YouTube 频道，那里提供了关于高级图像处理技巧的详尽教程。&lt;/p&gt;&#xA;&lt;h2&gt;致谢&lt;/h2&gt;&#xA;&lt;p&gt;图像来源于 &lt;a href=&#34;https://astropix.com&#34;&gt;Astropix&lt;/a&gt; 和 &lt;a href=&#34;https://astrobackyard.com&#34;&gt;AstroBackyard&lt;/a&gt;，感谢他们通过高质量天文摄影资源做出的&amp;quot;宝贵贡献&amp;quot;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;本教程翻译自 &lt;a href=&#34;https://sathvikacharyaa.github.io/sirilastro/&#34;&gt;https://sathvikacharyaa.github.io/sirilastro/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/12/05/siril-tutorial/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Robot Framework 新版教程 - 创建测试用例</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/12/04/robotframework-new-tutorial-create-test-cases/</id>
    <content type="html">&lt;p&gt;本节介绍测试用例的总体语法规则。关于如何通过套件文件及套件目录组织测试用例构成测试套件，将在下一文章中详细讨论。&lt;/p&gt;&#xA;&lt;h2&gt;测试用例语法&lt;/h2&gt;&#xA;&lt;h3&gt;基本语法&lt;/h3&gt;&#xA;&lt;p&gt;测试用例在 test case section 中通过可用关键字构建。关键字可从测试库或资源文件导入，或在测试用例文件自身的 keyword section 中创建。&lt;/p&gt;&#xA;&lt;p&gt;test case section 的第一列包含测试用例名称。测试用例从该列有内容的行开始，延续至下一个测试用例名称或 section 结尾。若在 section 标题与第一个测试用例之间存在内容，则视为错误。&lt;/p&gt;&#xA;&lt;p&gt;第二列通常为关键字名称。例外情况是通过关键字返回值设置变量时，第二列（及可能的后续列）包含变量名，而关键字名位于其后。无论哪种情况，关键字名之后的列都包含该关键字的参数。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Valid Login&#xA;    Open Login Page&#xA;    Input Username    demo&#xA;    Input Password    mode&#xA;    Submit Credentials&#xA;    Welcome Page Should Be Open&#xA;&#xA;Setting Variables&#xA;    Do Something    first argument    second argument&#xA;    ${value} =    Get Some Value&#xA;    Should Be Equal    ${value}    Expected value&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;测试用例中的设置部分&lt;/h3&gt;&#xA;&lt;p&gt;测试用例也可以包含专属设置项。设置名称始终位于第二列（通常放置关键字的位置），其参数值则位于后续列。设置名称需用方括号标识，以区别于普通关键字。可用的设置项如下所示，本节后续将详细说明：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;[Documentation]&lt;/code&gt;，用于指定测试用例的说明文档&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;[Setup]&lt;/code&gt;, &lt;code&gt;[Teardown]&lt;/code&gt;，指定测试的初始化和清理操作&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;[Tags]&lt;/code&gt;，用于为测试用例添加标签&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;[Template]&lt;/code&gt;，指定模板关键字。测试用例本身仅包含作为该关键字参数使用的数据&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;[Timeout]&lt;/code&gt;，用于设置测试用例超时时间。超时设置将在专门章节详细讨论&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;示例：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Test With Settings&#xA;    [Documentation]    Another dummy test&#xA;    [Tags]    dummy    owner-johndoe&#xA;    Log    Hello, world!&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;与测试用例相关的配置项&lt;/h3&gt;&#xA;&lt;p&gt;Setting section 可包含以下与测试用例相关的设置项。这些设置项主要为前文列出的测试用例专属设置提供默认值：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;Test Setup&lt;/code&gt;, &lt;code&gt;Test Teardown&lt;/code&gt;，测试初始化和清理操作的默认设置&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Test Tags&lt;/code&gt;，测试套件中所有测试用例都将继承的默认标签（会与各测试用例的自定义标签合并）&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Test Template&lt;/code&gt;，默认使用的模板关键字&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Test Timeout&lt;/code&gt;，测试用例超时的默认值（超时设置将在专门章节详细讨论）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;使用参数&lt;/h2&gt;&#xA;&lt;p&gt;之前的示例已展示了关键字如何接收不同参数，本节将更深入地探讨这一重要功能。关于如何实际实现带不同参数的用户关键字和库关键字，将在后续独立章节中详细讨论。&lt;/p&gt;&#xA;&lt;p&gt;关键字可接收零到多个参数，部分参数可能具有默认值。关键字具体支持哪些参数取决于其实现方式，通常最佳查询渠道是查阅关键字的说明文档。&lt;/p&gt;&#xA;&lt;h3&gt;位置参数&lt;/h3&gt;&#xA;&lt;p&gt;大多数关键字都有固定数量的必须提供的参数。在关键字文档中，这通过逗号分隔的参数名称表示，例如 &lt;code&gt;first&lt;/code&gt;, &lt;code&gt;second&lt;/code&gt;, &lt;code&gt;third&lt;/code&gt;。此时参数名称的实际含义并不重要（除非需要解释参数作用），但关键是要确保参数数量与文档严格一致。参数过少或过多都会触发错误。&lt;/p&gt;&#xA;&lt;p&gt;以下测试案例使用了 &lt;a href=&#34;https://robotframework.org/robotframework/latest/libraries/OperatingSystem.html&#34;&gt;OperatingSystem&lt;/a&gt; 库中的 &lt;code&gt;Create Directory&lt;/code&gt; 和 &lt;code&gt;Copy File&lt;/code&gt; 关键字。其参数分别标注为 &lt;code&gt;path&lt;/code&gt; 与 &lt;code&gt;source&lt;/code&gt;, &lt;code&gt;destination&lt;/code&gt;，表示前者需 1 个参数，后者需 2 个参数。最后调用的 &lt;a href=&#34;https://robotframework.org/robotframework/latest/libraries/BuiltIn.html&#34;&gt;BuiltIn&lt;/a&gt; 库关键字 &lt;code&gt;No Operation&lt;/code&gt; 则无需任何参数。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Example&#xA;    Create Directory    ${TEMPDIR}/stuff&#xA;    Copy File    ${CURDIR}/file.txt    ${TEMPDIR}/stuff&#xA;    No Operation&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;带默认值的参数&lt;/h3&gt;&#xA;&lt;p&gt;参数通常具有可选默认值。在文档中，默认值通过等号与参数名称连接表示，格式为 &lt;code&gt;name=default value&lt;/code&gt;。所有参数均可设置默认值，但注意：一旦某个参数设定了默认值，其后续的所有参数也必须具有默认值（即不能出现必选参数位于可选参数之后的情况）。&lt;/p&gt;&#xA;&lt;p&gt;以下示例通过 &lt;code&gt;Create File&lt;/code&gt; 关键字演示默认值的使用，该关键字参数定义为 &lt;code&gt;path&lt;/code&gt;, &lt;code&gt;content=&lt;/code&gt;, &lt;code&gt;encoding=UTF-8&lt;/code&gt;。若调用时不提供任何参数或超过三个参数，则会导致错误。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Example&#xA;    Create File    ${TEMPDIR}/empty.txt&#xA;    Create File    ${TEMPDIR}/utf-8.txt         Hyvä esimerkki&#xA;    Create File    ${TEMPDIR}/iso-8859-1.txt    Hyvä esimerkki    ISO-8859-1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;可变数量的参数&lt;/h3&gt;&#xA;&lt;p&gt;关键字也可以接受任意数量的参数。这些所谓的可变参数可以与强制参数和带默认值的参数结合使用，但必须始终位于这些参数之后。在文档中，这类参数名称前会带有一个星号，例如 &lt;code&gt;*varargs&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;例如，&lt;a href=&#34;https://robotframework.org/robotframework/latest/libraries/OperatingSystem.html&#34;&gt;OperatingSystem&lt;/a&gt; 库中的 &lt;code&gt;Remove Files&lt;/code&gt; 和 &lt;code&gt;Join Paths&lt;/code&gt; 关键字分别具有参数 &lt;code&gt;*paths&lt;/code&gt; 与 &lt;code&gt;base&lt;/code&gt;、&lt;code&gt;*parts&lt;/code&gt;。前者可以接受任意数量的参数，而后者至少需要一个参数。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Example&#xA;    Remove Files    ${TEMPDIR}/f1.txt    ${TEMPDIR}/f2.txt    ${TEMPDIR}/f3.txt&#xA;    @{paths} =    Join Paths    ${TEMPDIR}    f1.txt    f2.txt    f3.txt    f4.txt&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;命名参数&lt;/h3&gt;&#xA;&lt;p&gt;命名参数语法使得使用带有默认值的参数更加灵活，并且能够明确标注特定参数值的含义。从技术上讲，命名参数的工作原理与 Python 中的关键字参数完全相同。&lt;/p&gt;&#xA;&lt;h4&gt;基本语法&lt;/h4&gt;&#xA;&lt;p&gt;可以通过在参数值前添加&amp;quot;参数名=&amp;quot;的方式为关键字指定参数，例如 &lt;code&gt;arg=value&lt;/code&gt;。当多个参数具有默认值时，这种方式尤其有用，因为可以仅指定部分参数名称，而让其他参数继续使用默认值。例如，某个关键字接受参数 &lt;code&gt;arg1=a&lt;/code&gt;, &lt;code&gt;arg2=b&lt;/code&gt;, &lt;code&gt;arg3=c&lt;/code&gt;，若调用时只传入一个参数 &lt;code&gt;arg3=override&lt;/code&gt;，则 &lt;code&gt;arg1&lt;/code&gt; 和 &lt;code&gt;arg2&lt;/code&gt; 将保持默认值，而 &lt;code&gt;arg3&lt;/code&gt; 将获得 &lt;code&gt;override&lt;/code&gt; 值。如果这听起来有些复杂，希望下面关于命名参数的示例能帮助理解。&lt;/p&gt;&#xA;&lt;p&gt;命名参数语法对大小写和空格都很敏感。前者意味着如果存在参数 &lt;code&gt;arg&lt;/code&gt;，则必须使用 &lt;code&gt;arg=value&lt;/code&gt; 的形式，使用 &lt;code&gt;Arg=value&lt;/code&gt; 或 &lt;code&gt;ARG=value&lt;/code&gt; 均无效。后者意味着等号前不允许有空格，而等号后的空格将被视为给定值的一部分。&lt;/p&gt;&#xA;&lt;p&gt;在使用命名参数语法调用用户关键字时，参数名称必须省略 &lt;code&gt;${}&lt;/code&gt; 修饰符。例如，具有参数 &lt;code&gt;${arg1}=first&lt;/code&gt;, &lt;code&gt;${arg2}=second&lt;/code&gt; 的用户关键字必须使用 &lt;code&gt;arg2=override&lt;/code&gt; 的形式调用。&lt;/p&gt;&#xA;&lt;p&gt;在命名参数后使用常规的位置参数（例如 &lt;code&gt;| Keyword | arg=value | positional |&lt;/code&gt;）是无效的。而命名参数之间的相对顺序则无关紧要。&lt;/p&gt;&#xA;&lt;h4&gt;带变量的命名参数&lt;/h4&gt;&#xA;&lt;p&gt;在命名参数的参数名和参数值中都可以使用变量。如果参数值是单个标量变量，该变量将以原样传递给关键字。这使得在使用命名参数语法时，不仅可以使用字符串，还可以使用任何对象作为值。例如，使用 &lt;code&gt;arg=${object}&lt;/code&gt; 的形式调用关键字时，变量 &lt;code&gt;${object}&lt;/code&gt; 将直接传递给关键字，而不会转换为字符串。&lt;/p&gt;&#xA;&lt;p&gt;如果在命名参数的参数名中使用变量，变量会在与参数名匹配之前被解析。&lt;/p&gt;&#xA;&lt;p&gt;命名参数语法要求等号必须直接写在关键字调用中。这意味着仅靠变量本身永远不会触发命名参数语法，即使其值形如 &lt;code&gt;foo=bar&lt;/code&gt; 也不例外。这一点在将关键字封装到其他关键字中时尤其需要注意。例如，如果某个关键字接受可变数量的参数（如 &lt;code&gt;@{args}&lt;/code&gt;），并使用相同的 &lt;code&gt;@{args}&lt;/code&gt; 语法将所有参数传递给另一个关键字，那么调用端可能使用的 &lt;code&gt;named=arg&lt;/code&gt; 语法将无法被识别。下面的示例说明了这种情况。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Example&#xA;    Run Program    shell=True    # 此处的 shell=True 不会作为命名参数传递给 Run Process&#xA;&#xA;*** Keywords ***&#xA;Run Program&#xA;    [Arguments]    @{args}&#xA;    Run Process    program.py    @{args}    # 无法从 @{args} 中识别出命名参数&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4&gt;转义命名参数语法&lt;/h4&gt;&#xA;&lt;p&gt;仅当等号前的部分与关键字的某个参数名匹配时，才会触发命名参数语法。在某些情况下，可能存在一个值为字面量 &lt;code&gt;foo=quux&lt;/code&gt; 的位置参数，同时另一个不相关的参数恰好名为 &lt;code&gt;foo&lt;/code&gt;。此时，参数 &lt;code&gt;foo&lt;/code&gt; 可能会错误地获得值 &lt;code&gt;quux&lt;/code&gt;，或者更常见的是触发语法错误。&lt;/p&gt;&#xA;&lt;p&gt;在这类极少出现的意外匹配场景中，可以使用反斜杠字符对语法进行转义，例如写作 &lt;code&gt;foo\=quux&lt;/code&gt;。这样参数将直接获得字面值 &lt;code&gt;foo=quux&lt;/code&gt;。需要注意的是，如果不存在名为 &lt;code&gt;foo&lt;/code&gt; 的参数，则无需转义，但显式使用转义符能够使代码意图更明确，这通常是个值得提倡的做法。&lt;/p&gt;&#xA;&lt;h4&gt;命名参数的适用场景&lt;/h4&gt;&#xA;&lt;p&gt;如前所述，命名参数语法适用于关键字调用。除此之外，该语法同样适用于库导入场景。&lt;/p&gt;&#xA;&lt;p&gt;用户关键字和大多数测试库均支持命名参数，唯一例外的是显式使用仅限位置参数的 Python 关键字。&lt;/p&gt;&#xA;&lt;h4&gt;命名参数示例&lt;/h4&gt;&#xA;&lt;p&gt;以下示例展示了如何在库关键字、用户关键字以及导入 Telnet 测试库时使用命名参数语法。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Settings ***&#xA;Library    Telnet    prompt=$    default_log_level=DEBUG&#xA;&#xA;*** Test Cases ***&#xA;Example&#xA;    Open connection    10.0.0.42    port=${PORT}    alias=example&#xA;    List files    options=-lh&#xA;    List files    path=/tmp    options=-l&#xA;&#xA;*** Keywords ***&#xA;List files&#xA;    [Arguments]    ${path}=.    ${options}=&#xA;    Execute command    ls ${options} ${path}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;自由命名参数&lt;/h3&gt;&#xA;&lt;p&gt;Robot Framework 支持自由命名参数（通常也称为自由关键字参数或 kwargs），其实现方式与 Python 中的 **kwargs 类似。这意味着关键字可以接收所有使用命名参数语法（&lt;code&gt;name=value&lt;/code&gt;）且与关键字签名中定义的任何参数都不匹配的参数。&lt;/p&gt;&#xA;&lt;p&gt;支持普通命名参数的关键字类型同样支持自由命名参数。不同关键字类型定义接收自由命名参数的方式有所不同：基于 Python 的关键字直接使用 &lt;code&gt;**kwargs&lt;/code&gt;，而用户关键字则使用 &lt;code&gt;&amp;amp;{kwargs}&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;自由命名参数对变量的支持方式与命名参数类似。具体来说，变量既可用于参数名也可用于参数值，但转义符必须直接可见。例如，只要使用的变量存在，&lt;code&gt;foo=${bar}&lt;/code&gt; 和 &lt;code&gt;${foo}=${bar}&lt;/code&gt; 都是有效的。一个额外的限制是：自由参数名必须始终为字符串类型。&lt;/p&gt;&#xA;&lt;h4&gt;示例&lt;/h4&gt;&#xA;&lt;p&gt;作为使用自由命名参数的首个示例，我们来看 &lt;a href=&#34;https://robotframework.org/robotframework/latest/libraries/Process.html&#34;&gt;Process&lt;/a&gt; 库中的 &lt;code&gt;Run Process&lt;/code&gt; 关键字。其参数签名为 &lt;code&gt;command, *arguments, **configuration&lt;/code&gt;，这意味着它接收要执行的命令（&lt;code&gt;command&lt;/code&gt;）、可变数量的命令参数（&lt;code&gt;*arguments&lt;/code&gt;），以及最终以自由命名参数形式传入的可选配置参数（&lt;code&gt;**configuration&lt;/code&gt;）。以下示例同时展示了变量在自由关键字参数中的使用方式与命名参数语法完全一致。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Free Named Arguments&#xA;    Run Process    program.py    arg1    arg2    cwd=/home/user&#xA;    Run Process    program.py    argument    shell=True    env=${ENVIRON}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;更多关于在自定义测试库中使用自由命名参数语法的信息，请参阅《创建测试库》章节中的自由关键字参数（**kwargs）部分。&lt;/p&gt;&#xA;&lt;p&gt;作为第二个示例，我们为上文中的 &lt;code&gt;program.py&lt;/code&gt; 创建一个封装用户关键字。该封装关键字 &lt;code&gt;Run Program&lt;/code&gt; 接收所有位置参数和命名参数，并将它们与要执行的命令名一起传递给 &lt;code&gt;Run Process&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Free Named Arguments&#xA;    Run Program    arg1    arg2    cwd=/home/user&#xA;    Run Program    argument    shell=True    env=${ENVIRON}&#xA;&#xA;*** Keywords ***&#xA;Run Program&#xA;    [Arguments]    @{args}    &amp;amp;{config}&#xA;    Run Process    program.py    @{args}    &amp;amp;{config}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;仅限命名参数&lt;/h3&gt;&#xA;&lt;p&gt;自 Robot Framework 3.1 起，关键字可以支持必须通过命名参数语法指定的参数。例如，若某关键字接受一个仅限命名参数 &lt;code&gt;example&lt;/code&gt;，则调用时必须使用 &lt;code&gt;example=value&lt;/code&gt; 的形式，直接使用 &lt;code&gt;value&lt;/code&gt; 将无效。此语法设计灵感来源于 Python 3 中的仅限关键字参数。&lt;/p&gt;&#xA;&lt;p&gt;在大多数情况下，仅限命名参数的工作机制与普通命名参数一致。主要区别在于：基于 Python 2 静态库 API 实现的测试库不支持此语法。&lt;/p&gt;&#xA;&lt;p&gt;以下是通过用户关键字使用仅限命名参数的示例，这是对前文自由命名参数示例中 &lt;code&gt;Run Program&lt;/code&gt; 关键字的改造版本，现仅支持配置 &lt;code&gt;shell&lt;/code&gt; 参数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Named-only Arguments&#xA;    Run Program    arg1    arg2              # &#39;shell&#39; 取默认值 False&#xA;    Run Program    argument    shell=True    # &#39;shell&#39; 设置为 True&#xA;&#xA;*** Keywords ***&#xA;Run Program&#xA;    [Arguments]    @{args}    ${shell}=False&#xA;    Run Process    program.py    @{args}    shell=${shell}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;关键字名称中嵌入参数&lt;/h3&gt;&#xA;&lt;p&gt;另一种完全不同的参数指定方式是将参数直接嵌入到关键字名称中。该语法同时适用于测试库关键字和用户关键字。&lt;/p&gt;&#xA;&lt;h2&gt;处理失败&lt;/h2&gt;&#xA;&lt;h3&gt;当测试用例失败时&lt;/h3&gt;&#xA;&lt;p&gt;如果测试用例使用的任何关键字失败，则该测试用例被视为失败。通常，这意味着该测试用例的执行会停止，并可能执行测试清理工作，然后从下一个测试用例继续执行。如果不希望停止测试执行，也可以使用特殊的可继续运行的失败类型。&lt;/p&gt;&#xA;&lt;h3&gt;错误信息&lt;/h3&gt;&#xA;&lt;p&gt;分配给失败测试用例的错误信息直接来自失败的关键字。通常，错误信息由关键字本身生成，但某些关键字允许配置错误信息。&lt;/p&gt;&#xA;&lt;p&gt;在某些情况下，例如使用了可继续运行的失败类型时，一个测试用例可能会失败多次。此时，最终的错误信息将通过组合各个独立错误来生成。为便于阅读报告，过长的错误信息会自动从中间部分截断，但完整的错误信息始终可以在日志文件中作为失败关键字的记录进行查看。&lt;/p&gt;&#xA;&lt;p&gt;默认情况下，错误信息为纯文本格式，但它们也可以包含 HTML 格式。这需要通过以标记字符串 &lt;code&gt;*HTML*&lt;/code&gt; 开头来启用。此标记将在报告和日志中显示的最终错误信息里被移除。在自定义信息中使用 HTML 的示例如下。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Normal Error&#xA;    Fail    This is a rather boring example...&#xA;&#xA;HTML Error&#xA;    ${number} =    Get Number&#xA;    Should Be Equal    ${number}    42    *HTML* Number is not my &amp;lt;b&amp;gt;MAGIC&amp;lt;/b&amp;gt; number.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;测试用例名称与文档&lt;/h2&gt;&#xA;&lt;p&gt;测试用例的名称直接取自测试用例部分：即测试用例列中准确输入的内容。同一测试套件中的测试用例应具有唯一的名称。与此相关的是，您还可以在测试内部使用自动变量 &lt;code&gt;${TEST_NAME}&lt;/code&gt; 来引用测试名称。该变量在测试执行期间（包括所有用户关键字、测试初始化及测试清理）均可用。&lt;/p&gt;&#xA;&lt;p&gt;从 Robot Framework 3.2 开始，测试用例名称中可能存在的变量会被解析，从而使最终名称包含变量的值。如果变量不存在，其名称将保持不变。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;&#xA;*** Variables ***&#xA;${MAX AMOUNT}      ${5000000}&#xA;&#xA;*** Test Cases ***&#xA;Amount cannot be larger than ${MAX AMOUNT}&#xA;    # ...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;[Documentation]&lt;/code&gt; 设置项允许为测试用例设置自由格式的文档。该文本将显示在命令行输出以及生成的日志和报告中。如果文档内容较长，可以拆分为多行。可以使用简单的 HTML 格式化，并且可以通过变量使文档内容动态变化。可能存在的不存在的变量将保持不变。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Simple&#xA;    [Documentation]    Simple and short documentation.&#xA;    No Operation&#xA;&#xA;Multiple lines&#xA;    [Documentation]    First row of the documentation.&#xA;    ...&#xA;    ...                Documentation continues here. These rows form&#xA;    ...                a paragraph when shown in HTML outputs.&#xA;    No Operation&#xA;&#xA;Formatting&#xA;    [Documentation]&#xA;    ...    This list has:&#xA;    ...    - *bold*&#xA;    ...    - _italics_&#xA;    ...    - link: http://robotframework.org&#xA;    No Operation&#xA;&#xA;Variables&#xA;    [Documentation]    Executed at ${HOST} by ${USER}&#xA;    No Operation&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;为测试用例设定清晰且具有描述性的名称至关重要，通常情况下，这样做就不再需要额外的文档。如果测试用例的逻辑需要文档说明，这通常意味着测试用例中的关键字需要更好的命名或进行增强，而不是添加额外的文档。最后，像上述最后一个示例中的环境和用户信息这类元数据，通常更适合使用标签来指定。&lt;/p&gt;&#xA;&lt;h2&gt;为测试用例添加标签&lt;/h2&gt;&#xA;&lt;p&gt;在 Robot Framework 中使用标签是一种简单而强大的机制，用于对测试用例及用户关键字进行分类。标签为自由文本，除了下面讨论的保留标签外，Robot Framework 本身对它们没有特殊含义。标签至少可用于以下目的：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;它们显示在测试报告、日志中，当然也显示在测试数据中，因此它们为测试用例提供了元数据。&lt;/li&gt;&#xA;&lt;li&gt;系统会根据标签自动收集测试用例的统计数据（总计、通过、失败和跳过）。&lt;/li&gt;&#xA;&lt;li&gt;它们可用于包含、排除以及跳过测试用例。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;为测试用例指定标签有多种方式，如下所述：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Settings 节中的 &lt;code&gt;[Test Tags]&lt;/code&gt; 设置项&lt;/strong&gt;：具有此设置的测试用例文件中的所有测试始终获得指定的标签。如果在套件初始化文件中使用此设置，则所有子套件中的测试都会获得这些标签。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;每个测试用例中的 &lt;code&gt;[Tags]&lt;/code&gt; 设置项&lt;/strong&gt;：除了使用 &lt;code&gt;[Test Tags]&lt;/code&gt; 设置指定的标签外，测试还会获得这些标签。&lt;code&gt;[Tags]&lt;/code&gt; 设置还允许通过使用 &lt;code&gt;-tag&lt;/code&gt; 语法来移除由 &lt;code&gt;[Test Tags]&lt;/code&gt; 设置的标签。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;--settag 命令行选项&lt;/strong&gt;：所有测试除了从其他地方获得的标签外，还会获得通过此选项设置的标签。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Set Tags、Remove Tags、Fail 和 Pass Execution 关键字&lt;/strong&gt;：这些 BuiltIn 库中的关键字可用于在测试执行期间动态地操作标签。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;例子：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Settings ***&#xA;Test Tags       requirement: 42    smoke&#xA;&#xA;*** Variables ***&#xA;${HOST}         10.0.1.42&#xA;&#xA;*** Test Cases ***&#xA;No own tags&#xA;    [Documentation]    Test has tags &#39;requirement: 42&#39; and &#39;smoke&#39;.&#xA;    No Operation&#xA;&#xA;Own tags&#xA;    [Documentation]    Test has tags &#39;requirement: 42&#39;, &#39;smoke&#39; and &#39;not ready&#39;.&#xA;    [Tags]    not ready&#xA;    No Operation&#xA;&#xA;Own tags with variable&#xA;    [Documentation]    Test has tags &#39;requirement: 42&#39;, &#39;smoke&#39; and &#39;host: 10.0.1.42&#39;.&#xA;    [Tags]    host: ${HOST}&#xA;    No Operation&#xA;&#xA;Remove common tag&#xA;    [Documentation]    Test has only tag &#39;requirement: 42&#39;.&#xA;    [Tags]    -smoke&#xA;    No Operation&#xA;&#xA;Remove common tag using a pattern&#xA;    [Documentation]    Test has only tag &#39;smoke&#39;.&#xA;    [Tags]    -requirement: *&#xA;    No Operation&#xA;&#xA;Set Tags and Remove Tags keywords&#xA;    [Documentation]    This test has tags &#39;smoke&#39;, &#39;example&#39; and &#39;another&#39;.&#xA;    Set Tags    example    another&#xA;    Remove Tags    requirement: *&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如示例所示，标签可以通过变量创建，但在其他情况下，它们会保留在数据中使用的确切名称。当标签进行比较时（例如，用于收集统计数据、选择要执行的测试或去除重复项），比较操作对大小写、空格和下划线不敏感。&lt;/p&gt;&#xA;&lt;p&gt;如上文示例所示，使用 &lt;code&gt;-tag&lt;/code&gt; 语法移除标签支持简单的模式，例如 &lt;code&gt;-requirement:*&lt;/code&gt;。以连字符开头的标签，除非在 &lt;code&gt;[Tags]&lt;/code&gt; 设置中使用，否则没有特殊含义。如果需要使用 &lt;code&gt;[Tags]&lt;/code&gt; 设置一个以连字符开头的标签，可以使用转义格式，如 &lt;code&gt;\-tag&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;目前，&lt;code&gt;-tag&lt;/code&gt; 语法仅可用于通过 &lt;code&gt;[Tags]&lt;/code&gt; 设置项来移除标签，但计划在 Robot Framework 8.0 中，在 &lt;code&gt;Test Tags&lt;/code&gt; 设置中也支持此功能（&lt;a href=&#34;https://github.com/robotframework/robotframework/issues/5250&#34;&gt;#5250&lt;/a&gt;）。在 Robot Framework 7.2 中，已弃用 &lt;code&gt;Test Tags&lt;/code&gt; 设置中值为以连字符开头的字面量的标签（&lt;a href=&#34;https://github.com/robotframework/robotframework/issues/5252&#34;&gt;#5252&lt;/a&gt;）。如果需要此类值的标签，可以使用 &lt;code&gt;\-tag&lt;/code&gt; 这样的转义格式。&lt;/p&gt;&#xA;&lt;h3&gt;弃用 Force Tags 和 Default Tags&lt;/h3&gt;&#xA;&lt;p&gt;在 Robot Framework 6.0 之前，可以通过 Setting 节中的两种不同设置来为测试指定标签：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Force Tags&lt;/strong&gt;：所有测试都无条件获得这些标签。这与现今的 &lt;code&gt;Test Tags&lt;/code&gt; 完全相同。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Default Tags&lt;/strong&gt;：所有测试默认获得这些标签。如果测试已具有 &lt;code&gt;[Tags]&lt;/code&gt; 设置，则不会获得这些标签。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这两种设置目前仍然有效，但已被视为弃用。未来（很可能在 Robot Framework 8.0 中）会添加可见的弃用警告，并最终移除这些设置。可以使用 Tidy 等工具来简化迁移过程。&lt;/p&gt;&#xA;&lt;p&gt;更新 &lt;code&gt;Force Tags&lt;/code&gt; 仅需将其重命名为 &lt;code&gt;Test Tags&lt;/code&gt;。&lt;code&gt;Default Tags&lt;/code&gt; 设置将被完全移除，但 Robot Framework 7.0 引入的 &lt;code&gt;-tag&lt;/code&gt; 功能提供了相同的底层功能。以下示例展示了所需的更改。&lt;/p&gt;&#xA;&lt;p&gt;旧语法：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Settings ***&#xA;Force Tags      all&#xA;Default Tags    default&#xA;&#xA;*** Test Cases ***&#xA;Common only&#xA;    [Documentation]    Test has tags &#39;all&#39; and &#39;default&#39;.&#xA;    No Operation&#xA;&#xA;No default&#xA;    [Documentation]    Test has only tag &#39;all&#39;.&#xA;    [Tags]&#xA;    No Operation&#xA;&#xA;Own and no default&#xA;    [Documentation]    Test has tags &#39;all&#39; and &#39;own&#39;.&#xA;    [Tags]    own&#xA;    No Operation&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;新语法：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Settings ***&#xA;Test Tags      all    default&#xA;&#xA;*** Test Cases ***&#xA;Common only&#xA;    [Documentation]    Test has tags &#39;all&#39; and &#39;default&#39;.&#xA;    No Operation&#xA;&#xA;No default&#xA;    [Documentation]    Test has only tag &#39;all&#39;.&#xA;    [Tags]    -default&#xA;    No Operation&#xA;&#xA;Own and no default&#xA;    [Documentation]    Test has tags &#39;all&#39; and &#39;own&#39;.&#xA;    [Tags]    own    -default&#xA;    No Operation&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;保留标签&lt;/h3&gt;&#xA;&lt;p&gt;用户通常可以自由使用在其上下文中有效的任何标签。然而，存在某些标签对 Robot Framework 本身具有预定义的含义，将它们用于其他目的可能会导致意外结果。Robot Framework 目前及将来拥有的所有特殊标签都带有 &lt;code&gt;robot:&lt;/code&gt; 前缀。因此，为避免出现问题，用户除非确实需要激活特定功能，否则不应使用任何带有此前缀的标签。当前的保留标签列表如下，但未来可能会添加更多此类标签。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;robot:continue-on-failure&lt;/code&gt; 和 &lt;code&gt;robot:recursive-continue-on-failure&lt;/code&gt;，用于启用&amp;quot;失败后继续运行&amp;quot;模式。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;robot:stop-on-failure&lt;/code&gt; 和 &lt;code&gt;robot:recursive-stop-on-failure&lt;/code&gt;，用于禁用&amp;quot;失败后继续运行&amp;quot;模式。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;robot:exit-on-failure&lt;/code&gt;，如果带有此标签的测试失败，则停止整个执行过程。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;robot:skip-on-failure&lt;/code&gt;，标记测试在失败时将被跳过。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;robot:skip&lt;/code&gt;，无条件地标记测试为跳过。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;robot:exclude&lt;/code&gt;，无条件地标记测试为排除。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;robot:private&lt;/code&gt;，将关键字标记为私有。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;robot:no-dry-run&lt;/code&gt;，标记关键字不在&amp;quot;试运行&amp;quot;模式下执行。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;robot:exit&lt;/code&gt;，当执行被正常停止时，自动添加到测试中。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;robot:flatten&lt;/code&gt;，在执行时启用扁平化关键字功能。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;自 RobotFramework 4.1 起，保留标签默认在标签统计中被隐藏。当通过 &lt;code&gt;--tagstatinclude robot:*&lt;/code&gt; 命令行选项明确包含时，它们才会显示。&lt;/p&gt;&#xA;&lt;h2&gt;测试初始化与清理&lt;/h2&gt;&#xA;&lt;p&gt;Robot Framework 具备与其他许多自动化测试框架类似的测试初始化与清理功能。简而言之，测试初始化是在测试用例执行前运行的操作，而测试清理则在测试用例执行后运行。在 Robot Framework 中，初始化与清理操作本身也只是普通的关键字，可以附带参数。&lt;/p&gt;&#xA;&lt;p&gt;一次初始化或清理始终对应一个关键字。如果需要处理多个独立任务，可以为此创建更高级别的用户关键字。另一种解决方案是使用 BuiltIn 库中的 Run Keywords 关键字来执行多个关键字。&lt;/p&gt;&#xA;&lt;p&gt;测试清理在两个方面具有特殊性。首先，即使测试用例失败，清理也会执行，因此可用于执行那些无论测试用例状态如何都必须完成的清理活动。其次，即使清理中的某个关键字失败，其后的所有关键字仍会继续执行。这种&amp;quot;失败后继续运行&amp;quot;功能也可用于普通关键字，但在清理操作中默认启用。&lt;/p&gt;&#xA;&lt;p&gt;在测试用例文件中为测试用例指定初始化或清理的最简单方式，是在 Setting 节中使用 &lt;code&gt;Test Setup&lt;/code&gt; 和 &lt;code&gt;Test Teardown&lt;/code&gt; 设置项。单个测试用例也可以拥有自己的初始化或清理，它们通过测试用例节中的 &lt;code&gt;[Setup]&lt;/code&gt; 或 &lt;code&gt;[Teardown]&lt;/code&gt; 设置项定义，并会覆盖可能的 &lt;code&gt;Test Setup&lt;/code&gt; 和 &lt;code&gt;Test Teardown&lt;/code&gt; 设置。在 &lt;code&gt;[Setup]&lt;/code&gt; 或 &lt;code&gt;[Teardown]&lt;/code&gt; 设置项后不指定关键字，意味着没有初始化或清理操作。也可以使用值 &lt;code&gt;NONE&lt;/code&gt; 来表示测试没有初始化/清理。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Settings ***&#xA;Test Setup       Open Application    App A&#xA;Test Teardown    Close Application&#xA;&#xA;*** Test Cases ***&#xA;Default values&#xA;    [Documentation]    Setup and teardown from setting section&#xA;    Do Something&#xA;&#xA;Overridden setup&#xA;    [Documentation]    Own setup, teardown from setting section&#xA;    [Setup]    Open Application    App B&#xA;    Do Something&#xA;&#xA;No teardown&#xA;    [Documentation]    Default setup, no teardown at all&#xA;    Do Something&#xA;    [Teardown]&#xA;&#xA;No teardown 2&#xA;    [Documentation]    Setup and teardown can be disabled also with special value NONE&#xA;    Do Something&#xA;    [Teardown]    NONE&#xA;&#xA;Using variables&#xA;    [Documentation]    Setup and teardown specified using variables&#xA;    [Setup]    ${SETUP}&#xA;    Do Something&#xA;    [Teardown]    ${TEARDOWN}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;作为初始化或清理操作来执行的关键字名称可以是一个变量。这样便于通过从命令行以变量形式提供关键字名称，从而在不同环境中使用不同的初始化或清理例程。&lt;/p&gt;&#xA;&lt;h2&gt;测试模板&lt;/h2&gt;&#xA;&lt;p&gt;测试模板能够将常规的关键字驱动型测试用例转化为数据驱动型测试。普通的基于关键字的测试用例，其主体由关键字及其可能的参数构成；而使用模板的测试用例，仅包含模板关键字的参数。我们无需在每个测试中重复使用同一个关键字，也无需在文件的所有测试中重复使用，而可以实现每个测试只用一次，甚至整个文件仅使用一次。&lt;/p&gt;&#xA;&lt;p&gt;模板关键字既可以接收常规的位置参数和命名参数，也支持将参数内嵌于关键字名称中。与其他设置不同，无法使用变量来定义模板。&lt;/p&gt;&#xA;&lt;h3&gt;基本用法&lt;/h3&gt;&#xA;&lt;p&gt;下面的示例测试用例展示了如何将一个接受常规位置参数的关键字用作模板。这两个测试在功能上完全一致。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Normal test case&#xA;    Example keyword    first argument    second argument&#xA;&#xA;Templated test case&#xA;    [Template]    Example keyword&#xA;    first argument    second argument&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如示例所示，可以使用 &lt;code&gt;[Template]&lt;/code&gt; 设置来为单个测试用例指定模板。另一种方法是在 Settings 节中使用 &lt;code&gt;Test Template&lt;/code&gt; 设置，这样该模板将应用于该测试用例文件中的所有测试。&lt;code&gt;[Template]&lt;/code&gt; 设置会覆盖 Settings 节中可能设置的模板，并且将 &lt;code&gt;[Template]&lt;/code&gt; 的值设为空则表示该测试没有模板，即使使用了 &lt;code&gt;Test Template&lt;/code&gt; 也是如此。也可以使用值 &lt;code&gt;NONE&lt;/code&gt; 来表示测试没有模板。&lt;/p&gt;&#xA;&lt;p&gt;使用具有默认值的关键字、接受可变数量参数的关键字、使用命名参数以及自由命名参数等功能，在模板中的工作方式与在其他场景中完全相同。在参数中使用变量也照常支持。&lt;/p&gt;&#xA;&lt;h3&gt;含多次迭代的模板&lt;/h3&gt;&#xA;&lt;p&gt;如果一个模板化测试用例的主体包含多行数据，则该模板会逐一应用于所有行。这意味着同一个关键字会被执行多次，每次使用一行数据。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Settings ***&#xA;Test Template    Example keyword&#xA;&#xA;*** Test Cases ***&#xA;Templated test case&#xA;    first round 1     first round 2&#xA;    second round 1    second round 2&#xA;    third round 1     third round 2&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;模板化测试的特殊之处在于，即使其中一个或多个迭代失败或跳过，所有迭代仍会执行。具有多次迭代的模板化测试的汇总结果如下：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;FAIL：如果任意一次迭代失败。&lt;/li&gt;&#xA;&lt;li&gt;PASS：如果没有任何失败，且至少有一次迭代通过。&lt;/li&gt;&#xA;&lt;li&gt;SKIP：如果所有迭代都被跳过。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;使用嵌入式参数的模板&lt;/h3&gt;&#xA;&lt;p&gt;模板支持一种嵌入式参数的变体语法。在模板中，该语法的工作原理是：如果模板关键字的名称中包含变量，这些变量会被视为参数的占位符，并被替换为模板所使用的实际参数。然后，生成的关键字将被直接调用，而不再附带位置参数。这通过一个示例能最清晰地说明：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Normal test case with embedded arguments&#xA;    The result of 1 + 1 should be 2&#xA;    The result of 1 + 2 should be 3&#xA;&#xA;Template with embedded arguments&#xA;    [Template]    The result of ${calculation} should be ${expected}&#xA;    1 + 1    2&#xA;    1 + 2    3&#xA;&#xA;*** Keywords ***&#xA;The result of ${calculation} should be ${expected}&#xA;    ${result} =    Calculate    ${calculation}&#xA;    Should Be Equal    ${result}     ${expected}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当模板使用嵌入式参数时，模板关键字名称中的参数数量必须与使用时传入的参数数量相匹配。不过，参数名称不需要与原始关键字中的参数匹配，并且完全可以使用完全不同的参数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Different argument names&#xA;    [Template]    The result of ${foo} should be ${bar}&#xA;    1 + 1    2&#xA;    1 + 2    3&#xA;&#xA;Only some arguments&#xA;    [Template]    The result of ${calculation} should be 3&#xA;    1 + 2&#xA;    4 - 1&#xA;&#xA;New arguments&#xA;    [Template]    The ${meaning} of ${life} should be 42&#xA;    result    21 * 2&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在模板中使用嵌入式参数的主要好处在于，参数名称被显式地指定了。当使用普通参数时，可以通过为包含参数的数据列命名来实现相同的效果。这将在下一节数据驱动风格的示例中进行说明。&lt;/p&gt;&#xA;&lt;h3&gt;结合 FOR 循环的模板&lt;/h3&gt;&#xA;&lt;p&gt;如果模板与 FOR 循环结合使用，则该模板将应用于循环内的所有步骤。在这种情况下，同样会启用“失败后继续”的模式，这意味着即使存在失败，所有步骤仍会对所有循环元素执行。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Template with FOR loop&#xA;    [Template]    Example keyword&#xA;    FOR    ${item}    IN    @{ITEMS}&#xA;        ${item}    2nd arg&#xA;    END&#xA;    FOR    ${index}    IN RANGE    42&#xA;        1st arg    ${index}&#xA;    END&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;结合 IF/ELSE 结构的模板&lt;/h3&gt;&#xA;&lt;p&gt;IF/ELSE 结构也可以与模板结合使用。这很有用，例如，当与 FOR 循环一起使用时，可以过滤要执行的参数。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Template with FOR and IF&#xA;    [Template]    Example keyword&#xA;    FOR    ${item}    IN    @{ITEMS}&#xA;        IF  ${item} &amp;lt; 5&#xA;            ${item}    2nd arg&#xA;        END&#xA;    END&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;不同的测试用例风格&lt;/h2&gt;&#xA;&lt;p&gt;编写测试用例有几种不同的方式。描述某种工作流的测试用例可以采用关键字驱动或行为驱动风格来编写。数据驱动风格则可用于使用不同的输入数据来测试相同的工作流程。&lt;/p&gt;&#xA;&lt;h3&gt;关键字驱动风格&lt;/h3&gt;&#xA;&lt;p&gt;工作流测试（例如前面描述的 &lt;code&gt;Valid Login&lt;/code&gt; 测试）由多个关键字及其可能的参数构成。其典型结构是：首先将系统置于初始状态（&lt;code&gt;Valid Login&lt;/code&gt; 示例中的 &lt;code&gt;Open Login Page&lt;/code&gt;），然后对系统执行某些操作（&lt;code&gt;Input Name&lt;/code&gt;、&lt;code&gt;Input Password&lt;/code&gt;、&lt;code&gt;Submit Credentials&lt;/code&gt;），最后验证系统是否按预期响应（&lt;code&gt;Welcome Page Should Be Open&lt;/code&gt;）。&lt;/p&gt;&#xA;&lt;h3&gt;数据驱动风格&lt;/h3&gt;&#xA;&lt;p&gt;编写测试用例的另一种方式是数据驱动方法。在这种风格中，测试用例只使用一个更高级别的关键字（通常创建为用户关键字）来隐藏实际测试流程。当需要使用不同的输入和/或输出数据测试同一场景时，这类测试非常有用。尽管可以在每个测试中重复使用相同的关键字，但测试模板功能允许只指定一次要使用的关键字。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Settings ***&#xA;Test Template    Login with invalid credentials should fail&#xA;&#xA;*** Test Cases ***                USERNAME         PASSWORD&#xA;Invalid User Name                 invalid          ${VALID PASSWORD}&#xA;Invalid Password                  ${VALID USER}    invalid&#xA;Invalid User Name and Password    invalid          invalid&#xA;Empty User Name                   ${EMPTY}         ${VALID PASSWORD}&#xA;Empty Password                    ${VALID USER}    ${EMPTY}&#xA;Empty User Name and Password      ${EMPTY}         ${EMPTY}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;上面的示例包含了六个独立的测试，分别对应每种无效的用户名/密码组合。而下面的示例则展示了如何将所有组合整合在一个测试中。使用测试模板时，即使测试过程中出现失败，测试内的所有轮次仍会执行，因此这两种风格在功能上并没有本质区别。在上面的示例中，每个组合都有独立的命名，这使测试内容更加清晰易读；但如果有大量此类测试，可能会影响统计结果的整洁度。具体采用哪种风格取决于具体情境和个人偏好。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Invalid Password&#xA;    [Template]    Login with invalid credentials should fail&#xA;    invalid          ${VALID PASSWORD}&#xA;    ${VALID USER}    invalid&#xA;    invalid          whatever&#xA;    ${EMPTY}         ${VALID PASSWORD}&#xA;    ${VALID USER}    ${EMPTY}&#xA;    ${EMPTY}         ${EMPTY}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;行为驱动风格&lt;/h3&gt;&#xA;&lt;p&gt;测试用例也可以编写成非技术性项目相关人员也需理解的需求形式。这类可执行的需求通常被称为验收测试驱动开发（ATDD）或实例化规格，是这一开发流程的基石。&lt;/p&gt;&#xA;&lt;p&gt;编写这些需求/测试的一种方式是采用行为驱动开发（BDD）所推广的 &lt;code&gt;Given-When-Then&lt;/code&gt; 风格。以此风格编写测试用例时，初始状态通常使用以 &lt;code&gt;Given&lt;/code&gt; 开头的关键字描述，操作使用以 &lt;code&gt;When&lt;/code&gt; 开头的关键字描述，预期结果则使用以 &lt;code&gt;Then&lt;/code&gt; 开头的关键字描述。如果一个步骤包含多个动作，还可以使用以 &lt;code&gt;And&lt;/code&gt; 或 &lt;code&gt;But&lt;/code&gt; 开头的关键字。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Valid Login&#xA;    Given login page is open&#xA;    When valid username and password are inserted&#xA;    and credentials are submitted&#xA;    Then welcome page should be open&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4&gt;忽略 Given/When/Then/And/But 前缀&lt;/h4&gt;&#xA;&lt;p&gt;在创建关键字时，可以省略 &lt;code&gt;Given、When、Then、And&lt;/code&gt; 和 &lt;code&gt;But&lt;/code&gt; 这些前缀。例如，上面例子中的 &lt;code&gt;Given login page is open&lt;/code&gt; 通常在实现时会省略单词 &lt;code&gt;Given&lt;/code&gt;，使其名称仅为 &lt;code&gt;Login page is open&lt;/code&gt;。省略前缀使得同一个关键字可以与不同的前缀一起使用。例如，&lt;code&gt;Welcome page should be open&lt;/code&gt; 可以同时用作 &lt;code&gt;Then welcome page should be open&lt;/code&gt; 或 &lt;code&gt;And welcome page should be open&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h4&gt;将数据嵌入到关键字中&lt;/h4&gt;&#xA;&lt;p&gt;在编写具体示例时，能够将实际数据传递给关键字实现非常有用。这可以通过将参数嵌入到关键字名称中来实现。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/12/04/robotframework-new-tutorial-create-test-cases/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>星云跳动 - 隐私政策</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/12/03/nebuladance-privacy-policy/</id>
    <content type="html">&lt;p&gt;&lt;em&gt;最后更新日期：2025 年 12 月&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2&gt;1. 数据收集声明&lt;/h2&gt;&#xA;&lt;p&gt;《星云跳动》&lt;strong&gt;不收集任何用户数据&lt;/strong&gt;。所有处理均在您的设备本地完成。&lt;/p&gt;&#xA;&lt;h2&gt;2. 所需权限说明&lt;/h2&gt;&#xA;&lt;h3&gt;照片库访问权限&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;读取权限&lt;/strong&gt;：用于选择您希望处理的星云、星空照片。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;写入权限&lt;/strong&gt;：用于将生成的动态视频保存回您的设备相册。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;重要&lt;/strong&gt;：我们不会上传、存储或分析您的任何照片或视频。这些媒体文件仅在您的设备内存中进行处理，处理完成后不会保留任何副本。&lt;/p&gt;&#xA;&lt;h2&gt;3. 本地数据处理&lt;/h2&gt;&#xA;&lt;h3&gt;参数设置存储&lt;/h3&gt;&#xA;&lt;p&gt;应用使用 iOS 系统的 &lt;code&gt;UserDefaults&lt;/code&gt; 在您的设备本地存储您的偏好设置（如视频时长、粒子效果参数等），以实现“自动保存和恢复”功能。&lt;/p&gt;&#xA;&lt;p&gt;这些数据：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;仅存储在您的设备上&lt;/li&gt;&#xA;&lt;li&gt;不会同步到任何服务器&lt;/li&gt;&#xA;&lt;li&gt;卸载应用时会被自动清除&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;4. 第三方服务&lt;/h2&gt;&#xA;&lt;p&gt;本应用不包含任何第三方分析、广告或跟踪 SDK。&lt;/p&gt;&#xA;&lt;h2&gt;5. 儿童隐私&lt;/h2&gt;&#xA;&lt;p&gt;本应用不收集任何个人身份信息，因此符合儿童隐私保护规定。13岁以下儿童可在家长监护下使用。&lt;/p&gt;&#xA;&lt;h2&gt;6. 隐私政策变更&lt;/h2&gt;&#xA;&lt;p&gt;如果我们未来决定收集数据或更改数据处理方式，我们将更新此隐私政策，并在应用内提供显著通知。&lt;/p&gt;&#xA;&lt;h2&gt;7. 联系我们&lt;/h2&gt;&#xA;&lt;p&gt;如果您对本隐私政策有任何疑问，请通过以下方式联系：&lt;/p&gt;&#xA;&lt;p&gt;📧 邮箱：&lt;strong&gt;[lyyyuna@outlook.com]&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;本隐私政策符合 Apple App Store 审核指南要求，适用于《星云跳动》应用。&lt;/em&gt;&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/12/03/nebuladance-privacy-policy/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>20251031</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/10/31/diary10/</id>
    <content type="html">&lt;p&gt;AI 编程越来越火，什么乱七八糟的名词 MCP, Agent, Skills 听着太唬人了，各种“大咖”都在发表高见。。&lt;/p&gt;&#xA;&lt;p&gt;但，就我看来，AI 编程本质上是解决一个成本问题，这里的成本单纯指钱。用可能 10 美元一个月，换来一个高级或资深水平的全能程序员，还是不知疲倦的那种。。&lt;/p&gt;&#xA;&lt;p&gt;AI 有解决软件工程问题吗？答案可能是没有。工程问题不是堆人力算力可解决的，那些随着项目推进慢慢浮现的传统工程问题依旧会出现，而且由于 AI 思考方式的不同，这些问题对于它来讲反而不是问题，它依旧能很“顺畅”的写代码，最终项目彻底脱离人的思维边界。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/10/31/diary10/" rel="alternate"></link>
    <summary type="html">AI 编程</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Go 垃圾回收器指南（译）</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/09/01/go-gc/</id>
    <content type="html">&lt;style&gt;&#xA;.gc-guide-graph {&#xA;  display: inline-block;&#xA;  position: relative;&#xA;  width: 100%;&#xA;  vertical-align: top;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.gc-guide-graph-controls {&#xA;  display: flex;&#xA;  flex-direction: row;&#xA;  flex-wrap: wrap;&#xA;  justify-content: space-around;&#xA;  align-items: center;&#xA;  width: 100%;&#xA;}&#xA;&#xA;.gc-guide-graph-controls div {&#xA;  display: flex;&#xA;  flex-direction: row;&#xA;  flex-wrap: nowrap;&#xA;  align-items: center;&#xA;  padding-left: 5px;&#xA;  padding-right: 5px;&#xA;  height: 24px;&#xA;}&#xA;&#xA;.gc-guide-counter {&#xA;  display: block;&#xA;  overflow-x: hidden; /* Prevent automatic resizing, which makes the input jittery. */&#xA;  width: 10em; /* Never contains more than 10 characters. */&#xA;}&#xA;&#xA;.gc-guide-equation {&#xA;  display: block;&#xA;  text-align: center;&#xA;}&#xA;&#xA;.gc-guide-note {&#xA;  margin-left: 3em;&#xA;}&#xA;&lt;/style&gt;&#xA;&lt;p&gt;本文翻译自官网 &lt;a href=&#34;https://tip.golang.org/doc/gc-guide&#34;&gt;https://tip.golang.org/doc/gc-guide&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h2&gt;引言&lt;/h2&gt;&#xA;&lt;p&gt;本指南旨在通过深入解析 Go 垃圾回收器的工作原理，帮助高级 Go 开发者更准确地评估应用性能成本，并为优化应用程序资源利用率提供实践指导。本指南不要求你掌握垃圾回收相关知识，但最好熟悉 Go 编程语言。&lt;/p&gt;&#xA;&lt;p&gt;Go 语言负责管理所有 Go 值的存储分配 —— 在大多数情况下，开发者无需关心这些值的存储位置及存储机制。然而在实际运行中，这些值必须被存储在&lt;strong&gt;物理内存&lt;/strong&gt;中，而物理内存是有限资源。正因内存资源有限，必须通过精细化的内存管理和回收机制来确保 Go 程序运行期间不会出现内存耗尽的情况。内存的分配与回收工作由 Go 实现层自动完成。&lt;/p&gt;&#xA;&lt;p&gt;自动内存回收的另一个术语是&lt;strong&gt;垃圾回收&lt;/strong&gt;（garbage collection）。高阶视角下，垃圾回收器（简称 GC）是一种通过识别内存中不再使用的部分来替应用程序自动回收内存的系统。Go 标准工具链提供的运行时库随每个应用打包发布，该运行时库内置了垃圾回收器。&lt;/p&gt;&#xA;&lt;p&gt;需要特别说明的是：&lt;a href=&#34;https://tip.golang.org/ref/spec&#34;&gt;Go 语言规范&lt;/a&gt;并未强制要求实现本文所述的垃圾回收器，仅规定 Go 值的底层存储必须由语言自身管理。这种刻意留下的灵活性是为了允许采用完全不同的内存管理技术。&lt;/p&gt;&#xA;&lt;p&gt;因此，本指南针对的是 Go 编程语言的一种特定实现（标准工具链 —— gc Go 编译器和工具链）。虽然 Gccgo 和 Gollvm 采用了高度相似的GC实现，大部分概念相通，但具体实现细节可能存在差异。&lt;/p&gt;&#xA;&lt;p&gt;本文档是动态更新的活文档，将随时间推移持续更新以反映 Go 最新版本的特性。当前版本描述的是 Go 1.19 时期的垃圾回收器实现。&lt;/p&gt;&#xA;&lt;h3&gt;Go 值的存储位置&lt;/h3&gt;&#xA;&lt;p&gt;在深入探讨垃圾回收机制之前，我们首先需要了解哪些内存不需要 GC 管理。&lt;/p&gt;&#xA;&lt;p&gt;例如，存储在局部变量中的非指针类型 Go 值通常完全不受 Go 垃圾回收器管理。Go 会安排将这类内存分配与创建它们的&lt;a href=&#34;https://tip.golang.org/ref/spec#Declarations_and_scope&#34;&gt;词法作用域&lt;/a&gt;绑定。一般而言，这种方式比依赖 GC 更高效，因为 Go 编译器能够预先确定内存释放时机，并生成清理内存的机器指令。这种为 Go 值分配内存的方式通常被称为&amp;quot;栈分配&amp;quot;，因为存储空间位于 goroutine 栈上。&lt;/p&gt;&#xA;&lt;p&gt;而那些无法通过这种方式分配内存的Go值——因为编译器无法确定其生命周期——则被称为&amp;quot;逃逸到堆上&amp;quot;。可以将&amp;quot;堆&amp;quot;理解为内存分配的容错机制，用于存放需要特定存储位置的 Go 值。在堆上分配内存的行为通常称为&amp;quot;动态内存分配&amp;quot;，因为编译器和运行时都难以对这种内存的使用方式和清理时机做出预设。这正是垃圾回收器发挥作用的地方：它是专门用于识别和清理动态内存分配的系统。&lt;/p&gt;&#xA;&lt;p&gt;Go 值需要逃逸到堆上的原因有很多。其中一个可能是其大小动态决定。例如，当切片的底层数组初始大小由变量而非常量决定时。需要注意的是，逃逸行为具有传递性：如果将某个 Go 值的引用写入已确定要逃逸的另一个 Go 值中，则该值也必须逃逸。&lt;/p&gt;&#xA;&lt;p&gt;Go 值是否逃逸取决于其使用上下文以及编译器的逃逸分析算法。试图精确列举值逃逸的具体情况既不可靠也难以实现：该算法本身相当复杂，且会随着 Go 版本更新而变化。关于如何识别值逃逸的详细信息，请参阅&lt;a href=&#34;https://tip.golang.org/doc/gc-guide#Eliminating_heap_allocations&#34;&gt;消除堆分配&lt;/a&gt;章节。&lt;/p&gt;&#xA;&lt;h3&gt;追踪式垃圾回收&lt;/h3&gt;&#xA;&lt;p&gt;垃圾回收（Garbage collection）可指代多种自动回收内存的方法，例如引用计数。在本文语境中，垃圾回收特指&lt;strong&gt;追踪式&lt;/strong&gt;垃圾回收（tracing garbage collection）—— 通过指针传递关系来识别正在使用的所谓&lt;strong&gt;存活&lt;/strong&gt;对象。&lt;/p&gt;&#xA;&lt;p&gt;让我们更严谨地定义这些术语：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;对象&lt;/strong&gt;（Object）—— 指通过动态分配获得的内存块，其中包含一个或多个 Go 值。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;指针&lt;/strong&gt;（Pointer）—— 指向对象内任意值的内存地址。这自然包括 &lt;code&gt;*T&lt;/code&gt; 类型的 Go 值，但也包含内置 Go 值的组成部分。字符串、切片、通道、映射和接口值都包含 GC 必须追踪的内存地址。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;对象与指向其他对象的指针共同构成&lt;strong&gt;对象图&lt;/strong&gt;（object graph）。为识别存活内存，GC 从程序&lt;strong&gt;根节点&lt;/strong&gt;（roots）开始遍历对象图，这些根节点指针明确标识了程序正在使用的对象。局部变量和全局变量就是根节点的两个典型示例。遍历对象图的过程称为扫描（scanning）。在 Go 文档中可能遇到的另一个术语是对象&lt;strong&gt;是否可达&lt;/strong&gt;（reachable），这意味着该对象可通过扫描过程被发现。需要注意的是，除唯一例外情况外，内存一旦不可达将始终保持不可达状态。&lt;/p&gt;&#xA;&lt;p&gt;该基础算法是所有追踪式 GC 的共性。不同追踪式 GC 的差异在于发现存活内存后的处理方式。Go 的 GC 采用标记-清除（mark-sweep）技术，这意味着为了跟踪进度，G C会将其遇到的值&lt;strong&gt;标记&lt;/strong&gt;为存活。完成追踪后，GC 会遍历堆中所有内存，将未标记的内存释放供分配使用。此过程称为&lt;strong&gt;清除&lt;/strong&gt;（sweeping）。&lt;/p&gt;&#xA;&lt;p&gt;你可能熟悉的另一种技术是将对象实际移动到内存的新区域，并留下转发指针（forwarding pointer）用于后续更新所有应用程序指针。采用这种对象移动方式的 GC 称为&lt;strong&gt;移动式 GC&lt;/strong&gt;（moving GC）；而 Go 采用的是&lt;strong&gt;非移动式 GC&lt;/strong&gt;（non-moving GC）。&lt;/p&gt;&#xA;&lt;h2&gt;GC 工作周期&lt;/h2&gt;&#xA;&lt;p&gt;由于 Go 的垃圾回收器采用标记-清除算法，其运行主要分为两个阶段：标记阶段（mark phase）和清除阶段（sweep phase）。这个表述看似同义反复，却蕴含重要洞察：在所有内存完成追踪之前，不可能将内存释放回可用状态 —— 因为可能存在尚未扫描的指针仍维持着对象的存活状态。因此，清除操作必须与标记操作完全分离。此外，当没有与 GC 相关的工作需要处理时，GC 也可能处于完全非活跃状态。GC 会持续在清除、闲置和标记这三个阶段之间循环切换，这个过程被称为 &lt;strong&gt;GC 工作周期&lt;/strong&gt;。在本文档中，我们将 GC 工作周期视为从清除阶段开始，经关闭状态后进入标记阶段的循环过程。&lt;/p&gt;&#xA;&lt;p&gt;接下来几个章节将重点帮助读者建立对 GC 成本的直观认知，从而协助用户根据自身需求调整 GC 参数。&lt;/p&gt;&#xA;&lt;h3&gt;理解垃圾回收的成本&lt;/h3&gt;&#xA;&lt;p&gt;垃圾回收器本质上是构建在复杂系统之上的复杂软件。在尝试理解 GC 并调整其行为时，很容易陷入细节的泥潭。本节旨在提供一个分析框架，帮助理解 Go 垃圾回收器的成本构成及其调优参数。&lt;/p&gt;&#xA;&lt;p&gt;首先，我们基于三个基本公理建立GC成本模型：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;GC 仅涉及两种资源：物理内存和CPU时间。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;GC 的内存成本包括存活堆内存（live heap memory）、标记阶段前新分配的堆内存，以及元数据存储空间 —— 即使元数据与前述成本成比例，其占比也相对微小。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;第 N 个周期的 GC 内存成本 = 周期 N-1 的存活堆内存 + 新分配堆内存&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;存活堆内存是指前一个 GC 周期确认为存活的内存，而新分配堆内存是当前周期内分配的内存（这些内存到周期结束时可能存活也可能不再存活）。任意时间点的存活内存量是程序的固有属性，并非 GC 能直接控制。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;GC 的 CPU 成本模型由固定周期成本和与存活堆大小成比例的边际成本组成：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;第 N 个周期的 GC CPU 时间 = 每周期固定 CPU 时间成本 + 每字节平均 CPU 时间成本 × 周期 N 的存活堆内存&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;每周期固定 CPU 时间成本包括每个周期固定发生的操作，例如为下一个 GC 周期初始化数据结构。这项成本通常很小，仅为保持模型完整性而纳入。&lt;/p&gt;&#xA;&lt;p&gt;GC 的大部分 CPU 成本来自标记和扫描操作，这体现在边际成本中。标记扫描的平均成本既取决于 GC 实现，也受程序行为影响。例如：更多指针意味着更多 GC 工作，因为 GC 至少需要访问程序中的所有指针；链表和树等结构也会增加 GC 并行遍历的难度，从而提升每字节平均成本。&lt;/p&gt;&#xA;&lt;p&gt;本模型未纳入清除操作的成本（该成本与堆内存总量成正比，包括已失效内存的清理）。对于 Go 当前 GC 实现而言，清除速度远快于标记扫描，其成本相对可忽略不计。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;该模型简洁而有效：它准确归纳了 GC 的主要成本构成。同时表明，垃圾回收器的总 CPU 成本取决于给定时间范围内的 GC 周期总数。最终，这个模型揭示了 GC 本质上存在时间与空间权衡的基本规律。&lt;/p&gt;&#xA;&lt;p&gt;为理解其中机理，让我们探讨一个受限但实用的场景：&lt;strong&gt;稳态&lt;/strong&gt;（steady state）。从 GC 的视角来看，应用程序的稳态由以下特性定义：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;应用程序分配新内存的速率（单位：字节/秒）保持恒定&lt;/p&gt;&#xA;&lt;p&gt;这意味着从 GC 的角度看，应用程序的工作负载随时间推移基本保持一致。例如对于 Web 服务，这表现为稳定的请求速率，且请求类型分布与平均生命周期保持相对恒定。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;GC 的边际成本保持恒定&lt;/p&gt;&#xA;&lt;p&gt;这意味着对象图的统计特征——如对象大小分布、指针数量、数据结构平均深度等——在不同周期间保持稳定。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;让我们通过示例说明：假设某应用以 10 MiB/秒的速度分配内存，GC 扫描速率为 100 MiB/CPU 秒（此为假设值），且固定 GC 成本为零。稳态虽不对存活堆大小设限，但为简化起见，假设该应用的存活堆始终为 10 MiB（注意：恒定存活堆不意味着所有新分配内存都会失效，而是指 GC 运行后，新旧堆内存的某种组合保持存活状态）。若 GC 周期每 1 个 CPU 秒触发一次，那么在稳态下，示例应用每个 GC 周期的堆内存总量将为 20 MiB。每个 GC 周期需要 0.1 个 CPU 秒完成工作，导致 10% 的开销。&lt;/p&gt;&#xA;&lt;p&gt;现在假设 GC 周期降低频率，每 2 个 CPU 秒触发一次。此时在稳态下，示例应用每个 GC 周期的堆内存总量将增至 30 MiB。但由于扫描成本仅与存活堆相关，每个 GC 周期仍只需 0.1 个 CPU 秒完成工作。这意味着 GC 开销从 10% 降至 5%，代价是内存使用量增加 50%。&lt;/p&gt;&#xA;&lt;p&gt;这种开销变化正是前文所述的根本性时间/空间权衡。而 &lt;strong&gt;GC 频率&lt;/strong&gt;是这一权衡的核心：执行 GC 越频繁，内存使用越少，反之亦然。那么 G C实际执行频率如何确定？在 Go 中，决定 GC 启动时机是用户可控的主要参数。&lt;/p&gt;&#xA;&lt;h3&gt;GOGC&lt;/h3&gt;&#xA;&lt;p&gt;从高层视角看，GOGC 参数决定了 GC CPU 开销与内存占用之间的权衡关系。&lt;/p&gt;&#xA;&lt;p&gt;其运作机制是通过设定每个 GC 周期后的目标堆大小（target heap size），即下一个周期堆内存总量的目标值。GC 的目标是在堆内存总量超过目标值之前完成回收周期。堆内存总量定义为上一周期结束时的存活堆大小，加上自上一周期以来应用分配的新堆内存。而目标堆内存的计算公式为：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;目标堆内存 = 存活堆 + (存活堆 + GC根节点) * GOGC / 100&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;举例说明：假设某 Go 程序的存活堆为 8 MiB，goroutine 栈占用 1 MiB，全局变量中的指针占 1 MiB。当 GOGC 值为 100 时，下次 GC 触发前可分配的新内存量为 10 MiB（即 10 MiB 内存基数的 100%），此时堆内存总量将达到 18 MiB。若 GOGC 值为 50，则可分配新内存为 5 MiB（50%）；GOGC 值为 200 时，则可分配 20 MiB（200%）。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;注意：从 Go 1.18 开始，GOGC 计算才包含根节点集（GC roots）。此前版本仅计算存活堆大小。通常 goroutine 栈内存占比较小，存活堆大小是 GC 工作的主要来源，但在存在数十万 goroutine 的程序中，旧版 GC 会做出错误判断。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;堆内存目标值直接控制 GC 频率：目标值越大，GC 等待下一次标记阶段启动的时间就越长，反之亦然。虽然精确的计算公式有助于进行预估，但最好从根本目的来理解 GOGC：它是一个在 GC CPU 开销与内存占用之间选择平衡点的参数。核心结论是：&lt;strong&gt;GOGC 值翻倍会使堆内存开销翻倍，同时使 GC CPU 成本大致减半&lt;/strong&gt;，反之亦然（完整推导参见&lt;a href=&#34;https://tip.golang.org/doc/gc-guide#Additional_notes_on_GOGC&#34;&gt;附录&lt;/a&gt;）。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;注意：目标堆大小仅是一个目标值，实际 GC 周期可能因多种原因无法恰好在目标值处完成。一方面，足够大的堆分配操作可能直接超越目标值；另一方面，GC 实现中存在的其他因素（已超出本指南所述基础模型范畴）也会产生影响。更多细节请参阅延迟章节，完整实现细节可参考补充资源。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;GOGC 可通过两种方式配置：使用 GOGC 环境变量（所有 Go 程序均识别），或通过 &lt;code&gt;runtime/debug&lt;/code&gt; 包中的 &lt;a href=&#34;https://pkg.go.dev/runtime/debug#SetGCPercent&#34;&gt;SetGCPercent&lt;/a&gt; API 进行设置。&lt;/p&gt;&#xA;&lt;p&gt;需要注意，通过设置 &lt;code&gt;GOGC=off&lt;/code&gt; 或调用 &lt;code&gt;SetGCPercent(-1)&lt;/code&gt; 可以完全关闭 GC（前提是未设置内存限制）。从概念上讲，此设置相当于将 GOGC 设为无限大，因为触发 GC 前可分配的新内存量将没有上限。&lt;/p&gt;&#xA;&lt;p&gt;为更好地理解前述内容，请尝试使用基于前文 G C成本模型构建的交互式可视化工具。该可视化模拟了某个程序的执行过程：其非 GC 工作需要 10 秒 CPU 时间完成，在第一秒进行初始化操作（存活堆增长）后进入稳定状态。程序总共分配 200 MiB 内存，其中 20 MiB 为持续存活状态。假设仅存活堆产生 GC 工作量，且（为简化模型）程序不使用其他内存。&lt;/p&gt;&#xA;&lt;p&gt;通过滑动条调整 GOGC 值，观察应用程序在总耗时和 GC 开销方面的响应。每个 GC 周期在新分配堆内存降为零时结束。新分配内存降为零所需的时间包含周期N的标记阶段与周期 N+1 的清除阶段耗时。请注意本可视化（及本指南所有可视化工具）假设 GC 执行时应用程序暂停，因此 GC CPU 成本完全体现为新分配内存降为零的时间跨度。此设定仅为简化可视化，实际原理仍然适用。X 轴会动态缩放以完整显示程序 CPU 时间耗时。注意 GC 使用的额外 CPU 时间会增加总体持续时间。&lt;/p&gt;&#xA;&lt;div class=&#34;gc-guide-graph&#34; data-workload=&#39;[&#xA;    {&#34;duration&#34;: 1.0, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 1.00, &#34;oldDeathRate&#34;: 0.00},&#xA;    {&#34;duration&#34;: 9.0, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.00, &#34;oldDeathRate&#34;: 0.00}&#xA;]&#39; data-config=&#39;{&#xA;    &#34;fixedCost&#34;: 0.04,&#xA;    &#34;otherMem&#34;: 0,&#xA;    &#34;GOGC&#34;: &#34;graph1-gogc&#34;,&#xA;    &#34;memoryLimit&#34;: 100000&#xA;}&#39;&gt;&lt;/div&gt;&#xA;&lt;div class=&#34;gc-guide-graph-controls&#34;&gt;&#xA;    &lt;div&gt;&#xA;        GOGC&#xA;        &lt;input type=&#34;range&#34; min=&#34;0&#34; max=&#34;10&#34; step=&#34;0.005&#34; value=&#34;6.64&#34; id=&#34;graph1-gogc&#34;&gt;&#xA;        &lt;div class=&#34;gc-guide-counter&#34; id=&#34;graph1-gogc-display&#34;&gt;&lt;/div&gt;&#xA;    &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;可以观察到，GC 始终会产生一定的 CPU 和峰值内存开销。当 GOGC 值增大时，CPU 开销降低，但峰值内存会随存活堆大小成比例增加。当 GOGC 值减小时，峰值内存需求降低，但需要额外承担更多的 CPU 开销。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;注意：图表显示的是 CPU 时间，而非程序完成的挂钟时间（wall-clock time）。如果程序在单 CPU 上运行且完全利用资源，则两者等效。实际场景中的程序通常运行在多核系统上，且不会始终 100% 占用 CPU。这种情况下 GC 对挂钟时间的影响会更小。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;注意：Go GC 设有 4 MiB 的最小堆总量限制，因此若 GOGC 设置的目标值低于该阈值，会自动向上取整。可视化工具已体现此细节。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;下面是一个更动态且贴近实际的示例：同样假设无 GC 时程序需要 10 CPU 秒完成，但中期稳态分配速率急剧上升，且第一阶段存活堆大小存在波动。此示例展示了当存活堆大小实际变化时的稳态表现，以及更高分配速率如何导致更频繁的 GC 周期。&lt;/p&gt;&#xA;&lt;div class=&#34;gc-guide-graph&#34; data-workload=&#39;[&#xA;    {&#34;duration&#34;: 1.0, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 1.00, &#34;oldDeathRate&#34;: 0.00},&#xA;    {&#34;duration&#34;: 1.0, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.00, &#34;oldDeathRate&#34;: 0.50},&#xA;    {&#34;duration&#34;: 1.0, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.50, &#34;oldDeathRate&#34;: 0.00},&#xA;    {&#34;duration&#34;: 1.0, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.00, &#34;oldDeathRate&#34;: 0.50},&#xA;    {&#34;duration&#34;: 1.0, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.50, &#34;oldDeathRate&#34;: 0.00},&#xA;    {&#34;duration&#34;: 5.0, &#34;allocRate&#34;: 200, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.02, &#34;oldDeathRate&#34;: 1.00}&#xA;]&#39; data-config=&#39;{&#xA;    &#34;fixedCost&#34;: 0.04,&#xA;    &#34;otherMem&#34;: 0,&#xA;    &#34;GOGC&#34;: &#34;graph2-gogc&#34;,&#xA;    &#34;memoryLimit&#34;: 100000&#xA;}&#39;&gt;&lt;/div&gt;&#xA;&lt;div class=&#34;gc-guide-graph-controls&#34;&gt;&#xA;    &lt;div&gt;&#xA;        GOGC&#xA;        &lt;input type=&#34;range&#34; min=&#34;0&#34; max=&#34;10&#34; step=&#34;0.005&#34; value=&#34;6.64&#34; id=&#34;graph2-gogc&#34;&gt;&#xA;        &lt;div class=&#34;gc-guide-counter&#34; id=&#34;graph2-gogc-display&#34;&gt;&lt;/div&gt;&#xA;    &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;h3&gt;内存限制&lt;/h3&gt;&#xA;&lt;p&gt;在 Go 1.19 之前，GOGC 是唯一可用于调整 GC 行为的参数。虽然它能有效设定权衡关系，但存在一个根本缺陷：未考虑可用内存是有限的。试想当存活堆大小出现瞬时峰值时的情况：由于 GC 会根据存活堆大小按比例设置总堆大小，即使通常情况下更高的 GOGC 值能提供更好的权衡，也必须按照峰值存活堆大小来配置 GOGC。&lt;/p&gt;&#xA;&lt;p&gt;下面的可视化演示生动展现了这种瞬时堆内存峰值的情境：&lt;/p&gt;&#xA;&lt;div class=&#34;gc-guide-graph&#34; data-workload=&#39;[&#xA;    {&#34;duration&#34;: 1.0, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 1.00, &#34;oldDeathRate&#34;: 0.00},&#xA;    {&#34;duration&#34;: 4.0, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.00, &#34;oldDeathRate&#34;: 0.00},&#xA;    {&#34;duration&#34;: 0.5, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 1.00, &#34;oldDeathRate&#34;: 0.00},&#xA;    {&#34;duration&#34;: 0.5, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.00, &#34;oldDeathRate&#34;: 0.00},&#xA;    {&#34;duration&#34;: 0.5, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.00, &#34;oldDeathRate&#34;: 0.50},&#xA;    {&#34;duration&#34;: 3.5, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.00, &#34;oldDeathRate&#34;: 0.00}&#xA;]&#39; data-config=&#39;{&#xA;    &#34;fixedCost&#34;: 0.04,&#xA;    &#34;otherMem&#34;: 0,&#xA;    &#34;GOGC&#34;: &#34;graph3-gogc&#34;,&#xA;    &#34;memoryLimit&#34;: 100000&#xA;}&#39;&gt;&lt;/div&gt;&#xA;&lt;div class=&#34;gc-guide-graph-controls&#34;&gt;&#xA;    &lt;div&gt;&#xA;        GOGC&#xA;        &lt;input type=&#34;range&#34; min=&#34;0&#34; max=&#34;10&#34; step=&#34;0.005&#34; value=&#34;6.64&#34; id=&#34;graph3-gogc&#34;&gt;&#xA;        &lt;div class=&#34;gc-guide-counter&#34; id=&#34;graph3-gogc-display&#34;&gt;&lt;/div&gt;&#xA;    &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;若示例工作负载运行在可用内存略超 60 MiB 的容器中，那么即使其他 GC 周期本有充足内存空间可利用，GOGC 值也无法提升至 100 以上。更严重的是，在某些应用中这类瞬时峰值可能罕见且难以预测，导致偶尔出现不可避免且代价高昂的内存不足（out-of-memory）状况。&lt;/p&gt;&#xA;&lt;p&gt;正因如此，Go 在 1.19 版本中新增了运行时内存限制功能。内存限制可通过两种方式配置：使用 GOMEMLIMIT 环境变量（所有Go程序均识别），或调用 &lt;code&gt;runtime/debug&lt;/code&gt; 包中的 &lt;code&gt;SetMemoryLimit&lt;/code&gt; 函数。&lt;/p&gt;&#xA;&lt;p&gt;该内存限制设定了 Go 运行时所能使用的内存总量上限。其统计范围根据 &lt;a href=&#34;https://pkg.go.dev/runtime#MemStats&#34;&gt;runtime.MemStats&lt;/a&gt; 指标定义为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Sys - HeapReleased&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;或等价于基于 &lt;a href=&#34;https://pkg.go.dev/runtime/metrics&#34;&gt;runtime/metrics&lt;/a&gt; 包的表述方式：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;/memory/classes/total:bytes - /memory/classes/heap/released:bytes&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;由于 Go 垃圾回收器能够显式控制堆内存使用量，它会根据内存限制以及 Go 运行时使用的其他内存量来设定总堆大小。&lt;/p&gt;&#xA;&lt;p&gt;下方的可视化演示展现了与 GOGC 章节相同的单阶段稳态工作负载，但此次额外增加了 10 MiB 的 Go 运行时开销，并提供了可调节的内存限制功能。请尝试同步调整 GOGC 值和内存限制参数，观察系统的响应变化。&lt;/p&gt;&#xA;&lt;div class=&#34;gc-guide-graph&#34; data-workload=&#39;[&#xA;    {&#34;duration&#34;: 1.0, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 1.00, &#34;oldDeathRate&#34;: 0},&#xA;    {&#34;duration&#34;: 9.0, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.00, &#34;oldDeathRate&#34;: 0}&#xA;]&#39; data-config=&#39;{&#xA;    &#34;fixedCost&#34;: 0.04,&#xA;    &#34;otherMem&#34;: 10,&#xA;    &#34;GOGC&#34;: &#34;graph4-gogc&#34;,&#xA;    &#34;memoryLimit&#34;: &#34;graph4-memlimit&#34;&#xA;}&#39;&gt;&lt;/div&gt;&#xA;&lt;div class=&#34;gc-guide-graph-controls&#34;&gt;&#xA;    &lt;div&gt;&#xA;        GOGC&#xA;        &lt;input type=&#34;range&#34; min=&#34;0&#34; max=&#34;10&#34; step=&#34;0.005&#34; value=&#34;6.64&#34; id=&#34;graph4-gogc&#34;&gt;&#xA;        &lt;div class=&#34;gc-guide-counter&#34; id=&#34;graph4-gogc-display&#34;&gt;&lt;/div&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div&gt;&#xA;        Memory Limit&#xA;        &lt;input type=&#34;range&#34; min=&#34;1&#34; max=&#34;100&#34; step=&#34;0.5&#34; value=&#34;100&#34; id=&#34;graph4-memlimit&#34;&gt;&#xA;        &lt;div class=&#34;gc-guide-counter&#34; id=&#34;graph4-memlimit-display&#34;&gt;&lt;/div&gt;&#xA;    &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;可以观察到，当内存限制低于 GOGC 设定的峰值内存（GOGC 为 100 时对应 42 MiB）时，GC 会以更高频率运行以确保峰值内存不超限。&lt;/p&gt;&#xA;&lt;p&gt;回到先前讨论的瞬时堆内存峰值示例，通过设置内存限制并调高 GOGC 值，我们可以实现两全其美：既避免内存超限，又提升资源利用率。请尝试操作下方的交互式可视化演示：&lt;/p&gt;&#xA;&lt;div class=&#34;gc-guide-graph&#34; data-workload=&#39;[&#xA;&#x9;{&#34;duration&#34;: 1.0, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 1.00, &#34;oldDeathRate&#34;: 0.00},&#xA;&#x9;{&#34;duration&#34;: 4.0, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.00, &#34;oldDeathRate&#34;: 0.00},&#xA;&#x9;{&#34;duration&#34;: 0.5, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 1.00, &#34;oldDeathRate&#34;: 0.00},&#xA;&#x9;{&#34;duration&#34;: 0.5, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.00, &#34;oldDeathRate&#34;: 0.00},&#xA;&#x9;{&#34;duration&#34;: 0.5, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.00, &#34;oldDeathRate&#34;: 0.50},&#xA;&#x9;{&#34;duration&#34;: 3.5, &#34;allocRate&#34;: 20, &#34;scanRate&#34;: 1024, &#34;newSurvivalRate&#34;: 0.00, &#34;oldDeathRate&#34;: 0.00}&#xA;]&#39; data-config=&#39;{&#xA;&#x9;&#34;fixedCost&#34;: 0.04,&#xA;&#x9;&#34;otherMem&#34;: 0,&#xA;&#x9;&#34;GOGC&#34;: &#34;graph5-gogc&#34;,&#xA;&#x9;&#34;memoryLimit&#34;: &#34;graph5-memlimit&#34;&#xA;}&#39;&gt;&lt;/div&gt;&#xA;&lt;div class=&#34;gc-guide-graph-controls&#34;&gt;&#xA;&#x9;&lt;div&gt;&#xA;&#x9;&#x9;GOGC&#xA;&#x9;&#x9;&lt;input type=&#34;range&#34; min=&#34;0&#34; max=&#34;10&#34; step=&#34;0.005&#34; value=&#34;6.64&#34; id=&#34;graph5-gogc&#34;&gt;&#xA;&#x9;&#x9;&lt;div class=&#34;gc-guide-counter&#34; id=&#34;graph5-gogc-display&#34;&gt;&lt;/div&gt;&#xA;&#x9;&lt;/div&gt;&#xA;&#x9;&lt;div&gt;&#xA;&#x9;&#x9;Memory Limit&#xA;&#x9;&#x9;&lt;input type=&#34;range&#34; min=&#34;1&#34; max=&#34;100&#34; step=&#34;0.5&#34; value=&#34;100&#34; id=&#34;graph5-memlimit&#34;&gt;&#xA;&#x9;&#x9;&lt;div class=&#34;gc-guide-counter&#34; id=&#34;graph5-memlimit-display&#34;&gt;&lt;/div&gt;&#xA;&#x9;&lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;可以观察到，在某些 GOGC 值与内存限制的组合下，峰值内存使用会严格受限于内存限制值，但程序其他执行阶段仍遵循 GOGC 设定的总堆大小规则。&lt;/p&gt;&#xA;&lt;p&gt;这一现象引出一个重要细节：即使将 GOGC 设置为 off（关闭），内存限制仍然有效！实际上，这种特殊配置代表了资源利用效率的最大化，因为它设定了维持特定内存限制所需的最低 GC 频率。在这种情况下，程序整个执行过程中的堆大小都会增长至接近内存限制值。&lt;/p&gt;&#xA;&lt;p&gt;然而，尽管内存限制显然是一个强大的工具，&lt;strong&gt;但其使用并非没有代价&lt;/strong&gt;，也绝不会削弱 GOGC 的实用价值。&lt;/p&gt;&#xA;&lt;p&gt;试想当存活堆增长到使总内存使用接近内存限制时会发生什么。在上方的稳态可视化演示中，尝试关闭 GOGC 并逐步降低内存限制值，观察系统反应。可以注意到，当 GC 为维持一个不可能实现的内存限制而持续执行时，应用程序的总耗时将开始无限增长。&lt;/p&gt;&#xA;&lt;p&gt;这种因持续 GC 循环导致程序无法取得合理进展的情况称为&lt;strong&gt;系统颠簸&lt;/strong&gt;（thrashing）。这种情况特别危险，因为它实质上会使程序陷入停滞。更糟糕的是，它可能恰恰发生在我们试图用 GOGC 避免的场景中：足够大的瞬时堆峰值可能导致程序无限期停滞！尝试在瞬时堆峰值的可视化演示中降低内存限制（约 30 MiB 或更低），可以观察到最严重的行为正是从堆峰值开始出现的。&lt;/p&gt;&#xA;&lt;p&gt;在许多场景下，无限期停滞比内存不足（out-of-memory）状况更糟糕，因为后者往往会导致更快速的故障。&lt;/p&gt;&#xA;&lt;p&gt;正因如此，内存限制被定义为&lt;strong&gt;软性限制&lt;/strong&gt;（soft limit）。Go 运行时并不保证在所有情况下都能维持此内存限制，仅承诺会付出合理程度的努力。这种内存限制的宽松性对于避免系统颠簸行为至关重要，因为它为 GC 提供了回旋余地：允许内存使用暂时超出限制，以避免在 GC 上消耗过多时间。&lt;/p&gt;&#xA;&lt;p&gt;其内部运作机制是：GC 会在特定时间窗口内设置其可使用的CPU时间上限（并对极短瞬时的CPU使用峰值设置滞后缓冲）。当前该限制设定为约 50%，时间窗口为 &lt;code&gt;2 * GOMAXPROCS&lt;/code&gt; CPU 秒。限制 GC CPU 时间的后果是 GC 工作会被延迟，而此时 Go 程序可能持续分配新的堆内存，甚至可能超出内存限制。&lt;/p&gt;&#xA;&lt;p&gt;设定 50% GC CPU 限制的理念基于最坏情况考量：当程序拥有充足可用内存时，若内存限制设置错误（被误设过低），程序运行速度最多只会下降 2 倍，因为 GC 最多只能占用 50% 的 CPU 时间。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;注意：本页面的可视化演示未模拟 GC CPU 限制机制。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h4&gt;应用建议&lt;/h4&gt;&#xA;&lt;p&gt;虽然内存限制是一项强大工具，且 Go 运行时已采取措施减轻误用带来的最坏影响，但审慎使用仍然至关重要。以下提供一系列实用建议，说明内存限制最适合的应用场景以及可能弊大于利的情况。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;当 Go 程序的执行环境完全受控，且该程序是唯一访问特定资源集（如容器内存限制等内存预留机制）的应用时，应充分利用内存限制功能。&lt;/p&gt;&#xA;&lt;p&gt;典型示例：将Web服务部署到具有固定可用内存的容器中。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;此时的经验法则是：预留额外 5-10% 的内存余量，以应对 Go 运行时无法感知的内存开销。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;可实时调整内存限制以适应变化的环境条件。&lt;/p&gt;&#xA;&lt;p&gt;典型示例：CGO 程序中 C 语言库临时需要大量内存时。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;若 Go 程序可能与其他程序共享有限内存，且这些程序与 Go 程序通常解耦，则不应在设置内存限制的同时关闭 GOGC。应保留内存限制以抑制不良瞬时行为，但需将 GOGC 设置为适用于常规场景的合理较小值。&lt;/p&gt;&#xA;&lt;p&gt;除非程序完全同步（如 Go 程序调用子进程并阻塞等待），否则尝试为协同程序“预留”内存会导致可靠性下降 —— 因为不可避免地两个程序都会需要更多内存。让 Go 程序在不需要时减少内存使用，反而能带来更可靠的整体效果。此建议同样适用于内存超配（overcommit）场景，即单台机器上容器的内存限制总和可能超过实际物理内存。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;在部署到不可控的执行环境时，尤其是当程序内存使用量与输入数据量成正比时，应避免使用内存限制。&lt;/p&gt;&#xA;&lt;p&gt;典型示例：CLI 工具或桌面应用程序。在无法预知输入数据规模或系统可用内存的情况下固化内存限制，会导致难以排查的崩溃和性能劣化。此外，高级终端用户可根据需要自行设置内存限制。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;当程序已接近环境内存上限时，切勿试图通过设置内存限制来避免内存不足。&lt;/p&gt;&#xA;&lt;p&gt;这实际上是将内存不足风险替换为应用严重减速风险 —— 即使 Go 已努力缓解系统颠簸，这种权衡往往得不偿失。此时更有效的方案是：要么提升环境内存上限（然后酌情设置内存限制），要么降低 GOGC 值（其提供的权衡方案比缓解颠簸更清晰可控）。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;延迟&lt;/h3&gt;&#xA;&lt;p&gt;本文中的可视化模型将应用程序模拟为在 GC 执行期间暂停。确实存在这种行为的 GC 实现，它们被称为“全局暂停”（stop-the-world）式垃圾回收器。&lt;/p&gt;&#xA;&lt;p&gt;然而，Go 的 GC 并非完全全局暂停，其大部分工作是与应用程序并发执行的。这主要是为了降低应用程序的延迟 —— 特指单个计算单元（如 web 请求）的端到端持续时间。截至目前，本文主要考虑的是应用程序吞吐量（如每秒处理的 web 请求数），GC 周期章节中的每个示例都聚焦于程序执行的总 CPU 耗时。但对于 web 服务而言，此类总时长的意义远不如单个请求的延迟重要：虽然吞吐量（即每秒查询数）仍然关键，但每个请求的延迟往往更为重要。&lt;/p&gt;&#xA;&lt;p&gt;就延迟而言，全局暂停式 GC 可能需要相当长的时间来执行其标记和清除阶段，在此期间应用程序（对 web 服务而言即所有正在处理的请求）无法继续执行。相反，Go 的 GC 避免了让任何全局应用程序暂停的时长与堆大小成正比，其核心追踪算法在应用程序主动执行期间完成（暂停时间在算法上更强烈地与 &lt;code&gt;GOMAXPROCS&lt;/code&gt; 成正比，但通常主要受停止运行中的 goroutine 所需时间支配）。并发回收并非没有代价：实践中它通常导致设计出的 GC 吞吐量低于等效的全局暂停式垃圾回收器。但需要注意的是，&lt;strong&gt;低延迟并不意味着低吞吐量&lt;/strong&gt;，而且 Go 垃圾回收器的性能在延迟和吞吐量两方面都随着时间的推移稳步提升。&lt;/p&gt;&#xA;&lt;p&gt;Go 当前 GC 的并发特性并不影响本文至今讨论的任何内容：所有论述均不依赖于这一设计选择。 GC 频率仍然是 GC 在 CPU 时间和内存之间进行吞吐量权衡的主要方式，事实上它也在延迟方面扮演这一角色。这是因为 GC 的大部分成本发生在标记阶段活跃期间。&lt;/p&gt;&#xA;&lt;p&gt;关键结论是：&lt;strong&gt;降低 GC 频率也可能带来延迟改善&lt;/strong&gt;。这不仅适用于通过修改调优参数（如增加 GOGC 和/或内存限制）来降低 GC 频率，也适用于优化指南中描述的各种优化措施。&lt;/p&gt;&#xA;&lt;p&gt;然而，延迟通常比吞吐量更难理解，因为它是程序瞬间执行的产物，而不仅仅是成本的简单累加。因此，延迟与 GC 频率之间的关联并不直接。以下为有意深入探究者列出可能的延迟来源：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;GC 在标记与清除阶段切换时产生的短暂全局暂停，&lt;/li&gt;&#xA;&lt;li&gt;标记阶段 GC 占用 25% CPU 资源导致的调度延迟，&lt;/li&gt;&#xA;&lt;li&gt;用户 goroutine 为响应高分配速率而协助 GC 工作，&lt;/li&gt;&#xA;&lt;li&gt;GC 标记阶段指针写入需要执行额外工作，&lt;/li&gt;&#xA;&lt;li&gt;运行中的 goroutine 必须暂停以进行根节点扫描。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;除指针写入需额外工作外，这些延迟源均可在执行跟踪（execution traces）中观察到。&lt;/p&gt;&#xA;&lt;h3&gt;Finalizers, cleanups, and weak pointers&lt;/h3&gt;&#xA;&lt;p&gt;垃圾回收通过有限的内存营造出无限内存的假象。内存被分配后无需显式释放，这种机制使得 API 设计和并发算法相比基础的手动内存管理更为简洁（某些采用手动内存管理的语言使用&amp;quot;智能指针&amp;quot;和编译期所有权追踪等替代方案来确保对象释放，但这些特性已深度嵌入这些语言的 API 设计规范中）。&lt;/p&gt;&#xA;&lt;p&gt;只有存活对象——即那些可从全局变量或某个 goroutine 的计算中访问到的对象 —— 才能影响程序行为。对象在任何时间点变为不可达（即“死亡”）后，都可以被 GC 安全回收。这为 GC 设计提供了广阔空间，例如 Go 当前采用的追踪式设计。在语言层面，对象的死亡是不可观察事件。&lt;/p&gt;&#xA;&lt;p&gt;然而，Go 运行时库提供了三种打破这种假象的特性：清理函数（cleanups）、弱指针（weak pointers）和终结器（finalizers）。每种特性都提供了观察和响应对象死亡的方式，对于终结器而言甚至能逆转死亡状态。这自然增加了 Go 程序的复杂性，并为 GC 实现带来额外负担。但这些特性之所以存在，是因为它们在多种场景中非常实用，Go 程序始终在使用并受益于这些功能。&lt;/p&gt;&#xA;&lt;p&gt;关于每个特性的具体细节，请参阅相应的包文档（&lt;a href=&#34;https://tip.golang.org/pkg/runtime#AddCleanup&#34;&gt;runtime.AddCleanup&lt;/a&gt;、&lt;a href=&#34;https://tip.golang.org/pkg/weak#Pointer&#34;&gt;weak.Pointer&lt;/a&gt;、&lt;a href=&#34;https://tip.golang.org/pkg/runtime#SetFinalizer&#34;&gt;runtime.SetFinalizer&lt;/a&gt;）。下文提供使用这些特性的通用建议，列举各特性可能引发的常见问题，并给出测试这些功能使用的指导方案。&lt;/p&gt;&#xA;&lt;h4&gt;通用建议&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;编写单元测试。&lt;/p&gt;&#xA;&lt;p&gt;清理函数、弱指针和终结器的具体执行时机难以预测，即使经过多次连续运行，也很容易让人误以为一切正常。但这些特性极易引发难以察觉的错误。虽然为它们编写测试可能颇具挑战，但正因其使用如此微妙，测试工作显得比往常更加重要。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;避免在常规 Go 代码中直接使用这些特性。&lt;/p&gt;&#xA;&lt;p&gt;这些都是具有微妙限制和行为特性的底层功能。例如，无法保证清理函数或终结器在程序退出时一定会运行，甚至可能根本不会执行。其 API 文档中的长篇注释应被视为警告。绝大多数 Go 代码并不会直接受益于这些特性，而只是间接受益。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;将这些机制的使用封装在包内部。&lt;/p&gt;&#xA;&lt;p&gt;尽可能避免让这些机制的使用泄露到包的公共 API 中；应提供接口使用户难以或无法误用它们。例如，与其要求用户为某些 C 语言分配的内存设置清理函数进行释放，不如编写一个包装包并将这些细节隐藏其中。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;将对具有终结器、清理函数和弱指针的对象的访问权限，限制在创建并应用这些机制的包内部。&lt;/p&gt;&#xA;&lt;p&gt;这一点虽与前述建议相关，但值得特别强调，因为它是以更低错误率使用这些特性的强大模式。例如，&lt;a href=&#34;https://tip.golang.org/pkg/unique&#34;&gt;unique 包&lt;/a&gt;在底层使用弱指针，但完全封装了被弱指针引用的对象。这些值永远不会被应用程序的其他部分修改，只能通过 &lt;a href=&#34;https://tip.golang.org/pkg/unique#Handle.Value&#34;&gt;Value 方法&lt;/a&gt;进行复制，从而为包用户维持了无限内存的假象。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;优先确定性清理非内存资源，将终结器和清理函数作为备选方案。&lt;/p&gt;&#xA;&lt;p&gt;清理函数和终结器非常适合处理内存资源（如外部分配的内存：C 语言分配的内存或 mmap 映射的引用）。C 语言 malloc 分配的内存最终必须通过 C 的 free 释放。在为 C 内存创建的包装对象上附加调用 free 的终结器，是通过垃圾回收确保 C 内存最终被回收的合理方式。&lt;/p&gt;&#xA;&lt;p&gt;然而，非内存资源（如文件描述符）通常受到系统限制，而 Go 运行时通常无法感知这些限制。此外，包作者对特定 Go 程序中垃圾回收的时机几乎无法控制（例如，GC 运行频率由 GOGC 控制，而实际操作中该值可能被设置为各种不同数值）。这两个因素共同导致清理函数和终结器不适合作为释放非内存资源的唯一机制。&lt;/p&gt;&#xA;&lt;p&gt;如果你是封装非内存资源的包作者，请考虑提供显式 API 来确定性释放资源（通过 Close 方法或类似机制），而非依赖通过清理函数或终结器的垃圾回收。相反，建议将清理函数和终结器作为尽力而为的错误处理机制：要么像 &lt;a href=&#34;https://tip.golang.org/pkg/os#File&#34;&gt;os.File&lt;/a&gt; 那样始终清理资源，要么向用户报告未能确定性清理的故障。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;优先选择清理函数而非终结器。&lt;/p&gt;&#xA;&lt;p&gt;从历史来看，终结器的引入是为了简化 Go 代码与 C 代码的接口，并清理非内存资源。其预期用途是将其应用于拥有 C 内存或其他非内存资源的包装对象，以便在 Go 代码使用完毕后释放资源。这些原因至少部分解释了为何终结器适用范围狭窄、为何任何对象只能有一个终结器，以及为何该终结器必须仅附加到对象的首字节。这种限制已经抑制了一些用例：例如，任何希望内部缓存传入对象信息的包，都无法在对象消失后清理这些信息。&lt;/p&gt;&#xA;&lt;p&gt;但更严重的是，由于终结器会复活其附加的对象（以便传递给终结器函数，甚至允许对象继续存活），导致其效率低下且容易出错。这意味着如果对象是引用环的一部分，则永远无法被释放，且对象所占内存至少要到下一个垃圾回收周期才能被重用。&lt;/p&gt;&#xA;&lt;p&gt;然而，正因为终结器会复活对象，它们的执行顺序比清理函数更具明确定义。因此，终结器在清理具有复杂销毁顺序要求的结构时仍然可能（但很少）有用。&lt;/p&gt;&#xA;&lt;p&gt;但对于 Go 1.24 及更高版本的所有其他用途，我们推荐使用清理函数，因为它们比终结器更灵活、更不易出错且更高效。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4&gt;常见清理函数问题&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;附加了清理函数的对象绝不能从清理函数中可达（例如通过捕获的局部变量）。这将导致对象无法被回收，且清理函数永远无法执行。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;f := new(myFile)&#xA;f.fd = syscall.Open(...)&#xA;runtime.AddCleanup(f, func(fd int) {&#xA;    syscall.Close(f.fd) // 错误示例：此处引用了 f，导致清理函数无法执行！&#xA;}, f.fd)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;附加了清理函数的对象绝不能从清理函数的参数中可达。这将导致对象无法被回收，且清理函数永远无法执行。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;f := new(myFile)&#xA;f.fd = syscall.Open(...)&#xA;runtime.AddCleanup(f, func(f *myFile) {&#xA;    syscall.Close(f.fd)&#xA;}, f) // 错误示例：此处引用了 f，将导致清理函数永远无法执行！此特定情况还会引发 panic。&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;终结器具有明确定义的执行顺序，而清理函数则没有。清理函数之间还可以并发执行。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;长时间运行的清理函数应当创建 goroutine，以避免阻塞其他清理函数的执行。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;code&gt;runtime.GC&lt;/code&gt; 不会等待所有不可达对象的清理函数执行完成，仅会等待它们全部入队。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4&gt;常见弱指针问题&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;弱指针可能在其 &lt;code&gt;Value&lt;/code&gt; 方法中意外返回 &lt;code&gt;nil&lt;/code&gt;。务必通过 &lt;code&gt;nil&lt;/code&gt; 检查来保护 &lt;code&gt;Value&lt;/code&gt; 调用，并制定备用方案。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;当弱指针被用作映射键时，它们不会影响映射值的可达性。因此，若弱指针映射键指向的对象同时可从映射值中访问，该对象仍将被视为可达。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4&gt;常见终结器问题&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;附加了终结器的对象绝不能通过任何路径从自身可达（换言之，它们不能处于引用环中）。这将导致对象无法被回收，且终结器永远无法执行。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;f := new(myCycle)&#xA;f.self = f // 错误示例：f 可从 f 自身可达，因此该终结器将永远无法执行。&#xA;runtime.SetFinalizer(f, func(f *myCycle) {&#xA;    ...&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;附加了终结器的对象绝不能从终结器函数中可达（例如通过捕获的局部变量）。这将导致对象无法被回收，且终结器永远无法执行。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;f := new(myFile)&#xA;f.fd = syscall.Open(...)&#xA;runtime.SetFinalizer(f, func(_ *myFile) {&#xA;    syscall.Close(f.fd) // 错误示例：此处引用了外部 f，将导致清理函数无法执行！&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;附加了终结器的对象引用链（例如链表中的引用关系）至少需要经过与链中对象数量相等的 GC 周期才能完成全部清理。务必保持终结器层级扁平化！&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// 错误示例：回收此链表至少需要 10 个GC周期才能完成。&#xA;node := new(linkedListNode)&#xA;for range 10 {&#xA;    tmp := new(linkedListNode)&#xA;    tmp.next = node&#xA;    node = tmp&#xA;    runtime.SetFinalizer(node, func(node *linkedListNode) {&#xA;        ...&#xA;    })&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;避免在包边界返回的对象上设置终结器。这将导致包用户可能调用 &lt;code&gt;runtime.SetFinalizer&lt;/code&gt; 来修改你返回对象的终结器，这种意外行为可能被包用户最终依赖。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;长时间运行的终结器应当创建新的 goroutine，以避免阻塞其他终结器的执行。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;code&gt;runtime.GC&lt;/code&gt; 不会等待所有不可达对象的终结器执行完成，仅会等待它们全部入队。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4&gt;测试对象回收&lt;/h4&gt;&#xA;&lt;p&gt;使用这些特性时，为相关代码编写测试可能颇具挑战。以下是为使用这些特性的代码编写健壮测试的建议：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;避免将此类测试与其他测试并行运行。这能极大提高确定性，并确保在任何给定时刻都能精准掌控系统状态。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;使用 &lt;code&gt;runtime.GC&lt;/code&gt; 在测试开始时建立基准状态。通过 &lt;code&gt;runtime.GC&lt;/code&gt; 强制弱指针置为 &lt;code&gt;nil&lt;/code&gt;，并促使清理函数和终结器入队执行（注意：&lt;code&gt;runtime.GC&lt;/code&gt; 不会等待清理函数和终结器执行完成，仅会确保它们全部入队）。&lt;/p&gt;&#xA;&lt;p&gt;要编写最健壮的测试，可注入阻塞机制使测试能等待清理函数或终结器完成（例如：从测试中传递可选通道给清理函数/终结器，并在执行完成后向通道写入信号）。若实现难度过大，替代方案是循环检查特定清理后状态是否达成。例如：os 包测试在循环中调用 &lt;code&gt;runtime.Gosched&lt;/code&gt;，持续检查不可达文件是否已被关闭。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;若为终结器编写测试，且存在终结器对象链，则至少需要执行与测试创建的最长链长度相等的 &lt;code&gt;runtime.GC&lt;/code&gt; 调用次数，才能确保所有终结器执行完毕。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;在竞态检测模式下进行测试，以发现并发清理之间、清理/终结器代码与代码库其他部分之间的竞态条件。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;补充资源&lt;/h3&gt;&#xA;&lt;p&gt;尽管上文提供的信息准确无误，但若要深入理解 Go 垃圾回收器设计中的成本与权衡，仍需更多细节支撑。更多详细信息请参阅以下补充资源：&lt;/p&gt;&#xA;&lt;p&gt;1.&lt;a href=&#34;https://gchandbook.org/&#34;&gt;The GC Handbook&lt;/a&gt; —— 关于垃圾回收器设计的优秀通用参考资源。&#xA;2. &lt;a href=&#34;https://google.github.io/tcmalloc/design.html&#34;&gt;TCMalloc&lt;/a&gt; —— C/C++ 内存分配器 TCMalloc 的设计文档，Go 内存分配器基于此构建。&#xA;3. &lt;a href=&#34;https://tip.golang.org/blog/go15gc&#34;&gt;Go 1.5 GC announcement&lt;/a&gt; —— 宣布 Go 1.5 并发垃圾回收器的博客文章，详细描述了算法实现。&#xA;4. &lt;a href=&#34;https://tip.golang.org/blog/ismmkeynote&#34;&gt;Getting to Go&lt;/a&gt; —— 深入探讨截至 2018 年 Go 垃圾回收器设计演进的技术演讲。&#xA;5. &lt;a href=&#34;https://docs.google.com/document/d/1wmjrocXIWTr1JxU-3EQBI6BK6KgtiFArkG47XK73xIQ/edit&#34;&gt;Go 1.5 concurrent GC pacing&lt;/a&gt; —— 确定何时启动并发标记阶段的设计文档。&#xA;6. &lt;a href=&#34;https://tip.golang.org/issue/30333&#34;&gt;Smarter scavenging&lt;/a&gt; —— 修订 Go 运行时向操作系统归还内存方式的设计文档。&#xA;7. &lt;a href=&#34;https://tip.golang.org/issue/35112&#34;&gt;Scalable page allocator&lt;/a&gt; —— 修订Go运行时管理操作系统内存方式的设计文档。&#xA;8. &lt;a href=&#34;https://tip.golang.org/issue/44167&#34;&gt;GC pacer redesign (Go 1.18)&lt;/a&gt; —— 修订并发标记阶段启动算法的新设计文档。&#xA;9. &lt;a href=&#34;https://tip.golang.org/issue/48409&#34;&gt;Soft memory limit (Go 1.19)&lt;/a&gt; —— 关于软内存限制功能的设计文档。&lt;/p&gt;&#xA;&lt;h2&gt;关于虚拟内存的说明&lt;/h2&gt;&#xA;&lt;p&gt;本指南主要关注 GC 的物理内存使用，但经常出现的问题是：这具体意味着什么？以及与虚拟内存（通常在 to p等程序中显示为“VSS”）有何区别？&lt;/p&gt;&#xA;&lt;p&gt;物理内存是大多数计算机中实际物理 RAM 芯片承载的内存。虚拟内存是操作系统提供的对物理内存的抽象，用于隔离不同程序。程序保留不映射任何物理地址的虚拟地址空间通常也是可接受的。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;由于虚拟内存只是操作系统维护的映射，进行不映射物理内存的大容量虚拟内存保留通常成本极低。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Go 运行时在以下几个方面依赖这种虚拟内存成本视图：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Go 运行时从不删除已映射的虚拟内存。相反，它使用大多数操作系统提供的特殊操作来显式释放与某些虚拟内存范围关联的物理内存资源。&lt;/p&gt;&#xA;&lt;p&gt;该技术被显式用于管理内存限制，并将 Go 运行时不再需要的内存返还给操作系统。Go 运行时还会在后台持续释放不再需要的内存。详见补充资源。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;在 32 位平台上，Go 运行时会预先为堆保留 128 MiB 到 512 MiB 的地址空间，以限制碎片问题。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Go 运行时在多个内部数据结构的实现中使用大容量虚拟内存地址空间保留。在 64 位平台上，这些结构通常至少需要约 700 MiB 的虚拟内存占用。在 32 位平台上，其占用可忽略不计。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;因此，虚拟内存指标（如 top 中的“VSS”）通常对于理解 Go 程序的内存占用处不大。建议重点关注“RSS”等更能直接反映物理内存使用情况的指标。&lt;/p&gt;&#xA;&lt;h2&gt;调优指南&lt;/h2&gt;&#xA;&lt;h3&gt;成本识别&lt;/h3&gt;&#xA;&lt;p&gt;在优化 Go 应用与 GC 的交互之前，首要任务是确认 GC 确实是主要性能成本来源。&lt;/p&gt;&#xA;&lt;p&gt;Go 生态提供多种工具用于识别成本和优化应用。关于这些工具的简要概述，请参阅&lt;a href=&#34;https://tip.golang.org/doc/diagnostics&#34;&gt;诊断指南&lt;/a&gt;。此处我们将聚焦其中部分工具，并说明理解 GC 影响和行为的合理使用顺序。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;CPU 性能分析&lt;/p&gt;&#xA;&lt;p&gt;CPU 性能分析是理想的起点。虽然 CPU 分析能提供 CPU 时间消耗的概览，但未经训练的眼睛可能难以识别 GC 在特定应用中的影响程度。幸运的是，理解 GC 的作用主要归结于了解 runtime 包中不同函数的含义。以下是解读 CPU 分析结果时实用的函数子集：&lt;/p&gt;&#xA;&lt;p&gt;请注意，下列函数非叶函数（leaf functions），因此可能不会默认显示在 pprof 工具的 top 命令结果中。建议使用 &lt;code&gt;top -cum&lt;/code&gt; 命令或直接对这些函数使用 list 命令，并重点关注累计百分比（cumulative percent）列。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;code&gt;runtime.gcBgMarkWorker&lt;/code&gt;：后台标记工作 goroutine 的入口点。此处耗时与GC频率及对象图的复杂度和大小成正比，代表了应用在标记扫描阶段的基础时间成本。&lt;/p&gt;&#xA;&lt;p&gt;在这些 goroutine 中，你可能会发现对 &lt;code&gt;runtime.gcDrainMarkWorkerDedicated&lt;/code&gt;、&lt;code&gt;runtime.gcDrainMarkWorkerFractional&lt;/code&gt; 和 &lt;code&gt;runtime.gcDrainMarkWorkerIdle&lt;/code&gt; 的调用，这些指示了工作器类型。在基本空闲的 Go 应用中，GC 会利用额外的（空闲）CPU 资源来加速工作，这通过 &lt;code&gt;runtime.gcDrainMarkWorkerIdle&lt;/code&gt; 符号体现。因此，此处的时间可能占据 CPU 样本的很大比例 —— GC 认为这些是免费资源。若应用变得活跃，空闲工作器的 CPU 时间将下降。常见场景是应用完全在单个 goroutine 中运行但 &lt;code&gt;GOMAXPROCS &amp;gt; 1&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;code&gt;runtime.mallocgc&lt;/code&gt;：堆内存分配器的入口点。此处累计耗时过高（&amp;gt;15%）通常表明存在大量内存分配。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;code&gt;runtime.gcAssistAlloc&lt;/code&gt;：goroutine 通过此函数投入时间协助GC进行标记扫描。此处累计耗时过高（&amp;gt;5%）表明应用分配速度可能超过了 GC 处理能力，这既反映了 GC 的显著影响，也代表了应用在标记扫描上花费的时间。注意此函数包含在 &lt;code&gt;runtime.mallocgc&lt;/code&gt; 调用树中，因此也会推高该函数的耗时统计。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;执行跟踪分析&lt;/p&gt;&#xA;&lt;p&gt;虽然 CPU 性能分析非常适合识别总体时间消耗，但对于更细微、罕见或专门与延迟相关的性能成本，其作用有限。相比之下，执行跟踪（execution traces）能为 Go 程序的短期执行窗口提供丰富而深入的视角。执行跟踪包含各种与 Go GC 相关的事件，可以直接观察具体的执行路径以及应用程序与 Go GC 的交互方式。所有被追踪的 GC 事件在跟踪查看器（trace viewer）中都配有清晰的标签标识。&lt;/p&gt;&#xA;&lt;p&gt;有关如何开始使用执行跟踪，请参阅 &lt;a href=&#34;https://pkg.go.dev/runtime/trace&#34;&gt;runtime/trace 包的文档说明&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;GC 跟踪日志&lt;/p&gt;&#xA;&lt;p&gt;当其他方法均无效时，Go GC 提供了几种不同的专用跟踪方式，可深入揭示 GC 行为细节。这些跟踪日志总是直接输出到 STDERR（每 GC 周期一行），通过所有 Go 程序识别的 &lt;code&gt;GODEBUG&lt;/code&gt; 环境变量配置。由于需要熟悉GC实现细节，这些日志主要用于调试 Go GC 本身，但偶尔也有助于深入理解 GC 行为。&lt;/p&gt;&#xA;&lt;p&gt;核心GC跟踪通过设置 &lt;code&gt;GODEBUG=gctrace=1&lt;/code&gt; 启用，其输出格式在 &lt;a href=&#34;https://pkg.go.dev/runtime#hdr-Environment_Variables&#34;&gt;runtime 包文档的环境变量章节&lt;/a&gt; 中有详细说明。&lt;/p&gt;&#xA;&lt;p&gt;补充性的“节奏器跟踪”（pacer trace）通过设置 &lt;code&gt;GODEBUG=gcpacertrace=1&lt;/code&gt; 启用，可提供更深入的洞察。解读此输出需要理解 GC 的“节奏器”机制（参见补充资源），这已超出本指南范围。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3&gt;消除堆分配&lt;/h3&gt;&#xA;&lt;p&gt;降低 GC 成本的一种根本方法是减少 GC 需要管理的值数量。下文所述的技术可带来最显著的性能提升，因为正如 GOGC 章节所示，Go 程序的分配速率是影响 GC 频率的关键因素 —— 而 GC 频率正是本指南的核心成本指标。&lt;/p&gt;&#xA;&lt;h4&gt;堆内存分析&lt;/h4&gt;&#xA;&lt;p&gt;在确认 GC 是主要成本来源后，下一步是定位大部分堆分配的来源。内存分析（确切地说是堆内存分析）对此非常有用。请查阅相关文档了解如何开始使用。&lt;/p&gt;&#xA;&lt;p&gt;内存分析通过分配时的堆栈跟踪来定位程序中的堆分配来源。每份内存分析报告可通过四种方式分解内存：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用中对象（inuse_objects）—— 按存活对象数量进行分解。&lt;/li&gt;&#xA;&lt;li&gt;使用中空间（inuse_space）—— 按存活对象占用的字节内存量进行分解。&lt;/li&gt;&#xA;&lt;li&gt;分配对象数（alloc_objects）—— 按程序启动后分配的对象总数进行分解。&lt;/li&gt;&#xA;&lt;li&gt;分配空间（alloc_space）—— 按程序启动后分配的内存总量进行分解。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;在这些不同的堆内存视图间切换，可通过 pprof 工具的 &lt;code&gt;-sample_index&lt;/code&gt; 标志实现，或在交互模式下使用 sample_index 选项完成。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;注意：内存分析默认仅对堆对象进行抽样采样，因此不会包含每个堆分配的完整信息。但这已足以识别热点区域。如需调整采样率，请参阅 &lt;a href=&#34;https://pkg.go.dev/runtime#pkg-variables&#34;&gt;runtime.MemProfileRate&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;就降低 GC 成本而言，分配空间（alloc_space）通常是最实用的视图，因其直接对应分配速率。该视图能指示能带来最大优化收益的分配热点区域。&lt;/p&gt;&#xA;&lt;h4&gt;逃逸分析&lt;/h4&gt;&#xA;&lt;p&gt;在借助堆内存分析定位候选堆分配点后，如何消除它们？关键在于利用 Go 编译器的逃逸分析机制，让编译器为这些内存找到更高效的存储方案（例如 goroutine 栈）。幸运的是，Go 编译器能够描述将 Go 值逃逸到堆中的具体原因。掌握这些信息后，问题就转化为通过重组源代码来改变分析结果（这通常是最困难的部分，但已超出本指南范围）。&lt;/p&gt;&#xA;&lt;p&gt;关于如何获取 Go 编译器逃逸分析信息，最简单的方式是通过 Go 编译器支持的调试标志，该标志会以文本格式描述对指定包应用或未应用的所有优化措施（包括值是否逃逸）。尝试以下命令（其中 &lt;code&gt;[package]&lt;/code&gt; 为 Go 包路径）：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ go build -gcflags=-m=3 [package]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;该信息还可在支持 LSP 的编辑器中以可视化叠加层形式呈现 —— 它以代码操作（code action）功能对外提供。例如在 VS Code 中，调用“Source Action... &amp;gt; Show compiler optimization details”命令可为当前包启用诊断信息（也可运行“Go: Toggle compiler optimization details”命令）。通过以下配置设置控制显示的注释类型：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;通过设置 &lt;a href=&#34;https://github.com/golang/vscode-go/wiki/settings#uidiagnosticannotations&#34;&gt;ui.diagnostic.annotations&lt;/a&gt; 包含 escape 来启用逃逸分析叠加层。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;最后，Go 编译器还以机器可读（JSON）格式提供这些信息，可用于构建额外的自定义工具。详细信息请参阅 &lt;a href=&#34;https://cs.opensource.google/go/go/+/master:src/cmd/compile/internal/logopt/log_opts.go;l=25;drc=351e0f4083779d8ac91c05afebded42a302a6893&#34;&gt;Go 源代码中的相关文档&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h3&gt;实现特异性优化&lt;/h3&gt;&#xA;&lt;p&gt;Go 垃圾回收器对存活内存的分布特征非常敏感，因为复杂的对象图和指针结构既会限制并行性，也会为GC带来更多工作负荷。因此，GC 包含针对特定常见结构的优化措施。以下列出对性能优化最直接有用的几项：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;注意：应用下述优化可能会降低代码可读性（掩盖设计意图），且可能随 Go 版本迭代失效。建议仅在最关键处应用这些优化，具体位置可通过&amp;quot;成本识别&amp;quot;章节所列工具确定。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;不含指针的值与其他值分开存储。&lt;/p&gt;&#xA;&lt;p&gt;因此，从数据结构中消除非必需的指针可能带来优势，因为这能降低 GC 对程序造成的缓存压力。相应地，依赖索引而非指针的数据结构（尽管类型安全性降低）可能表现更佳。但仅当明确对象图复杂且 GC 在标记扫描上耗时显著时，才值得采用此优化。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;GC 会在值的最后一个指针处停止扫描。&lt;/p&gt;&#xA;&lt;p&gt;因此，将指针字段集中在结构体值的开头可能有利。但仅当明确应用在标记扫描上耗时显著时才值得这样做（理论上编译器可自动完成，但尚未实现，目前结构体字段仍按源代码书写顺序排列）。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;此外，GC 必须与其看到的几乎每个指针进行交互，因此使用切片索引（而非指针）有助于降低  GC 成本。&lt;/p&gt;&#xA;&lt;h3&gt;Linux 透明大页（THP）&lt;/h3&gt;&#xA;&lt;p&gt;当程序访问内存时，CPU 需要将其使用的虚拟内存地址转换为指向所访问数据的物理内存地址。为此，CPU 会查询“页表”（page table）—— 这个由操作系统管理的数据结构负责维护虚拟内存到物理内存的映射关系。页表中的每个条目代表一个不可分割的物理内存块（称为页，page），故名页表。&lt;/p&gt;&#xA;&lt;p&gt;透明大页（THP）是 Linux 的一项特性，它能透明地将支撑连续虚拟内存区域的物理内存页替换为更大的内存块（称为大页）。通过使用更大的内存块，表示相同内存区域所需的页表条目更少，从而提升页表查询速度。然而，如果系统只使用大页的一小部分，更大的内存块会导致更多浪费。&lt;/p&gt;&#xA;&lt;p&gt;在生产环境运行 Go 程序时，启用 Linux 透明大页可以提升吞吐量和降低延迟，但代价是增加内存使用量。堆内存较小的应用通常无法从 THP 中受益，反而可能消耗大量额外内存（最高达50%）。而堆内存较大（1 GiB 或以上）的应用往往能获得显著收益（吞吐量提升最高 10%），且额外内存开销很小（1-2% 或更低）。无论哪种情况，了解 THP 设置都很有帮助，建议始终进行实际测试。&lt;/p&gt;&#xA;&lt;p&gt;在 Linux 环境中，可通过修改 &lt;code&gt;/sys/kernel/mm/transparent_hugepage/enabled&lt;/code&gt; 来启用或禁用透明大页。详见官方 &lt;a href=&#34;https://www.kernel.org/doc/html/next/admin-guide/mm/transhuge.html&#34;&gt;Linux 管理指南&lt;/a&gt;。如果你选择在生产环境中启用透明大页，我们为 Go 程序推荐以下附加设置：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;将 &lt;code&gt;/sys/kernel/mm/transparent_hugepage/defrag&lt;/code&gt; 设置为 &lt;code&gt;defer&lt;/code&gt; 或 &lt;code&gt;defer+madvise&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;此设置控制 Linux 内核将常规页合并为大页的激进程度。&lt;code&gt;defer&lt;/code&gt; 指示内核在后台以惰性方式合并大页。更激进的设置在内存受限系统中可能引发停滞，并通常会损害应用延迟。&lt;code&gt;defer+madvise&lt;/code&gt; 类似 &lt;code&gt;defer&lt;/code&gt;，但对系统中显式请求大页且依赖其提升性能的其他应用更友好。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;将 &lt;code&gt;/sys/kernel/mm/transparent_hugepage/khugepaged/max_ptes_none&lt;/code&gt; 设置为 0。&lt;/p&gt;&#xA;&lt;p&gt;此设置控制 Linux 内核守护进程在尝试分配大页时可分配的额外页数量。默认设置为最大激进模式，通常会抵消 Go 运行时归还内存给操作系统的努力。在 Go 1.21 之前，Go 运行时尝试缓解默认设置的负面影响，但会带来 CPU 成本。从 Go 1.21+ 和 Linux 6.2+ 开始，Go 运行时不再改变大页状态。&lt;/p&gt;&#xA;&lt;p&gt;如果你在升级到 Go 1.21.1 或更高版本后遇到内存使用增加的问题，尝试应用此设置很可能解决问题。作为额外解决方案，你可调用 &lt;a href=&#34;https://tip.golang.org/pkg/golang.org/x/sys/unix#Prctl&#34;&gt;Prctl&lt;/a&gt; 函数并传入 &lt;code&gt;PR_SET_THP_DISABLE&lt;/code&gt; 在进程级别禁用大页，或设置 &lt;code&gt;GODEBUG=disablethp=1&lt;/code&gt;（该选项在 Go 1.21.6 和 Go 1.22 中添加）来禁用堆内存的大页功能。请注意 &lt;code&gt;GODEBUG&lt;/code&gt; 设置可能在未来的版本中被移除。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;附录&lt;/h2&gt;&#xA;&lt;h3&gt;关于 GOGC 的补充说明&lt;/h3&gt;&#xA;&lt;p&gt;GOGC 章节曾指出：GOGC 值翻倍会使堆内存开销翻倍，同时使 GC CPU 成本减半。为理解其原理，让我们进行数学分解。&lt;/p&gt;&#xA;&lt;p&gt;首先，堆目标值为总堆大小设定目标。但这个目标主要影响新分配堆内存，因为存活堆是应用的基础固有属性：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;目标堆内存 = 存活堆 + (存活堆 + GC 根节点) * GOGC / 100&#xA;&#xA;总堆内存 = 存活堆 + 新分配堆内存&#xA;&#xA;⇒&#xA;&#xA;新分配堆内存 = (存活堆 + GC根节点) * GOGC / 100&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;由此可见，GOGC 翻倍会使每周期新分配堆内存量也翻倍，这正体现了堆内存开销。注意：存活堆 + GC 根节点是 GC 需扫描内存量的近似值。&lt;/p&gt;&#xA;&lt;p&gt;接下来分析 GC CPU 成本。总成本可分解为单周期成本乘以某时间段 T 内的 GC 频率：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;总 GC CPU 成本 = (单周期 GC CPU 成本) * (GC 频率) * T&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;单周期GC CPU成本可从GC模型推导：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;单周期 GC CPU 成本 = (存活堆 + GC 根节点) * (每字节成本) + 固定成本&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;（此处忽略清除阶段成本，因为标记扫描成本占主导）&lt;/p&gt;&#xA;&lt;p&gt;稳态由恒定分配速率和恒定每字节成本定义，因此可推导 GC 频率：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;GC 频率 = 分配速率 / 新分配堆内存 = 分配速率 / [(存活堆 + GC 根节点) * GOGC / 100]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;整合公式得到总成本完整方程：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;总 GC CPU 成本 = [分配速率 / ((存活堆 + GC 根节点) * GOGC / 100)] * [(存活堆 + GC 根节点) * 每字节成本 + 固定成本] * T&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;对于足够大的堆（代表大多数情况），GC 周期的边际成本远高于固定成本，可简化公式：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;总 GC CPU 成本 = (分配速率) / (GOGC / 100) * (每字节成本) * T&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;由此简化公式可知：GOGC 翻倍会使总 GC CPU 成本减半（注意：本指南可视化模拟了固定成本，因此当 GOGC 翻倍时，显示的 GC CPU 开销不会精确减半）。此外，GC CPU 成本主要取决于分配速率和内存扫描的每字节成本。具体降低这些成本的方法请参阅优化指南。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;注意：存活堆大小与 GC 实际需扫描的内存量存在差异——相同大小的存活堆若结构不同，将导致不同的 CPU 成本但相同的内存成本，从而产生不同的权衡结果。这就是为什么堆结构是稳态定义的一部分。理论上堆目标应仅包含可扫描的存活堆（作为 GC 需扫描内存的更精确近似），但当可扫描存活堆很小而存活堆总体很大时，会导致异常行为。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;script src=&#34;https://www.lyyyuna.com/libs/d3/d3.v7.min.js&#34;&gt;&lt;/script&gt;&#xA;&lt;script&gt;&#xA;    // Complete JavaScript implementation from Go&#39;s gc-guide.js&#xA;    function StackedAreaChart({&#xA;        xSeries,&#xA;        marginTop = 30,&#xA;        marginRight = 100,&#xA;        marginBottom = 60,&#xA;        marginLeft = 50,&#xA;    } = {}) {&#xA;        const width = 756;&#xA;        const height = 189;&#xA;        const svg = d3.create(&#34;svg&#34;)&#xA;            .attr(&#34;preserveAspectRatio&#34;, &#34;xMinYMin meet&#34;)&#xA;            .attr(&#34;viewBox&#34;, [0, 0, width, height]);&#xA;&#xA;        const xRange = [marginLeft, width - marginRight];&#xA;        const yRange = [height - marginBottom, marginTop];&#xA;&#xA;        // Add empty axes first.&#xA;        svg.append(&#34;g&#34;)&#xA;            .classed(&#34;x axis&#34;, true)&#xA;            .attr(&#34;transform&#34;, `translate(0,${height-marginBottom})`)&#xA;&#xA;        svg.append(&#34;g&#34;)&#xA;            .classed(&#34;y axis&#34;, true)&#xA;            .attr(&#34;transform&#34;, `translate(${marginLeft},0)`)&#xA;&#xA;        const update = function(data, mutTime) {&#xA;            const seriesKeys = Object.keys(data[0]).filter(s =&gt; s !== xSeries);&#xA;&#xA;            let seriesColors = new Array();&#xA;            if (seriesKeys.length &gt; 3) {&#xA;                const colorFn = d3.interpolateViridis;&#xA;                for (let i = 0; i &lt; seriesKeys.length; i++) {&#xA;                    seriesColors.push(colorFn((i / 10) - Math.floor(i/10)));&#xA;                }&#xA;            } else {&#xA;                seriesColors = [&#34;#253443&#34;, &#34;#007d9c&#34;, &#34;#50b7e0&#34;];&#xA;                if (seriesKeys.length &lt; 3) {&#xA;                    seriesColors = seriesColors.slice(seriesKeys.length-1);&#xA;                }&#xA;            }&#xA;            const seriesScale = d3.scaleOrdinal()&#xA;                .domain(seriesKeys)&#xA;                .range(seriesColors);&#xA;&#xA;            const yStack = (d3.stack().keys(seriesKeys))(data);&#xA;&#xA;            const xDomain = d3.extent(d3.map(data, p =&gt; p[xSeries]));&#xA;            const yDomain = d3.extent(d3.map(yStack[yStack.length-1], p =&gt; p[1]));&#xA;            yDomain[0] = 0;&#xA;&#xA;            const xScale = d3.scaleLinear(xDomain, xRange);&#xA;            const yScale = d3.scaleLinear(yDomain, yRange);&#xA;&#xA;            const xAxis = d3.axisBottom(xScale).tickFormat(x =&gt; `${x.toFixed(1)} s`);&#xA;            svg.selectAll(&#34;g.x.axis&#34;)&#xA;                .style(&#34;font-size&#34;, &#34;11px&#34;)&#xA;                .call(xAxis);&#xA;&#xA;            const yAxis = d3.axisLeft(yScale).ticks(5).tickFormat(x =&gt; `${x.toFixed(0)} MiB`);&#xA;            svg.selectAll(&#34;g.y.axis&#34;)&#xA;                .style(&#34;font-size&#34;, &#34;11px&#34;)&#xA;                .call(yAxis);&#xA;&#xA;            const area = d3.area()&#xA;                .curve(d3.curveLinear)&#xA;                .x(d =&gt; xScale(d.data[xSeries]))&#xA;                .y0(d =&gt; yScale(d[0]))&#xA;                .y1(d =&gt; yScale(d[1]));&#xA;&#xA;            svg.selectAll(&#34;path.series&#34;)&#xA;                .data(yStack)&#xA;                .join(&#34;path&#34;)&#xA;                    .classed(&#34;series&#34;, true)&#xA;                    .attr(&#34;d&#34;, area)&#xA;                    .style(&#34;fill&#34;, d =&gt; seriesScale(d.key));&#xA;&#xA;            svg.selectAll(&#34;text.label&#34;)&#xA;                .data(seriesKeys)&#xA;                .join(&#34;text&#34;)&#xA;                    .classed(&#34;label&#34;, true)&#xA;                    .attr(&#34;text-anchor&#34;, &#34;left&#34;)&#xA;                    .attr(&#34;font-size&#34;, &#34;12px&#34;)&#xA;                    .attr(&#34;x&#34;, width-marginRight+20)&#xA;                    .attr(&#34;y&#34;, d =&gt; (seriesKeys.length-1-seriesKeys.indexOf(d))*24+60)&#xA;                    .attr(&#34;fill&#34;, &#34;currentColor&#34;)&#xA;                    .attr(&#34;display&#34;, (() =&gt; {&#xA;                        if (seriesKeys.length &lt;= 3) {&#xA;                            return &#34;inherit&#34;;&#xA;                        }&#xA;                        return &#34;none&#34;;&#xA;                    })())&#xA;                    .text(d =&gt; d);&#xA;&#xA;            svg.selectAll(&#34;rect.legend&#34;)&#xA;                .data(seriesKeys)&#xA;                .join(&#34;rect&#34;)&#xA;                    .classed(&#34;legend&#34;, true)&#xA;                    .attr(&#34;stroke&#34;, &#34;none&#34;)&#xA;                    .attr(&#34;x&#34;, width-marginRight+7)&#xA;                    .attr(&#34;y&#34;, d =&gt; (seriesKeys.length-1-seriesKeys.indexOf(d))*24+51)&#xA;                    .attr(&#34;width&#34;, 10)&#xA;                    .attr(&#34;height&#34;, 10)&#xA;                    .attr(&#34;display&#34;, (() =&gt; {&#xA;                        if (seriesKeys.length &lt;= 3) {&#xA;                            return &#34;inherit&#34;;&#xA;                        }&#xA;                        return &#34;none&#34;;&#xA;                    })())&#xA;                    .attr(&#34;fill&#34;, d =&gt; seriesScale(d));&#xA;&#xA;            svg.selectAll(&#34;text.duration&#34;)&#xA;                .data([xDomain[1]])&#xA;                .join(&#34;text&#34;)&#xA;                    .classed(&#34;duration&#34;, true)&#xA;                    .attr(&#34;text-anchor&#34;, &#34;left&#34;)&#xA;                    .attr(&#34;font-size&#34;, &#34;10px&#34;)&#xA;                    .attr(&#34;x&#34;, width-marginRight+5)&#xA;                    .attr(&#34;y&#34;, height-marginBottom+10)&#xA;                    .attr(&#34;fill&#34;, &#34;currentColor&#34;)&#xA;                    .attr(&#34;font-weight&#34;, &#34;bold&#34;)&#xA;                    .text(d =&gt; `Total: ${d.toFixed(2)} s`);&#xA;&#xA;            svg.selectAll(&#34;text.results&#34;)&#xA;                .data([[(xDomain[1]-mutTime)/xDomain[1]*100, yDomain[1]]])&#xA;                .join(&#34;text&#34;)&#xA;                    .classed(&#34;results&#34;, true)&#xA;                    .attr(&#34;text-anchor&#34;, &#34;middle&#34;)&#xA;                    .attr(&#34;font-size&#34;, &#34;12px&#34;)&#xA;                    .attr(&#34;x&#34;, marginLeft + (width-marginLeft-marginRight)/2)&#xA;                    .attr(&#34;y&#34;, height-marginBottom+37)&#xA;                    .attr(&#34;fill&#34;, &#34;currentColor&#34;)&#xA;                    .attr(&#34;font-weight&#34;, &#34;bold&#34;)&#xA;                    .text(d =&gt; `GC CPU = ${d[0].toFixed(1)}%, Peak Mem = ${d[1].toFixed(1)} MiB`);&#xA;&#xA;            const peakLive = d3.max(d3.map(data, p =&gt; p[&#34;Live Heap&#34;]));&#xA;            const otherMem = d3.max(d3.map(data, p =&gt; p[&#34;Other Mem.&#34;]));&#xA;&#xA;            svg.selectAll(&#34;text.subresults&#34;)&#xA;                .data([[peakLive, otherMem]])&#xA;                .join(&#34;text&#34;)&#xA;                    .classed(&#34;subresults&#34;, true)&#xA;                    .attr(&#34;text-anchor&#34;, &#34;middle&#34;)&#xA;                    .attr(&#34;font-size&#34;, &#34;11px&#34;)&#xA;                    .attr(&#34;x&#34;, marginLeft + (width-marginLeft-marginRight)/2)&#xA;                    .attr(&#34;y&#34;, height-marginBottom+51)&#xA;                    .attr(&#34;fill&#34;, &#34;currentColor&#34;)&#xA;                    .text(d =&gt; {&#xA;                        let base = &#34;&#34;;&#xA;                        if (d[0]) {&#xA;                            base += `Peak Live Mem = ${d[0].toFixed(1)} MiB`;&#xA;                        }&#xA;                        if (d[1]) {&#xA;                            base += `, Other Mem = ${d[1].toFixed(1)} MiB`;&#xA;                        }&#xA;                        if (base !== &#34;&#34;) {&#xA;                            base = &#34;(&#34; + base + &#34;)&#34;;&#xA;                        }&#xA;                        return base;&#xA;                    });&#xA;        }&#xA;        return [svg.node(), update];&#xA;    }&#xA;&#xA;    function gcModel(workload, config) {&#xA;        let otherMem = config[&#34;otherMem&#34;];&#xA;        if (typeof(otherMem) !== &#39;number&#39;) {&#xA;            otherMem = document.getElementById(config[&#34;otherMem&#34;]).value;&#xA;        }&#xA;        let gogc = config[&#34;GOGC&#34;];&#xA;        if (typeof(gogc) !== &#39;number&#39;) {&#xA;            gogc = document.getElementById(config[&#34;GOGC&#34;]).value;&#xA;        }&#xA;        let memoryLimit = config[&#34;memoryLimit&#34;];&#xA;        if (typeof(memoryLimit) !== &#39;number&#39;) {&#xA;            memoryLimit = document.getElementById(config[&#34;memoryLimit&#34;]).value;&#xA;        }&#xA;        let initialLive = 0;&#xA;        if (&#34;initialLive&#34; in config) {&#xA;            initialLive = config[&#34;initialLive&#34;];&#xA;        }&#xA;        let trackLive = false;&#xA;        if (&#34;trackLive&#34; in config) {&#xA;            trackLive = config[&#34;trackLive&#34;];&#xA;            if (typeof(trackLive) !== &#39;boolean&#39;) {&#xA;                trackLive = document.getElementById(config[&#34;trackLive&#34;]).checked;&#xA;            }&#xA;        }&#xA;        let fixedWindow = Infinity;&#xA;        if (&#34;fixedWindow&#34; in config) {&#xA;            fixedWindow = config[&#34;fixedWindow&#34;];&#xA;        }&#xA;        const data = new Array();&#xA;&#xA;        // State.&#xA;        const minHeapGoal = 4; // MiB&#xA;        let t = 0;&#xA;        let liveHeap = initialLive;&#xA;        let newHeap = 0;&#xA;        let liveFromCycle = new Array();&#xA;        liveFromCycle.push(initialLive);&#xA;        liveFromCycle.push(0);&#xA;&#xA;        const computeHeapGoal = (liveHeap) =&gt; {&#xA;            let heapGoal = liveHeap*(1.0 + (gogc / 100));&#xA;            if (gogc === Infinity) {&#xA;                heapGoal = Infinity;&#xA;            }&#xA;            if (heapGoal+otherMem &gt; memoryLimit) {&#xA;                heapGoal = memoryLimit - otherMem&#xA;            }&#xA;            if (gogc !== Infinity &amp;&amp; heapGoal &lt; minHeapGoal) {&#xA;                heapGoal = minHeapGoal&#xA;            }&#xA;            if (heapGoal &lt; liveHeap + 0.0625) {&#xA;                heapGoal = liveHeap + 0.0625&#xA;            }&#xA;            return heapGoal&#xA;        }&#xA;        let heapGoal = computeHeapGoal(minHeapGoal / (1 + gogc/100)); // Fake a live heap for minHeapGoal.&#xA;        if (initialLive !== 0) {&#xA;            heapGoal = computeHeapGoal(initialLive);&#xA;        }&#xA;&#xA;        let n = 0;&#xA;        const emit = function() {&#xA;            const datum = {&#34;t&#34;: t};&#xA;            // The series will be automatically stacked, so for the best&#xA;            // possible presentation, we should make sure to put in&#xA;            // &#34;other mem&#34; first, then &#34;live,&#34; then &#34;new.&#34;&#xA;            // This is roughly in order of &#34;least dynamic&#34; series&#xA;            // to &#34;most dynamic&#34; which helps make the graph easier to&#xA;            // interpret.&#xA;            if (otherMem !== 0) {&#xA;                datum[&#34;Other Mem.&#34;] = otherMem;&#xA;            }&#xA;            if (trackLive) {&#xA;                for (let i = 0; i &lt; liveFromCycle.length; i++) {&#xA;                    datum[`Live Heap From GC ${i+1}`] = liveFromCycle[i];&#xA;                }&#xA;            } else {&#xA;                datum[&#34;Live Heap&#34;] = liveHeap;&#xA;                datum[&#34;New Heap&#34;] = newHeap;&#xA;            }&#xA;            data.push(datum)&#xA;        }&#xA;&#xA;        // Emit points.&#xA;        emit();&#xA;        let nextLive = 0;&#xA;        let nextWillLive = 0;&#xA;        let nextWillDie = 0;&#xA;        let totalMutTime = 0;&#xA;        for (const work of workload) {&#xA;            let left = work.duration;&#xA;            let lastLive = liveHeap + nextLive;&#xA;            const willLive = work.duration * work.allocRate * work.newSurvivalRate;&#xA;            const willDie = lastLive * work.oldDeathRate;&#xA;            while (left &gt; 0) {&#xA;                if (t &gt;= fixedWindow) {&#xA;                    break;&#xA;                } else if (t + left &gt; fixedWindow) {&#xA;                    left = fixedWindow - t;&#xA;                }&#xA;                let alloc = left * work.allocRate;&#xA;                let endCycle = false;&#xA;                if (liveHeap+newHeap+alloc &gt; heapGoal) {&#xA;                    alloc = heapGoal-liveHeap-newHeap;&#xA;                    endCycle = true;&#xA;                }&#xA;                newHeap += alloc;&#xA;&#xA;                // Calculate mutator time.&#xA;                const mutTime = alloc / work.allocRate;&#xA;                left -= mutTime;&#xA;                t += mutTime;&#xA;                totalMutTime += mutTime;&#xA;                nextLive += (willLive - willDie) * (mutTime / work.duration);&#xA;&#xA;                // For tracking per-GC live memory.&#xA;                nextWillLive += willLive * (mutTime / work.duration);&#xA;                nextWillDie += willDie * (mutTime / work.duration);&#xA;                liveFromCycle[liveFromCycle.length-1] = newHeap;&#xA;&#xA;                if (endCycle) {&#xA;                    emit();&#xA;&#xA;                    liveHeap += nextLive;&#xA;                    for (let i = 0; i &lt; liveFromCycle.length; i++) {&#xA;                        const live = liveFromCycle[i];&#xA;                        if (live &gt; 0) {&#xA;                            if (live &gt; nextWillDie) {&#xA;                                liveFromCycle[i] -= nextWillDie;&#xA;                                nextWillDie = 0;&#xA;                                break;&#xA;                            }&#xA;                            nextWillDie -= live;&#xA;                            liveFromCycle[i] = 0;&#xA;                        }&#xA;                    }&#xA;                    liveFromCycle[liveFromCycle.length-1] = nextWillLive;&#xA;&#xA;                    nextLive = 0;&#xA;                    nextWillLive = 0;&#xA;                    nextWillDie = 0;&#xA;                    newHeap = 0;&#xA;                    const gcTime = liveHeap / work.scanRate + config.fixedCost;&#xA;                    t += gcTime;&#xA;&#xA;                    emit();&#xA;&#xA;                    heapGoal = computeHeapGoal(liveHeap)&#xA;&#xA;                    liveFromCycle.push(newHeap);&#xA;                }&#xA;            }&#xA;            emit();&#xA;        }&#xA;        if (trackLive) {&#xA;            for (let i = 0; i &lt; data.length; i++) {&#xA;                for (let j = 0; j &lt; liveFromCycle.length; j++) {&#xA;                    const key = `Live Heap From GC ${j+1}`;&#xA;                    if (!(key in data[i])) {&#xA;                        data[i][key] = 0;&#xA;                    }&#xA;                }&#xA;            }&#xA;        }&#xA;        return [data, totalMutTime];&#xA;    }&#xA;&#xA;    const graphs = document.querySelectorAll(&#39;.gc-guide-graph&#39;);&#xA;&#xA;    for (let i = 0; i &lt; graphs.length; i++) {&#xA;        const workload = JSON.parse(graphs[i].getAttribute(&#34;data-workload&#34;));&#xA;        const config = JSON.parse(graphs[i].getAttribute(&#34;data-config&#34;));&#xA;        const [chart, update] = StackedAreaChart({xSeries: &#34;t&#34;});&#xA;&#xA;        const setupSlider = function(parameter, f, fmt) {&#xA;            if (typeof(config[parameter]) !== &#39;number&#39;) {&#xA;                const id = config[parameter];&#xA;                const slider = document.getElementById(id);&#xA;                const display = document.getElementById(id+&#34;-display&#34;);&#xA;                const value = f(slider.value);&#xA;&#xA;                if (display) {&#xA;                    display.innerHTML = fmt(value);&#xA;                }&#xA;                config[parameter] = value;&#xA;&#xA;                slider.oninput = function() {&#xA;                    const value = f(this.value);&#xA;&#xA;                    if (display) {&#xA;                        display.innerHTML = fmt(value);&#xA;                    }&#xA;                    config[parameter] = value;&#xA;&#xA;                    const [data, mutTime] = gcModel(workload, config);&#xA;                    update(data, mutTime);&#xA;                }&#xA;            }&#xA;        };&#xA;        const setupCheckbox = function(parameter) {&#xA;            if (parameter in config &amp;&amp; typeof(config[parameter]) !== &#39;boolean&#39;) {&#xA;                const id = config[parameter];&#xA;                const checkbox = document.getElementById(id);&#xA;&#xA;                config[parameter] = checkbox.checked;&#xA;&#xA;                checkbox.oninput = function() {&#xA;                    config[parameter] = checkbox.checked;&#xA;&#xA;                    const [data, mutTime] = gcModel(workload, config);&#xA;                    update(data, mutTime);&#xA;                }&#xA;            }&#xA;        };&#xA;        setupSlider(&#34;otherMem&#34;, x =&gt; parseInt(x), x =&gt; `${x} MiB`);&#xA;        setupSlider(&#34;GOGC&#34;, x =&gt; {&#xA;            const v = Math.round(Math.pow(2, parseFloat(x)))&#xA;            if (v &gt;= 1024) {&#xA;                return Infinity;&#xA;            }&#xA;            return v;&#xA;        }, x =&gt; {&#xA;            if (x === Infinity) {&#xA;                return &#34;off&#34;;&#xA;            }&#xA;            return `${x}`;&#xA;        });&#xA;        setupSlider(&#34;memoryLimit&#34;, x =&gt; parseFloat(x), x =&gt; `${x.toFixed(1)} MiB`);&#xA;        setupCheckbox(&#34;trackLive&#34;);&#xA;&#xA;        const [data, mutTime] = gcModel(workload, config);&#xA;        update(data, mutTime);&#xA;        graphs[i].appendChild(chart);&#xA;    }&#xA;&lt;/script&gt;</content>
    <link href="https://www.lyyyuna.com/2025/09/01/go-gc/" rel="alternate"></link>
    <summary type="html">把官网的动画也搬来了</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>使用 testing/synctest 测试并发代码</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/08/15/go-testing-synctest/</id>
    <content type="html">&lt;p&gt;Go 语言的核心特性之一是其原生支持的并发编程能力。Goroutine 和 channel 作为语言原语，为编写并发程序提供了简洁高效的构建模块。&lt;/p&gt;&#xA;&lt;p&gt;然而，并发程序的测试往往颇具挑战且容易出错。&lt;/p&gt;&#xA;&lt;p&gt;在 Go 1.24 版本中，我们引入了全新的实验性测试包 &lt;code&gt;testing/synctest&lt;/code&gt; 来支持并发代码测试。本文将阐述该实验功能的研发背景，演示synctest包的具体使用方法，并探讨其未来发展前景。&lt;/p&gt;&#xA;&lt;p&gt;需要注意的是，Go 1.24 中的 &lt;code&gt;testing/synctest&lt;/code&gt; 目前处于实验阶段，不受 Go 语言兼容性承诺的保障。该功能默认不开启，如需使用，必须在编译时通过设置环境变量 &lt;code&gt;GOEXPERIMENT=synctest&lt;/code&gt; 来激活。&lt;/p&gt;&#xA;&lt;h2&gt;测试并发代码是困难的&lt;/h2&gt;&#xA;&lt;p&gt;首先，让我们从一个简单示例开始分析。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;context.AfterFunc&lt;/code&gt; 函数的作用是在上下文取消后，安排特定函数在独立的 goroutine 中执行。以下是针对 AfterFunc 的测试：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func TestAfterFunc(t *testing.T) {&#xA;    ctx, cancel := context.WithCancel(context.Background())&#xA;&#xA;    calledCh := make(chan struct{}) // AfterFunc调用时关闭&#xA;    context.AfterFunc(ctx, func() {&#xA;        close(calledCh)&#xA;    })&#xA;&#xA;    // TODO: 验证AfterFunc尚未被调用&#xA;    cancel()&#xA;    // TODO: 验证AfterFunc已被调用&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这个测试需要验证两个关键条件：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;上下文取消前函数未被调用&lt;/li&gt;&#xA;&lt;li&gt;上下文取消后函数被调用&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;在并发系统中验证否定条件（未被调用）尤其困难。虽然我们可以轻松检测函数当前是否被调用，但如何确保它将来也不会被调用？&lt;/p&gt;&#xA;&lt;p&gt;常见的解决方案是引入等待超时机制。我们在测试中添加以下辅助函数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// funcCalled检测函数是否被调用&#xA;funcCalled := func() bool {&#xA;    select {&#xA;    case &amp;lt;-calledCh:&#xA;        return true&#xA;    case &amp;lt;-time.After(10 * time.Millisecond):&#xA;        return false&#xA;    }&#xA;}&#xA;&#xA;if funcCalled() {&#xA;    t.Fatalf(&amp;quot;上下文取消前AfterFunc已被调用&amp;quot;)&#xA;}&#xA;cancel()&#xA;if !funcCalled() {&#xA;    t.Fatalf(&amp;quot;上下文取消后AfterFunc未被调用&amp;quot;)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这种实现存在两个明显问题：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;执行效率低：虽然单次10毫秒延迟看似短暂，但在大量测试用例累积时会显著拖慢整体测试速度&lt;/li&gt;&#xA;&lt;li&gt;结果不可靠：&#xA;&lt;ol&gt;&#xA;&lt;li&gt;在性能强劲的机器上，10毫秒已经是较长的等待时间&lt;/li&gt;&#xA;&lt;li&gt;在共享且高负载的CI环境中，经常会出现数秒级的延迟波动&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;我们面临两难选择：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;若要提高稳定性，就需要延长等待时间，导致测试更慢&lt;/li&gt;&#xA;&lt;li&gt;若要加快测试速度，就必须缩短等待时间，但会降低可靠性&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;无论如何折衷，都无法同时实现快速和可靠的测试效果。&lt;/p&gt;&#xA;&lt;h2&gt;引入 testing/synctest 包&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;testing/synctest&lt;/code&gt; 包解决了这个问题。它让我们可以重写这个测试，使其简单、快速且可靠，而无需修改被测试的代码。&lt;/p&gt;&#xA;&lt;p&gt;该包仅包含两个函数：&lt;code&gt;Run&lt;/code&gt; 和 &lt;code&gt;Wait&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Run&lt;/code&gt; 会在一个新的 goroutine 中调用函数。这个 goroutine 和它启动的任何 goroutine 都存在于一个我们称为 &lt;strong&gt;bubble&lt;/strong&gt; 的隔离环境中。&lt;code&gt;Wait&lt;/code&gt; 函数则会等待当前 goroutine 所在 &lt;strong&gt;bubble&lt;/strong&gt; 中的所有 goroutine 都进入阻塞状态（等待同一个 &lt;strong&gt;bubble&lt;/strong&gt; 内的其他 goroutine）。&lt;/p&gt;&#xA;&lt;p&gt;让我们使用 &lt;code&gt;testing/synctest&lt;/code&gt; 包重写上面的测试：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func TestAfterFunc(t *testing.T) {&#xA;    synctest.Run(func() {&#xA;        ctx, cancel := context.WithCancel(context.Background())&#xA;&#xA;        funcCalled := false&#xA;        context.AfterFunc(ctx, func() {&#xA;            funcCalled = true&#xA;        })&#xA;&#xA;        synctest.Wait()&#xA;        if funcCalled {&#xA;            t.Fatalf(&amp;quot;AfterFunc function called before context is canceled&amp;quot;)&#xA;        }&#xA;&#xA;        cancel()&#xA;&#xA;        synctest.Wait()&#xA;        if !funcCalled {&#xA;            t.Fatalf(&amp;quot;AfterFunc function not called after context is canceled&amp;quot;)&#xA;        }&#xA;    })&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这与我们最初的测试几乎完全相同，但我们将测试封装在 &lt;code&gt;synctest.Run&lt;/code&gt; 调用中，并在断言函数是否被调用之前调用了 &lt;code&gt;synctest.Wait&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Wait&lt;/code&gt; 函数会等待调用者 &lt;strong&gt;bubble&lt;/strong&gt; 内的所有 goroutine 进入阻塞状态。当它返回时，我们就可以确定 &lt;code&gt;context&lt;/code&gt; 包要么已经调用了该函数，要么在我们采取进一步行动之前不会调用它。&lt;/p&gt;&#xA;&lt;p&gt;现在这个测试既快速又可靠。&lt;/p&gt;&#xA;&lt;p&gt;测试也变得更简单：我们用布尔值替换了原来的 &lt;code&gt;calledCh&lt;/code&gt; 通道。之前我们需要使用通道来避免测试 goroutine 和 &lt;code&gt;AfterFunc&lt;/code&gt; goroutine 之间的数据竞争，但现在 &lt;code&gt;Wait&lt;/code&gt; 函数提供了这种同步机制。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;race&lt;/code&gt; 检测器也能够理解 &lt;code&gt;Wait&lt;/code&gt; 调用，这个测试在使用 &lt;code&gt;-race&lt;/code&gt; 参数运行时能够通过。如果我们移除第二个 &lt;code&gt;Wait&lt;/code&gt; 调用，&lt;code&gt;race&lt;/code&gt; 检测器会正确地报告测试中存在数据竞争。&lt;/p&gt;&#xA;&lt;h2&gt;和时间相关的测试&lt;/h2&gt;&#xA;&lt;p&gt;并发代码常常需要处理时间问题。&lt;/p&gt;&#xA;&lt;p&gt;测试涉及时间的代码可能会很困难。正如前文所见，在测试中使用真实时间会导致测试缓慢且不稳定。有人可能会使用模拟时间，这样则需要避免直接调用 &lt;code&gt;time&lt;/code&gt; 包中的函数，并确保被测代码能兼容可选的模拟时钟。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;testing/synctest&lt;/code&gt; 包让测试涉及时间的代码变得更加简单。&lt;/p&gt;&#xA;&lt;p&gt;在 &lt;code&gt;Run&lt;/code&gt; 启动的作用域 &lt;strong&gt;bubble&lt;/strong&gt; 内，goroutine 会使用一个模拟时钟。在该作用域内，&lt;code&gt;time&lt;/code&gt; 包的所有函数都会操作这个模拟时钟。只有当所有 goroutine 都进入阻塞状态时，模拟时间才会向前推进。&lt;/p&gt;&#xA;&lt;p&gt;为了演示这一点，我们来为 &lt;code&gt;context.WithTimeout&lt;/code&gt; 函数编写一个测试。&lt;code&gt;WithTimeout&lt;/code&gt; 会创建一个子 &lt;code&gt;context&lt;/code&gt;，并在给定的超时时间后自动失效。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func TestWithTimeout(t *testing.T) {&#xA;    synctest.Run(func() {&#xA;        const timeout = 5 * time.Second&#xA;        ctx, cancel := context.WithTimeout(context.Background(), timeout)&#xA;        defer cancel()&#xA;&#xA;        // 先等待至接近超时时刻。&#xA;        time.Sleep(timeout - time.Nanosecond)&#xA;        synctest.Wait()&#xA;        if err := ctx.Err(); err != nil {&#xA;            t.Fatalf(&amp;quot;before timeout, ctx.Err() = %v; want nil&amp;quot;, err)&#xA;        }&#xA;&#xA;        // 再等待剩余时间直至超时生效。&#xA;        time.Sleep(time.Nanosecond)&#xA;        synctest.Wait()&#xA;        if err := ctx.Err(); err != context.DeadlineExceeded {&#xA;            t.Fatalf(&amp;quot;after timeout, ctx.Err() = %v; want DeadlineExceeded&amp;quot;, err)&#xA;        }&#xA;    })&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们编写这个测试的方式，就像在使用真实时间一样。唯一的区别在于：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;我们将测试函数包裹在 &lt;code&gt;synctest.Run&lt;/code&gt; 中。&lt;/li&gt;&#xA;&lt;li&gt;在每次调用 &lt;code&gt;time.Sleep&lt;/code&gt; 后，都会调用 &lt;code&gt;synctest.Wait&lt;/code&gt; 来等待 &lt;code&gt;context&lt;/code&gt; 包的计时器完成运行。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;阻塞和 bubble&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;testing/synctest&lt;/code&gt; 的核心概念是 &lt;strong&gt;bubble&lt;/strong&gt; 进入持久阻塞状态。当 &lt;strong&gt;bubble&lt;/strong&gt; 内的所有 goroutine 均被阻塞，且只能由同一 &lt;strong&gt;bubble&lt;/strong&gt; 内的其他 goroutine 解除阻塞时，即触发此状态。&lt;/p&gt;&#xA;&lt;p&gt;持久阻塞的判定规则:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;存在等待调用：若有未完成的 &lt;code&gt;Wait&lt;/code&gt; 调用，则立即返回&lt;/li&gt;&#xA;&lt;li&gt;时间推进机制：若无等待调用，模拟时钟将跳转到下一个可能唤醒 goroutine 的时间点&lt;/li&gt;&#xA;&lt;li&gt;死锁检测：若上述条件均不满足，则判定为死锁并触发 &lt;code&gt;Run&lt;/code&gt; 函数 panic&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;注意：若 goroutine 的阻塞可能被 &lt;strong&gt;bubble&lt;/strong&gt; 外部事件解除，则不符合持久阻塞定义&lt;/p&gt;&#xA;&lt;p&gt;可触发持久阻塞的操作:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;对 nil 通道的发送/接收操作&lt;/li&gt;&#xA;&lt;li&gt;对同 &lt;strong&gt;bubble&lt;/strong&gt; 内创建的通道的阻塞式发送/接收&lt;/li&gt;&#xA;&lt;li&gt;所有 case 分支均满足持久阻塞条件的 select 语句&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;time.Sleep&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;sync.Cond.Wait&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;sync.WaitGroup.Wait&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;Mutexes&lt;/h2&gt;&#xA;&lt;p&gt;对 &lt;code&gt;sync.Mutex&lt;/code&gt; 的操作不属于持久阻塞行为。&lt;/p&gt;&#xA;&lt;p&gt;在实际开发中，函数获取全局互斥锁的情况十分常见。例如，&lt;code&gt;reflect&lt;/code&gt; 包中的许多函数都会使用受互斥锁保护的全局缓存。如果在 synctest 测试 &lt;strong&gt;bubble&lt;/strong&gt; 内的某个 goroutine 因尝试获取被外部 goroutine 持有的互斥锁而阻塞，这种情况并不构成持久阻塞——虽然当前处于阻塞状态，但其解除阻塞依赖于测试 &lt;strong&gt;bubble&lt;/strong&gt; 之外的 goroutine。&lt;/p&gt;&#xA;&lt;p&gt;考虑到互斥锁通常不会长时间持有，直接将其排除在 &lt;code&gt;testing/synctest&lt;/code&gt; 的考量范围之外。&lt;/p&gt;&#xA;&lt;h2&gt;Channels&lt;/h2&gt;&#xA;&lt;p&gt;在 &lt;strong&gt;bubble&lt;/strong&gt; 内创建的通道与外部通道具有不同的行为特性：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;通道阻塞规则。只有当通道属于当前 &lt;strong&gt;bubble&lt;/strong&gt; 时，通道操作才可能触发持久阻塞。对非 &lt;strong&gt;bubble&lt;/strong&gt; 通道的操作不会被视为持久阻塞条件。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;跨 &lt;strong&gt;bubble&lt;/strong&gt; 访问限制。从外部 &lt;strong&gt;bubble&lt;/strong&gt; 操作内部通道将直接引发 panic（运行时恐慌）。这一机制确保了 goroutine 只会在与同 &lt;strong&gt;bubble&lt;/strong&gt; 内的其他 goroutine 通信时才可能进入持久阻塞状态。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;I/O&lt;/h2&gt;&#xA;&lt;p&gt;外部 I/O 操作（例如从网络连接读取数据）不属于持久阻塞行为。&lt;/p&gt;&#xA;&lt;p&gt;网络读取操作可能会被来自测试 &lt;strong&gt;bubble&lt;/strong&gt; 外部的写入操作解除阻塞，甚至可能来自其他进程。即使某个网络连接的唯一写入方也位于同一个测试 &lt;strong&gt;bubble&lt;/strong&gt; 内，运行时系统仍然无法区分以下两种情况：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;连接正在等待更多数据到达&lt;/li&gt;&#xA;&lt;li&gt;内核已经接收到数据但正在传递过程中&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;使用 synctest 测试网络服务器或客户端时，通常需要提供模拟网络实现。例如，&lt;a href=&#34;https://go.dev/pkg/net#Pipe&#34;&gt;net.Pipe&lt;/a&gt; 函数可以创建一对使用内存网络连接的 &lt;code&gt;net.Conn&lt;/code&gt;，这些连接可用于 synctest 测试。&lt;/p&gt;&#xA;&lt;h2&gt;Bubble 生命周期&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;Run&lt;/code&gt; 函数会在一个新的 &lt;strong&gt;bubble&lt;/strong&gt; 中启动 goroutine。该函数会在以下两种情况下返回：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;当 &lt;strong&gt;bubble&lt;/strong&gt; 内的所有 goroutine 都退出时&lt;/li&gt;&#xA;&lt;li&gt;如果 &lt;strong&gt;bubble&lt;/strong&gt; 进入持久阻塞状态且无法通过时间推进来解除阻塞，则会触发 panic&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;由于 Run 函数要求 &lt;strong&gt;bubble&lt;/strong&gt; 的所有 goroutine 都必须退出后才能返回，这意味着测试代码必须特别注意：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;在测试完成前清理所有后台 goroutine&lt;/li&gt;&#xA;&lt;li&gt;确保没有 goroutine 被意外泄漏&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;测试含有网络的操作的代码&lt;/h2&gt;&#xA;&lt;p&gt;让我们看另一个示例，这次使用 &lt;code&gt;testing/synctest&lt;/code&gt; 包来测试网络程序。在这个示例中，我们将测试 &lt;code&gt;net/http&lt;/code&gt; 包对 &lt;code&gt;100 Continue&lt;/code&gt; 响应的处理。&lt;/p&gt;&#xA;&lt;p&gt;发送请求的 HTTP 客户端可以包含 &amp;quot;Expect: 100-continue&amp;quot; 头，告诉服务器客户端有额外的数据要发送。然后，服务器可能会响应 &lt;code&gt;100 Continue&lt;/code&gt; 信息性响应以请求剩余的请求内容，或者用其他状态码告诉客户端不需要内容。例如，上传大文件的客户端可以使用此功能在发送文件前确认服务器是否愿意接收该文件。&lt;/p&gt;&#xA;&lt;p&gt;我们的测试将验证：当发送 &amp;quot;Expect: 100-continue&amp;quot; 头时，HTTP 客户端不会在服务器请求前发送请求内容，并且在收到 &lt;code&gt;100 Continue&lt;/code&gt; 响应后会发送内容。&lt;/p&gt;&#xA;&lt;p&gt;通常，测试通信的客户端和服务器可以使用环回网络连接。然而，在使用 &lt;code&gt;testing/synctest&lt;/code&gt; 时，我们通常希望使用模拟网络连接，以便检测所有 goroutine 何时在网络操作上阻塞。我们将通过创建一个使用 &lt;a href=&#34;https://go.dev/pkg/net#Pipe&#34;&gt;net.Pipe&lt;/a&gt; 创建的内存网络连接的 &lt;code&gt;http.Transport&lt;/code&gt;(HTTP 客户端)来开始这个测试。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func Test(t *testing.T) {&#xA;    synctest.Run(func() {&#xA;        srvConn, cliConn := net.Pipe()&#xA;        defer srvConn.Close()&#xA;        defer cliConn.Close()&#xA;        tr := &amp;amp;http.Transport{&#xA;            DialContext: func(ctx context.Context, network, address string) (net.Conn, error) {&#xA;                return cliConn, nil&#xA;            },&#xA;            // 设置非零超时时间会启用&amp;quot;Expect: 100-continue&amp;quot;处理机制&#xA;            // 由于后续测试中没有使用 sleep 操作&#xA;            // 即使在运行缓慢的机器上测试耗时较长&#xA;            // 也不会触发这个超时条件&#xA;            ExpectContinueTimeout: 5 * time.Second,&#xA;        }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们通过这个 &lt;code&gt;transport&lt;/code&gt; 发送一个设置了&amp;quot;Expect: 100-continue&amp;quot;请求头的请求。该请求在一个新的 goroutine 中发送，因为它要到测试结束时才会完成。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;        body := &amp;quot;request body&amp;quot;&#xA;        go func() {&#xA;            req, _ := http.NewRequest(&amp;quot;PUT&amp;quot;, &amp;quot;http://test.tld/&amp;quot;, strings.NewReader(body))&#xA;            req.Header.Set(&amp;quot;Expect&amp;quot;, &amp;quot;100-continue&amp;quot;)&#xA;            resp, err := tr.RoundTrip(req)&#xA;            if err != nil {&#xA;                t.Errorf(&amp;quot;RoundTrip: unexpected error %v&amp;quot;, err)&#xA;            } else {&#xA;                resp.Body.Close()&#xA;            }&#xA;        }()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们读取客户端发送的请求头信息。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;        req, err := http.ReadRequest(bufio.NewReader(srvConn))&#xA;        if err != nil {&#xA;            t.Fatalf(&amp;quot;ReadRequest: %v&amp;quot;, err)&#xA;        }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;现在进入测试的核心部分：我们需要确认客户端此时尚未发送请求体内容。&lt;/p&gt;&#xA;&lt;p&gt;我们启动一个新的 goroutine，将发送给服务器的请求体内容复制到 &lt;code&gt;strings.Builder&lt;/code&gt; 中，等待 &lt;strong&gt;bubble&lt;/strong&gt; 中的所有 goroutine 进入阻塞状态，然后验证此时尚未从请求体中读取到任何数据。&lt;/p&gt;&#xA;&lt;p&gt;如果忘记调用 &lt;code&gt;synctest.Wait&lt;/code&gt;，竞态检测器会正确报告存在数据竞争，但加入了 &lt;code&gt;Wait&lt;/code&gt; 调用后就能保证测试的安全性。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;        var gotBody strings.Builder&#xA;        go io.Copy(&amp;amp;gotBody, req.Body)&#xA;        synctest.Wait()&#xA;        if got := gotBody.String(); got != &amp;quot;&amp;quot; {&#xA;            t.Fatalf(&amp;quot;before sending 100 Continue, unexpectedly read body: %q&amp;quot;, got)&#xA;        }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们向客户端写入&amp;quot;100 Continue&amp;quot;响应，并验证此时客户端已开始发送请求体数据。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;        srvConn.Write([]byte(&amp;quot;HTTP/1.1 100 Continue\r\n\r\n&amp;quot;))&#xA;        synctest.Wait()&#xA;        if got := gotBody.String(); got != body {&#xA;            t.Fatalf(&amp;quot;after sending 100 Continue, read body %q, want %q&amp;quot;, got, body)&#xA;        }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;最后，我们发送&amp;quot;200 OK&amp;quot;响应来完成此次请求处理。&lt;/p&gt;&#xA;&lt;p&gt;在本测试过程中，我们启动了多个 goroutine。&lt;code&gt;synctest.Run&lt;/code&gt; 调用将等待所有 goroutine 退出后才会返回。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;        srvConn.Write([]byte(&amp;quot;HTTP/1.1 200 OK\r\n\r\n&amp;quot;))&#xA;    })&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;该测试可轻松扩展以验证其他行为，例如：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;当服务器未要求时，确保请求体不会被发送。&lt;/li&gt;&#xA;&lt;li&gt;当服务器未在超时时间内响应时，确保请求体会被正常发送。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/08/15/go-testing-synctest/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Go JSON 进化：从 v1 到 v2</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/08/14/go-json-v2/</id>
    <content type="html">&lt;p&gt;Go 1.25 带来了一个实验性的新 JSON 包 &lt;code&gt;encoding/json/v2&lt;/code&gt;。它提供了改进的 API、更好的性能以及向后兼容的迁移路径。&lt;/p&gt;&#xA;&lt;p&gt;要尝试新的 JSON 包，你需要：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Go 1.25&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;GOEXPERIMENT=jsonv2&lt;/code&gt; 环境变量&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;让我们探索主要功能和改进。&lt;/p&gt;&#xA;&lt;h2&gt;基本用法&lt;/h2&gt;&#xA;&lt;p&gt;基本的编码和解码操作看起来很熟悉：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main&#xA;&#xA;import (&#xA;    &amp;quot;fmt&amp;quot;&#xA;    jsonv2 &amp;quot;encoding/json/v2&amp;quot;&#xA;)&#xA;&#xA;type Person struct {&#xA;    Name string `json:&amp;quot;name&amp;quot;`&#xA;    Age  int    `json:&amp;quot;age&amp;quot;`&#xA;}&#xA;&#xA;func main() {&#xA;    // 编码&#xA;    p := Person{Name: &amp;quot;Alice&amp;quot;, Age: 30}&#xA;    data, err := jsonv2.Marshal(p)&#xA;    if err != nil {&#xA;        panic(err)&#xA;    }&#xA;    fmt.Println(string(data)) // {&amp;quot;name&amp;quot;:&amp;quot;Alice&amp;quot;,&amp;quot;age&amp;quot;:30}&#xA;&#xA;    // 解码&#xA;    var p2 Person&#xA;    err = jsonv2.Unmarshal(data, &amp;amp;p2)&#xA;    if err != nil {&#xA;        panic(err)&#xA;    }&#xA;    fmt.Printf(&amp;quot;%+v\n&amp;quot;, p2) // {Name:Alice Age:30}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;MarshalWrite 和 UnmarshalRead&lt;/h2&gt;&#xA;&lt;p&gt;新包引入了流式接口，允许直接向/从 &lt;code&gt;io.Writer&lt;/code&gt; 和 &lt;code&gt;io.Reader&lt;/code&gt; 进行编码/解码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import (&#xA;    &amp;quot;bytes&amp;quot;&#xA;    &amp;quot;strings&amp;quot;&#xA;    jsonv2 &amp;quot;encoding/json/v2&amp;quot;&#xA;)&#xA;&#xA;func main() {&#xA;    p := Person{Name: &amp;quot;Bob&amp;quot;, Age: 25}&#xA;    &#xA;    // 写入缓冲区&#xA;    var buf bytes.Buffer&#xA;    err := jsonv2.MarshalWrite(&amp;amp;buf, p, nil)&#xA;    if err != nil {&#xA;        panic(err)&#xA;    }&#xA;    &#xA;    // 从 reader 读取&#xA;    reader := strings.NewReader(buf.String())&#xA;    var p2 Person&#xA;    err = jsonv2.UnmarshalRead(reader, &amp;amp;p2, nil)&#xA;    if err != nil {&#xA;        panic(err)&#xA;    }&#xA;    &#xA;    fmt.Printf(&amp;quot;%+v\n&amp;quot;, p2) // {Name:Bob Age:25}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;MarshalEncode 和 UnmarshalDecode&lt;/h2&gt;&#xA;&lt;p&gt;对于更复杂的场景，新包提供了 &lt;code&gt;Encoder&lt;/code&gt; 和 &lt;code&gt;Decoder&lt;/code&gt; 类型：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import (&#xA;    &amp;quot;bytes&amp;quot;&#xA;    &amp;quot;strings&amp;quot;&#xA;    jsonv2 &amp;quot;encoding/json/v2&amp;quot;&#xA;)&#xA;&#xA;func main() {&#xA;    // 使用编码器&#xA;    var buf bytes.Buffer&#xA;    enc := jsonv2.NewEncoder(&amp;amp;buf)&#xA;    &#xA;    people := []Person{&#xA;        {Name: &amp;quot;Alice&amp;quot;, Age: 30},&#xA;        {Name: &amp;quot;Bob&amp;quot;, Age: 25},&#xA;    }&#xA;    &#xA;    for _, p := range people {&#xA;        err := enc.Encode(p)&#xA;        if err != nil {&#xA;            panic(err)&#xA;        }&#xA;    }&#xA;    &#xA;    // 使用解码器&#xA;    dec := jsonv2.NewDecoder(strings.NewReader(buf.String()))&#xA;    &#xA;    for {&#xA;        var p Person&#xA;        err := dec.Decode(&amp;amp;p)&#xA;        if err != nil {&#xA;            break // EOF 或其他错误&#xA;        }&#xA;        fmt.Printf(&amp;quot;%+v\n&amp;quot;, p)&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;选项&lt;/h2&gt;&#xA;&lt;p&gt;新包引入了灵活的选项系统来自定义编码/解码行为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import jsonv2 &amp;quot;encoding/json/v2&amp;quot;&#xA;&#xA;func main() {&#xA;    p := Person{Name: &amp;quot;Charlie&amp;quot;, Age: 35}&#xA;    &#xA;    // 使用选项进行美观打印&#xA;    data, err := jsonv2.Marshal(p, jsonv2.WithIndent(&amp;quot;&amp;quot;, &amp;quot;  &amp;quot;))&#xA;    if err != nil {&#xA;        panic(err)&#xA;    }&#xA;    &#xA;    fmt.Println(string(data))&#xA;    // {&#xA;    //   &amp;quot;name&amp;quot;: &amp;quot;Charlie&amp;quot;,&#xA;    //   &amp;quot;age&amp;quot;: 35&#xA;    // }&#xA;    &#xA;    // 严格解码 - 拒绝未知字段&#xA;    jsonStr := `{&amp;quot;name&amp;quot;:&amp;quot;David&amp;quot;,&amp;quot;age&amp;quot;:40,&amp;quot;unknown&amp;quot;:&amp;quot;field&amp;quot;}`&#xA;    var p2 Person&#xA;    err = jsonv2.Unmarshal([]byte(jsonStr), &amp;amp;p2, jsonv2.WithRejectUnknownMembers(true))&#xA;    if err != nil {&#xA;        fmt.Printf(&amp;quot;错误: %v\n&amp;quot;, err) // 错误: 未知字段 &amp;quot;unknown&amp;quot;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;标签&lt;/h2&gt;&#xA;&lt;p&gt;v2 包增强了对结构体标签的支持：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Product struct {&#xA;    ID    int     `json:&amp;quot;id&amp;quot;`&#xA;    Name  string  `json:&amp;quot;name&amp;quot;`&#xA;    Price float64 `json:&amp;quot;price,omitempty&amp;quot;`&#xA;    Tags  []string `json:&amp;quot;tags,omitzero&amp;quot;`&#xA;}&#xA;&#xA;func main() {&#xA;    // omitempty: 省略空值&#xA;    p1 := Product{ID: 1, Name: &amp;quot;Widget&amp;quot;}&#xA;    data1, _ := jsonv2.Marshal(p1)&#xA;    fmt.Println(string(data1)) // {&amp;quot;id&amp;quot;:1,&amp;quot;name&amp;quot;:&amp;quot;Widget&amp;quot;}&#xA;    &#xA;    // omitzero: 省略零值&#xA;    p2 := Product{ID: 2, Name: &amp;quot;Gadget&amp;quot;, Tags: []string{}}&#xA;    data2, _ := jsonv2.Marshal(p2)&#xA;    fmt.Println(string(data2)) // {&amp;quot;id&amp;quot;:2,&amp;quot;name&amp;quot;:&amp;quot;Gadget&amp;quot;}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;自定义编组&lt;/h2&gt;&#xA;&lt;p&gt;新包为自定义编组提供了改进的接口：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import (&#xA;    &amp;quot;time&amp;quot;&#xA;    jsonv2 &amp;quot;encoding/json/v2&amp;quot;&#xA;)&#xA;&#xA;type CustomTime struct {&#xA;    time.Time&#xA;}&#xA;&#xA;func (ct CustomTime) MarshalJSONV2(enc *jsonv2.Encoder, opts jsonv2.Options) error {&#xA;    return enc.WriteString(ct.Format(&amp;quot;2006-01-02&amp;quot;))&#xA;}&#xA;&#xA;func (ct *CustomTime) UnmarshalJSONV2(dec *jsonv2.Decoder, opts jsonv2.Options) error {&#xA;    str, err := dec.ReadString()&#xA;    if err != nil {&#xA;        return err&#xA;    }&#xA;    &#xA;    t, err := time.Parse(&amp;quot;2006-01-02&amp;quot;, str)&#xA;    if err != nil {&#xA;        return err&#xA;    }&#xA;    &#xA;    ct.Time = t&#xA;    return nil&#xA;}&#xA;&#xA;type Event struct {&#xA;    Name string     `json:&amp;quot;name&amp;quot;`&#xA;    Date CustomTime `json:&amp;quot;date&amp;quot;`&#xA;}&#xA;&#xA;func main() {&#xA;    e := Event{&#xA;        Name: &amp;quot;Meeting&amp;quot;,&#xA;        Date: CustomTime{time.Date(2025, 6, 22, 0, 0, 0, 0, time.UTC)},&#xA;    }&#xA;    &#xA;    data, err := jsonv2.Marshal(e)&#xA;    if err != nil {&#xA;        panic(err)&#xA;    }&#xA;    &#xA;    fmt.Println(string(data)) // {&amp;quot;name&amp;quot;:&amp;quot;Meeting&amp;quot;,&amp;quot;date&amp;quot;:&amp;quot;2025-06-22&amp;quot;}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;默认行为&lt;/h2&gt;&#xA;&lt;p&gt;v2 包改变了一些默认行为：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;字符串值中的 HTML 字符默认不再被转义&lt;/li&gt;&#xA;&lt;li&gt;更严格的数字解析&lt;/li&gt;&#xA;&lt;li&gt;改进的错误消息，提供更好的上下文&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Config struct {&#xA;    HTML string `json:&amp;quot;html&amp;quot;`&#xA;}&#xA;&#xA;func main() {&#xA;    c := Config{HTML: &amp;quot;&amp;lt;script&amp;gt;alert(&#39;hello&#39;)&amp;lt;/script&amp;gt;&amp;quot;}&#xA;    &#xA;    // v1 会转义 &amp;lt; &amp;gt; &amp;amp;&#xA;    // v2 默认不转义&#xA;    data, _ := jsonv2.Marshal(c)&#xA;    fmt.Println(string(data)) // {&amp;quot;html&amp;quot;:&amp;quot;&amp;lt;script&amp;gt;alert(&#39;hello&#39;)&amp;lt;/script&amp;gt;&amp;quot;}&#xA;    &#xA;    // 如果需要转义，使用选项&#xA;    dataEscaped, _ := jsonv2.Marshal(c, jsonv2.WithEscapeHTML(true))&#xA;    fmt.Println(string(dataEscaped)) // {&amp;quot;html&amp;quot;:&amp;quot;\u003cscript\u003ealert(&#39;hello&#39;)\u003c/script\u003e&amp;quot;}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;性能&lt;/h2&gt;&#xA;&lt;p&gt;新包提供了显著的性能改进，特别是在反编组操作方面：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;反编组速度提升高达 2-3 倍&lt;/li&gt;&#xA;&lt;li&gt;更少的内存分配&lt;/li&gt;&#xA;&lt;li&gt;更好的缓存局部性&lt;/li&gt;&#xA;&lt;li&gt;改进的大型数据集处理&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;迁移&lt;/h2&gt;&#xA;&lt;p&gt;从 v1 迁移到 v2 通常很简单：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;将导入从 &lt;code&gt;&amp;quot;encoding/json&amp;quot;&lt;/code&gt; 更改为 &lt;code&gt;jsonv2 &amp;quot;encoding/json/v2&amp;quot;&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;如果有的话，更新自定义编组接口&lt;/li&gt;&#xA;&lt;li&gt;测试并调整任何依赖于更改的默认行为的代码&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;新包设计为大多数现有代码的直接替代品，只需要最少的更改。&lt;/p&gt;&#xA;&lt;h2&gt;结论&lt;/h2&gt;&#xA;&lt;p&gt;Go 的新 JSON v2 包代表了 JSON 处理的重大改进，提供了：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;更好的性能&lt;/li&gt;&#xA;&lt;li&gt;更灵活的 API&lt;/li&gt;&#xA;&lt;li&gt;改进的流式支持&lt;/li&gt;&#xA;&lt;li&gt;增强的自定义选项&lt;/li&gt;&#xA;&lt;li&gt;向后兼容的迁移路径&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;虽然仍然是实验性的，但 JSON v2 有望成为 Go 生态系统中 JSON 处理的新标准。随着 Go 1.25 发布，现在是探索这些新功能并为迁移做准备的绝佳时机。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/08/14/go-json-v2/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>星云跳动</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/08/06/nebula-dance/</id>
    <content type="html">&lt;p&gt;开源一个动态星云生成软件。&lt;/p&gt;&#xA;&lt;h2&gt;源码&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/lyyyuna/NebulaDance&#34;&gt;https://github.com/lyyyuna/NebulaDance&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2&gt;下载链接&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;&lt;strong&gt;平台&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;链接&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Mac&lt;/td&gt;&#xA;&lt;td&gt;&lt;a href=&#34;https://analytics.lyyyuna.com/v1/download/ws3JiR5g3YYUTISg&#34;&gt;点击下载&lt;/a&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2&gt;软件截图&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/tianwen/2025/nebula-dance.png&#34; alt=&#34;图片&#34;&gt;&lt;/p&gt;&#xA;&lt;h2&gt;使用视频&lt;/h2&gt;&#xA;&lt;iframe src=&#34;//player.bilibili.com/player.html?isOutside=true&amp;aid=114976744413356&amp;bvid=BV1Cf4Rz1EeN&amp;cid=31508072263&amp;p=1&#34; scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34; width=&#34;800&#34; height=&#34;600&#34;&gt;&lt;/iframe&gt;</content>
    <link href="https://www.lyyyuna.com/2025/08/06/nebula-dance/" rel="alternate"></link>
    <summary type="html">开源一个动态星云生成软件</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>监督树和应用程序</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/07/25/elixir-beginner-2/</id>
    <content type="html">&lt;p&gt;在上一章关于 &lt;code&gt;GenServer&lt;/code&gt; 的内容中，我们实现了 &lt;code&gt;KV.Registry&lt;/code&gt; 来管理 bucket 。在某个时刻，我们开始监控这些 bucket，这样当 &lt;code&gt;KV.Bucket&lt;/code&gt; 进程崩溃时，我们就能采取相应的措施。虽然这个改动相对较小，但它引入了一个经常被 Elixir 开发者问到的问题：故障时会发生什么？&lt;/p&gt;&#xA;&lt;p&gt;在我们添加监控之前，如果一个 bucket 崩溃了，注册表(&lt;code&gt;registry&lt;/code&gt;)会永远指向一个已经不存在的 bucket 。如果用户试图读取或写入这个已崩溃的 bucket ，操作将会失败。任何尝试用相同名称创建新 bucket 的操作都只会返回已崩溃 bucket 的 PID。换句话说，该 bucket 在注册表中的条目将永远处于错误状态。一旦我们添加了监控，注册表会自动移除已崩溃 bucket 的条目。现在尝试查找已崩溃的 bucket 时，会提示该 bucket 不存在，系统用户可以根据需要成功创建一个新的 bucket 。&lt;/p&gt;&#xA;&lt;p&gt;在实践中，我们并不期望作为 bucket 的进程会失败。但如果确实发生了故障，无论出于什么原因，我们都可以确信系统将继续按预期工作。&lt;/p&gt;&#xA;&lt;p&gt;如果你有编程经验，你可能会想知道：我们能否从一开始就保证 bucket 不会崩溃？正如我们将看到的，Elixir 开发者倾向于将这类实践称为&amp;quot;防御性编程&amp;quot;。这是因为一个在线生产系统有数不清的原因可能导致出错。磁盘可能故障，内存可能损坏，出现 bug，网络可能中断一秒等等。如果我们编写软件试图保护或规避所有这些错误，那么我们花在处理故障上的时间将超过编写自己软件的时间！&lt;/p&gt;&#xA;&lt;p&gt;因此，Elixir 开发者更倾向于&lt;strong&gt;让它崩溃&lt;/strong&gt;或&lt;strong&gt;快速失败&lt;/strong&gt;。而从故障中恢复的最常见方式之一就是重新启动系统中崩溃的部分。&lt;/p&gt;&#xA;&lt;p&gt;例如，想象你的电脑、路由器、打印机或任何设备工作不正常。你有多少次通过重启来修复它？一旦我们重启设备，就将设备重置回初始状态，这是经过充分测试并保证能正常工作的状态。在 Elixir 中，我们将同样的方法应用于软件：每当一个进程崩溃时，我们就启动一个新进程来执行与崩溃进程相同的工作。&lt;/p&gt;&#xA;&lt;p&gt;在 Elixir 中，这是通过**监督者(Supervisor)**来实现的。监督者是一个进程，它监督其他进程并在它们崩溃时重新启动它们。为此，监督者管理任何被监督进程的整个生命周期，包括启动和关闭。&lt;/p&gt;&#xA;&lt;p&gt;在本文中，我们将学习如何通过监督 &lt;code&gt;KV.Registry&lt;/code&gt; 进程来将这些概念付诸实践。毕竟，如果注册表出了问题，整个注册表都会丢失，任何 bucket 都无法被找到！为了解决这个问题，我们将定义一个 &lt;code&gt;KV.Supervisor&lt;/code&gt; 模块，保证我们的 &lt;code&gt;KV.Registry&lt;/code&gt; 在任何时刻都能正常运行。&lt;/p&gt;&#xA;&lt;p&gt;在本文的最后，我们还将讨论&lt;strong&gt;应用程序(Applications)&lt;/strong&gt;。正如我们将看到的，Mix 一直在将我们所有的代码打包成一个应用程序，我们将学习如何自定义我们的应用程序，以保证每当系统启动时，我们的监督者和注册表都能正常运行。&lt;/p&gt;&#xA;&lt;h2&gt;第一个监督者&lt;/h2&gt;&#xA;&lt;p&gt;监督者是一个监督其他进程的进程，我们称之为子进程。监督一个进程包括三个不同的职责。首先是启动子进程。一旦子进程开始运行，监督者可能会重启子进程，要么因为它异常终止，要么因为达到了某种条件。例如，如果任何子进程死亡，监督者可能会重启所有子进程。最后，当系统关闭时，监督者还负责关闭子进程。请参阅 &lt;a href=&#34;https://hexdocs.pm/elixir/Supervisor.html&#34;&gt;Supervisor&lt;/a&gt; 模块以获得更深入的讨论。&lt;/p&gt;&#xA;&lt;p&gt;创建一个监督者与创建 &lt;code&gt;GenServer&lt;/code&gt; 没有多大区别。我们将在 &lt;code&gt;lib/kv/supervisor.ex&lt;/code&gt; 文件中定义一个名为 &lt;code&gt;KV.Supervisor&lt;/code&gt; 的模块，它将使用 &lt;code&gt;Supervisor&lt;/code&gt; 的 &lt;code&gt;behaviour&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;defmodule KV.Supervisor do&#xA;  use Supervisor&#xA;&#xA;  def start_link(opts) do&#xA;    Supervisor.start_link(__MODULE__, :ok, opts)&#xA;  end&#xA;&#xA;  @impl true&#xA;  def init(:ok) do&#xA;    children = [&#xA;      KV.Registry&#xA;    ]&#xA;&#xA;    Supervisor.init(children, strategy: :one_for_one)&#xA;  end&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;到目前为止，我们的监督者只有一个子进程：&lt;code&gt;KV.Registry&lt;/code&gt;。在我们定义了子进程列表后，我们调用 &lt;code&gt;Supervisor.init/2&lt;/code&gt;，传入子进程列表和监督策略。&lt;/p&gt;&#xA;&lt;p&gt;监督策略决定了当其中一个子进程崩溃时会发生什么。&lt;code&gt;:one_for_one&lt;/code&gt; 意味着如果一个子进程死亡，只有它会被重启。由于我们现在只有一个子进程，这就足够了。&lt;code&gt;Supervisor&lt;/code&gt; 的 &lt;code&gt;behaviour&lt;/code&gt; 支持几种策略，我们将在本文中讨论它们。&lt;/p&gt;&#xA;&lt;p&gt;一旦监督者启动，它将遍历子进程列表，并在每个模块上调用 &lt;code&gt;child_spec/1&lt;/code&gt; 函数。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;child_spec/1&lt;/code&gt; 函数返回子进程规范，该规范描述了如何启动进程、进程是工作者还是监督者、进程是临时的、瞬态的还是永久的等等。当我们使用 &lt;code&gt;Agent&lt;/code&gt;、&lt;code&gt;use GenServer&lt;/code&gt;、&lt;code&gt;use Supervisor&lt;/code&gt; 等时，&lt;code&gt;child_spec/1&lt;/code&gt; 函数会自动定义。让我们在终端中用 &lt;code&gt;iex -S mix&lt;/code&gt; 试试看：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;iex&amp;gt; KV.Registry.child_spec([])&#xA;%{id: KV.Registry, start: {KV.Registry, :start_link, [[]]}}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在我们继续本指南的过程中，我们将学习这些细节。如果你想提前了解，可以查看 &lt;a href=&#34;https://hexdocs.pm/elixir/Supervisor.html&#34;&gt;Supervisor&lt;/a&gt; 文档。&lt;/p&gt;&#xA;&lt;p&gt;在监督者检索到所有子进程规范后，它会按照定义的顺序，使用子进程规范中 &lt;code&gt;:start&lt;/code&gt; 键的信息，逐个启动其子进程。对于我们当前的规范，它将调用 &lt;code&gt;KV.Registry.start_link([])&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;让我们来试用一下这个监督者：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;iex&amp;gt; {:ok, sup} = KV.Supervisor.start_link([])&#xA;{:ok, #PID&amp;lt;0.148.0&amp;gt;}&#xA;iex&amp;gt; Supervisor.which_children(sup)&#xA;[{KV.Registry, #PID&amp;lt;0.150.0&amp;gt;, :worker, [KV.Registry]}]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;到目前为止，我们已经启动了监督者并列出了它的子进程。一旦监督者启动，它也启动了所有的子进程。&lt;/p&gt;&#xA;&lt;p&gt;如果我们故意让监督者启动的注册表崩溃会发生什么？让我们通过在调用时发送一个错误的输入来实现：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;iex&amp;gt; [{_, registry, _, _}] = Supervisor.which_children(sup)&#xA;[{KV.Registry, #PID&amp;lt;0.150.0&amp;gt;, :worker, [KV.Registry]}]&#xA;iex&amp;gt; GenServer.call(registry, :bad_input)&#xA;08:52:57.311 [error] GenServer #PID&amp;lt;0.150.0&amp;gt; terminating&#xA;** (FunctionClauseError) no function clause matching in KV.Registry.handle_call/3&#xA;iex&amp;gt; Supervisor.which_children(sup)&#xA;[{KV.Registry, #PID&amp;lt;0.157.0&amp;gt;, :worker, [KV.Registry]}]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;注意，当我们由于错误输入导致注册表崩溃后，监督者如何自动启动了一个新的注册表，使用新的 PID 来替代第一个注册表。&lt;/p&gt;&#xA;&lt;p&gt;在前面的章节中，我们总是直接启动进程。例如，我们会调用 &lt;code&gt;KV.Registry.start_link([])&lt;/code&gt;，它会返回 &lt;code&gt;{:ok, pid}&lt;/code&gt;，这样我们就可以通过 PID 与注册表进行交互。现在进程是由监督者启动的，我们必须直接询问监督者它的子进程是谁，并从返回的子进程列表中获取 PID。在实践中，每次都这样做会非常昂贵。为了解决这个问题，我们经常给进程命名，允许它们在单台机器上从我们代码的任何地方被唯一标识。&lt;/p&gt;&#xA;&lt;p&gt;让我们学习如何做到这一点。&lt;/p&gt;&#xA;&lt;h2&gt;给进程命名&lt;/h2&gt;&#xA;&lt;p&gt;虽然我们的应用程序会有很多 bucket ，但它只会有一个注册表。因此，每当我们启动注册表时，我们想要给它一个唯一的名称，这样我们就可以从任何地方访问它。我们通过向 &lt;code&gt;KV.Registry.start_link/1&lt;/code&gt; 传递 &lt;code&gt;:name&lt;/code&gt; 选项来实现这一点。&lt;/p&gt;&#xA;&lt;p&gt;让我们稍微改变一下子进程的定义（在 &lt;code&gt;KV.Supervisor.init/1&lt;/code&gt; 中），使用元组列表而不是 atom 列表：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;  def init(:ok) do&#xA;    children = [&#xA;      {KV.Registry, name: KV.Registry}&#xA;    ]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;通过这样做，监督者现在将通过调用 &lt;code&gt;KV.Registry.start_link(name: KV.Registry)&lt;/code&gt; 来启动 &lt;code&gt;KV.Registry&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;如果你重新查看 &lt;code&gt;KV.Registry.start_link/1&lt;/code&gt; 的实现，你会记得它只是将选项传递给 &lt;code&gt;GenServer&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;  def start_link(opts) do&#xA;    GenServer.start_link(__MODULE__, :ok, opts)&#xA;  end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这反过来会用给定的名称注册进程。&lt;code&gt;:name&lt;/code&gt; 选项期望使用 atom 作为本地命名进程（本地命名意味着它在此机器上可用——还有其他选项，我们在这里不讨论）。由于模块标识符是 atom，我们可以用实现该进程的模块名来命名进程，前提是该名称只有一个进程。这在调试和检查系统时很有帮助。&lt;/p&gt;&#xA;&lt;p&gt;让我们在 &lt;code&gt;iex -S mix&lt;/code&gt; 中尝试更新后的监督者：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;iex&amp;gt; KV.Supervisor.start_link([])&#xA;{:ok, #PID&amp;lt;0.66.0&amp;gt;}&#xA;iex&amp;gt; KV.Registry.create(KV.Registry, &amp;quot;shopping&amp;quot;)&#xA;:ok&#xA;iex&amp;gt; KV.Registry.lookup(KV.Registry, &amp;quot;shopping&amp;quot;)&#xA;{:ok, #PID&amp;lt;0.70.0&amp;gt;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这次监督者启动了一个命名的注册表，使我们能够创建 bucket ，而无需显式地从监督者那里获取 PID。你也应该知道如何在不查找其 PID 的情况下再次使注册表崩溃：试试看吧。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;此时，你可能会想：是否也应该给 bucket 进程本地命名？记住 bucket 是根据用户输入动态启动的。由于本地名称必须是 atom，我们必须动态创建 atom，但这不是一个好主意，因为一旦定义了 atom，它永远不会被擦除或垃圾回收。这意味着，如果我们根据用户输入动态创建 atom，最终会耗尽内存（或者更准确地说，虚拟机会因为对 atom 数量设置了硬限制而崩溃）。正是这个限制促使我们创建了自己的注册表（或者使用 Elixir 内置的 Registry 模块的原因）。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;我们越来越接近一个完全工作的系统了。监督者会自动启动注册表。但是我们如何在系统启动时自动启动监督者呢？要回答这个问题，让我们来谈谈应用程序。&lt;/p&gt;&#xA;&lt;h2&gt;理解应用程序&lt;/h2&gt;&#xA;&lt;p&gt;我们一直以来都在一个应用程序中工作。每当我们更改文件并运行 &lt;code&gt;mix compile&lt;/code&gt; 时，我们都能在编译输出中看到 &lt;code&gt;Generated kv app&lt;/code&gt; 消息。&lt;/p&gt;&#xA;&lt;p&gt;我们可以在 &lt;code&gt;_build/dev/lib/kv/ebin/kv.app&lt;/code&gt; 找到生成的 &lt;code&gt;.app&lt;/code&gt; 文件。让我们看看它的内容：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;{application,kv,&#xA;             [{applications,[kernel,stdlib,elixir,logger]},&#xA;              {description,&amp;quot;kv&amp;quot;},&#xA;              {modules,[&#39;Elixir.KV&#39;,&#39;Elixir.KV.Bucket&#39;,&#39;Elixir.KV.Registry&#39;,&#xA;                        &#39;Elixir.KV.Supervisor&#39;]},&#xA;              {registered,[]},&#xA;              {vsn,&amp;quot;0.1.0&amp;quot;}]}.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这个文件包含 Erlang 项（使用 Erlang 语法编写）。尽管我们不熟悉 Erlang，但很容易猜到这个文件保存了我们的应用程序定义。它包含我们的应用程序版本、所有由它定义的模块，以及我们依赖的应用程序列表，如 Erlang 的 &lt;code&gt;kernel&lt;/code&gt;、&lt;code&gt;elixir&lt;/code&gt; 本身和 &lt;code&gt;logger&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;简而言之，一个应用程序由 &lt;code&gt;.app&lt;/code&gt; 文件中定义的所有模块组成，包括 &lt;code&gt;.app&lt;/code&gt; 文件本身。一个应用程序通常只有两个目录：&lt;code&gt;ebin&lt;/code&gt;，用于存放 Elixir 的编译产物，如 &lt;code&gt;.beam&lt;/code&gt; 和 &lt;code&gt;.app&lt;/code&gt; 文件；以及 &lt;code&gt;priv&lt;/code&gt;，存放应用程序可能需要的其他产物或资源文件。&lt;/p&gt;&#xA;&lt;p&gt;尽管 Mix 为我们生成并维护 &lt;code&gt;.app&lt;/code&gt; 文件，但我们可以通过在 &lt;code&gt;mix.exs&lt;/code&gt; 项目文件中的 &lt;code&gt;application/0&lt;/code&gt; 函数内添加新条目来自定义其内容。我们很快就会进行第一次自定义。&lt;/p&gt;&#xA;&lt;h2&gt;启动应用程序&lt;/h2&gt;&#xA;&lt;p&gt;我们系统中的每个应用程序都可以启动和停止。启动和停止应用程序的规则也在 &lt;code&gt;.app&lt;/code&gt; 文件中定义。当我们调用 &lt;code&gt;iex -S mix&lt;/code&gt; 时，Mix 会编译我们的应用程序然后启动它。&lt;/p&gt;&#xA;&lt;p&gt;让我们在实践中看看这一点。使用 &lt;code&gt;iex -S mix&lt;/code&gt; 启动一个控制台并尝试：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;iex&amp;gt; Application.start(:kv)&#xA;{:error, {:already_started, :kv}}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;哎呀，它已经启动了。Mix 会自动启动当前应用程序及其所有依赖项。对于 &lt;code&gt;mix test&lt;/code&gt; 和许多其他 Mix 命令也是如此。&lt;/p&gt;&#xA;&lt;p&gt;但是，我们可以停止我们的 &lt;code&gt;:kv&lt;/code&gt; 应用程序，以及 &lt;code&gt;:logger&lt;/code&gt; 应用程序：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;iex&amp;gt; Application.stop(:kv)&#xA;:ok&#xA;iex&amp;gt; Application.stop(:logger)&#xA;:ok&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;再次启动我们的应用程序：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;iex&amp;gt; Application.start(:kv)&#xA;{:error, {:not_started, :logger}}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;现在我们得到了一个错误，因为 &lt;code&gt;:kv&lt;/code&gt; 依赖的一个应用程序（在这个例子中是 &lt;code&gt;:logger&lt;/code&gt;）没有启动。我们需要按照正确的顺序手动启动每个应用程序，或者调用 &lt;code&gt;Application.ensure_all_started/1&lt;/code&gt;，如下所示：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;iex&amp;gt; Application.ensure_all_started(:kv)&#xA;{:ok, [:logger, :kv]}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在实践中，我们的工具总是为我们启动应用程序，但如果你需要细粒度的控制，也有相应的 API 可用。&lt;/p&gt;&#xA;&lt;h2&gt;应用程序回调&lt;/h2&gt;&#xA;&lt;p&gt;每当我们调用 &lt;code&gt;iex -S mix&lt;/code&gt; 时，Mix 会通过调用 &lt;code&gt;Application.start(:kv)&lt;/code&gt; 自动启动我们的应用程序。但是我们能自定义应用程序启动时发生的事情吗？事实上，我们可以！为此，我们得定义一个应用程序回调。&lt;/p&gt;&#xA;&lt;p&gt;首先是告诉我们的应用程序定义（例如，我们的 &lt;code&gt;.app&lt;/code&gt; 文件）哪个模块将实现应用程序回调。让我们打开 &lt;code&gt;mix.exs&lt;/code&gt; 并将 &lt;code&gt;def application&lt;/code&gt; 更改为以下内容：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;  def application do&#xA;    [&#xA;      extra_applications: [:logger],&#xA;      mod: {KV, []}&#xA;    ]&#xA;  end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;:mod&lt;/code&gt; 选项指定了“应用程序回调模块”，后面跟着在应用程序启动时要传递的参数。应用程序回调模块可以是任何实现了 &lt;code&gt;Application&lt;/code&gt; 行为的模块。&lt;/p&gt;&#xA;&lt;p&gt;要实现 &lt;code&gt;Application&lt;/code&gt; 行为，我们必须使用 &lt;code&gt;Application&lt;/code&gt; 并定义一个 &lt;code&gt;start/2&lt;/code&gt; 函数。&lt;code&gt;start/2&lt;/code&gt; 函数的目标是启动一个监督者，然后由该监督者启动任何子服务或执行我们的应用程序可能需要的任何其他代码。让我们利用这个机会来启动我们在本文之前实现的 &lt;code&gt;KV.Supervisor&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;由于我们已经指定 &lt;code&gt;KV&lt;/code&gt; 作为模块回调，让我们修改在 &lt;code&gt;lib/kv.ex&lt;/code&gt; 中定义的 &lt;code&gt;KV&lt;/code&gt; 模块来实现 &lt;code&gt;start/2&lt;/code&gt; 函数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;defmodule KV do&#xA;  use Application&#xA;&#xA;  @impl true&#xA;  def start(_type, _args) do&#xA;    # 我们不需要直接使用下面的监督者名称，但在调试或检查系统时，它可能很有用。&#xA;    KV.Supervisor.start_link(name: KV.Supervisor)&#xA;  end&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当我们使用 &lt;code&gt;Application&lt;/code&gt; 时，我们可以定义几个函数，类似于我们使用 &lt;code&gt;Supervisor&lt;/code&gt; 或 &lt;code&gt;GenServer&lt;/code&gt; 时。这次我们只需要定义一个 &lt;code&gt;start/2&lt;/code&gt; 函数。&lt;code&gt;Application&lt;/code&gt; 行为还有一个 &lt;code&gt;stop/1&lt;/code&gt; 回调，但在实践中很少使用。你可以查看文档获取更多信息。&lt;/p&gt;&#xA;&lt;p&gt;现在你已经定义了一个启动我们监督者的应用程序回调，我们期望一旦启动 &lt;code&gt;iex -S mix&lt;/code&gt;，&lt;code&gt;KV.Registry&lt;/code&gt; 进程就会上线并运行。让我们再试一次：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;iex&amp;gt; KV.Registry.create(KV.Registry, &amp;quot;shopping&amp;quot;)&#xA;:ok&#xA;iex&amp;gt; KV.Registry.lookup(KV.Registry, &amp;quot;shopping&amp;quot;)&#xA;{:ok, #PID&amp;lt;0.88.0&amp;gt;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;让我们回顾一下正在发生的事情。每当我们调用 &lt;code&gt;iex -S mix&lt;/code&gt; 时，它会通过调用 &lt;code&gt;Application.start(:kv)&lt;/code&gt; 自动启动我们的应用程序，然后调用应用程序回调。应用程序回调的任务是启动一个监督树。现在，我们的监督者有一个名为 &lt;code&gt;KV.Registry&lt;/code&gt; 的子进程，以 &lt;code&gt;KV.Registry&lt;/code&gt; 名称启动。我们的监督者可能还有其他子进程，其中一些子进程可能是它们自己的监督者，有自己的子进程，从而形成所谓的监督树。&lt;/p&gt;&#xA;&lt;h2&gt;项目还是应用程序？&lt;/h2&gt;&#xA;&lt;p&gt;Mix 区分项目和应用程序。根据我们的 &lt;code&gt;mix.exs&lt;/code&gt; 文件内容，我们可以说我们有一个定义了 &lt;code&gt;:kv&lt;/code&gt; 应用程序的 Mix 项目。正如我们将在后续章节中看到的，有些项目不定义任何应用程序。&lt;/p&gt;&#xA;&lt;p&gt;当我们说“项目”时，你应该想到 Mix。Mix 是管理你的项目的工具。它知道如何编译你的项目、测试你的项目等等。它还知道如何编译和启动与你的项目相关的应用程序。&lt;/p&gt;&#xA;&lt;p&gt;当我们谈论应用程序时，我们谈论的是 OTP。应用程序是运行时整体启动和停止的实体。你可以在 &lt;a href=&#34;https://hexdocs.pm/elixir/Application.html&#34;&gt;Application&lt;/a&gt; 模块的文档中了解更多关于应用程序以及它们如何与整个系统的启动和关闭相关联的信息。&lt;/p&gt;&#xA;&lt;h2&gt;下一步&lt;/h2&gt;&#xA;&lt;p&gt;虽然这是我们第一次实现监督者，但这不是我们第一次使用监督者！在上一篇文章中，当我们在测试中使用 &lt;code&gt;start_supervised!&lt;/code&gt; 启动注册表时，ExUnit 在框架自身管理的监督者下启动了注册表。通过定义我们自己的监督者，我们为如何在应用程序中初始化、关闭和监督进程提供了更多结构，使我们的生产代码和测试与最佳实践保持一致。&lt;/p&gt;&#xA;&lt;p&gt;但我们还没有完成。到目前为止，我们只是在监督注册表，但我们的应用程序也在启动 bucket 。由于 bucket 是动态启动的，我们可以使用一种特殊类型的监督者，称为 &lt;code&gt;DynamicSupervisor&lt;/code&gt;，它针对处理此类场景进行了优化。让我们在下一篇中继续探索。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/07/25/elixir-beginner-2/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Nest 初识</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/07/15/nest-init/</id>
    <content type="html">&lt;h1&gt;Nest 是啥？&lt;/h1&gt;&#xA;&lt;p&gt;Nest 是一个 nodejs 服务端应用程序开发框架，它有几个特点：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;内置支持 Typescript&lt;/li&gt;&#xA;&lt;li&gt;底层默认使用 Express 框架，也可以通过配置使用 Fastify&lt;/li&gt;&#xA;&lt;li&gt;核心思想是控制反转和依赖注入&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;下面我们先创建一个简单的 Nest 项目，通过项目了解 Nest 中的一些基本概念，最后再聊一聊核心思想控制反转（IoC）和依赖注入（DI）是咋回事。&lt;/p&gt;&#xA;&lt;h1&gt;创建项目与基本概念&lt;/h1&gt;&#xA;&lt;h2&gt;创建与启动&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;全局安装 @nestjs/cli&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;code&gt;pnpm i -g @nestjs/cli&lt;/code&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;通过 cli 创建项目&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;code&gt;nest new &amp;lt;project-name&amp;gt;&lt;/code&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;启动项目&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;code&gt;cd &amp;lt;project-name&amp;gt;&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;pnpm run start&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以看到项目已经成功运行起来了。&lt;/p&gt;&#xA;&lt;p&gt;![image](/imgrrr/Nest 指北系列/1.webp)&lt;/p&gt;&#xA;&lt;h2&gt;项目结构与基本概念&lt;/h2&gt;&#xA;&lt;p&gt;项目的核心结构如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;src&#xA;├── app.controller.spec.ts&#xA;├── app.controller.ts&#xA;├── app.module.ts&#xA;├── app.service.ts&#xA;├── main.ts&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;main&lt;/h3&gt;&#xA;&lt;p&gt;main 文件是应用程序的入口文件，其中通过 NestFactory.create 创建应用实例，然后监听端口。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import { NestFactory } from &amp;quot;@nestjs/core&amp;quot;;&#xA;import { AppModule } from &amp;quot;./app.module&amp;quot;;&#xA;&#xA;async function bootstrap() {&#xA;  const app = await NestFactory.create(AppModule);&#xA;  await app.listen(process.env.PORT ?? 3000);&#xA;}&#xA;bootstrap();&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;module&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;module 是使用 @Module 装饰器声明的类，其中可以注册其他 module、controller、provider ，也可以导出。&lt;/li&gt;&#xA;&lt;li&gt;Nest 中用模块来组织应用程序，每个应用至少需要一个根模块。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import { Module } from &amp;quot;@nestjs/common&amp;quot;;&#xA;import { AppController } from &amp;quot;./app.controller&amp;quot;;&#xA;import { AppService } from &amp;quot;./app.service&amp;quot;;&#xA;&#xA;@Module({&#xA;  imports: [],&#xA;  controllers: [AppController],&#xA;  providers: [AppService],&#xA;  exports: [],&#xA;})&#xA;export class AppModule {}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;controller&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;controller 是被 @Controller 装饰器声明的类。&lt;/li&gt;&#xA;&lt;li&gt;负责处理请求和响应，可以注入 provider，比如下面例子中创建了一个 Get 接口，其中依赖了 AppService。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import { Controller, Get } from &#39;@nestjs/common&#39;;&#xA;import { AppService } from &#39;./app.service&#39;;&#xA;&#xA;@Controller()&#xA;export class AppController {&#xA;  constructor(private readonly appService: AppService) {}&#xA;&#xA;  @Get(&amp;quot;/hello&amp;quot;)&#xA;  getHello(): string {&#xA;    return this.appService.getHello();&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;provider&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;provider 是被 @Injectable 装饰器声明的类。&lt;/li&gt;&#xA;&lt;li&gt;通常用于提供一些具体的功能实现，可以被注入到 controller 或者其他 provider 使用。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import { Injectable } from &amp;quot;@nestjs/common&amp;quot;;&#xA;&#xA;@Injectable()&#xA;export class AppService {&#xA;  getHello(): string {&#xA;    return &amp;quot;Hello World!&amp;quot;;&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;至此，Nest 应用程序对外提供了一个 /hello 接口，返回 &amp;quot;hello world!&amp;quot;，尝试 curl 调用：&lt;/p&gt;&#xA;&lt;p&gt;![image.png](/imgrrr/Nest 指北系列/2.webp)&lt;/p&gt;&#xA;&lt;h1&gt;控制反转和依赖注入&lt;/h1&gt;&#xA;&lt;p&gt;控制反转和依赖注入是 Nest 的核心思想，怎么理解呢？我们来举个 🌰。&lt;/p&gt;&#xA;&lt;h2&gt;传统写法的问题&lt;/h2&gt;&#xA;&lt;p&gt;一个应用程序的组织，本质上就是很多的类，互相调用来实现整体的功能。比如有两个低层类 Dog 和 Cat，用于创建猫和狗；有一个高层 Animal 类，依赖低层类去创建小动物。下面的写法中，直接在 Animal 中实例化 Dog 类并创建了一只小狗。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;class Dog {&#xA;    create() {&#xA;        console.log(&amp;quot;create a dog, wangwang～&amp;quot;)&#xA;    }&#xA;}&#xA;&#xA;class Cat {&#xA;    create() {&#xA;        console.log(&amp;quot;create a cat, miaomiao~&amp;quot;)&#xA;    }&#xA;}&#xA;&#xA;class Animal {&#xA;    private dog = new Dog()&#xA;    create() {&#xA;        this.dog.create()&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这个写法会有什么问题呢？思考一下：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;假如需求改变，不想让 Animal 创建一只小狗而是想创建一只小猫，那么需要改变 Animal 类的实现，如果想创建其他小动物就需要一次又一次的改变类的实现，&lt;code&gt;Animal 和它依赖的类产生了强耦合&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;class Animal {&#xA;    private cat = new Cat()&#xA;    create() {&#xA;        this.cat.create()&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;假如还有很多个 Animal2、Animal3 ......，它们都想要创建一只小狗，那么代码就变成下面这样，&lt;code&gt;Dog 需要被实例化很多次&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;class Animal {&#xA;    private dog = new Dog()&#xA;    create() {&#xA;        this.dog.create()&#xA;    }&#xA;}&#xA;&#xA;class Animal2 {&#xA;    private dog = new Dog()&#xA;    create() {&#xA;        this.dog.create()&#xA;    }&#xA;}&#xA;&#xA;class Animal3 {&#xA;    private dog = new Dog()&#xA;    create() {&#xA;        this.dog.create()&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当应用复杂度增加，类和类之间依赖关系复杂度也随之增加，这两个问题会变得越来越严重。&lt;/p&gt;&#xA;&lt;h2&gt;改进&lt;/h2&gt;&#xA;&lt;p&gt;那更好的写法是什么呢？当 Animal 类依赖 Dog 类时，可以不在 Animal 中直接创建 Dog 的实例，而是定义一套抽象接口，Animal 类和 Dog 类都依赖于这套抽象去实现，然后在外部工厂类中创建 Dog 实例传入 Animal。即: &lt;code&gt;Animal 不用关心实例如何创建，只需要按照抽象接口的规范去使用它即可&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;class Animal {&#xA;    private animal&#xA;    constructor(animal) {&#xA;        this.animal = animal&#xA;    }&#xA;    create() {&#xA;        this.animal.create()&#xA;    }&#xA;}&#xA;&#xA;class Animal2 {&#xA;    private animal&#xA;    constructor(animal) {&#xA;        this.animal = animal&#xA;    }&#xA;    create() {&#xA;        this.animal.create()&#xA;    }&#xA;}&#xA;&#xA;class Factory {&#xA;    create() {&#xA;        // 先创建一只狗&#xA;        const dog = new Dog()&#xA;        const dogAnimal = new Animal(dog)&#xA;        dogAnimal.create()&#xA;        // 再创建一只猫&#xA;        const cat = new Cat()&#xA;        const catAnimal = new Animal(cat)&#xA;        catAnimal.create()&#xA;        // Animal2 复用同一个 Dog 实例创建一只狗&#xA;        const animal2 = new Animal2(dog)&#xA;        animal2.create()&#xA;    }&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这样就解决了上面两个问题：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;当我们想从创建一只狗变为创建一只猫时，Animal 类的实现完全不需要改动。&lt;/li&gt;&#xA;&lt;li&gt;当多个 Animal 都想创建一只狗时，可以复用同一个实例。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;这个例子中，将类实例化的过程交给 IoC 容器（即 Factory 类）处理，就是&lt;strong&gt;控制反转（IoC）&lt;/strong&gt;；在类之外创建依赖对象并提供给类，就是&lt;strong&gt;依赖注入（DI）&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;h2&gt;Nest 中的 IoC&lt;/h2&gt;&#xA;&lt;p&gt;Nest 框架本身就是一个 IoC 容器，负责统一管理类的实例化以及注入，开发者不需要手动实例化，只需要向 IoC 容器拿实例化后的对象使用即可。这种将控制权交给框架的做法，有利于实现类和类之间的松耦合。&lt;/p&gt;&#xA;&lt;h3&gt;具体实现&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;module 中通过 @Module 装饰器注册依赖。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;通过 @Injectable 装饰器定义 provider，声明这个类被 IoC 容器接管，即实例化过程委托给 IoC 容器。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;controller 和 provider 中都可以通过 constructor 注入依赖关系。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;// test.module.ts&#xA;@Module({&#xA;    controllers: [TestController],&#xA;    providers: [TestService],&#xA;})&#xA;export class TestModule {}&#xA;&#xA;// test.service.ts&#xA;@Injectable()&#xA;export class TestService {&#xA;    constructor(private test2Service: Test2Service) {}&#xA;&#xA;    findAll() {}&#xA;}&#xA;&#xA;// test.controller.ts&#xA;@Controller(&#39;test&#39;)&#xA;export class TestController {&#xA;    // 注入对 TestService 的依赖&#xA;    constructor(private testService: TestService) {}&#xA;&#xA;    @Get()&#xA;    async findAll() {&#xA;        return this.testService.findAll();&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h1&gt;最后&lt;/h1&gt;&#xA;&lt;p&gt;至此，我们简单了解了 Nest 的几个基本概念 module、controller、provider，以及它的核心思想控制反转与依赖注入。此系列后续文章会更详细的介绍它的使用并对核心源码进行解析。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/07/15/nest-init/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Robot Framework 新版教程 - 测试数据语法</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/07/11/robotframework-new-tutorial-test-data-syntax/</id>
    <content type="html">&lt;p&gt;本文介绍了 Robot Framework 的测试数据语法，后续章节将详细讲解如何实际创建测试用例、测试套件等内容。虽然本节主要使用&amp;quot;测试&amp;quot;这一术语，但这些规则同样适用于创建任务。&lt;/p&gt;&#xA;&lt;h2&gt;文件和目录&lt;/h2&gt;&#xA;&lt;p&gt;构建测试用例的层次结构安排如下：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;测试用例创建在套件文件中。&lt;/li&gt;&#xA;&lt;li&gt;一个测试用例文件会自动创建一个包含该文件内所有测试用例的测试套件。&lt;/li&gt;&#xA;&lt;li&gt;包含测试用例文件的目录会形成一个更高层级的测试套件。此类套件目录的子测试套件即是由其中的测试用例文件生成的套件。&lt;/li&gt;&#xA;&lt;li&gt;测试套件目录也可以包含其他测试套件目录，并且这种层级结构可以根据需要无限嵌套。&lt;/li&gt;&#xA;&lt;li&gt;测试套件目录可以包含特殊的初始化文件，用于配置所创建的测试套件。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;除此之外，还包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;测试库（Test libraries） - 包含最底层的关键字&lt;/li&gt;&#xA;&lt;li&gt;资源文件（Resource files） - 存放变量及高层级用户关键字&lt;/li&gt;&#xA;&lt;li&gt;变量文件（Variable files） - 提供比资源文件更灵活的变量定义方式&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;测试用例文件、测试套件初始化文件和资源文件均采用 Robot Framework 测试数据语法编写。而测试库和变量文件则使用&amp;quot;真正的&amp;quot;编程语言（通常为 Python）创建。&lt;/p&gt;&#xA;&lt;h2&gt;测试数据 section&lt;/h2&gt;&#xA;&lt;p&gt;Robot Framework 测试数据通过以下不同 section（通常也称为表格）进行定义：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Settings&lt;/strong&gt;，导入测试库、资源文件和变量文件，为测试套件和测试用例定义元数据。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Variables&lt;/strong&gt;，定义可在测试数据其他位置使用的变量。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Test Cases&lt;/strong&gt;，从可用的关键字创建测试用例。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tasks&lt;/strong&gt;，从可用的关键字创建任务。单个文件只能包含测试或任务中的一种。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Keywords&lt;/strong&gt;，基于现有底层关键字创建用户关键字。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Comments&lt;/strong&gt;，附加注释或数据（Robot Framework 将忽略此内容）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;不同 section 通过其 header 行进行识别。推荐的 header 格式是 &lt;code&gt;** Settings **&lt;/code&gt;，但 header 不区分大小写，前后空格可选，且开头的星号数量可以变化（只要至少有一个星号）。例如，&lt;code&gt;*settings&lt;/code&gt; 也会被识别为 section header。&lt;/p&gt;&#xA;&lt;p&gt;Robot Framework 也支持单数形式的 header（如 *** Setting ***），但从 Robot Framework 6.0 开始该支持已被弃用。自 Robot Framework 7.0 起会显示弃用警告，最终将完全不再支持单数形式的 header。&lt;/p&gt;&#xA;&lt;p&gt;header 行除了实际的 section header 外，还可以包含其他内容。额外内容必须使用数据格式相关的分隔符（通常是两个或更多空格）与 section header 隔开。解析时会忽略这些额外内容，但可用于文档说明。这在采用数据驱动风格创建测试用例时特别有用。&lt;/p&gt;&#xA;&lt;p&gt;第一个 section 之前的所有数据都会被忽略。&lt;/p&gt;&#xA;&lt;h2&gt;支持的文件格式&lt;/h2&gt;&#xA;&lt;p&gt;Robot Framework 最常见的数据创建方式是采用空格分隔格式，其中数据单元（如关键字及其参数）之间用两个或更多空格分隔。另一种方式是使用管道分隔格式，其分隔符为带空格的管道符（ | ）。&lt;/p&gt;&#xA;&lt;p&gt;测试套件文件通常使用 &lt;code&gt;.robot&lt;/code&gt; 扩展名，但实际可解析的文件类型可配置。资源文件也可使用 &lt;code&gt;.robot&lt;/code&gt; 扩展名，但推荐使用专用的 &lt;code&gt;.resource&lt;/code&gt; 扩展名，未来可能强制要求使用该扩展名。包含非 ASCII 字符的文件必须使用 UTF-8 编码保存。&lt;/p&gt;&#xA;&lt;p&gt;Robot Framework 也支持 reStructuredText 文件，其中标准的 Robot Framework 数据被嵌入到代码块中。默认情况下，只有扩展名为 &lt;code&gt;.robot.rst&lt;/code&gt; 的文件会被解析。若希望使用 &lt;code&gt;.rst&lt;/code&gt; 或 &lt;code&gt;.rest&lt;/code&gt; 扩展名，需单独配置。&lt;/p&gt;&#xA;&lt;p&gt;Robot Framework 数据还可采用 JSON 格式创建，该格式主要面向工具开发者而非普通用户。默认情况下，只有使用自定义 &lt;code&gt;.rbt&lt;/code&gt; 扩展名的 JSON 文件会被解析。&lt;/p&gt;&#xA;&lt;p&gt;早期 Robot Framework 版本还支持 HTML 和 TSV 格式的数据。若数据与空格分隔格式兼容，TSV 格式仍可使用，但对 HTML 格式的支持已完全移除。若遇到此类数据文件，需将其转换为纯文本格式才能在 Robot Framework 3.2 或更新版本中使用。最简单的方法是使用 Tidy 工具，但必须使用 Robot Framework 3.1 附带的版本，因为更新版本已完全不支持 HTML 格式。&lt;/p&gt;&#xA;&lt;h3&gt;空格分隔的格式&lt;/h3&gt;&#xA;&lt;p&gt;当 Robot Framework 解析数据时，首先会将数据拆分成行，然后将每行拆分为多个标记（如关键字和参数）。在使用空格分隔格式时，标记之间的分隔符为两个及以上空格，或者一个及以上制表符。除普通的 ASCII 空格外，任何被视为空格的 Unicode 字符（如不间断空格）均可作为分隔符。只要保证至少有两个空格，用作分隔符的空格数量可以变化——这样在配置等场景中就能通过合理对齐数据来提升可读性。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Settings ***&#xA;Documentation     Example using the space separated format.&#xA;Library           OperatingSystem&#xA;&#xA;*** Variables ***&#xA;${MESSAGE}        Hello, world!&#xA;&#xA;*** Test Cases ***&#xA;My Test&#xA;    [Documentation]    Example test.&#xA;    Log    ${MESSAGE}&#xA;    My Keyword    ${CURDIR}&#xA;&#xA;Another Test&#xA;    Should Be Equal    ${MESSAGE}    Hello, world!&#xA;&#xA;*** Keywords ***&#xA;My Keyword&#xA;    [Arguments]    ${path}&#xA;    Directory Should Exist    ${path}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;由于制表符和连续空格均被视为分隔符，若需在关键字参数或实际数据中使用这些字符时，必须进行转义处理。可通过特殊转义语法实现，例如：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用 &lt;code&gt;\t&lt;/code&gt; 表示制表符&lt;/li&gt;&#xA;&lt;li&gt;使用 &lt;code&gt;\xA0&lt;/code&gt; 表示不间断空格&lt;/li&gt;&#xA;&lt;li&gt;使用内置变量 &lt;code&gt;${SPACE}&lt;/code&gt; 和 &lt;code&gt;${EMPTY}&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;管道分隔的格式&lt;/h3&gt;&#xA;&lt;p&gt;空格分隔格式的最大痛点在于：关键字与参数的视觉区分较为困难。当关键字需要接收大量参数，或参数本身包含空格时，这一问题尤为突出。此时采用管道分隔格式往往更优，因为管道符能提供更明显的视觉分隔效果。&lt;/p&gt;&#xA;&lt;p&gt;同一文件可同时包含空格分隔行和管道分隔行。管道分隔行通过行首强制的管道符识别（行尾管道符可选），除行首行尾外，每个管道符两侧必须至少保留一个空格或制表符。虽然不强制要求管道符纵向对齐，但保持对齐能显著提升代码可读性。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;| *** Settings ***   |&#xA;| Documentation      | Example using the pipe separated format.&#xA;| Library            | OperatingSystem&#xA;&#xA;| *** Variables ***  |&#xA;| ${MESSAGE}         | Hello, world!&#xA;&#xA;| *** Test Cases *** |                 |               |&#xA;| My Test            | [Documentation] | Example test. |&#xA;|                    | Log             | ${MESSAGE}    |&#xA;|                    | My Keyword      | ${CURDIR}     |&#xA;| Another Test       | Should Be Equal | ${MESSAGE}    | Hello, world!&#xA;&#xA;| *** Keywords ***   |                        |         |&#xA;| My Keyword         | [Arguments]            | ${path} |&#xA;|                    | Directory Should Exist | ${path} |&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在使用管道分隔格式时，参数内部的连续空格或制表符无需转义处理。同样，空列通常也无需转义——除非位于行末。但需特别注意：若实际测试数据中包含被空格包围的管道符（ | ），则必须使用反斜杠进行转义。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;| *** Test Cases *** |                 |                 |                      |&#xA;| Escaping Pipe      | ${file count} = | Execute Command | ls -1 *.txt \| wc -l |&#xA;|                    | Should Be Equal | ${file count}   | 42                   |&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;reStructuredText 格式&lt;/h3&gt;&#xA;&lt;p&gt;reStructuredText（reST）是一种易读的纯文本标记语法，常用于 Python 项目的文档编写，包括 Python 官方文档及本用户指南。reST 文档通常被编译为 HTML 格式，同时也支持其他输出格式。将 reST 与 Robot Framework 结合使用，既能编写格式丰富的文档，又能以简洁的文本格式保存测试数据，便于通过简易文本编辑器、差异比对工具和版本控制系统进行操作。&lt;/p&gt;&#xA;&lt;p&gt;在 Robot Framework 与 reStructuredText 文件结合使用时，常规的 Robot Framework 数据会被嵌入到所谓的代码块(code blocks)中。标准的 reST 代码块使用 &lt;code&gt;code&lt;/code&gt; 指令进行标记，但 Robot Framework 同时支持 &lt;a href=&#34;http://sphinx-doc.org/&#34;&gt;Sphinx&lt;/a&gt; 工具所使用的 &lt;code&gt;code-block&lt;/code&gt; 或 &lt;code&gt;sourcecode&lt;/code&gt; 指令格式。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;reStructuredText example&#xA;&#xA;&#xA;code 块之外的文字会被忽略。&#xA;&#xA;.. code:: robotframework&#xA;&#xA;   *** Settings ***&#xA;   Documentation    Example using the reStructuredText format.&#xA;   Library          OperatingSystem&#xA;&#xA;   *** Variables ***&#xA;   ${MESSAGE}       Hello, world!&#xA;&#xA;   *** Test Cases ***&#xA;   My Test&#xA;       [Documentation]    Example test.&#xA;       Log    ${MESSAGE}&#xA;       My Keyword    ${CURDIR}&#xA;&#xA;   Another Test&#xA;       Should Be Equal    ${MESSAGE}    Hello, world!&#xA;&#xA;此段文本同样位于代码块之外，将被忽略。不包含 Robot Framework 数据的代码块也会被忽略。&#xA;&#xA;.. code:: robotframework&#xA;&#xA;   # Both space and pipe separated formats are supported.&#xA;&#xA;   | *** Keywords ***  |                        |         |&#xA;   | My Keyword        | [Arguments]            | ${path} |&#xA;   |                   | Directory Should Exist | ${path} |&#xA;&#xA;.. code:: python&#xA;&#xA;   # This code block is ignored.&#xA;   def example():&#xA;       print(&#39;Hello, world!&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Robot Framework 支持使用以下扩展名的 reStructuredText 文件：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;.robot.rst&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;.rst&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;.rest&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;为避免解析无关的 reStructuredText 文件，默认情况下执行目录时仅会解析 &lt;code&gt;.robot.rst&lt;/code&gt; 扩展名的文件。如需解析其他扩展名的文件，可通过以下任一命令行选项启用：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;--parseinclude&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;--extension&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;当 Robot Framework 解析 reStructuredText 文件时，会忽略低于 &lt;code&gt;SEVERE&lt;/code&gt; 级别的错误，以避免因非标准指令等标记产生的干扰信息。虽然这可能掩盖部分真实错误，但这些错误在使用标准 reStructuredText 工具处理文件时仍可被发现。&lt;/p&gt;&#xA;&lt;h3&gt;JSON 格式&lt;/h3&gt;&#xA;&lt;p&gt;Robot Framework 同时支持 JSON 格式的数据文件。该格式主要面向工具开发者而非普通用户，且不建议手动编辑。其主要应用场景包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;跨进程/机器数据传输。测试套件可在某台机器转换为 JSON 格式，并在其他机器重建。&lt;/li&gt;&#xA;&lt;li&gt;高效存储测试套件。将常规 Robot Framework 数据（包括嵌套套件）保存为单个 JSON 文件，可显著提升解析速度。&lt;/li&gt;&#xA;&lt;li&gt;外部工具测试生成。为生成测试/任务的外部工具提供替代数据格式。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4&gt;把套件转换为 JSON 格式&lt;/h4&gt;&#xA;&lt;p&gt;可通过 &lt;a href=&#34;https://robot-framework.readthedocs.io/en/master/autodoc/robot.running.html#robot.running.model.TestSuite.to_json&#34;&gt;TestSuite.to_json&lt;/a&gt; 方法将测试套件结构序列化为 JSON 格式。该方法在不带参数调用时，会以字符串形式返回 JSON 数据；同时也支持接收文件路径或已打开的文件对象作为写入目标，并可通过配置选项调整 JSON 格式输出：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from robot.running import TestSuite&#xA;&#xA;&#xA;# 基于文件系统中的数据创建测试套件&#xA;suite = TestSuite.from_file_system(&#39;/path/to/data&#39;)&#xA;&#xA;# 以字符串形式获取 JSON 数据&#xA;data = suite.to_json()&#xA;&#xA;# 使用自定义缩进格式将 JSON 数据保存至文件&#xA;suite.to_json(&#39;data.rbt&#39;, indent=2)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;若你更倾向使用 Python 原生数据结构，并自行转换为 JSON 或其他格式，可改用 &lt;a href=&#34;https://robot-framework.readthedocs.io/en/master/autodoc/robot.running.html#robot.running.model.TestSuite.to_dict&#34;&gt;TestSuite.to_dict&lt;/a&gt; 方法实现。&lt;/p&gt;&#xA;&lt;h4&gt;从 JSON 格式转换成套件&lt;/h4&gt;&#xA;&lt;p&gt;可通过 &lt;a href=&#34;https://robot-framework.readthedocs.io/en/master/autodoc/robot.running.html#robot.running.model.TestSuite.from_json&#34;&gt;TestSuite.from_json&lt;/a&gt; 方法基于 JSON 数据构建测试套件，该方法同时支持以下两种输入形式：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;JSON 格式字符串&lt;/li&gt;&#xA;&lt;li&gt;JSON 文件路径&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from robot.running import TestSuite&#xA;&#xA;&#xA;# 从 JSON 文件创建测试套件&#xA;suite = TestSuite.from_json(&#39;data.rbt&#39;)&#xA;&#xA;# 从 JSON 字符串创建测试套件&#xA;suite = TestSuite.from_json(&#39;{&amp;quot;name&amp;quot;: &amp;quot;Suite&amp;quot;, &amp;quot;tests&amp;quot;: [{&amp;quot;name&amp;quot;: &amp;quot;Test&amp;quot;}]}&#39;)&#xA;&#xA;# 执行测试套件（注意：需单独生成日志和报告）&#xA;suite.run(output=&#39;example.xml&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;若已有 Python 字典格式的数据，可改用 &lt;a href=&#34;https://robot-framework.readthedocs.io/en/master/autodoc/robot.running.html#robot.running.model.TestSuite.from_dict&#34;&gt;TestSuite.from_dict&lt;/a&gt; 方法。无论采用何种方式重建测试套件，其结果仅存在于内存中，不会在文件系统重建原始数据文件。&lt;/p&gt;&#xA;&lt;p&gt;如上述示例所示，可通过 &lt;a href=&#34;https://robot-framework.readthedocs.io/en/master/autodoc/robot.running.html#robot.running.model.TestSuite.run&#34;&gt;TestSuite.run&lt;/a&gt; 方法执行创建的测试套件。但直接执行 JSON 文件可能更为简便，具体方法将在下节说明。&lt;/p&gt;&#xA;&lt;h4&gt;执行 JSON 文件&lt;/h4&gt;&#xA;&lt;p&gt;通过 &lt;code&gt;robot&lt;/code&gt; 命令执行测试或任务时，系统会自动解析采用自定义 &lt;code&gt;.rbt&lt;/code&gt; 扩展名的 JSON 文件，包括以下两种场景：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;直接运行单个 JSON 文件（如 &lt;code&gt;robot tests.rbt&lt;/code&gt;）&lt;/li&gt;&#xA;&lt;li&gt;运行包含 &lt;code&gt;.rbt&lt;/code&gt; 文件的目录&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;若需使用标准 &lt;code&gt;.json&lt;/code&gt; 扩展名，则需额外配置待解析文件。&lt;/p&gt;&#xA;&lt;h4&gt;调整套件源&lt;/h4&gt;&#xA;&lt;p&gt;通过 &lt;code&gt;TestSuite.to_json&lt;/code&gt; 和 &lt;code&gt;TestSuite.to_dict&lt;/code&gt; 获取的数据中，套件源路径(suite source)采用绝对路径格式。若后续在不同机器上重建套件，源路径可能与目标机器的目录结构不匹配。为解决此问题，可先使用 &lt;a href=&#34;https://robot-framework.readthedocs.io/en/master/autodoc/robot.model.html#robot.model.testsuite.TestSuite.adjust_source&#34;&gt;TestSuite.adjust_source&lt;/a&gt; 方法将套件源转为相对路径再获取数据，待套件重建后补充正确的根目录路径：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from robot.running import TestSuite&#xA;&#xA;&#xA;# 创建测试套件 -&amp;gt; 调整源路径 -&amp;gt; 转换为JSON格式&#xA;suite = TestSuite.from_file_system(&#39;/path/to/data&#39;)  # 从文件系统加载原始套件&#xA;suite.adjust_source(relative_to=&#39;/path/to&#39;)          # 将源路径转换为相对于指定目录的路径&#xA;suite.to_json(&#39;data.rbt&#39;)                            # 序列化为JSON文件&#xA;&#xA;# 在其他环境重建套件并相应调整源路径&#xA;suite = TestSuite.from_json(&#39;data.rbt&#39;)             # 从JSON文件重建套件&#xA;suite.adjust_source(root=&#39;/new/path/to&#39;)            # 根据新环境设置根目录路径&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4&gt;JSON 结构&lt;/h4&gt;&#xA;&lt;p&gt;在生成的 JSON 数据中，测试套件文件中的以下元素将与测试用例/任务一同被包含：导入项、变量、关键字。具体 JSON 结构规范详见 &lt;code&gt;running.json&lt;/code&gt; schema文件。&lt;/p&gt;&#xA;&lt;h2&gt;解析测试数据的规则&lt;/h2&gt;&#xA;&lt;h3&gt;忽略数据&lt;/h3&gt;&#xA;&lt;p&gt;Robot Framework 解析测试数据文件时会自动忽略以下内容：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;首个测试数据 section 之前的所有内容&lt;/li&gt;&#xA;&lt;li&gt;Comments section 内的全部数据&lt;/li&gt;&#xA;&lt;li&gt;所有空白行&lt;/li&gt;&#xA;&lt;li&gt;使用管道分隔格式时，行末的空单元格&lt;/li&gt;&#xA;&lt;li&gt;未用于转义的单反斜线符号（\）&lt;/li&gt;&#xA;&lt;li&gt;当井号（#）出现在单元格开头时，该单元格后续所有字符（支持在测试数据中添加行内注释）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Robot Framework 忽略的数据将不会出现在任何结果报告中，且大多数配套工具也会忽略这些数据。如需在输出中显示信息，请将其放入测试用例或套件的文档或其他元数据中，或使用 BuiltIn 关键字 Log 或 Comment 进行记录。&lt;/p&gt;&#xA;&lt;h3&gt;转义&lt;/h3&gt;&#xA;&lt;p&gt;Robot Framework 测试数据中的转义字符是反斜杠（\），此外内置变量 &lt;code&gt;${EMPTY}&lt;/code&gt; 和 &lt;code&gt;${SPACE}&lt;/code&gt; 也常用于转义操作。不同转义机制的具体用法将在后续章节详细讨论。&lt;/p&gt;&#xA;&lt;h4&gt;转义特殊字符&lt;/h4&gt;&#xA;&lt;p&gt;反斜杠字符（\）可用于转义特殊字符，使其保留字面值。&lt;/p&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;转义字符&lt;/th&gt;&#xA;&lt;th&gt;功能说明&lt;/th&gt;&#xA;&lt;th&gt;示例代码&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\$&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;避免被识别为标量变量起始符&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;${notvar}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\@&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;避免被识别为列表变量起始符&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;@{notvar}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\&amp;amp;&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;避免被识别为字典变量起始符&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;&amp;amp;{notvar}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\%&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;避免被识别为环境变量起始符&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;%{notvar}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\#&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;避免被识别为注释起始符&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;# not comment&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\=&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;避免被识别为命名参数语法&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;not=named&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;|&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;在管道分隔格式中不作为分隔符&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;ls -1 *.txt | wc -l&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\\&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;作为普通字符使用（不进行转义）&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;c:\\temp&lt;/code&gt;, &lt;code&gt;\\${var}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h4&gt;构建转义序列&lt;/h4&gt;&#xA;&lt;p&gt;反斜杠字符（\）还可用于创建特殊转义序列，这些序列会被解析为测试数据中难以直接输入的字符。&lt;/p&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;转义序列&lt;/th&gt;&#xA;&lt;th&gt;说明&lt;/th&gt;&#xA;&lt;th&gt;示例&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\n&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;换行符&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;first line\n2nd line&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\r&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;回车符&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;text\rmore text&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\t&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;制表符&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;text\tmore text&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\xhh&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;十六进制值字符（2位）&lt;/td&gt;&#xA;&lt;td&gt;空字符：&lt;code&gt;\x00&lt;/code&gt;&lt;br&gt;ä：&lt;code&gt;\xE4&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\uhhhh&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;十六进制值字符（4位）&lt;/td&gt;&#xA;&lt;td&gt;雪人符号：&lt;code&gt;\u2603&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\Uhhhhhhhh&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;十六进制值字符（8位）&lt;/td&gt;&#xA;&lt;td&gt;爱情酒店符号：&lt;code&gt;\U0001f3e9&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h4&gt;处理空值&lt;/h4&gt;&#xA;&lt;p&gt;在使用空格分隔格式时，用作分隔符的空格数量可以变化，因此除非进行转义处理，否则无法识别空值。空单元格可通过反斜杠字符或内置变量 &lt;code&gt;${EMPTY}&lt;/code&gt; 进行转义。通常推荐使用后者，因为更易于理解。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Test Cases ***&#xA;Using backslash&#xA;    Do Something    first arg    \&#xA;    Do Something    \            second arg&#xA;&#xA;Using ${EMPTY}&#xA;    Do Something    first arg    ${EMPTY}&#xA;    Do Something    ${EMPTY}     second arg&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在使用竖线分隔格式时，空值仅当位于行末时才需要进行转义：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;| *** Test Cases *** |              |           |            |&#xA;| Using backslash    | Do Something | first arg | \          |&#xA;|                    | Do Something |           | second arg |&#xA;|                    |              |           |            |&#xA;| Using ${EMPTY}     | Do Something | first arg | ${EMPTY}   |&#xA;|                    | Do Something |           | second arg |&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4&gt;处理空格&lt;/h4&gt;&#xA;&lt;p&gt;在关键字参数或其他情况下，空格（尤其是连续空格）会引发问题，主要原因有二：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;若采用空格分隔格式，两个及以上连续空格会被视作分隔符&lt;/li&gt;&#xA;&lt;li&gt;若采用竖线分隔格式，首尾空格会被自动忽略&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;此时必须对空格进行转义处理。与空值转义方式类似，既可使用反斜杠字符（\），也可调用内置变量 &lt;code&gt;${SPACE}&lt;/code&gt; 实现转义。&lt;/p&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;反斜杠转义方式&lt;/th&gt;&#xA;&lt;th&gt;${SPACE}变量转义方式&lt;/th&gt;&#xA;&lt;th&gt;技术说明&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\ leading space&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;${SPACE}leading space&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;前导空格转义&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;trailing space \&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;trailing space${SPACE}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;&lt;strong&gt;反斜杠必须跟在空格后&lt;/strong&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;\ \&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;${SPACE}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;需在两侧使用反斜杠&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;consecutive \ \ spaces&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;consecutive${SPACE * 3}spaces&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;使用扩展变量语法&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;如上述示例所示，使用 &lt;code&gt;${SPACE}&lt;/code&gt; 变量通常能让测试数据更易于理解。当需要多个空格时，结合扩展变量语法使用尤为方便。&lt;/p&gt;&#xA;&lt;h3&gt;将数据分成多行&lt;/h3&gt;&#xA;&lt;p&gt;当数据过长无法完整显示在一行时，可通过省略号（&lt;code&gt;...&lt;/code&gt;）进行分行处理。省略号可采用与起始行相同的缩进格式，且其后必须跟随常规的测试数据分隔符。&lt;/p&gt;&#xA;&lt;p&gt;在多数情况下，分行数据与未分行数据具有完全相同的语义。但套件文档、测试用例文档、关键字文档以及套件元数据除外 —— 这些内容的分行值会自动以换行符连接，便于创建多行文本值。&lt;/p&gt;&#xA;&lt;p&gt;此 &lt;code&gt;...&lt;/code&gt; 语法同样适用于变量表中的变量分行。当长标量变量（如 &lt;code&gt;${STRING}&lt;/code&gt;）被分割至多行时，最终值将通过行间拼接获得，默认以空格作为分隔符。如需更改分隔方式，可在值前添加 &lt;code&gt;SEPARATOR=&amp;lt;sep&amp;gt;&lt;/code&gt; 声明。&lt;/p&gt;&#xA;&lt;p&gt;以下两个示例展示了包含完全相同数据的不分行与分行处理方案：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Settings ***&#xA;Documentation      Here we have documentation for this suite.\nDocumentation is often quite long.\n\nIt can also contain multiple paragraphs.&#xA;Test Tags          test tag 1    test tag 2    test tag 3    test tag 4    test tag 5&#xA;&#xA;*** Variables ***&#xA;${STRING}          This is a long string. It has multiple sentences. It does not have newlines.&#xA;${MULTILINE}       This is a long multiline string.\nThis is the second line.\nThis is the third and the last line.&#xA;@{LIST}            this     list     is    quite    long     and    items in it can also be long&#xA;&amp;amp;{DICT}            first=This value is pretty long.    second=This value is even longer. It has two sentences.&#xA;&#xA;*** Test Cases ***&#xA;Example&#xA;    [Tags]    you    probably    do    not    have    this    many    tags    in    real    life&#xA;    Do X    first argument    second argument    third argument    fourth argument    fifth argument    sixth argument&#xA;    ${var} =    Get X    first argument passed to this keyword is pretty long    second argument passed to this keyword is long too&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;*** Settings ***&#xA;Documentation      Here we have documentation for this suite.&#xA;...                Documentation is often quite long.&#xA;...&#xA;...                It can also contain multiple paragraphs.&#xA;Test Tags          test tag 1    test tag 2    test tag 3&#xA;...                test tag 4    test tag 5&#xA;&#xA;*** Variables ***&#xA;${STRING}          This is a long string.&#xA;...                It has multiple sentences.&#xA;...                It does not have newlines.&#xA;${MULTILINE}       SEPARATOR=\n&#xA;...                This is a long multiline string.&#xA;...                This is the second line.&#xA;...                This is the third and the last line.&#xA;@{LIST}            this     list     is      quite    long     and&#xA;...                items in it can also be long&#xA;&amp;amp;{DICT}            first=This value is pretty long.&#xA;...                second=This value is even longer. It has two sentences.&#xA;&#xA;*** Test Cases ***&#xA;Example&#xA;    [Tags]    you    probably    do    not    have    this    many&#xA;    ...       tags    in    real    life&#xA;    Do X    first argument    second argument    third argument&#xA;    ...    fourth argument    fifth argument    sixth argument&#xA;    ${var} =    Get X&#xA;    ...    first argument passed to this keyword is pretty long&#xA;    ...    second argument passed to this keyword is long too&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;本地化&lt;/h2&gt;&#xA;&lt;p&gt;Robot Framework 的本地化工作始于 6.0 版本，该版本支持翻译以下内容：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;section header&lt;/li&gt;&#xA;&lt;li&gt;设置项&lt;/li&gt;&#xA;&lt;li&gt;行为驱动开发(BDD)中使用的 Given/When/Then 前缀&lt;/li&gt;&#xA;&lt;li&gt;布尔参数自动转换使用的 true 和 false 字符串&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;未来计划进一步扩展本地化支持范围，例如扩展到日志和报告模块，并可能包含控制结构。&lt;/p&gt;&#xA;&lt;h3&gt;启用语言支持&lt;/h3&gt;&#xA;&lt;h4&gt;使用命令行开启&lt;/h4&gt;&#xA;&lt;p&gt;激活语言支持的主要方式是通过命令行使用 &lt;code&gt;--language&lt;/code&gt; 选项进行指定。对于内置语言，既可使用语言名称（如 &lt;code&gt;Finnish&lt;/code&gt;）也可使用语言代码（如 &lt;code&gt;fi&lt;/code&gt;）。名称和代码均不区分大小写及空格，连字符（&lt;code&gt;-&lt;/code&gt;）也会被忽略。如需启用多语言支持，需多次使用 &lt;code&gt;--language&lt;/code&gt; 选项：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;robot --language Finnish testit.robot&#xA;robot --language pt --language ptbr testes.robot&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;该 &lt;code&gt;--language&lt;/code&gt; 选项同样适用于激活自定义语言文件。此时参数值可以是文件路径，若文件位于模块搜索路径中，也可直接使用模块名：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;robot --language Custom.py tests.robot&#xA;robot --language MyLang tests.robot&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;出于向后兼容性考虑，以及支持部分翻译场景，系统会始终自动激活英语支持。未来版本可能会提供禁用该特性的选项。&lt;/p&gt;&#xA;&lt;h4&gt;文件预配置&lt;/h4&gt;&#xA;&lt;p&gt;还可以直接在数据文件中通过在任何节标题前添加一行 &lt;code&gt;Language: &amp;lt;value&amp;gt;&lt;/code&gt;（不区分大小写）来启用语言。冒号后的值与 &lt;code&gt;--language&lt;/code&gt; 选项的解析方式相同：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Language: Finnish&#xA;&#xA;*** Asetukset ***&#xA;Dokumentaatio        Finnish language example.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;若需启用多语言，可重复 &lt;code&gt;Language:&lt;/code&gt; 行。此类配置行不可置于注释中，因此类似 &lt;code&gt;# Language: Finnish&lt;/code&gt; 的写法无效。&lt;/p&gt;&#xA;&lt;p&gt;由于技术限制，单文件语言配置会影响后续文件的解析及整个执行过程。此行为未来可能变更，请勿依赖该特性。若使用单文件配置，请确保所有文件统一使用该方式，或通过&lt;code&gt; --language&lt;/code&gt; 选项全局启用语言。&lt;/p&gt;&#xA;&lt;h3&gt;内置语言支持&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Arabic (ar)&lt;/li&gt;&#xA;&lt;li&gt;Bulgarian (bg)&lt;/li&gt;&#xA;&lt;li&gt;Bosnian (bs)&lt;/li&gt;&#xA;&lt;li&gt;Czech (cs)&lt;/li&gt;&#xA;&lt;li&gt;German (de)&lt;/li&gt;&#xA;&lt;li&gt;Spanish (es)&lt;/li&gt;&#xA;&lt;li&gt;Finnish (fi)&lt;/li&gt;&#xA;&lt;li&gt;French (fr)&lt;/li&gt;&#xA;&lt;li&gt;Hindi (hi)&lt;/li&gt;&#xA;&lt;li&gt;Italian (it)&lt;/li&gt;&#xA;&lt;li&gt;Japanese (ja)&lt;/li&gt;&#xA;&lt;li&gt;Korean (ko)&lt;/li&gt;&#xA;&lt;li&gt;Dutch (nl)&lt;/li&gt;&#xA;&lt;li&gt;Polish (pl)&lt;/li&gt;&#xA;&lt;li&gt;Portuguese (pt)&lt;/li&gt;&#xA;&lt;li&gt;Brazilian Portuguese (pt-BR)&lt;/li&gt;&#xA;&lt;li&gt;Romanian (ro)&lt;/li&gt;&#xA;&lt;li&gt;Russian (ru)&lt;/li&gt;&#xA;&lt;li&gt;Swedish (sv)&lt;/li&gt;&#xA;&lt;li&gt;Thai (th)&lt;/li&gt;&#xA;&lt;li&gt;Turkish (tr)&lt;/li&gt;&#xA;&lt;li&gt;Ukrainian (uk)&lt;/li&gt;&#xA;&lt;li&gt;Vietnamese (vi)&lt;/li&gt;&#xA;&lt;li&gt;Chinese Simplified (zh-CN)&lt;/li&gt;&#xA;&lt;li&gt;Chinese Traditional (zh-TW)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;自定义语言文件&lt;/h3&gt;&#xA;&lt;p&gt;若所需语言未内置，或需为特定需求创建完全自定义的语言，你可以轻松创建自定义语言文件。语言文件是 Python 文件，内含一个或多个语言定义——启用该文件时将加载所有定义。语言定义通过继承 &lt;code&gt;robot.api.Language&lt;/code&gt; 基类并按需覆盖类属性来实现：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;from robot.api import Language&#xA;&#xA;class Example(Language):&#xA;    test_cases_header = &#39;Validations&#39;      &#xA;    tags_setting = &#39;Labels&#39;                &#xA;    given_prefixes = [&#39;Assuming&#39;]         &#xA;    true_strings = [&#39;OK&#39;, &#39;\N{THUMBS UP SIGN}&#39;]  &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;假设上述代码保存在 &lt;code&gt;example.py&lt;/code&gt; 文件中，启用语言文件时只需提供该文件路径或模块名 &lt;code&gt;example&lt;/code&gt; 即可。&lt;/p&gt;&#xA;&lt;p&gt;此示例仅实现了部分可翻译项（因英语会默认启用）。多数属性需指定为字符串，但BDD前缀和真/假值字符串允许使用列表形式定义多个值。更多示例可参考 Robot Framework 内置的 &lt;a href=&#34;https://github.com/robotframework/robotframework/blob/master/src/robot/conf/languages.py&#34;&gt;languages&lt;/a&gt; 模块——该模块包含 &lt;code&gt;Language&lt;/code&gt; 类及所有内置语言定义。&lt;/p&gt;&#xA;&lt;h2&gt;风格&lt;/h2&gt;&#xA;&lt;p&gt;Robot Framework 的语法构建了一种简易编程语言，与其他编程语言类似，代码风格的规范性至关重要。虽然 Robot Framework 的语法设计具有高度灵活性，但仍存在一些普遍推荐的规范：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;缩进：采用 4 个空格。&lt;/li&gt;&#xA;&lt;li&gt;间隔：关键字与参数、设置项与其值之间保留 4 个空格。某些场景（如 Settings/Variables 中的值对齐或数据驱动风格）可适当增加空格。&lt;/li&gt;&#xA;&lt;li&gt;变量命名：全局变量使用大写字母（如 &lt;code&gt;${EXAMPLE}&lt;/code&gt;），局部变量使用小写字母（如 &lt;code&gt;${example}&lt;/code&gt;）&lt;/li&gt;&#xA;&lt;li&gt;一致性：确保单文件内风格统一，推荐整个项目保持相同规范&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;目前尚未形成强约束规范的场景是关键字的命名格式。Robot Framework 官方文档通常采用首字母大写形式（如 &lt;code&gt;Example Keyword&lt;/code&gt;），该风格在测试数据中也较为常见。但对于较长的句子型关键字（例如 &lt;code&gt;Log into system as an admin&lt;/code&gt;），这种格式可能不够理想。&lt;/p&gt;&#xA;&lt;p&gt;建议使用 Robot Framework 的团队制定专属编码规范。社区开发的&lt;a href=&#34;https://docs.robotframework.org/docs/style_guide&#34;&gt;《Robot Framework 风格指南》&lt;/a&gt;可作为优质基准模板，支持按需调整。此外，可通过 &lt;a href=&#34;https://robocop.readthedocs.io/&#34;&gt;Robocop&lt;/a&gt; 静态检查工具和 &lt;a href=&#34;https://robotidy.readthedocs.io/&#34;&gt;Robotidy&lt;/a&gt; 代码格式化工具强制实施这些规范。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/07/11/robotframework-new-tutorial-test-data-syntax/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>准备出发，前往古希腊</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/07/08/ac-odyssey0/</id>
    <content type="html">&lt;p&gt;去年出国去法意瑞旅游，激起了我了解欧洲的兴趣，回来之后就广泛搜集各种介绍欧洲的书籍，这半年来囫囵吞枣看了不少。想起来我以前玩的《刺客信条》系列，其中不少是和欧洲有关的作品，于是便掏出尘封已久的 PS5，再次玩了起来。说起欧洲的历史，就绕不开欧洲的起点 - 古希腊，所以，我选择《刺客信条：奥德赛》作为这一系列的开篇之作。&lt;/p&gt;&#xA;&lt;p&gt;说来惭愧，我高中这些历史地理科目一向名列前茅，加上那时候喜欢看《天文爱好者》，对希腊/罗马神话有所耳闻，自认为比普通人了解的要多，可几年前第一次玩起游戏来看到的那些历史事件、那些地名、那些人物，都像没听说过似的。所以我还是要摆正心态，借着再玩的契机，好好补一补历史知识。当然，我连历史业余爱好者也算不上，所以这些文章不能算作严肃的历史课。&lt;/p&gt;&#xA;&lt;h2&gt;游戏世界观&lt;/h2&gt;&#xA;&lt;p&gt;首先介绍一下《刺客信条》系列的世界观（非真实历史），方便非游戏爱好者代入。游戏中存在一个名为“先行者”（The First Civilization）或“伊述人”（Isu）的高度发达史前文明。他们拥有远超现代的科技，创造了人类并将其作为奴隶使用。但一场灾难性的太阳耀斑几乎毁灭了伊述文明，仅存的伊述人通过与人类结合延续血脉。&lt;/p&gt;&#xA;&lt;p&gt;游戏系列构建了一个融合历史与科幻元素的独特世界观，核心围绕两大阵营之间的千年争斗展开。两大阵营分别为：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;圣殿骑士团&lt;/strong&gt;：致力于建立秩序，认为人类需要被引导和控制，才能避免混乱和灾难。他们不择手段地收集强大的古代遗物，以实现统治世界的目的。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://www.lyyyuna.com/img/posts/odyssey/ac-odyssey-0001.jpg&#34; alt=&#34;圣殿骑士团&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;刺客兄弟会&lt;/strong&gt;：追求自由，坚信人类应拥有自由意志，能自主决定命运。他们反对圣殿骑士团对人类的控制，通过各种手段阻止圣殿骑士的阴谋。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://www.lyyyuna.com/img/posts/odyssey/ac-odyssey-0002.jpg&#34; alt=&#34;刺客兄弟会&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;游戏里，现代人类发明了通过 DNA 回溯祖先记忆的科技，并借此体验了古希腊、古埃及、文艺复兴时期的意大利，到工业革命时期的英国等不同历史时期刺客与圣殿骑士的斗争。&lt;/p&gt;&#xA;&lt;h2&gt;本作背景&lt;/h2&gt;&#xA;&lt;p&gt;游戏里的几个重要事件背景：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;公元前 1000 年左右：荷马史诗描述的迈锡尼文明时期（特洛伊木马）&lt;/li&gt;&#xA;&lt;li&gt;公元前 499-449：波希战争（温泉关战役）&lt;/li&gt;&#xA;&lt;li&gt;公元前 431-404：伯罗奔尼撒战争（雅典 vs 斯巴达）&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;《刺客信条：奥德赛》虽然名字里带“奥德赛”，但描写的是主人公在伯罗奔尼撒战争时期的冒险故事。这一作的游戏很特别，主人公可选，我选择了卡珊德拉这个女性主人公。这选择可能不符合历史事实，古希腊的女性地位并不高，不太可能像女主那样到处抛头露面，还上战场当雇佣兵。卡珊德拉是斯巴达人，她的外公就是温泉关之战中的战死的斯巴达国王列奥尼达斯。&lt;/p&gt;&#xA;&lt;h2&gt;温泉关之战&lt;/h2&gt;&#xA;&lt;p&gt;游戏开始是回忆“温泉关之战”，与电影《斯巴达 300 勇士》中不同，斯巴达军队不是只穿了内裤，而是全副武装，装备包括青铜头盔、胸甲、胫甲、大圆盾、长矛和短剑等。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://www.lyyyuna.com/img/posts/odyssey/ac-odyssey-0000.jpg&#34; alt=&#34;列奥尼达斯-温泉关&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这样装备的军队，在古希腊称为重装步兵，在这之前，古希腊主要是荷马史诗那种英雄式的决斗，战争水平比较低。重装步兵需要公民接受基础的军事训练，需服役常备军一定时间，还需要自备武器和铠甲，因此有一定的经济基础。后来各个城邦越来越倚重自己的重装步兵，导致服役士兵的社会地位逐步升高，也间接促进了古希腊社会民主政治的发展。&lt;/p&gt;&#xA;&lt;p&gt;斯巴达社会有几个和其他希腊城邦不同的特点：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;全民皆兵，一生都在进行军事训练。&lt;/li&gt;&#xA;&lt;li&gt;斯巴达是双王制度，两个国王共同治理。&lt;/li&gt;&#xA;&lt;li&gt;斯巴达人政治上保守且迷信，经常举行宗教活动。&lt;/li&gt;&#xA;&lt;li&gt;奴役了大量的希洛人，来从事生产和军队后勤活动。这些奴隶被称为黒劳士，需要供养完全不耕种的斯巴达人。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;电影《斯巴达 300 勇士》刻画了勇猛爱国的斯巴达人，受限于迂腐的祭祀和懦弱的雅典，导致温泉关之战只能以少战多。但是历史实际原因是多方面的：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;当时正在举行宗教活动，大部分斯巴达人不希望出战。&lt;/li&gt;&#xA;&lt;li&gt;双王制度下，斯巴达人不希望出现单个国王统治的局面，所以对列奥尼达斯独自出战并不支持。&lt;/li&gt;&#xA;&lt;li&gt;由于奴隶毫无人权，一旦斯巴达军队主力外出作战就有奴隶叛乱的风险，这对斯巴达社会来说是个大问题。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;虽然看起来我在 diss 斯巴达人，但从正面讲，列奥尼达斯所率领三百勇士确实是真正的战士，他们在知道波斯已经从小路绕后的情况下，主动疏散了其他联军，自己留下来殿后，这绝对是荷马史诗般的英雄行为。战斗结束后，斯巴达人被全歼，后来温泉关立起一块纪念碑，上面有一段令人动容的铭文：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;异乡的过客啊，请带话给斯巴达人，说我们忠实地履行了诺言，长眠于此。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/07/08/ac-odyssey0/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>k6 模块</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/07/07/grafana-k6-8/</id>
    <content type="html">&lt;h2&gt;导入模块&lt;/h2&gt;&#xA;&lt;p&gt;在测试脚本中导入模块或模块的部分内容是很常见的。在 k6 中，可以导入以下几种类型的模块：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;内置模块&lt;/li&gt;&#xA;&lt;li&gt;本地模块&lt;/li&gt;&#xA;&lt;li&gt;远程模块&lt;/li&gt;&#xA;&lt;li&gt;扩展模块&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;内置模块&lt;/h3&gt;&#xA;&lt;p&gt;k6 提供了许多内置模块来实现核心功能。例如，HTTP 客户端模块可用于向被测系统发送请求。完整的内置模块列表请参考 &lt;a href=&#34;https://grafana.com/docs/k6/latest/javascript-api/&#34;&gt;API 文档&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;本地模块&lt;/h3&gt;&#xA;&lt;p&gt;这些模块存储在本地文件系统中，可通过相对路径或绝对文件系统路径访问。&lt;/p&gt;&#xA;&lt;p&gt;k6 采用类似&lt;strong&gt;浏览器的模块解析机制&lt;/strong&gt;，不支持 Node.js 的模块解析方式。导入的文件名必须完整指定，例如 &lt;code&gt;./helpers.js&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;// helpers.js&#xA;export function someHelper() {&#xA;  // ...&#xA;}&#xA;&#xA;// my-test.js&#xA;import { someHelper } from &#39;./helpers.js&#39;;&#xA;&#xA;export default function () {&#xA;  someHelper();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;远程模块&lt;/h3&gt;&#xA;&lt;p&gt;这些模块通过 HTTP(S) 协议从公开来源获取，例如 GitHub、任意 CDN 或任何可公开访问的 Web 服务器。导入的模块会在运行时下载并执行，因此在将代码纳入测试脚本前，务必确保其来源可信。&lt;/p&gt;&#xA;&lt;p&gt;例如，&lt;a href=&#34;https://grafana.com/docs/k6/latest/javascript-api/jslib/&#34;&gt;jslib&lt;/a&gt; 是一组 k6 JavaScript 库，可作为远程 HTTPS 模块使用。它们既可以被下载后作为本地模块导入，也能直接作为远程模块引用。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import { randomItem } from &#39;https://jslib.k6.io/k6-utils/1.2.0/index.js&#39;;&#xA;&#xA;export default function () {&#xA;  randomItem([1, 2, 3]);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;你也可以构建自定义的 JavaScript 库，并通过公共网络托管平台进行分发。例如，&lt;a href=&#34;https://github.com/grafana/k6-jslib-aws&#34;&gt;k6-jslib-aws&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/grafana/k6-rollup-example&#34;&gt;k6-rollup-example&lt;/a&gt; 项目就将它们的模块托管为 GitHub 的发布资源。&lt;/p&gt;&#xA;&lt;h3&gt;扩展模块&lt;/h3&gt;&#xA;&lt;p&gt;与 k6 API 类似，您可以使用 Go 代码构建自定义模块，并将其作为 JavaScript 模块公开。这类自定义的 Go 转 JS 模块被称为 k6 扩展。&lt;/p&gt;&#xA;&lt;p&gt;以下示例演示了如何从 &lt;a href=&#34;https://github.com/grafana/xk6-kubernetes&#34;&gt;xk6-kubernetes&lt;/a&gt; 扩展中导入 k6/x/kubernetes 模块：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import { Kubernetes } from &#39;k6/x/kubernetes&#39;;&#xA;&#xA;const podSpec = {&#xA;  apiVersion: &#39;v1&#39;,&#xA;  kind: &#39;Pod&#39;,&#xA;  metadata: { name: &#39;busybox&#39;, namespace: &#39;testns&#39; },&#xA;  spec: {&#xA;    containers: [&#xA;      {&#xA;        name: &#39;busybox&#39;,&#xA;        image: &#39;busybox&#39;,&#xA;        command: [&#39;sh&#39;, &#39;-c&#39;, &#39;sleep 30&#39;],&#xA;      },&#xA;    ],&#xA;  },&#xA;};&#xA;export default function () {&#xA;  const kubernetes = new Kubernetes();&#xA;  kubernetes.create(podSpec);&#xA;  const pods = kubernetes.list(&#39;Pod&#39;, &#39;testns&#39;);&#xA;  pods.map(function (pod) {&#xA;    console.log(pod.metadata.name);&#xA;  });&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;k6 扩展（Go 转 JS 模块）是如何工作的？为了提升性能，k6 引擎采用 Go 语言编写，并内置了一个 JavaScript 虚拟机（sobek）来执行 JavaScript 测试代码。这种架构使得你能够用 Go 编写模块，并像普通 JavaScript 模块一样导入使用。&lt;/p&gt;&#xA;&lt;h2&gt;分享 JavaScript 模块&lt;/h2&gt;&#xA;&lt;p&gt;如先前所述，用户可通过加载本地模块或远程模块来导入自定义JavaScript库。因此，我们不仅有两种模块导入方式，还支持多种模块分发方案。&lt;/p&gt;&#xA;&lt;h3&gt;远程模块&lt;/h3&gt;&#xA;&lt;p&gt;你可以将模块部署在 GitHub 等公共网络服务器或 CDN 上，以便远程调用这些模块。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;// As GitHub release assets&#xA;import {&#xA;  WorkloadConfig,&#xA;  sayHello,&#xA;} from &#39;https://github.com/grafana/k6-rollup-example/releases/download/v0.0.2/index.js&#39;;&#xA;&#xA;// or hosted in a CDN&#xA;import { randomIntBetween, randomItem } from &#39;https://jslib.k6.io/k6-utils/1.4.0/index.js&#39;;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当库包含多个文件和模块时，你可能需要将这些模块打包以创建公共版本。&lt;/p&gt;&#xA;&lt;p&gt;需要特别注意的是，k6 会自动执行远程模块，因此必须确保这些远程模块的源代码可信。某些托管机制可能存在篡改远程模块的风险。为降低此类安全隐患，部分用户倾向于先将模块下载到本地再导入，从而完全掌控源代码。&lt;/p&gt;&#xA;&lt;h3&gt;本地模块&lt;/h3&gt;&#xA;&lt;p&gt;在本示例中，前述远程模块已被下载至测试项目的 lib 目录，并按以下方式导入：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import { WorkloadConfig, sayHello } from &#39;./libs/test-commons.js&#39;;&#xA;&#xA;import { randomIntBetween, randomItem } from &#39;./libs/k6-utils.js&#39;;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;另一种分发库的方法是使用 npm 等包管理工具，这种方式支持版本锁定和本地库链接功能，后者在开发阶段特别实用。&lt;/p&gt;&#xA;&lt;p&gt;k6 既非 Node.js 也非浏览器环境。依赖于 Node.js 特有 API（如 os 和 fs 模块）的包无法在 k6 中运行，同理浏览器专属 API（例如 window 对象）也不受支持。虽然 k6 不支持解析 Node 模块，但可以通过打包工具（如 &lt;a href=&#34;https://github.com/grafana/k6-rollup-example&#34;&gt;k6-rollup-example&lt;/a&gt; 所示）来加载 npm 依赖项。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/07/07/grafana-k6-8/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Robot Framework 新版教程 - 入门指南</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/07/02/robotframework-new-tutorial-getting-started/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;十年前我翻译过 &lt;a href=&#34;https://www.lyyyuna.com/series/Robot%20Framework%20%E6%95%99%E7%A8%8B/&#34;&gt;Robot Framework 的一些列文章&lt;/a&gt;，这些年其实我早已不再使用这个框架，但是看到搜索引擎仍有读者访问我翻译的旧文章，因此我决定更新一下。&lt;/p&gt;&#xA;&lt;h2&gt;介绍&lt;/h2&gt;&#xA;&lt;p&gt;Robot Framework 是一个基于 Python 的、可扩展的关键字驱动自动化框架，适用于以下领域：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;验收测试（Acceptance Testing）&lt;/li&gt;&#xA;&lt;li&gt;验收测试驱动开发（ATDD）&lt;/li&gt;&#xA;&lt;li&gt;行为驱动开发（BDD）&lt;/li&gt;&#xA;&lt;li&gt;机器人流程自动化（RPA）&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;该框架可在分布式异构环境中使用，支持跨不同技术和接口的自动化需求。&lt;/p&gt;&#xA;&lt;h3&gt;为什么使用 Robot Framework？&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;直观的表格化语法&#xA;&lt;ul&gt;&#xA;&lt;li&gt;提供统一、易用的表格语法编写测试用例&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;关键字复用体系&#xA;&lt;ul&gt;&#xA;&lt;li&gt;支持基于现有关键字创建更高层次的可复用关键字&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;可视化测试报告&#xA;&lt;ul&gt;&#xA;&lt;li&gt;生成易读的HTML格式测试报告与日志&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;跨平台独立性&#xA;&lt;ul&gt;&#xA;&lt;li&gt;与平台和被测应用解耦&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;可扩展库架构&#xA;&lt;ul&gt;&#xA;&lt;li&gt;提供简洁的库 API，支持使用 Python 原生开发定制测试库&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;持续集成支持&#xA;&lt;ul&gt;&#xA;&lt;li&gt;提供命令行接口与基于 XML 的输出文件，轻松对接 CI 系统&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;全栈测试能力，支持测试类型包括：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Web应用&lt;/li&gt;&#xA;&lt;li&gt;REST APIs&lt;/li&gt;&#xA;&lt;li&gt;移动应用&lt;/li&gt;&#xA;&lt;li&gt;进程监控&lt;/li&gt;&#xA;&lt;li&gt;远程系统（Telnet/SSH等）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;数据驱动测试&#xA;&lt;ul&gt;&#xA;&lt;li&gt;支持创建数据驱动的测试用例&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;多环境变量支持&#xA;&lt;ul&gt;&#xA;&lt;li&gt;内置变量机制，特别适合多环境测试&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;智能测试分类&#xA;&lt;ul&gt;&#xA;&lt;li&gt;通过标签(tag)体系实现测试用例的分类与筛选&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;版本控制集成&#xA;&lt;ul&gt;&#xA;&lt;li&gt;测试套件以文件/目录形式存储，可与产品代码同步版本管理&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;生命周期控制&#xA;&lt;ul&gt;&#xA;&lt;li&gt;提供测试用例级和测试套件级的setup/teardown机制&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;模块化架构&#xA;&lt;ul&gt;&#xA;&lt;li&gt;支持为具有多接口的复杂应用创建测试&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3&gt;架构&lt;/h3&gt;&#xA;&lt;p&gt;Robot Framework 是一个通用的、与应用和具体技术无关的框架。它具有一个高度模块化的架构，如下图所示：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/rf-new-tutor/architecture.png&#34; alt=&#34;Robot Framework 架构&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;测试数据采用简单、易编辑的表格格式。Robot Framework 启动时会对数据进行处理，执行测试用例并生成日志和报告。该核心框架本身不涉及任何被测目标信息，与目标的交互均由库文件处理。这些库既可直接调用应用程序接口，也能通过底层测试工具作为驱动进行操作。&lt;/p&gt;&#xA;&lt;h3&gt;截图&lt;/h3&gt;&#xA;&lt;p&gt;以下截图展示了测试数据样例及生成的报告和日志。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/rf-new-tutor/testdata_screenshots.png&#34; alt=&#34;测试用例文件&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/rf-new-tutor/screenshots.png&#34; alt=&#34;测试报告和日志&#34;&gt;&lt;/p&gt;&#xA;&lt;h2&gt;安装步骤&lt;/h2&gt;&#xA;&lt;p&gt;本指南介绍了在不同操作系统上安装 Robot Framework 及其前置条件的方法。若已安装 Python，则可通过标准包管理器 pip 安装 Robot Framework：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pip install robotframework&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;安装 Python&lt;/h3&gt;&#xA;&lt;p&gt;Robot Framework 基于 Python 实现，因此安装前需预先安装 Python 或其替代实现 PyPy。另一项推荐的前置条件是确保已配置 pip 包管理器。&lt;/p&gt;&#xA;&lt;p&gt;Robot Framework 要求 Python 版本为 3.8 或更高。&lt;/p&gt;&#xA;&lt;h4&gt;在 Linux 上安装 Python&lt;/h4&gt;&#xA;&lt;p&gt;在 Linux 系统上，默认情况下应该已安装合适的 Python 版本并自带 pip 工具。若未安装，则需要查阅所用发行版的官方文档了解安装方法。如果想使用发行版默认提供版本之外的其它 Python 版本，同样需要参考发行版文档进行操作。&lt;/p&gt;&#xA;&lt;p&gt;要检查当前安装的Python版本，可在终端中运行以下命令：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ python --version&#xA;Python 3.10.13&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;请注意，如果你的 Linux 发行版同时提供了较旧的 Python 2，直接运行 &lt;code&gt;python&lt;/code&gt; 命令可能会调用 Python 2。要使用 Python 3，你可以使用 &lt;code&gt;python3&lt;/code&gt; 命令，或者更精确地指定版本（例如 &lt;code&gt;python3.8&lt;/code&gt;）。如果你安装了多个 Python 3 版本，并且需要明确指定使用哪一个，同样需要使用这些带版本号的命令：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ python3.11 --version&#xA;Python 3.11.7&#xA;$ python3.12 --version&#xA;Python 3.12.1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在系统自带的 Python 环境下直接安装 Robot Framework 存在一定风险，可能导致操作系统依赖的 Python 环境出现问题。如今大多数 Linux 发行版默认采用用户级安装（user installs）来避免此类情况，但用户也可以自行选择使用虚拟环境（virtual environments）进行隔离。&lt;/p&gt;&#xA;&lt;h4&gt;在 Windows 上安装 Python&lt;/h4&gt;&#xA;&lt;p&gt;在 Windows 系统上，Python 默认并未预装，但安装过程十分简便。推荐通过 &lt;a href=&#34;http://python.org/&#34;&gt;python.org&lt;/a&gt; 下载官方 Windows 安装程序进行安装。若需了解其他安装方式（如通过 Microsoft Store 安装），请参阅 &lt;a href=&#34;https://docs.python.org/3/using/windows.html&#34;&gt;Python 官方文档&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;在 Windows 上安装 Python 时，建议将 Python 添加至 PATH 环境变量，以便通过命令行更便捷地运行 Python 及其相关工具（如 pip 和 Robot Framework）。若使用&lt;a href=&#34;https://docs.python.org/3/using/windows.html#windows-full&#34;&gt;官方安装程序&lt;/a&gt;，只需在初始对话框勾选&amp;quot;将 Python 3.x 添加到 PATH&amp;quot;选项即可。&lt;/p&gt;&#xA;&lt;p&gt;要验证 Python 是否安装成功并已添加至 PATH 环境变量，可打开命令提示符并执行以下命令：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;C:\&amp;gt;python --version&#xA;Python 3.10.9&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 Windows 系统中安装多个 Python 版本时，执行 &lt;code&gt;python&lt;/code&gt; 命令将默认调用 PATH 环境变量中优先级最高的版本。如需使用其他版本，最简单的方法是使用 &lt;a href=&#34;https://docs.python.org/3/using/windows.html#launcher&#34;&gt;py launcher&lt;/a&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;C:\&amp;gt;py --version&#xA;Python 3.10.9&#xA;C:\&amp;gt;py -3.12 --version&#xA;Python 3.12.1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4&gt;在 macOS 上安装 Python&lt;/h4&gt;&#xA;&lt;p&gt;在 macOS 系统中，默认提供的 Python 版本不兼容 Python 3，因此需要单独安装。推荐访问 &lt;a href=&#34;http://python.org/&#34;&gt;python.org&lt;/a&gt; 下载官方 macOS 安装程序进行安装。若使用 &lt;a href=&#34;https://brew.sh/&#34;&gt;Homebrew&lt;/a&gt; 等包管理器，也可以通过它来安装 Python。&lt;/p&gt;&#xA;&lt;p&gt;与其他操作系统相同，可以在 macOS 上使用 &lt;code&gt;python --version&lt;/code&gt; 命令来验证 Python 是否安装成功。&lt;/p&gt;&#xA;&lt;h4&gt;安装 PyPy&lt;/h4&gt;&#xA;&lt;p&gt;PyPy 是 Python 的另一种实现方案。相较于标准 Python 实现，其主要优势在于运行速度更快且内存占用更低，但实际效果取决于具体使用场景。若执行效率至关重要，至少尝试测试 PyPy 通常是个不错的选择。&lt;/p&gt;&#xA;&lt;p&gt;PyPy 的安装过程简单直接，你可在 &lt;a href=&#34;http://pypy.org/&#34;&gt;pypy.org&lt;/a&gt; 获取安装程序及详细指南。要验证 PyPy 是否安装成功，可运行以下命令：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pypy --version&#xA;&#xA;pypy3 --version&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4&gt;配置 PATH&lt;/h4&gt;&#xA;&lt;p&gt;PATH 环境变量定义了系统在哪些目录中查找可执行命令。为方便通过命令行使用 Python、pip 和 Robot Framework，建议将以下两个目录添加至 PATH 中：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Python 的安装目录&lt;/li&gt;&#xA;&lt;li&gt;存放 pip 和 robot 等命令的目录&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;在 Linux 或 macOS 系统上使用 Python 时，Python 及其相关工具通常会自动配置到 PATH 中。若仍需手动更新 PATH，通常需要编辑系统级或用户级的配置文件。具体需要编辑哪个文件以及如何编辑，取决于操作系统类型，请查阅相应系统的文档获取详细信息。&lt;/p&gt;&#xA;&lt;p&gt;在 Windows 系统中，确保 PATH 正确配置的最简便方法是在运行安装程序时勾选&amp;quot;将 Python 3.x 添加到 PATH&amp;quot;选项。如需手动修改 PATH，请按以下步骤操作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;通过系统设置找到&amp;quot;环境变量&amp;quot;配置项&#xA;&lt;ul&gt;&#xA;&lt;li&gt;系统变量影响所有用户（需管理员权限）&lt;/li&gt;&#xA;&lt;li&gt;用户变量仅影响当前账户（通常修改此项即可）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;选择 PATH 变量（可能显示为 Path）并点击&amp;quot;编辑&amp;quot;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;若编辑用户变量且 PATH 不存在，请点击&amp;quot;新建&amp;quot;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;将以下两个目录添加到 PATH 中：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Python 安装目录&lt;/li&gt;&#xA;&lt;li&gt;安装目录下的 Scripts 子目录&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;点击&amp;quot;确定&amp;quot;保存修改&lt;/li&gt;&#xA;&lt;li&gt;需启动新的命令提示符窗口才能使变更生效&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3&gt;用 pip 安装 Robot Framework&lt;/h3&gt;&#xA;&lt;p&gt;这里介绍了使用 Python 标准包管理工具 pip 安装 Robot Framework 的方法。若你使用的是 Conda 等其他包管理器，虽可替代使用，但需查阅其官方文档获取具体安装说明。&lt;/p&gt;&#xA;&lt;p&gt;通常情况下，安装 Python 时会自动附带安装 pip。如未自动安装，请参考该 Python 发行版的官方文档，了解如何单独安装 pip。&lt;/p&gt;&#xA;&lt;h4&gt;运行 pip 命令&lt;/h4&gt;&#xA;&lt;p&gt;通常可以直接运行 pip 命令使用 pip 工具，但在 Linux 系统上，可能需要改用 pip3 或更具体的版本号命令（如 pip3.8）。执行 pip 命令时，系统会优先调用 PATH 环境变量中第一个匹配的可执行文件。若安装了多个 Python 版本，可通过 &lt;code&gt;python -m pip&lt;/code&gt; 方式明确指定使用特定版本的 pip。&lt;/p&gt;&#xA;&lt;p&gt;要确认系统是否已安装 pip，可执行 &lt;code&gt;pip --version&lt;/code&gt; 来检查。&lt;/p&gt;&#xA;&lt;p&gt;Linux 上的例子：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pip --version&#xA;pip 23.2.1 from ... (python 3.10)&#xA;$ python3.12 -m pip --version&#xA;pip 23.3.1 from ... (python 3.12)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Windows 上的例子：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;C:\&amp;gt; pip --version&#xA;pip 23.2.1 from ... (python 3.10)&#xA;C:\&amp;gt; py -m 3.12 -m pip --version&#xA;pip 23.3.2 from ... (python 3.12)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在后续章节中，我们将统一使用 &lt;code&gt;pip&lt;/code&gt; 命令作为示例。根据你的具体环境，可能需要改用前文所述的其他替代方案（如 &lt;code&gt;pip3&lt;/code&gt; 或 &lt;code&gt;python -m pip&lt;/code&gt;）。&lt;/p&gt;&#xA;&lt;h4&gt;安装和卸载 Robot Framework&lt;/h4&gt;&#xA;&lt;p&gt;使用 pip 最简单的方式是让其自动从 Python 软件包索引(&lt;a href=&#34;https://pypi.org/project/robotframework&#34;&gt;PyPI&lt;/a&gt;)查找并下载安装包，但也可以手动安装从 PyPI 单独下载的软件包。以下是几种最常用的安装方式，更多详细信息和示例请参阅 &lt;a href=&#34;https://pip.pypa.io/&#34;&gt;pip 官方文档&lt;/a&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 安装最新版 (不会升级)&#xA;pip install robotframework&#xA;&#xA;# 升级到最新稳定版本&#xA;pip install --upgrade robotframework&#xA;&#xA;# 升级到最新 pre 版本&#xA;pip install --upgrade --pre robotframework&#xA;&#xA;# 安装特定版本&#xA;pip install robotframework==7.0&#xA;&#xA;# 从下载的包中安装（无网络）&#xA;pip install robotframework-7.0-py3-none-any.whl&#xA;&#xA;# 从 GitHub 最新的代码中安装&#xA;pip install https://github.com/robotframework/robotframework/archive/master.zip&#xA;&#xA;# 卸载&#xA;pip uninstall robotframework&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;从源码安装 Robot Framework&lt;/h3&gt;&#xA;&lt;p&gt;另一种安装方式是获取 Robot Framework 源码并通过 setup.py 脚本进行安装。此方法仅建议在无法使用 pip 的情况下采用。&lt;/p&gt;&#xA;&lt;p&gt;获取源码有两种途径：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;从 PyPI 下载源码发行包并解压&lt;/li&gt;&#xA;&lt;li&gt;克隆 GitHub 仓库后检出所需的发布标签&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;获取源码后，执行以下命令即可完成安装：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python setup.py install&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;setup.py&lt;/code&gt; 脚本支持多个参数配置，例如：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;可指定非默认安装路径（无需管理员权限）&lt;/li&gt;&#xA;&lt;li&gt;可用于生成不同格式的发行包&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;运行 &lt;code&gt;python setup.py --help&lt;/code&gt; 命令查看完整参数说明。&lt;/p&gt;&#xA;&lt;h3&gt;验证安装&lt;/h3&gt;&#xA;&lt;p&gt;要验证安装的 Robot Framework 版本是否正确，请执行以下命令：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ robot --version&#xA;Robot Framework 7.0 (Python 3.10.3 on linux)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;若执行上述命令时提示&amp;quot;command not found&amp;quot;（命令未找到）或&amp;quot;无法识别&amp;quot;等错误，建议首先检查 PATH 环境变量配置是否正确。&lt;/p&gt;&#xA;&lt;p&gt;若已在多个 Python 版本下安装 Robot Framework，直接运行 robot 命令将执行 PATH 中优先级最高的版本。如需指定特定版本，可使用 &lt;code&gt;python -m robot&lt;/code&gt; 命令格式：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ python3.12 -m robot --version&#xA;Robot Framework 7.0 (Python 3.12.1 on linux)&#xA;&#xA;C:\&amp;gt;py -3.11 -m robot --version&#xA;Robot Framework 7.0 (Python 3.11.7 on win32)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;虚拟环境&lt;/h3&gt;&#xA;&lt;p&gt;Python 虚拟环境（&lt;a href=&#34;https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/#creating-a-virtual-environment&#34;&gt;virtual environments&lt;/a&gt;）可将 Python 包安装在特定项目或应用的独立隔离位置，而非全部安装到全局共享位置。其主要应用场景包括：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;项目依赖隔离&#xA;&lt;ul&gt;&#xA;&lt;li&gt;为不同项目创建独立环境安装所需依赖包&lt;/li&gt;&#xA;&lt;li&gt;避免项目间因需要同一包的不同版本而产生冲突&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;系统环境保护&#xA;&lt;ul&gt;&#xA;&lt;li&gt;防止全局 Python 环境被污染&lt;/li&gt;&#xA;&lt;li&gt;在 Linux 系统中尤为重要，因其发行版可能依赖系统 Python 环境&lt;/li&gt;&#xA;&lt;li&gt;随意修改全局安装可能导致严重系统问题&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/07/02/robotframework-new-tutorial-getting-started/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>使用 GenServer 的客户端-服务器通信</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/06/30/elixir-beginner-1/</id>
    <content type="html">&lt;p&gt;由于 agent 本身就是进程，每个 bucket 都有一个进程标识符(PID)，但这些 bucket 并没有名称，可以通过 atoms 在 Elixir 中注册进程：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;iex&amp;gt; Agent.start_link(fn -&amp;gt; %{} end, name: :shopping)&#xA;{:ok, #PID&amp;lt;0.43.0&amp;gt;}&#xA;iex&amp;gt; KV.Bucket.put(:shopping, &amp;quot;milk&amp;quot;, 1)&#xA;:ok&#xA;iex&amp;gt; KV.Bucket.get(:shopping, &amp;quot;milk&amp;quot;)&#xA;1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;然而，使用 atoms 来命名动态进程是个糟糕的主意！如果采用 atoms 命名方式，我们就需要将 bucket 名称（通常来自外部客户端输入）转换为 atoms，而&lt;strong&gt;绝对不应该将用户输入直接转换为 atoms&lt;/strong&gt;。这是因为 atoms 不会被垃圾回收机制处理——一旦 atoms 被创建就永远存在。若根据用户输入动态生成 atoms，意味着用户可以注入大量不同的名称，最终耗尽系统内存！&lt;/p&gt;&#xA;&lt;p&gt;实际上，在内存耗尽之前，你更有可能先达到 Erlang 虚拟机对 atoms 数量的上限限制，无论如何这都会导致你的系统崩溃。&lt;/p&gt;&#xA;&lt;p&gt;与其滥用内置的命名机制，我们将创建自己的进程注册表，将 bucket 名称与对应的 bucket 进程关联起来。&lt;/p&gt;&#xA;&lt;p&gt;注册表必须保证始终处于最新状态。例如，当某个 bucket 进程因故障崩溃时，注册表必须感知这一变更，避免提供过期的进程信息。在 Elixir 中，这种机制称为&amp;quot;注册表需要监控（monitor）每个 bucket 进程&amp;quot;。由于注册表需要能够接收并处理系统发送的即时消息，仅靠 &lt;code&gt;Agent&lt;/code&gt; API 已无法满足需求。&lt;/p&gt;&#xA;&lt;p&gt;我们将使用 &lt;code&gt;GenServer&lt;/code&gt; 来创建一个能够监控 bucket 进程的注册表进程。&lt;code&gt;GenServer&lt;/code&gt; 为 Elixir 和 OTP 提供了工业级强度的服务器构建功能。&lt;/p&gt;&#xA;&lt;h2&gt;GenServer 回调&lt;/h2&gt;&#xA;&lt;p&gt;GenServer 是一种进程，它会在特定条件下调用一组有限的函数。当我们使用 Agent 时，客户端代码和服务器端代码通常是并列编写的，如下所示：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;def put(bucket, key, value) do&#xA;  Agent.update(bucket, &amp;amp;Map.put(&amp;amp;1, key, value))&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;让我们来稍微拆解一下这段代码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;def put(bucket, key, value) do&#xA;  # 这里是客户端代码&#xA;  Agent.update(bucket, fn state -&amp;gt;&#xA;    # 这里是服务端代码&#xA;    Map.put(state, key, value)&#xA;  end)&#xA;  # 回到客户端代码&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在上面这段代码中，我们有一个进程（称为&amp;quot;客户端&amp;quot;）向一个 Agent 进程（称为&amp;quot;服务端&amp;quot;）发送请求。该请求包含一个匿名函数，这个函数必须在服务端执行。&lt;/p&gt;&#xA;&lt;p&gt;而在 GenServer 的实现中，上述代码会被拆分成两个独立的函数，大致如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;def put(bucket, key, value) do&#xA;  # 发送给服务器 :put 指令&#xA;  GenServer.call(bucket, {:put, key, value})&#xA;end&#xA;&#xA;# 服务器回调&#xA;&#xA;def handle_call({:put, key, value}, _from, state) do&#xA;  {:reply, :ok, Map.put(state, key, value)}&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;GenServer 的代码确实需要更多的规范步骤，但正如我们将要看到的，这也带来了一些优势。&lt;/p&gt;&#xA;&lt;p&gt;目前，我们暂时只为 bucket 注册逻辑编写服务器回调函数，稍后再提供完整的 API 接口。&lt;/p&gt;&#xA;&lt;p&gt;新建一个文件 &lt;code&gt;lib/kv/registry.ex&lt;/code&gt;，内容如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;defmodule KV.Registry do&#xA;  use GenServer&#xA;&#xA;  ## Missing Client API - will add this later&#xA;&#xA;  ## Defining GenServer Callbacks&#xA;&#xA;  @impl true&#xA;  def init(:ok) do&#xA;    {:ok, %{}}&#xA;  end&#xA;&#xA;  @impl true&#xA;  def handle_call({:lookup, name}, _from, names) do&#xA;    {:reply, Map.fetch(names, name), names}&#xA;  end&#xA;&#xA;  @impl true&#xA;  def handle_cast({:create, name}, names) do&#xA;    if Map.has_key?(names, name) do&#xA;      {:noreply, names}&#xA;    else&#xA;      {:ok, bucket} = KV.Bucket.start_link([])&#xA;      {:noreply, Map.put(names, name, bucket)}&#xA;    end&#xA;  end&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 GenServer 中，您可以发送两种类型的请求：call（同步调用）和 cast（异步调用）。call 是同步请求，服务器必须返回响应，在服务器计算响应期间客户端会保持等待。cast 是异步请求，服务器不会返回响应，因此客户端也不会等待响应。这两种请求都是以消息形式发送给服务器的，并且会按顺序依次处理。&lt;/p&gt;&#xA;&lt;p&gt;在上述实现中，我们通过模式匹配来区分不同消息：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;处理 &lt;code&gt;:create&lt;/code&gt; 消息时采用 cast（异步调用）&lt;/li&gt;&#xA;&lt;li&gt;处理 &lt;code&gt;:lookup&lt;/code&gt; 消息时采用 call（同步调用）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;要触发上述回调函数，我们需要通过相应的 GenServer 函数来操作。让我们启动一个注册表进程，创建一个具名 bucket，然后进行查询：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;iex&amp;gt; {:ok, registry} = GenServer.start_link(KV.Registry, :ok)&#xA;{:ok, #PID&amp;lt;0.136.0&amp;gt;}&#xA;iex&amp;gt; GenServer.cast(registry, {:create, &amp;quot;shopping&amp;quot;})&#xA;:ok&#xA;iex&amp;gt; {:ok, bucket} = GenServer.call(registry, {:lookup, &amp;quot;shopping&amp;quot;})&#xA;{:ok, #PID&amp;lt;0.174.0&amp;gt;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们的 &lt;code&gt;KV.Registry&lt;/code&gt; 进程依次接收到了两条消息：首先是 cast 方式的 &lt;code&gt;{:create, &amp;quot;shopping&amp;quot;}&lt;/code&gt; 请求，随后是 call 方式的 &lt;code&gt;{:lookup, &amp;quot;shopping&amp;quot;}&lt;/code&gt; 请求。&lt;code&gt;GenServer.cast &lt;/code&gt;在消息发送给注册表后会立即返回，而 &lt;code&gt;GenServer.call&lt;/code&gt; 则会等待来自 &lt;code&gt;KV.Registry.handle_call&lt;/code&gt; 回调函数提供的响应结果。&lt;/p&gt;&#xA;&lt;p&gt;你可能已经注意到，我们在每个回调函数前都添加了 &lt;code&gt;@impl true&lt;/code&gt; 注解。&lt;code&gt;@impl true&lt;/code&gt; 会告知编译器：我们接下来要定义的函数是一个回调实现。这样，如果我们不小心写错了函数名或参数数量（比如错误地定义了一个 &lt;code&gt;handle_call/2&lt;/code&gt; 函数），编译器就会警告我们并不存在需要实现的 &lt;code&gt;handle_call/2&lt;/code&gt; 回调，同时还会列出 GenServer 模块所有已知的回调函数清单。&lt;/p&gt;&#xA;&lt;p&gt;虽然目前实现得不错，但我们还需要为用户提供一个 API 接口层，这样就能隐藏具体的实现细节。&lt;/p&gt;&#xA;&lt;h2&gt;客户端 API&lt;/h2&gt;&#xA;&lt;p&gt;GenServer 的实现包含两个部分：客户端 API 和服务器回调。你可以选择将这两部分合并到单个模块中，也可以将它们分别放在客户端模块和服务器模块中。客户端是指调用客户端函数的任何进程，而服务器始终是进程标识符(PID)或进程名称，我们会将其作为参数显式传递给客户端 API。在本文中，我们将使用单个模块来同时包含服务器回调和客户端 API。&lt;/p&gt;&#xA;&lt;p&gt;编辑 &lt;code&gt;lib/kv/registry.ex&lt;/code&gt; 文件，补全客户端 API 的空缺部分：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;  ## Client API&#xA;&#xA;  @doc &amp;quot;&amp;quot;&amp;quot;&#xA;  启动注册中心&#xA;  &amp;quot;&amp;quot;&amp;quot;&#xA;  def start_link(opts) do&#xA;    GenServer.start_link(__MODULE__, :ok, opts)&#xA;  end&#xA;&#xA;  @doc &amp;quot;&amp;quot;&amp;quot;&#xA;  查找存储在 server 中与 name 对应的 bucket 进程 pid&#xA;&#xA;  如果 bucket 存在则返回 {:ok, pid}，否则返回 :error&#xA;  &amp;quot;&amp;quot;&amp;quot;&#xA;  def lookup(server, name) do&#xA;    GenServer.call(server, {:lookup, name})&#xA;  end&#xA;&#xA;  @doc &amp;quot;&amp;quot;&amp;quot;&#xA;  确保在 server 中存在与指定 name 关联的 bucket&#xA;  &amp;quot;&amp;quot;&amp;quot;&#xA;  def create(server, name) do&#xA;    GenServer.cast(server, {:create, name})&#xA;  end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;第一个函数是 &lt;code&gt;start_link/1&lt;/code&gt;，它会启动一个新的 GenServer 进程并传入一个选项列表。&lt;code&gt;start_link/1&lt;/code&gt; 内部调用了 &lt;code&gt;GenServer.start_link/3&lt;/code&gt; 函数，后者接收三个参数：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;实现服务器回调的模块（此处使用 &lt;code&gt;__MODULE__&lt;/code&gt; 宏表示当前模块）&lt;/li&gt;&#xA;&lt;li&gt;初始化参数（此处使用原子 &lt;code&gt;:ok&lt;/code&gt; 作为参数）&lt;/li&gt;&#xA;&lt;li&gt;选项列表（可用于配置服务器名称等参数）。目前，我们将 &lt;code&gt;start_link/1&lt;/code&gt; 接收到的选项列表直接透传给 &lt;code&gt;GenServer.start_link/3&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;接下来的两个函数 &lt;code&gt;lookup/2&lt;/code&gt; 和 &lt;code&gt;create/2&lt;/code&gt; 负责向服务器发送请求。这里我们分别使用了 &lt;code&gt;{:lookup, name}&lt;/code&gt; 和 &lt;code&gt;{:create, name}&lt;/code&gt; 这样的元组结构。通常会将请求动作指定为元组的第一个元素，而将相关参数放在后续元素中，这样就能在第一个参数槽位传递多个&amp;quot;参数&amp;quot;。需要注意的是，这些请求必须与 &lt;code&gt;handle_call/3&lt;/code&gt; 或 &lt;code&gt;handle_cast/2&lt;/code&gt; 的第一个参数模式相匹配。&lt;/p&gt;&#xA;&lt;p&gt;客户端 API 部分就介绍到这里。在服务器端，我们可以实现多种回调函数来确保服务器的初始化、终止和请求处理。这些回调都是可选的，目前我们只实现了所需的部分。下面做个简要回顾：&lt;/p&gt;&#xA;&lt;p&gt;首先是 &lt;code&gt;init/1&lt;/code&gt; 回调函数，它接收传给 &lt;code&gt;GenServer.start_link/3&lt;/code&gt; 的第二个参数，并返回 &lt;code&gt;{:ok, state}&lt;/code&gt;（其中 state 是一个新建的映射）。从这里我们就能看出 &lt;code&gt;GenServer&lt;/code&gt; 的 API 设计如何清晰地区分了客户端和服务端逻辑：&lt;code&gt;start_link/3&lt;/code&gt; 在客户端执行，而 &lt;code&gt;init/1&lt;/code&gt; 则是对应在服务端运行的回调。&lt;/p&gt;&#xA;&lt;p&gt;对于 &lt;code&gt;call/2&lt;/code&gt; 请求，我们通过实现 &lt;code&gt;handle_call/3&lt;/code&gt; 回调来处理，该回调接收三个参数：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;请求内容（&lt;code&gt;request&lt;/code&gt;）&lt;/li&gt;&#xA;&lt;li&gt;请求来源进程（&lt;code&gt;_from&lt;/code&gt;，使用下划线表示未使用变量）&lt;/li&gt;&#xA;&lt;li&gt;当前服务器状态（&lt;code&gt;names&lt;/code&gt;）&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;该回调需要返回 &lt;code&gt;{:reply, reply, new_state}&lt;/code&gt; 格式的元组，其中：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;元组首元素 &lt;code&gt;:reply&lt;/code&gt; 表示服务器需要向客户端返回响应&lt;/li&gt;&#xA;&lt;li&gt;第二个元素 &lt;code&gt;reply&lt;/code&gt; 是将发送给客户端的实际响应数据&lt;/li&gt;&#xA;&lt;li&gt;第三个元素 &lt;code&gt;new_state&lt;/code&gt; 是更新后的服务器状态&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;针对 &lt;code&gt;cast/2&lt;/code&gt; 请求，我们通过实现 &lt;code&gt;handle_cast/2&lt;/code&gt; 回调函数来处理，该函数接收两个参数：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;请求内容（&lt;code&gt;request&lt;/code&gt;）&lt;/li&gt;&#xA;&lt;li&gt;当前服务器状态（&lt;code&gt;names&lt;/code&gt;）&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;回调函数需返回 &lt;code&gt;{:noreply, new_state}&lt;/code&gt; 格式的元组。值得注意的是，在实际生产应用中，我们通常会使用同步调用（call）而非异步请求（cast）来实现 &lt;code&gt;:create&lt;/code&gt; 操作。这里之所以采用 cast 方式，是为了演示如何实现异步回调处理。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;handle_call/3&lt;/code&gt; 和 &lt;code&gt;handle_cast/2&lt;/code&gt; 回调函数还可以返回其他格式的元组响应。此外，我们还可以实现像 &lt;code&gt;terminate/2&lt;/code&gt; 和 &lt;code&gt;code_change/3&lt;/code&gt; 这样的回调函数。&lt;/p&gt;&#xA;&lt;p&gt;现在，让我们编写一些测试来验证 GenServer 是否按预期工作。&lt;/p&gt;&#xA;&lt;h2&gt;测试 GenServer&lt;/h2&gt;&#xA;&lt;p&gt;测试 GenServer 与测试 Agent 并无太大差异。我们会在测试的 setup 回调中启动服务器进程，并在所有测试用例中复用该进程。创建 &lt;code&gt;test/kv/registry_test.exs&lt;/code&gt; 文件，内容如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;defmodule KV.RegistryTest do&#xA;  use ExUnit.Case, async: true&#xA;&#xA;  setup do&#xA;    registry = start_supervised!(KV.Registry)&#xA;    %{registry: registry}&#xA;  end&#xA;&#xA;  test &amp;quot;spawns buckets&amp;quot;, %{registry: registry} do&#xA;    assert KV.Registry.lookup(registry, &amp;quot;shopping&amp;quot;) == :error&#xA;&#xA;    KV.Registry.create(registry, &amp;quot;shopping&amp;quot;)&#xA;    assert {:ok, bucket} = KV.Registry.lookup(registry, &amp;quot;shopping&amp;quot;)&#xA;&#xA;    KV.Bucket.put(bucket, &amp;quot;milk&amp;quot;, 1)&#xA;    assert KV.Bucket.get(bucket, &amp;quot;milk&amp;quot;) == 1&#xA;  end&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;测试用例的执行流程如下：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;首先验证注册表中不存在任何 bucket&lt;/li&gt;&#xA;&lt;li&gt;创建一个具名 bucket&lt;/li&gt;&#xA;&lt;li&gt;查询该 bucket&lt;/li&gt;&#xA;&lt;li&gt;最终验证其确为可用的 bucket 实例&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;我们为 &lt;code&gt;KV.Registry&lt;/code&gt; 编写的 &lt;code&gt;setup&lt;/code&gt; 代码块与之前 &lt;code&gt;KV.Bucket&lt;/code&gt; 的 &lt;code&gt;setup&lt;/code&gt; 有一个重要区别：不再手动调用 &lt;code&gt;KV.Registry.start_link/1&lt;/code&gt; 来启动注册表，而是改用 &lt;code&gt;ExUnit.Callbacks.start_supervised!/2&lt;/code&gt; 函数并传入 &lt;code&gt;KV.Registry&lt;/code&gt; 模块来启动。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;start_supervised!&lt;/code&gt; 函数通过 &lt;code&gt;use ExUnit.Case&lt;/code&gt; 被注入到我们的测试模块中。它的工作原理是通过调用 &lt;code&gt;KV.Registry.start_link/1&lt;/code&gt; 来启动注册表进程。使用 &lt;code&gt;start_supervised!&lt;/code&gt; 的优势在于：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;进程生命周期管理&lt;/strong&gt;：ExUnit 会确保注册表进程在下个测试开始前被关闭&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;测试隔离保障&lt;/strong&gt;：防止依赖共享资源的测试用例之间产生状态干扰&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;自动清理机制&lt;/strong&gt;：即使测试失败也会执行进程终止操作&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;在测试中启动进程时，我们应当始终优先使用 &lt;code&gt;start_supervised!&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h2&gt;监控的必要性&lt;/h2&gt;&#xA;&lt;p&gt;截至目前，我们实现的所有功能其实都可以通过 Agent 来完成。而在本节中，我们将展示 GenServer 相比 Agent 的独特优势——它能实现许多 Agent 无法完成的功能。&lt;/p&gt;&#xA;&lt;p&gt;让我们从一个测试用例开始，该用例描述了当 bucket 进程停止或崩溃时期望注册表表现的行为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;test &amp;quot;removes buckets on exit&amp;quot;, %{registry: registry} do&#xA;  KV.Registry.create(registry, &amp;quot;shopping&amp;quot;)&#xA;  {:ok, bucket} = KV.Registry.lookup(registry, &amp;quot;shopping&amp;quot;)&#xA;  Agent.stop(bucket)&#xA;  assert KV.Registry.lookup(registry, &amp;quot;shopping&amp;quot;) == :error&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;上述测试会在最后一个断言处失败，因为即使 bucket 进程停止后，其名称仍会保留在注册表中。&lt;/p&gt;&#xA;&lt;p&gt;要修复这个问题，我们需要让注册表监控其创建的每个 bucket 进程。建立监控后，每当 bucket 进程退出时，注册表都会收到通知，从而使我们能够清理注册表。&lt;/p&gt;&#xA;&lt;p&gt;首先让我们通过 &lt;code&gt;iex -S mix&lt;/code&gt; 启动新控制台来实践监控机制：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;iex&amp;gt; {:ok, pid} = KV.Bucket.start_link([])&#xA;{:ok, #PID&amp;lt;0.66.0&amp;gt;}&#xA;iex&amp;gt; Process.monitor(pid)&#xA;#Reference&amp;lt;0.0.0.551&amp;gt;&#xA;iex&amp;gt; Agent.stop(pid)&#xA;:ok&#xA;iex&amp;gt; flush()&#xA;{:DOWN, #Reference&amp;lt;0.0.0.551&amp;gt;, :process, #PID&amp;lt;0.66.0&amp;gt;, :normal}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;请注意，&lt;code&gt;Process.monitor(pid)&lt;/code&gt; 会返回一个唯一的监控引用（reference），这个引用允许我们将后续收到的消息与对应的监控请求相匹配。当我们停止 Agent 进程后，可以通过 &lt;code&gt;flush/0&lt;/code&gt; 查看所有消息，此时会观察到一条 &lt;code&gt;:DOWN&lt;/code&gt; 消息 —— 其中包含与监控引用完全匹配的应用，通知我们 bucket 进程已以 &lt;code&gt;:normal&lt;/code&gt; 原因退出。&lt;/p&gt;&#xA;&lt;p&gt;让我们重新实现服务器回调函数来修复这个错误并使测试通过。具体需要以下修改步骤：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;状态结构调整：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;将 GenServer 状态改为包含两个映射表：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;name_to_pid&lt;/code&gt;：存储 名称 -&amp;gt; 进程ID 的映射&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;ref_to_name&lt;/code&gt;：存储 监控引用 -&amp;gt; 名称 的映射&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;监控机制实现：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;在 &lt;code&gt;handle_cast/2&lt;/code&gt; 回调中为每个新创建的 bucket 进程设置监控&lt;/li&gt;&#xA;&lt;li&gt;新增 &lt;code&gt;handle_info/2&lt;/code&gt; 回调处理监控消息：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;匹配 &lt;code&gt;:DOWN&lt;/code&gt; 消息&lt;/li&gt;&#xA;&lt;li&gt;清理已终止进程的注册信息&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;下面是修改后的服务器回调完整实现：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;## Server callbacks&#xA;&#xA;@impl true&#xA;def init(:ok) do&#xA;  names = %{}&#xA;  refs = %{}&#xA;  {:ok, {names, refs}}&#xA;end&#xA;&#xA;@impl true&#xA;def handle_call({:lookup, name}, _from, state) do&#xA;  {names, _} = state&#xA;  {:reply, Map.fetch(names, name), state}&#xA;end&#xA;&#xA;@impl true&#xA;def handle_cast({:create, name}, {names, refs}) do&#xA;  if Map.has_key?(names, name) do&#xA;    {:noreply, {names, refs}}&#xA;  else&#xA;    {:ok, bucket} = KV.Bucket.start_link([])&#xA;    ref = Process.monitor(bucket)&#xA;    refs = Map.put(refs, ref, name)&#xA;    names = Map.put(names, name, bucket)&#xA;    {:noreply, {names, refs}}&#xA;  end&#xA;end&#xA;&#xA;@impl true&#xA;def handle_info({:DOWN, ref, :process, _pid, _reason}, {names, refs}) do&#xA;  {name, refs} = Map.pop(refs, ref)&#xA;  names = Map.delete(names, name)&#xA;  {:noreply, {names, refs}}&#xA;end&#xA;&#xA;@impl true&#xA;def handle_info(msg, state) do&#xA;  require Logger&#xA;  Logger.debug(&amp;quot;Unexpected message in KV.Registry: #{inspect(msg)}&amp;quot;)&#xA;  {:noreply, state}&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到，我们在完全不修改客户端 API 的情况下，就完成了服务端实现的重大调整——这正是明确分离客户端与服务端架构带来的核心优势之一。&lt;/p&gt;&#xA;&lt;p&gt;特别需要注意的是，与其他回调不同，我们为 &lt;code&gt;handle_info/2&lt;/code&gt; 定义了一个&amp;quot;全捕获&amp;quot;（catch-all）处理分支，该分支会记录并丢弃所有未知消息。要理解这样设计的原因，让我们继续下一章节的探讨。&lt;/p&gt;&#xA;&lt;h2&gt;call, cast 还是 info？&lt;/h2&gt;&#xA;&lt;p&gt;截至目前，我们已经使用了三种回调函数：&lt;code&gt;handle_call/3&lt;/code&gt;、&lt;code&gt;handle_cast/2&lt;/code&gt; 和 &lt;code&gt;handle_info/2&lt;/code&gt;。以下是各回调函数的使用场景指南：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;同步请求处理 - &lt;code&gt;handle_call/3&lt;/code&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;必须用于同步请求&lt;/li&gt;&#xA;&lt;li&gt;应作为默认选择，因为等待服务端响应本身就是一种有效的背压(back-pressure)机制&lt;/li&gt;&#xA;&lt;li&gt;示例：本应在本章 &lt;code&gt;create/2&lt;/code&gt; 函数中使用（当前为教学目的使用了 cast）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;异步请求处理 - &lt;code&gt;handle_cast/2&lt;/code&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;必须用于不需要回复的异步请求&lt;/li&gt;&#xA;&lt;li&gt;不保证服务端必定收到消息，故应谨慎使用&lt;/li&gt;&#xA;&lt;li&gt;典型场景：无需确认的广播类操作&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;系统消息处理 - &lt;code&gt;handle_info/2&lt;/code&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;必须处理所有非 GenServer 标准调用消息&lt;/li&gt;&#xA;&lt;li&gt;包括：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;原生 &lt;code&gt;send/2&lt;/code&gt; 发送的消息&lt;/li&gt;&#xA;&lt;li&gt;系统监控消息（如 &lt;code&gt;:DOWN&lt;/code&gt; 通知）&lt;/li&gt;&#xA;&lt;li&gt;其他意外消息（需实现兜底处理）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;由于所有消息（包括通过 &lt;code&gt;send/2&lt;/code&gt; 发送的消息）都会交由 &lt;code&gt;handle_info/2&lt;/code&gt; 处理，因此服务端很可能会收到预期之外的消息。如果不定义&amp;quot;全捕获&amp;quot;（catch-all）处理分支，这些消息就会因无法匹配任何模式而导致注册表进程崩溃。不过对于 &lt;code&gt;handle_call/3&lt;/code&gt; 和 &lt;code&gt;handle_cast/2&lt;/code&gt; 则无需此类担忧——因为 call/cast 操作只能通过 &lt;code&gt;GenServer&lt;/code&gt; API 发起，未知消息通常意味着开发者的编码错误。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/06/30/elixir-beginner-1/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Agent 实现简单的状态管理</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/06/27/elixir-beginner-0/</id>
    <content type="html">&lt;p&gt;在本章中，我们将学习如何在多个实体之间保存和共享状态。如果你有编程经验，可能会想到全局共享变量，但我们这里要学习的模式截然不同。后续章节将对这里介绍的概念进行拓展。&lt;/p&gt;&#xA;&lt;h2&gt;创建工程&lt;/h2&gt;&#xA;&lt;p&gt;让我们通过命令行调用 &lt;code&gt;mix new&lt;/code&gt; 来创建第一个项目。我们将项目路径作为参数传入（本例中为 &lt;code&gt;kv&lt;/code&gt;）。默认情况下，应用程序名称和模块名称会从路径中获取。因此我们需要告知 Mix，我们的主模块应该是全大写的 &lt;code&gt;KV&lt;/code&gt;，而不是默认的 &lt;code&gt;Kv&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ mix new kv --module KV&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Mix 会创建一个名为 &lt;code&gt;kv&lt;/code&gt; 的目录，其中包含以下文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;* creating README.md&#xA;* creating .formatter.exs&#xA;* creating .gitignore&#xA;* creating mix.exs&#xA;* creating lib&#xA;* creating lib/kv.ex&#xA;* creating test&#xA;* creating test/test_helper.exs&#xA;* creating test/kv_test.exs&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;（可变）状态带来的问题&lt;/h2&gt;&#xA;&lt;p&gt;Elixir 是一门基于不可变数据的语言，默认情况下所有数据都不共享。当我们需要在多个地方读取和修改共享信息时，Elixir 主要提供两种方案：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;通过进程与消息传递：每个进程维护自己的状态，通过异步消息进行通信&lt;/li&gt;&#xA;&lt;li&gt;ETS (Erlang Term Storage)：内存中的键值存储，支持高效并发访问&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;我们很少手动创建原始进程，而是使用 Elixir 和 OTP 提供的抽象层：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Agent - 对状态进行简单封装&lt;/li&gt;&#xA;&lt;li&gt;GenServer - “通用服务器”进程，封装状态并提供同步/异步调用，支持代码热更新等特性&lt;/li&gt;&#xA;&lt;li&gt;Task - 异步计算单元，允许创建进程并在稍后获取计算结果&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这里我们将使用 Agent 来创建一个名为 &lt;code&gt;KV.Bucket&lt;/code&gt; 的模块，该模块负责以允许其他进程读取和修改的方式存储我们的键值对数据。&lt;/p&gt;&#xA;&lt;h2&gt;Agent 代理入门&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;Agent&lt;/code&gt; 代理是对状态的简单封装。如果你只需要一个进程来维护状态，那么 agent 会是一个很好的选择。让我们在项目内启动一个 &lt;code&gt;iex&lt;/code&gt; 会话：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ iex -S mix&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;然后我们来简单体验一下 agent 的使用：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;iex&amp;gt; {:ok, agent} = Agent.start_link(fn -&amp;gt; [] end)&#xA;{:ok, #PID&amp;lt;0.57.0&amp;gt;}&#xA;iex&amp;gt; Agent.update(agent, fn list -&amp;gt; [&amp;quot;eggs&amp;quot; | list] end)&#xA;:ok&#xA;iex&amp;gt; Agent.get(agent, fn list -&amp;gt; list end)&#xA;[&amp;quot;eggs&amp;quot;]&#xA;iex&amp;gt; Agent.stop(agent)&#xA;:ok&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们启动了一个初始状态为空列表的 agent。随后更新了 agent 的状态，将新项添加到列表头部。&lt;code&gt;Agent.update/3&lt;/code&gt; 的第二个参数是一个函数，它接收 agent 当前状态作为输入并返回期望的新状态。最后，我们获取了整个列表。&lt;code&gt;Agent.get/3&lt;/code&gt; 的第二个参数同样是一个函数，它接收状态作为输入并返回 &lt;code&gt;Agent.get/3&lt;/code&gt; 自身将输出的值。当我们完成 agent 操作后，可以调用 &lt;code&gt;Agent.stop/3&lt;/code&gt; 来终止 agent 进程。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Agent.update/3&lt;/code&gt; 函数的第二个参数可以接收任何单参数函数（该函数接收一个参数并返回一个值）。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;iex&amp;gt; {:ok, agent} = Agent.start_link(fn -&amp;gt; [] end)&#xA;{:ok, #PID&amp;lt;0.338.0&amp;gt;}&#xA;iex&amp;gt; Agent.update(agent, fn _list -&amp;gt; 123 end)&#xA;:ok&#xA;iex&amp;gt; Agent.update(agent, fn content -&amp;gt; %{a: content} end)&#xA;:ok&#xA;iex&amp;gt; Agent.update(agent, fn content -&amp;gt; [12 | [content]] end)&#xA;:ok&#xA;iex&amp;gt; Agent.update(agent, fn list -&amp;gt; [:nop | list] end)&#xA;:ok&#xA;iex&amp;gt; Agent.get(agent, fn content -&amp;gt; content end)&#xA;[:nop, 12, %{a: 123}]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如你所见，我们可以任意修改 agent 的状态。因此，我们通常不希望在整个代码库的多个不同位置直接访问 Agent 的 API。相反，我们希望将所有与 Agent 相关的功能封装在一个单独的模块中，这里我们将其命名为 &lt;code&gt;KV.Bucket&lt;/code&gt;。在实现这个模块之前，我们先编写一些测试用例，通过这些测试来明确该模块对外暴露的 API 接口。&lt;/p&gt;&#xA;&lt;p&gt;创建一个文件 &lt;code&gt;test/kv/bucket_test.exs&lt;/code&gt;（注意扩展名是 &lt;code&gt;.exs&lt;/code&gt;），内容如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;defmodule KV.BucketTest do&#xA;  use ExUnit.Case, async: true&#xA;&#xA;  test &amp;quot;stores values by key&amp;quot; do&#xA;    {:ok, bucket} = KV.Bucket.start_link([])&#xA;    assert KV.Bucket.get(bucket, &amp;quot;milk&amp;quot;) == nil&#xA;&#xA;    KV.Bucket.put(bucket, &amp;quot;milk&amp;quot;, 3)&#xA;    assert KV.Bucket.get(bucket, &amp;quot;milk&amp;quot;) == 3&#xA;  end&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;use ExUnit.Case&lt;/code&gt; 负责为我们的模块设置测试环境，并导入许多与测试相关的功能，例如 &lt;code&gt;test/2&lt;/code&gt; 宏。&lt;/p&gt;&#xA;&lt;p&gt;我们的第一个测试通过调用 &lt;code&gt;start_link/1&lt;/code&gt; 并传入一个空列表作为选项来启动一个新的 &lt;code&gt;KV.Bucket&lt;/code&gt;。然后对其执行了一些 &lt;code&gt;get/2&lt;/code&gt; 和 &lt;code&gt;put/3&lt;/code&gt; 操作，并对结果进行了断言。&lt;/p&gt;&#xA;&lt;p&gt;需要特别注意的是传入 &lt;code&gt;ExUnit.Case&lt;/code&gt; 的 &lt;code&gt;async: true&lt;/code&gt; 选项。这个选项会让测试用例以异步方式运行，与其他标记了 &lt;code&gt;:async&lt;/code&gt; 的测试用例并行执行，充分利用机器的多核处理能力。这对于加速测试套件执行非常有效。但需要注意：只有当测试用例不依赖或修改任何全局状态时才能设置 &lt;code&gt;:async&lt;/code&gt; 标志。例如，如果测试需要写入文件系统或访问数据库，就应该保持同步运行（去掉 &lt;code&gt;:async&lt;/code&gt; 选项），以避免测试间出现竞态条件。&lt;/p&gt;&#xA;&lt;p&gt;无论是否异步运行，我们新添加的测试显然会失败，因为被测模块中尚未实现任何相关功能：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;** (UndefinedFunctionError) function KV.Bucket.start_link/1 is undefined (module KV.Bucket is not available)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;为了修复失败的测试，我们将创建 &lt;code&gt;lib/kv/bucket.ex&lt;/code&gt; 文件，内容如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;defmodule KV.Bucket do&#xA;  use Agent&#xA;&#xA;  @doc &amp;quot;&amp;quot;&amp;quot;&#xA;  Starts a new bucket.&#xA;  &amp;quot;&amp;quot;&amp;quot;&#xA;  def start_link(_opts) do&#xA;    Agent.start_link(fn -&amp;gt; %{} end)&#xA;  end&#xA;&#xA;  @doc &amp;quot;&amp;quot;&amp;quot;&#xA;  Gets a value from the `bucket` by `key`.&#xA;  &amp;quot;&amp;quot;&amp;quot;&#xA;  def get(bucket, key) do&#xA;    Agent.get(bucket, &amp;amp;Map.get(&amp;amp;1, key))&#xA;  end&#xA;&#xA;  @doc &amp;quot;&amp;quot;&amp;quot;&#xA;  Puts the `value` for the given `key` in the `bucket`.&#xA;  &amp;quot;&amp;quot;&amp;quot;&#xA;  def put(bucket, key, value) do&#xA;    Agent.update(bucket, &amp;amp;Map.put(&amp;amp;1, key, value))&#xA;  end&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;第一步是调用 &lt;code&gt;use Agent&lt;/code&gt;。我们将学习的大多数功能（如 &lt;code&gt;GenServer&lt;/code&gt; 和 &lt;code&gt;Supervisor&lt;/code&gt;）都遵循这个模式。对于所有这些模块，调用 &lt;code&gt;use&lt;/code&gt; 都会生成一个带有默认配置的 &lt;code&gt;child_spec/1&lt;/code&gt; 函数，这对于监督进程非常有用（后面的博客会介绍）。接着，我们定义 &lt;code&gt;start_link/1&lt;/code&gt; 函数来实际启动 &lt;code&gt;agent&lt;/code&gt;。按照惯例，&lt;code&gt;start_link/1&lt;/code&gt; 函数总是接收一个选项列表参数。然后我们调用 &lt;code&gt;Agent.start_link/1&lt;/code&gt;，它接收一个返回 &lt;code&gt;agent&lt;/code&gt; 初始状态的匿名函数。我们在 &lt;code&gt;agent&lt;/code&gt; 内部维护一个 &lt;code&gt;map&lt;/code&gt; 来存储键值对。通过 Agent API 和捕获操作符 &lt;code&gt;&amp;amp;&lt;/code&gt; 来实现对 &lt;code&gt;map&lt;/code&gt; 的读写操作。当调用 &lt;code&gt;Agent.get/2&lt;/code&gt; 和 &lt;code&gt;Agent.update/2&lt;/code&gt; 时，&lt;code&gt;agent&lt;/code&gt; 会通过 &lt;code&gt;&amp;amp;1&lt;/code&gt; 参数将其状态传递给匿名函数。&lt;/p&gt;&#xA;&lt;p&gt;现在 &lt;code&gt;KV.Bucket&lt;/code&gt; 模块已经定义完成，我们的测试应该可以通过了！可以通过运行 &lt;code&gt;mix test&lt;/code&gt; 亲自验证。&lt;/p&gt;&#xA;&lt;h2&gt;使用 ExUnit 回调函数配置测试&lt;/h2&gt;&#xA;&lt;p&gt;在继续为 &lt;code&gt;KV.Bucket&lt;/code&gt; 添加更多功能之前，我们先来讨论一下 &lt;code&gt;ExUnit&lt;/code&gt; 的回调机制。所有 &lt;code&gt;KV.Bucket&lt;/code&gt; 测试都需要启动并运行一个 bucket agent。幸运的是，ExUnit 支持回调函数，可以帮助我们省去这类重复性工作。&lt;/p&gt;&#xA;&lt;p&gt;让我们用回调来重写测试用例：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;defmodule KV.BucketTest do&#xA;  use ExUnit.Case, async: true&#xA;&#xA;  setup do&#xA;    {:ok, bucket} = KV.Bucket.start_link([])&#xA;    %{bucket: bucket}&#xA;  end&#xA;&#xA;  test &amp;quot;stores values by key&amp;quot;, %{bucket: bucket} do&#xA;    assert KV.Bucket.get(bucket, &amp;quot;milk&amp;quot;) == nil&#xA;&#xA;    KV.Bucket.put(bucket, &amp;quot;milk&amp;quot;, 3)&#xA;    assert KV.Bucket.get(bucket, &amp;quot;milk&amp;quot;) == 3&#xA;  end&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们首先使用 &lt;code&gt;setup/1&lt;/code&gt; 宏定义了一个设置回调。这个 &lt;code&gt;setup/1&lt;/code&gt; 宏定义的回调会在每个测试之前运行，并且与测试本身在同一个进程中执行。&lt;/p&gt;&#xA;&lt;p&gt;需要注意的是，我们需要一种机制将 &lt;code&gt;bucket PID&lt;/code&gt; 从回调传递给测试。这里我们通过测试上下文(test context)实现这一功能。当回调返回 &lt;code&gt;%{bucket: bucket}&lt;/code&gt; 时，ExUnit 会将该映射合并到测试上下文中。由于测试上下文本身就是一个映射，我们可以通过模式匹配从中提取出 bucket，从而在测试内部访问这个 bucket 实例：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;test &amp;quot;stores values by key&amp;quot;, %{bucket: bucket} do&#xA;  # `bucket` is now the bucket from the setup block&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;其他 agent 行为&lt;/h2&gt;&#xA;&lt;p&gt;除了可以分别获取值和更新 Agent 状态外，Agent 还允许我们通过 &lt;code&gt;Agent.get_and_update/2&lt;/code&gt; 函数在一次调用中同时完成获取值和更新状态的操作。让我们实现一个 &lt;code&gt;KV.Bucket.delete/2&lt;/code&gt; 函数，该函数会从 bucket 中删除指定键并返回其当前值：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;@doc &amp;quot;&amp;quot;&amp;quot;&#xA;Deletes `key` from `bucket`.&#xA;&#xA;Returns the current value of `key`, if `key` exists.&#xA;&amp;quot;&amp;quot;&amp;quot;&#xA;def delete(bucket, key) do&#xA;  Agent.get_and_update(bucket, &amp;amp;Map.pop(&amp;amp;1, key))&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;agents 中的服务端/客户端架构&lt;/h2&gt;&#xA;&lt;p&gt;在进入下一章节之前，让我们先探讨 Agent 中的客户端/服务端二分架构。我们将扩展刚才实现的 &lt;code&gt;delete/2&lt;/code&gt; 函数来说明这一概念：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;def delete(bucket, key) do&#xA;  Agent.get_and_update(bucket, fn map -&amp;gt;&#xA;    Map.pop(map, key)&#xA;  end)&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们传递给 Agent 的函数内部所有操作都在 Agent 进程中执行。在这种情况下，由于 Agent 进程负责接收和响应我们的消息，我们称 Agent 进程为服务端。而函数外部的所有操作都发生在客户端。&lt;/p&gt;&#xA;&lt;p&gt;这个区分非常重要。如果需要执行耗时操作，你必须仔细考虑是在客户端还是服务端执行更为合适。例如：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-elixir&#34;&gt;def delete(bucket, key) do&#xA;  Process.sleep(1000) # 让客户端 sleep&#xA;  Agent.get_and_update(bucket, fn map -&amp;gt;&#xA;    Process.sleep(1000) # 让服务端 sleep&#xA;    Map.pop(map, key)&#xA;  end)&#xA;end&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当在服务端执行耗时操作时，该特定服务端的所有其他请求都将阻塞等待当前操作完成，这可能导致部分客户端请求超时。&lt;/p&gt;&#xA;&lt;p&gt;在下一章中，我们将探讨 GenServer，其客户端与服务端的隔离机制将体现得更加明显。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/06/27/elixir-beginner-0/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>k6 测试生命周期</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/06/18/grafana-k6-7/</id>
    <content type="html">&lt;h2&gt;概览&lt;/h2&gt;&#xA;&lt;p&gt;在 k6 测试的生命周期中，脚本总是按照以下固定顺序依次执行各个阶段：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;init&lt;/code&gt; 上下文中的代码准备脚本、加载文件、导入模块并定义测试生命周期函数。&lt;strong&gt;必须阶段&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;setup&lt;/code&gt; 函数执行阶段，设置测试环境并生成测试数据。&lt;strong&gt;可选阶段&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;VU 代码执行阶段，在 &lt;code&gt;default&lt;/code&gt; 或 &lt;code&gt;scenario&lt;/code&gt; 函数中运行，根据测试配置执行指定时长和次数。&lt;strong&gt;必选阶段&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;teardown&lt;/code&gt; 函数执行阶段，进行数据后处理并关闭测试环境。&lt;strong&gt;可选阶段&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;// 1. init code&#xA;&#xA;export function setup() {&#xA;  // 2. setup code&#xA;}&#xA;&#xA;export default function (data) {&#xA;  // 3. VU code&#xA;}&#xA;&#xA;export function teardown(data) {&#xA;  // 4. teardown code&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;&lt;strong&gt;测试阶段&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;目的&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;示例&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;调用规则&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;1. init&lt;/td&gt;&#xA;&lt;td&gt;加载本地文件、导入模块、声明生命周期函数&lt;/td&gt;&#xA;&lt;td&gt;打开 JSON 文件、导入模块&lt;/td&gt;&#xA;&lt;td&gt;每个 VU 执行一次&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;2. Setup&lt;/td&gt;&#xA;&lt;td&gt;准备测试数据，在 VU 间共享数据&lt;/td&gt;&#xA;&lt;td&gt;调用 API 启动测试环境&lt;/td&gt;&#xA;&lt;td&gt;整个测试执行一次&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;3. VU 代码&lt;/td&gt;&#xA;&lt;td&gt;执行测试函数（通常为 &lt;code&gt;default&lt;/code&gt; 函数）&lt;/td&gt;&#xA;&lt;td&gt;发送 HTTPS 请求、验证响应&lt;/td&gt;&#xA;&lt;td&gt;每次迭代执行一次，次数由测试配置决定&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;4. Teardown&lt;/td&gt;&#xA;&lt;td&gt;处理 Setup 阶段的结果数据，停止测试环境&lt;/td&gt;&#xA;&lt;td&gt;验证 Setup 结果、发送测试完成 Webhook 通知&lt;/td&gt;&#xA;&lt;td&gt;整个测试执行一次&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2&gt;init 阶段&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;init&lt;/code&gt; 阶段是必选的。在测试运行前，k6 需要初始化测试环境。为准备测试，&lt;code&gt;init&lt;/code&gt; 上下文中的代码会为每个 VU 执行一次。&lt;/p&gt;&#xA;&lt;p&gt;在 &lt;code&gt;init&lt;/code&gt; 阶段可能进行的操作包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;导入模块&lt;/li&gt;&#xA;&lt;li&gt;从本地文件系统加载文件&lt;/li&gt;&#xA;&lt;li&gt;为所有测试选项进行配置&lt;/li&gt;&#xA;&lt;li&gt;为 VU、&lt;code&gt;setup&lt;/code&gt; 和 &lt;code&gt;teardown&lt;/code&gt; 阶段定义生命周期函数（也包括自定义函数或 &lt;code&gt;handleSummary()&lt;/code&gt; 函数）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;所有未包含在生命周期函数内的代码都属于 &lt;code&gt;init&lt;/code&gt; 上下文。&lt;code&gt;init&lt;/code&gt; 上下文中的代码总是最先执行。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;// init context: importing modules&#xA;import http from &#39;k6/http&#39;;&#xA;import { Trend } from &#39;k6/metrics&#39;;&#xA;&#xA;// init context: define k6 options&#xA;export const options = {&#xA;  vus: 10,&#xA;  duration: &#39;30s&#39;,&#xA;};&#xA;&#xA;// init context: global variables&#xA;const customTrend = new Trend(&#39;oneCustomMetric&#39;);&#xA;&#xA;// init context: define custom function&#xA;function myCustomFunction() {&#xA;  // ...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;将 &lt;code&gt;init&lt;/code&gt; 阶段 与 VU 阶段分离，可以避免在 VU 代码中执行无关的计算，从而提升 k6 的性能并确保测试结果更加可靠。不过，&lt;code&gt;init&lt;/code&gt; 代码有一个限制：它不能发起 HTTP 请求。这一限制是为了确保 &lt;code&gt;init&lt;/code&gt; 阶段在不同测试中具有可复现性（因为协议请求的响应是动态且不可预测的）。&lt;/p&gt;&#xA;&lt;h2&gt;VU 阶段&lt;/h2&gt;&#xA;&lt;p&gt;脚本必须至少包含一个场景函数（scenario function），用于定义虚拟用户（VU）的执行逻辑。该函数内部的代码即为 VU 代码。通常情况下，VU 代码位于 &lt;code&gt;default&lt;/code&gt; 函数中，但也可以定义在场景配置指定的函数内（具体示例请参阅后续章节）。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;export default function () {&#xA;  // do things here...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;VU 代码会在整个测试期间循环执行。它可以发起 HTTP 请求、输出指标数据，基本上能完成负载测试所需的所有操作——唯独那些属于 &lt;code&gt;init&lt;/code&gt; 上下文的操作除外。&lt;/p&gt;&#xA;&lt;p&gt;具体限制包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;无法读取本地文件系统的文件&lt;/li&gt;&#xA;&lt;li&gt;无法导入其他模块&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这些功能必须由 &lt;code&gt;init&lt;/code&gt; 代码来实现，而非 VU 代码。&lt;/p&gt;&#xA;&lt;h3&gt;默认函数的生命周期&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;顺序执行机制。VU 会从头到尾顺序执行 &lt;code&gt;default()&lt;/code&gt; 函数。当执行到函数末尾时，会自动跳转回起始位置重新执行，形成循环测试。&lt;/li&gt;&#xA;&lt;li&gt;重启重置机制。每次循环开始时，k6 会对 VU 执行重置操作：&#xA;&lt;ol&gt;&#xA;&lt;li&gt;自动清除所有 cookies&lt;/li&gt;&#xA;&lt;li&gt;根据测试配置决定是否断开TCP连接（连接保持行为可通过测试参数配置）&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;setup 和 teardown 阶段&lt;/h2&gt;&#xA;&lt;p&gt;与 &lt;code&gt;default&lt;/code&gt; 函数类似，&lt;code&gt;setup&lt;/code&gt; 和 &lt;code&gt;teardown&lt;/code&gt; 也必须是导出函数。但与 &lt;code&gt;default&lt;/code&gt; 函数不同的是，k6 在整个测试过程中只会调用 &lt;code&gt;setup&lt;/code&gt; 和 &lt;code&gt;teardown&lt;/code&gt; 各一次。具体调用时机如下：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;setup&lt;/code&gt;：在测试开始时调用，位于 &lt;code&gt;init&lt;/code&gt; 阶段之后、VU 阶段之前&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;teardown&lt;/code&gt;：在测试结束时调用，位于 VU 阶段（即 &lt;code&gt;default&lt;/code&gt; 函数执行）之后&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;与 &lt;code&gt;init&lt;/code&gt; 阶段不同，在 &lt;code&gt;setup&lt;/code&gt; 和 &lt;code&gt;teardown&lt;/code&gt; 阶段可以调用完整的 k6 API。例如，你可以执行以下操作：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;发起 HTTP 请求&lt;/li&gt;&#xA;&lt;li&gt;使用所有 k6 模块功能&lt;/li&gt;&#xA;&lt;li&gt;访问完整的运行时指标系统&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;&#xA;export function setup() {&#xA;  const res = http.get(&#39;https://quickpizza.grafana.com/api/json&#39;);&#xA;  return { data: res.json() };&#xA;}&#xA;&#xA;export function teardown(data) {&#xA;  console.log(JSON.stringify(data));&#xA;}&#xA;&#xA;export default function (data) {&#xA;  console.log(JSON.stringify(data));&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;忽略 setup 和 teardown 的执行&lt;/h3&gt;&#xA;&lt;p&gt;你可以通过命令行选项 &lt;code&gt;--no-setup&lt;/code&gt; 和 &lt;code&gt;--no-teardown&lt;/code&gt; 来跳过 &lt;code&gt;setup&lt;/code&gt; 和 &lt;code&gt;teardown&lt;/code&gt; 阶段的执行。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;k6 run --no-setup --no-teardown ...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;在 default 和 teardown 中使用 setup 中的数据&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;// 1. init code&#xA;&#xA;export function setup() {&#xA;  // 2. setup code&#xA;}&#xA;&#xA;export default function (data) {&#xA;  // 3. VU code&#xA;}&#xA;&#xA;export function teardown(data) {&#xA;  // 4. teardown code&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;你可能已经注意到，&lt;code&gt;default()&lt;/code&gt; 和 &lt;code&gt;teardown()&lt;/code&gt; 函数的签名都接收一个参数（本文中称为 &lt;code&gt;data&lt;/code&gt;）。&lt;/p&gt;&#xA;&lt;p&gt;以下示例演示了如何将数据从 &lt;code&gt;setup&lt;/code&gt; 代码传递到 VU 和 &lt;code&gt;teardown&lt;/code&gt; 阶段：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;export function setup() {&#xA;  return { v: 1 };&#xA;}&#xA;&#xA;export default function (data) {&#xA;  console.log(JSON.stringify(data));&#xA;}&#xA;&#xA;export function teardown(data) {&#xA;  if (data.v != 1) {&#xA;    throw new Error(&#39;incorrect data: &#39; + JSON.stringify(data));&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;例如，利用 &lt;code&gt;setup()&lt;/code&gt; 函数返回的数据，你可以实现以下功能：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;统一数据分发：为每个 VU（虚拟用户）提供数据的相同副本&lt;/li&gt;&#xA;&lt;li&gt;结果后处理：在 &lt;code&gt;teardown&lt;/code&gt; 代码中对数据进行最终处理&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;但需注意以下限制事项：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;数据类型限制&#xA;&lt;ul&gt;&#xA;&lt;li&gt;仅支持传递 JSON 格式的数据（不可传递函数）&lt;/li&gt;&#xA;&lt;li&gt;无法在 &lt;code&gt;default()&lt;/code&gt; 中修改数据后传递给 &lt;code&gt;teardown()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;内存消耗警告&#xA;&lt;ul&gt;&#xA;&lt;li&gt;当 &lt;code&gt;setup()&lt;/code&gt; 返回大数据量时会显著增加内存占用&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;数据隔离特性&#xA;&lt;ul&gt;&#xA;&lt;li&gt;每个阶段和每个 VU 访问的都是 &lt;code&gt;setup()&lt;/code&gt; 返回数据的独立副本&lt;/li&gt;&#xA;&lt;li&gt;修改副本不会影响其他 VU 或阶段的数据&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;在分布式测试场景中，若要在所有虚拟用户(VU)之间传递可变数据并最终移交至 teardown 阶段，其实现将异常复杂且计算资源消耗巨大。这种设计会直接违背 k6 的核心设计原则：确保同一测试脚本可跨多种执行模式运行。&lt;/p&gt;&#xA;&lt;h2&gt;额外的生命周期&lt;/h2&gt;&#xA;&lt;p&gt;k6 还提供了其他几种使用生命周期函数的方式：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;handleSummary()&lt;/code&gt;，若需生成自定义测试报告，k6 会在测试完全结束时额外调用此生命周期函数。&lt;/li&gt;&#xA;&lt;li&gt;场景函数 (Scenario Functions)，除了默认的 &lt;code&gt;default&lt;/code&gt; 函数外，你也可以在场景函数中运行 VU 代码。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;import { sleep } from &#39;k6&#39;;&#xA;&#xA;export const options = {&#xA;  scenarios: {&#xA;    my_web_test: {&#xA;      // the function this scenario will execute&#xA;      exec: &#39;webtest&#39;,&#xA;      executor: &#39;constant-vus&#39;,&#xA;      vus: 50,&#xA;      duration: &#39;1m&#39;,&#xA;    },&#xA;  },&#xA;};&#xA;&#xA;export function webtest() {&#xA;  http.get(&#39;https://test.k6.io/contacts.php&#39;);&#xA;  sleep(Math.random() * 2);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/06/18/grafana-k6-7/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>20250613</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/06/13/diary9/</id>
    <content type="html">&lt;p&gt;有必要认真考虑美国急速崩解后的各种交接问题：科技、影响力、知识产权、有影响力的公司/组织等等。一个急速崩解的强权是一个灾难，对于对手也是。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/06/13/diary9/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>20250612 - 成仙之路</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/06/12/diary8/</id>
    <content type="html">&lt;p&gt;大模型越来越火，AI 似乎也在变的越来越强大，看起来超过人类指日可待。反过来想，人类到底需要什么样的智能？&lt;/p&gt;&#xA;&lt;p&gt;是更聪明吗？还是一个更像人脑的 AI？这很难说的。人必定是有什么需要在智力上的追求，才借助于计算机来实现。如果是更快的计算速度，更强的算力，更理性的推导，那人类自身就没有存在的价值，人类社会干不过一个纯计算机的机器人社会（比如黑客帝国）。&lt;/p&gt;&#xA;&lt;p&gt;人的自性是一个我之前未曾涉足的领域，有必要探一探她的奥秘。在自己博客写的好处是，这种禅宗、神秘学、炼金术之类的东西，一来像封建迷信，二来可能早就有学者研究，我这胡思乱想出来的结论也未必正确，省的被人批评。然而这些东西最重要的就是她的体验，结论来说反而是次要的，所以需要自己慢慢乱想而写下来。&lt;/p&gt;&#xA;&lt;p&gt;最后也是点一下题，这就是一条成仙之路，一个心理上完整的自我，或许也是一个更高维度的自我。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/06/12/diary8/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>k6 选项的使用</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/06/10/grafana-k6-6/</id>
    <content type="html">&lt;p&gt;选项（Options）用于配置测试运行行为。比如你可以通过选项定义测试标签、阈值、用户代理以及虚拟用户数和迭代次数。&lt;/p&gt;&#xA;&lt;h2&gt;如何使用&lt;/h2&gt;&#xA;&lt;p&gt;k6 提供多种设置选项的方式：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;通过命令行标志设置&lt;/li&gt;&#xA;&lt;li&gt;通过环境变量设置&lt;/li&gt;&#xA;&lt;li&gt;在脚本的 &lt;code&gt;options&lt;/code&gt; 对象中设置&lt;/li&gt;&#xA;&lt;li&gt;通过配置文件设置&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;具体在何处设置测试选项通常取决于使用场景，还可以在测试运行时动态获取这些选项值。&lt;/p&gt;&#xA;&lt;h2&gt;选项的顺序&lt;/h2&gt;&#xA;&lt;p&gt;你可以在多个位置设置选项。当配置出现冲突时，k6 将按照优先级顺序决定哪个起作用。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;默认值 -&amp;gt; 配置文件 -&amp;gt; 测试脚本设置 -&amp;gt; 环境变量 -&amp;gt; 命令行参数&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;首先采用选项的默认值。&lt;/li&gt;&#xA;&lt;li&gt;其次使用通过 --config 参数指定的配置文件中的设置。&lt;/li&gt;&#xA;&lt;li&gt;然后读取脚本中定义的值（如已设置）。&lt;/li&gt;&#xA;&lt;li&gt;接着采用环境变量中的值（如已设置）。&lt;/li&gt;&#xA;&lt;li&gt;最终以命令行参数（CLI flag）的设置为最高优先级。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;在何处设置选项&lt;/h2&gt;&#xA;&lt;p&gt;选项的设置方式有时取决于个人偏好，有时则需根据测试场景选择最合理的位置。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;脚本内选项：便于版本控制与测试整洁化&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;通常建议将选项定义在脚本的 options 对象中：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;自动纳入版本控制系统&lt;/li&gt;&#xA;&lt;li&gt;便于测试脚本复用&lt;/li&gt;&#xA;&lt;li&gt;支持模块化脚本开发&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;CLI参数：快速动态配置&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;命令行参数适合临时测试场景：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;可即时覆盖脚本中的配置（遵循优先级规则）&lt;/li&gt;&#xA;&lt;li&gt;示例：当脚本预设60秒测试时长时，通过 &lt;code&gt;--duration 30s&lt;/code&gt; 参数即可临时改为30秒测试，其他配置保持不变&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;环境变量：与构建流程集成&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;适用于从以下系统获取配置：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Docker容器定义&lt;/li&gt;&#xA;&lt;li&gt;CI/CD系统界面&lt;/li&gt;&#xA;&lt;li&gt;密钥管理系统，典型用例：如 block hostnames 这类选项就非常适合通过环境变量配置&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;示例&lt;/h2&gt;&#xA;&lt;h3&gt;在脚本中设置选项&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;&#xA;export const options = {&#xA;  hosts: { &#39;test.k6.io&#39;: &#39;1.2.3.4&#39; },&#xA;  stages: [&#xA;    { duration: &#39;1m&#39;, target: 10 },&#xA;    { duration: &#39;1m&#39;, target: 20 },&#xA;    { duration: &#39;1m&#39;, target: 0 },&#xA;  ],&#xA;  thresholds: { http_req_duration: [&#39;avg&amp;lt;100&#39;, &#39;p(95)&amp;lt;200&#39;] },&#xA;  noConnectionReuse: true,&#xA;  userAgent: &#39;MyK6UserAgentString/1.0&#39;,&#xA;};&#xA;&#xA;export default function () {&#xA;  http.get(&#39;http://test.k6.io/&#39;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;在环境变量中设置选项&lt;/h3&gt;&#xA;&lt;p&gt;你也可以通过环境变量和命令行参数来配置上述示例中的选项：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;K6_NO_CONNECTION_REUSE=true K6_USER_AGENT=&amp;quot;MyK6UserAgentString/1.0&amp;quot; k6 run script.js&#xA;&#xA;$ k6 run --no-connection-reuse --user-agent &amp;quot;MyK6UserAgentString/1.0&amp;quot; script.js&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;从 k6 变量中设置选项&lt;/h3&gt;&#xA;&lt;p&gt;通过 &lt;code&gt;--env&lt;/code&gt; 命令行标志，你可以直接在 CLI 中定义 k6 变量，然后在脚本文件中使用这些变量来动态设置选项值。&lt;/p&gt;&#xA;&lt;p&gt;例如，你可以通过以下方式为用户代理(user agent)定义变量：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ k6 run script.js --env MY_USER_AGENT=&amp;quot;hello&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;随后，脚本便可根据该变量值动态设置 &lt;code&gt;userAgent&lt;/code&gt; 选项，实现快速配置。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;&#xA;export const options = {&#xA;  userAgent: __ENV.MY_USER_AGENT,&#xA;};&#xA;&#xA;export default function () {&#xA;  http.get(&#39;http://test.k6.io/&#39;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;通过 --config 设置选项&lt;/h3&gt;&#xA;&lt;p&gt;k6 提供了以下配置文件管理方式：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;可直接编辑默认配置文件&lt;/li&gt;&#xA;&lt;li&gt;或创建新配置文件并通过 CLI 参数指定路径&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;通过 &lt;code&gt;--config&lt;/code&gt; 参数指定配置文件路径，例如：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ k6 run --config options.json script.js&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;执行此命令时，k6 将按照 &lt;code&gt;options.json&lt;/code&gt; 文件中的值来设置测试选项。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &amp;quot;hosts&amp;quot;: {&#xA;    &amp;quot;test.k6.io&amp;quot;: &amp;quot;1.2.3.4&amp;quot;&#xA;  },&#xA;  &amp;quot;stages&amp;quot;: [&#xA;    {&#xA;      &amp;quot;duration&amp;quot;: &amp;quot;1m&amp;quot;,&#xA;      &amp;quot;target&amp;quot;: 10&#xA;    },&#xA;    {&#xA;      &amp;quot;duration&amp;quot;: &amp;quot;1m&amp;quot;,&#xA;      &amp;quot;target&amp;quot;: 30&#xA;    },&#xA;    {&#xA;      &amp;quot;duration&amp;quot;: &amp;quot;1m&amp;quot;,&#xA;      &amp;quot;target&amp;quot;: 0&#xA;    }&#xA;  ],&#xA;  &amp;quot;thresholds&amp;quot;: {&#xA;    &amp;quot;http_req_duration&amp;quot;: [&amp;quot;avg&amp;lt;100&amp;quot;, &amp;quot;p(95)&amp;lt;200&amp;quot;]&#xA;  },&#xA;  &amp;quot;noConnectionReuse&amp;quot;: true,&#xA;  &amp;quot;userAgent&amp;quot;: &amp;quot;MyK6UserAgentString/1.0&amp;quot;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;若需实现配置与逻辑分离，你还可以在脚本文件中使用 &lt;code&gt;JSON.parse()&lt;/code&gt; 方法：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const testConfig = JSON.parse(open(&#39;./config/test.json&#39;));&#xA;&#xA;export const options = testConfig;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;从脚本中获取选项值&lt;/h2&gt;&#xA;&lt;p&gt;k6 的 &lt;code&gt;k6/execution&lt;/code&gt; API 提供了 &lt;code&gt;test.options&lt;/code&gt; 对象。通过该对象，你可以在测试运行时访问经过整合处理后的最终选项值。&lt;/p&gt;&#xA;&lt;p&gt;该功能常用于记录标签值，但实际用途远不止于此。例如，以下脚本演示了如何获取当前测试阶段的配置值：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import exec from &#39;k6/execution&#39;;&#xA;&#xA;export const options = {&#xA;  stages: [&#xA;    { duration: &#39;5s&#39;, target: 100 },&#xA;    { duration: &#39;5s&#39;, target: 50 },&#xA;  ],&#xA;};&#xA;&#xA;export default function () {&#xA;  console.log(exec.test.options.scenarios.default.stages[0].target); // 100&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/06/10/grafana-k6-6/" rel="alternate"></link>
    <summary type="html">选项 -&gt; Options</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>哈勃望远镜同款“创生之柱” -- M16 鹰状星云</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/06/09/tianwen-m16/</id>
    <content type="html">&lt;p&gt;&lt;img src=&#34;/img/posts/tianwen/2025/002.jpg&#34; alt=&#34;M16 鹰状星云&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/tianwen/2025/003.jpg&#34; alt=&#34;M16 鹰状星云局部&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这次带来了 M16 鹰状星云，拍摄于上海闵行。前前后后尝试了一个月，终于在楼顶等到了极好的天气。拍摄的照片正中心就可以看到三根尘埃柱，自己拍到还是非常神奇的。&lt;/p&gt;&#xA;&lt;p&gt;鹰状星云位于天球视野上银河中心的位置，得名于其形状，看起来像一只展翅的雄鹰。它是银河系中重要的恒星诞生区，内部包含大量的气体和尘埃，其中许多恒星正处于形成过程中。最著名的部分是其中的“创生之柱”，由三根主要的柱状结构组成。这些巨大的气体和尘埃柱子展示了新恒星的诞生过程。哈勃望远镜最著名的十大照片之一，就是 1995 年 4 月 1 日拍摄的“创生之柱”（见下图）。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/tianwen/2025/004.jpg&#34; alt=&#34;哈勃原图&#34;&gt;&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/06/09/tianwen-m16/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>上海九级区拍摄的猎户座 M42 大星云</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/06/08/tianwen-m42/</id>
    <content type="html">&lt;p&gt;&lt;img src=&#34;/img/posts/tianwen/2025/001.jpg&#34; alt=&#34;猎户座大星云&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;拍摄参数：60iso/60s，20 张叠加。拍摄于上海闵行，九级光害区。拍摄设备：DWARF3 智能望远镜。这张照片拍摄于 4 月份，6 月份上海这个纬度已经拍不到 M42 了。M42 不愧是最适合新手拍摄的第一张深空天文照片了，视星等 4.0，又是发射星云，即使加上双窄带滤镜也能拍出绚丽的色彩。&lt;/p&gt;&#xA;&lt;p&gt;这是我第一次用 DWARF3 赤道仪模式拍摄。赤道仪模式还是很好调整的，花了不到 5 分钟。所谓赤道仪模式，就是让 DWARF3 底盘的旋转轴对准北极星（或者叫让望远镜的极轴平行于地球自转轴）。我用的就是官方的方法：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;首先确认所处的纬度，上海大约是北纬 31 度。&lt;/li&gt;&#xA;&lt;li&gt;用手机自带的水平仪贴住 DWARF3 的机壳，然后调整云台，直至显示水平角度为 31 度。&lt;/li&gt;&#xA;&lt;li&gt;最后用手机自带的指南针，调整极轴朝向正北方。&lt;/li&gt;&#xA;&lt;li&gt;开机进入赤道仪模式，再根据机器显示微调。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;有人可能会有疑问，上海市中心这么亮，怎么可能拍摄到星星呢？那是因为光都是有不同的波长的，天上有些星星的波长和城市灯光的波长恰好不同，像发射星云这类目标，它的光波长就和城市灯光波长处于不同频谱。所以加上双窄带滤镜（非常适合滤掉城市灯光）也能让你在城市中拍到美丽的星星。&lt;/p&gt;&#xA;&lt;p&gt;高中三年，买了三年的《天文爱好者》，这 DWARF3 无疑是圆了我一大梦想。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/06/08/tianwen-m42/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Python asyncio 与 Go 的横向比较</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/06/04/asyncio-goroutine/</id>
    <content type="html">&lt;p&gt;Python asyncio 出现也十年了，这十年，主流语言都在朝这个方向探索，即在用户态模拟线程的概念，让使用者以类似同步线程的方式编写并发代码。抛开各个底层的线程、协程、纤程、绿色线程等等名词，其实，对上层的使用者来讲，各个语言是非常相似的。这也说明，工业界在并发编程上达成了某些共识，这些共识并不是性能层面的共识，而是一种使用模式的共识。虽然我的并发编程经验只能算 so so，但我始终认为，对大多是人来讲，并发编程的关键绝不在什么高性能，而在于你是否能设计出一个易于理解，不易出错的模式。就像在多个线程中通信的时候，共享内存的出错概率远远大于消息队列。&lt;/p&gt;&#xA;&lt;p&gt;Python asyncio 这种用户态模拟的 coroutine 就是一个革命性的并发编程方式。在这之前，通常是基于单线程 + 同步非阻塞 + 多路复用来实现高并发服务的，这种模式下，业务逻辑是分散在多个 callback 中，让人头痛。asyncio 让使用者能继续使用多线程编程的习惯，业务代码在视觉上都是同步的，清晰明了。我认为 Go 语言一开始就走了一条非常正确的道路，它的并发编程模式从一开始到现在就没怎么变过。&lt;/p&gt;&#xA;&lt;p&gt;下面来看看 Python asyncio 和 Go 的类似之处。&lt;/p&gt;&#xA;&lt;p&gt;启动一个 goroutine 运行：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;go func()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;而 Python 启动 coroutine 运行：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;asyncio.create_task(func())&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Go 中 goroutine 之间推荐的通信机制为为 &lt;code&gt;chan&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;ch := make(chan int)     // 无缓冲 channel&#xA;ch := make(chan int, 10) // 缓冲大小为 10 的 channel&#xA;&#xA;ch &amp;lt;- 42      // 发送数据到 channel&#xA;value := &amp;lt;-ch // 从 channel 接收数据&#xA;close(ch)     // 关闭 channel&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Python 中 coroutine 之间也可用异步队列 &lt;code&gt;asyncio.Queue&lt;/code&gt; 通信：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;q = asyncio.Queue(0)     # 无限长度的队列，和 Go 不同&#xA;q = asyncio.Queue(10)    # 长度为 10 的队列&#xA;&#xA;await q.put(42)          # 发送数据到队列&#xA;value = await q.get()    # 从队列获取数据&#xA;q.shutdown()             # 关闭队列&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;需要注意，0 在 Python &lt;code&gt;asyncio.Queue&lt;/code&gt; 中代表无限长度的队列，和 Go 有很大的区别。&lt;/p&gt;&#xA;&lt;p&gt;Go 中等待一组 goroutine 都结束：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var wg sync.WaitGroup&#xA;&#xA;for i := 0; i &amp;lt; 10; i++ {&#xA;    wg.Add(1)&#xA;    go func() {&#xA;        defer wg.Done()&#xA;    }&#xA;}&#xA;&#xA;// 阻塞&#xA;wg.Wait()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Python 中等待一组 coroutine 都结束：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;async with asyncio.TaskGroup() as tg:&#xA;    for i in range(10):&#xA;        tg.create_task(func())&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;asyncio.TaskGroup&lt;/code&gt;，是 &lt;code&gt;Python 3.11&lt;/code&gt; 才加入的，因为 Python 有上下文管理器，语法更简练。&lt;/p&gt;&#xA;&lt;p&gt;Go 中的 &lt;code&gt;context.Context&lt;/code&gt; 兼具多种功能，是一个跨 goroutine 存储信息，传递控制的对象：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// 存储信息&#xA;func parent() {&#xA;    ctx := context.Value(context.Background(), &amp;quot;key&amp;quot;, &amp;quot;value&amp;quot;)&#xA;&#xA;    go child(ctx)&#xA;}&#xA;&#xA;func child(ctx context.Context) {&#xA;   val := ctx.Value(&amp;quot;key&amp;quot;)&#xA;}&#xA;&#xA;// 控制&#xA;func parent1() {&#xA;    ctx1, cancel := context.WithCancel(context.Background())&#xA;    go child1(ctx1)&#xA;&#xA;    // 让 child1 直接结束 &#xA;    cancel() &#xA;&#xA;    // 若 child1 超时，则不再等待，结束&#xA;    ctx2 := context.WithTimeout(context.Background(), 5 * time.Second)&#xA;    child1(ctx2)&#xA;}&#xA;&#xA;func child1(ctx context.Context) {&#xA;    select {&#xA;    case &amp;lt;-ctx.Done():&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Python 中没有直接对应的东西，和 &lt;code&gt;context.Value&lt;/code&gt; 类似的是 &lt;code&gt;contextvars.ContextVar&lt;/code&gt;，这玩意又和多线程编程中的&lt;strong&gt;线程本地变量&lt;/strong&gt;极其相似：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;request_id = contextvars.ContextVar(&#39;request_id&#39;)&#xA;&#xA;async def handle_request(id):&#xA;    # 为每个请求设置不同的 request_id&#xA;    request_id.set(id)&#xA;    &#xA;    # 即使在嵌套的协程中也能正确获取&#xA;    await asyncio.sleep(0.1)&#xA;    print(f&amp;quot;Request {request_id.get()} processed&amp;quot;)&#xA;&#xA;# 同时运行多个请求处理&#xA;await asyncio.gather(&#xA;    handle_request(1),&#xA;    handle_request(2),&#xA;    handle_request(3)&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;而控制 coroutine 又有多种方式，比如取消一个正在运行的 coroutine：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;async def my_coroutine():&#xA;    try:&#xA;        while True:&#xA;            await asyncio.sleep(1)&#xA;    except asyncio.CancelledError:&#xA;        print(&amp;quot;Coroutine was cancelled!&amp;quot;)&#xA;        raise&#xA;&#xA;# 创建任务&#xA;task = asyncio.create_task(my_coroutine())&#xA;&#xA;# 取消任务&#xA;task.cancel()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;又比如超时退出：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;# 最多等 2 秒&#xA;await asyncio.wait_for(my_coroutine(), timeout=2)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/06/04/asyncio-goroutine/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>BitTorrent 一点进展</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/05/25/bittorrent-one-small-step/</id>
    <content type="html">&lt;p&gt;过去三四个月又是零零碎碎的在实现这个协议，目前有了&lt;a href=&#34;https://github.com/lyyyuna/torrent-cli/releases/tag/v0.0.1&#34;&gt;小的进展&lt;/a&gt;。下面来介绍一下。&lt;/p&gt;&#xA;&lt;p&gt;实现过程不免参考一些开源代码，大家可在上一篇文章中找到些出处，这里不一一列举，需要指出的是，参考并不是简单的 copy，因为很多开源的代码架构风格我并不喜欢，基本都做了重写。&lt;/p&gt;&#xA;&lt;h2&gt;bencode 编解码&lt;/h2&gt;&#xA;&lt;p&gt;这次尽量实现所有细节，所以 bencode 的编解码没有用现成库。好在 bencode 本身简单，源码不到 150 行：&lt;a href=&#34;https://github.com/lyyyuna/torrent-cli/blob/v0.0.1/zhongzi/bencode.py&#34;&gt;https://github.com/lyyyuna/torrent-cli/blob/v0.0.1/zhongzi/bencode.py&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;Bencoding 支持四种数据类型：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;字符串&#xA;&lt;ul&gt;&#xA;&lt;li&gt;格式：&amp;lt;长度&amp;gt;:&amp;lt;内容&amp;gt;&lt;/li&gt;&#xA;&lt;li&gt;例如：&lt;code&gt;4:spam&lt;/code&gt; 表示字符串 &lt;code&gt;&amp;quot;spam&amp;quot;&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;整数&#xA;&lt;ul&gt;&#xA;&lt;li&gt;格式：i&amp;lt;数字&amp;gt;e&lt;/li&gt;&#xA;&lt;li&gt;例如：&lt;code&gt;i42e&lt;/code&gt; 表示整数 &lt;code&gt;42&lt;/code&gt;，&lt;code&gt;i-3e&lt;/code&gt; 表示 &lt;code&gt;-3&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;列表&#xA;&lt;ul&gt;&#xA;&lt;li&gt;格式：l&amp;lt;元素1&amp;gt;&amp;lt;元素2&amp;gt;...e&lt;/li&gt;&#xA;&lt;li&gt;例如：&lt;code&gt;l4:spami42ee&lt;/code&gt; 表示列表 &lt;code&gt;[&amp;quot;spam&amp;quot;, 42]&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;字典&#xA;&lt;ul&gt;&#xA;&lt;li&gt;格式：d&amp;lt;键1&amp;gt;&amp;lt;值1&amp;gt;&amp;lt;键2&amp;gt;&amp;lt;值2&amp;gt;...e&lt;/li&gt;&#xA;&lt;li&gt;键必须是字符串，且按字典序排列。&lt;/li&gt;&#xA;&lt;li&gt;例如：&lt;code&gt;d3:foo3:bar5:helloi52ee&lt;/code&gt; 表示字典 &lt;code&gt;{&amp;quot;foo&amp;quot;: &amp;quot;bar&amp;quot;, &amp;quot;hello&amp;quot;: 52}&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;torrent 文件&lt;/h2&gt;&#xA;&lt;p&gt;torrent 文件是一个 bencode 编码的对象。其中关键的信息如下(这里换用 json 来表示)：&lt;/p&gt;&#xA;&lt;p&gt;单文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;    &amp;quot;announce&amp;quot; : &amp;quot;http://torrent.ubuntu.com:6969/announce&amp;quot;,&#xA;    &amp;quot;info&amp;quot; : {&#xA;        &amp;quot;name&amp;quot; : &amp;quot;ubuntu-14.04.6-server-amd64.iso&amp;quot;,&#xA;        &amp;quot;length&amp;quot; : 662700032,&#xA;        &amp;quot;piece length&amp;quot; : 524288,&#xA;        &amp;quot;pieces&amp;quot; : xxxxx&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;announce&lt;/code&gt; 是 http tracker 的地址，客户端可以通过 tracker 拿到 peers 信息。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;length&lt;/code&gt; 是整个文件的长度。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;bittorrent 把被做种的文件分成了多个 piece，除了最后一个 piece，每个 piece 的长度是固定的 &lt;code&gt;piece length&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;pieces&lt;/code&gt; 是一串二进制，可按照 20 个字节切割成一个二进制字符串列表。按次序，每 20 个字节是对应序号的 piece 的 sha1。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;每个种子还有个重要属性是 &lt;code&gt;info_hash&lt;/code&gt;，没有记录在 torrent 文件中，而是直接对 torrent 文件内容计算 sha1。&lt;/p&gt;&#xA;&lt;p&gt;多文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;    &amp;quot;announce&amp;quot; : &amp;quot;http://torrent.ubuntu.com:6969/announce&amp;quot;,&#xA;    &amp;quot;info&amp;quot; : {&#xA;        &amp;quot;name&amp;quot; : &amp;quot;ubuntu-14.04.6-server-amd64.iso&amp;quot;,&#xA;        &amp;quot;piece length&amp;quot; : 524288,&#xA;        &amp;quot;files&amp;quot; : [&#xA;            {&#xA;                &amp;quot;path&amp;quot; : &amp;quot;/a.mp4&amp;quot;,&#xA;                &amp;quot;lenth&amp;quot; : 12334,&#xA;            },&#xA;            {&#xA;                &amp;quot;path&amp;quot; : &amp;quot;/g.mp4&amp;quot;,&#xA;                &amp;quot;lenth&amp;quot; : 23423,                &#xA;            }&#xA;        ],&#xA;        &amp;quot;pieces&amp;quot; : xxxxx&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;多文件没有 &lt;code&gt;length&lt;/code&gt; 属性，取而代之的是 &lt;code&gt;files&lt;/code&gt; 列表，记录每个文件的名称和大小。&lt;code&gt;files&lt;/code&gt; 列表的顺序是重要的，所有文件按次序拼接在 &lt;code&gt;pieces&lt;/code&gt; 中。&lt;/p&gt;&#xA;&lt;p&gt;源码见&lt;a href=&#34;https://github.com/lyyyuna/torrent-cli/blob/v0.0.1/zhongzi/torrent.py&#34;&gt;https://github.com/lyyyuna/torrent-cli/blob/v0.0.1/zhongzi/torrent.py&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h3&gt;piece 信息&lt;/h3&gt;&#xA;&lt;p&gt;从 torrent 文件角度看，文件的最小单元是 piece，但 &lt;a href=&#34;https://bittorrent.org/beps/bep_0003.html&#34;&gt;BEP-3&lt;/a&gt; 指出，下载的最小单元其实是 block，block 一般为 &lt;code&gt;2**14&lt;/code&gt; 大小。为了后续下载方便，我实现的时候也为 piece 构建了虚拟的 block 列表：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;class Piece:&#xA;    def __init__(self, index: int, length: int, offset: int, checksum: bytes):&#xA;        self.index = index&#xA;        self.length = length&#xA;        self.offset = offset&#xA;        self.checksum = checksum&#xA;&#xA;        self.blocks: List[Block] = []&#xA;&#xA;class Block:&#xA;    def __init__(self, index: int, offset: int, length: int):&#xA;        self.index = index&#xA;        self.offset = offset&#xA;        self.length = length&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;是否用 tracker？&lt;/h2&gt;&#xA;&lt;p&gt;很多网上的 bittorrent 教程/开源项目，都用 torrent 中的 &lt;code&gt;tracker&lt;/code&gt; 来获取 &lt;code&gt;peers&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;但我实际测试下来，这种方式获取的 &lt;code&gt;peers&lt;/code&gt; 质量太差，不是数量太少，就是对端所持有的 &lt;code&gt;piece&lt;/code&gt; 不全，导致根本无法下载。大伙可以看看这个挑战 &lt;a href=&#34;https://app.codecrafters.io/courses/bittorrent/overview&#34;&gt;Build your own BitTorrent&lt;/a&gt; 中的发帖，很多人卡在这一步。&lt;/p&gt;&#xA;&lt;p&gt;源码见&lt;a href=&#34;https://github.com/lyyyuna/torrent-cli/blob/v0.0.1/zhongzi/tracker.py&#34;&gt;https://github.com/lyyyuna/torrent-cli/blob/v0.0.1/zhongzi/tracker.py&lt;/a&gt;。实际客户端并未使用这个模块。&lt;/p&gt;&#xA;&lt;h2&gt;用 DHT 吧&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://bittorrent.org/beps/bep_0005.html&#34;&gt;BEP-5&lt;/a&gt; 描述的 DHT 协议是另一种获取和交换 &lt;code&gt;peers&lt;/code&gt; 信息的方式，它主要有两大部分：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;路由表 &lt;code&gt;routing table&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;krpc 协议&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;基于 Kademlia 的 routing table 路由表&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;routing table&lt;/code&gt; 是每个节点用来维护网络中其他节点信息的数据结构，其核心作用是&lt;strong&gt;高效定位目标节点或数据&lt;/strong&gt;。不同的 DHT 实现（如 Kademlia、Chord、Pastry）有各自的路由表设计，但核心逻辑相似：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;快速查找：帮助节点确定如何将查询请求（如查找数据或节点）逐步转发到目标节点。&lt;/li&gt;&#xA;&lt;li&gt;网络拓扑维护：动态记录其他节点的联系信息（如 IP、端口、Node ID），保证网络的连通性。&lt;/li&gt;&#xA;&lt;li&gt;减少跳数：通过分层或分桶的优化设计，提高查询性能。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://bittorrent.org/beps/bep_0005.html&#34;&gt;BEP-5&lt;/a&gt; 官方用的是 Kademlia 算法。Python 有一个完整的 Kademlia 实现 &lt;a href=&#34;https://github.com/bmuller/kademlia&#34;&gt;https://github.com/bmuller/kademlia&lt;/a&gt;，它完全等价地实现了论文&lt;a href=&#34;https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf&#34;&gt;https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf&lt;/a&gt;中提到的算法。其中作者用 &lt;a href=&#34;https://github.com/bmuller/rpcudp&#34;&gt;https://github.com/bmuller/rpcudp&lt;/a&gt; 作为底层通信协议，如果读者想移植到自己的 bittorrent 客户端中，需要做些修改。&lt;/p&gt;&#xA;&lt;p&gt;接着介绍 Kademlia，其路由表是一个&lt;strong&gt;二叉树分桶结构&lt;/strong&gt;，按节点 ID 的&lt;strong&gt;异或距离&lt;/strong&gt;（XOR Distance）组织：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Node ID：每个节点有一个唯一标识（如 160 位哈希值）。&lt;/li&gt;&#xA;&lt;li&gt;异或距离：两个节点 ID 的异或结果（a⊕b）表示它们的逻辑距离。&lt;/li&gt;&#xA;&lt;li&gt;K-Buckets：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;路由表被划分为多个桶（Bucket），每个桶负责一定范围的异或距离。&lt;/li&gt;&#xA;&lt;li&gt;每个桶最多维护 k 个节点（如 k=20），按最近活跃顺序排列（LRU 策略）。&lt;/li&gt;&#xA;&lt;li&gt;例如，对于 160 位 ID，路由表可能有 160 个桶，第 i 个桶存储距离在 &lt;code&gt;[i**2, i**(2+1))&lt;/code&gt; 范围内的节点。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;code&gt;routing table&lt;/code&gt; 涉及以下操作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;插入节点：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;计算新节点与自己的异或距离，找到对应的 K-Bucket。&lt;/li&gt;&#xA;&lt;li&gt;如果桶未满，直接插入；如果已满，剔除最久未响应的节点（防止攻击）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;查找节点：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;从路由表中选择与目标 ID 异或距离最近的 k 个节点，向它们发起查询。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;动态更新：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;节点定期 Ping 桶中的节点，移除失效节点。&lt;/li&gt;&#xA;&lt;li&gt;新遇到的节点会被加入合适的桶中（保持网络新鲜度）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3&gt;简化的 routing table&lt;/h3&gt;&#xA;&lt;p&gt;如果觉得 &lt;a href=&#34;https://github.com/bmuller/kademlia&#34;&gt;Kademlia&lt;/a&gt; 实现非常复杂，你可以参考 &lt;a href=&#34;https://github.com/bashkirtsevich-llc/aiobtdht/tree/master/src/aiobtdht/routing_table&#34;&gt;https://github.com/bashkirtsevich-llc/aiobtdht/tree/master/src/aiobtdht/routing_table&lt;/a&gt; 和我的 &lt;a href=&#34;https://github.com/lyyyuna/torrent-cli/blob/main/zhongzi/dht/routing_table.py&#34;&gt;https://github.com/lyyyuna/torrent-cli/blob/main/zhongzi/dht/routing_table.py&lt;/a&gt; 实现。&lt;/p&gt;&#xA;&lt;p&gt;之所以 &lt;a href=&#34;https://bittorrent.org/beps/bep_0005.html&#34;&gt;BEP-5&lt;/a&gt; 要搞一个复杂 Kademlia，是因为它能在超大网络节点数下，仍能保持 &lt;code&gt;O(logN)&lt;/code&gt; 的查询效率。而我们目前所要实现的只是客户端：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;不像服务端那样需要长时间维护超大网络节点数信息。一次下载，有几百个节点信息就足够了。&lt;/li&gt;&#xA;&lt;li&gt;查询 &lt;code&gt;peers&lt;/code&gt; 不频繁。一次下载，只需要有十来个 &lt;code&gt;peers&lt;/code&gt;，当有效 &lt;code&gt;peers&lt;/code&gt; 数量减少，再做一次查询即可。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;这个策略下，&lt;code&gt;routing table&lt;/code&gt; 甚至可以更简单，直接用一个 LRU list 存储即可，查找最近节点时，遍历 list 做异或距离计算。如果 list 只存储 1000 个以内的节点信息，遍历带来的时间复杂度是完全可以接受的。&lt;/p&gt;&#xA;&lt;p&gt;P.S. 这只是我实现的客户端的策略。这个策略能保证在家庭网络中，下载 ubuntu.iso 达到 &lt;code&gt;3-4 MB/s&lt;/code&gt; 的速度。&lt;/p&gt;&#xA;&lt;h3&gt;krpc 协议&lt;/h3&gt;&#xA;&lt;p&gt;krpc 是基于 udp 的轻量级 RPC 协议，它主要有 4 种 RPC 方法：&lt;/p&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;&lt;strong&gt;方法&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;用途&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;参数&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;返回值&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;ping&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;检查节点是否在线&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;{&amp;quot;id&amp;quot;: &amp;quot;&amp;lt;sender_node_id&amp;gt;&amp;quot;}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;{&amp;quot;id&amp;quot;: &amp;quot;&amp;lt;responder_node_id&amp;gt;&amp;quot;}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;find_node&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;查找离 &lt;code&gt;target&lt;/code&gt; 最近的节点&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;{&amp;quot;id&amp;quot;: &amp;quot;&amp;lt;sender_id&amp;gt;&amp;quot;, &amp;quot;target&amp;quot;: &amp;quot;&amp;lt;target_node_id&amp;gt;&amp;quot;}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;{&amp;quot;id&amp;quot;: &amp;quot;&amp;lt;responder_id&amp;gt;&amp;quot;, &amp;quot;nodes&amp;quot;: &amp;quot;&amp;lt;compact_node_info&amp;gt;&amp;quot;}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;get_peers&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;查找某个 &lt;code&gt;info_hash&lt;/code&gt; 的 &lt;code&gt;peers&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;{&amp;quot;id&amp;quot;: &amp;quot;&amp;lt;sender_id&amp;gt;&amp;quot;, &amp;quot;info_hash&amp;quot;: &amp;quot;&amp;lt;torrent_hash&amp;gt;&amp;quot;}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;{&amp;quot;id&amp;quot;: &amp;quot;&amp;lt;responder_id&amp;gt;&amp;quot;, &amp;quot;values&amp;quot;: [&amp;quot;&amp;lt;peer1&amp;gt;&amp;quot;, ...]}&lt;/code&gt; 或 &lt;code&gt;{&amp;quot;nodes&amp;quot;: &amp;quot;&amp;lt;compact_node_info&amp;gt;&amp;quot;}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;&lt;code&gt;announce_peer&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;声明自己拥有某个 &lt;code&gt;info_hash&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;{&amp;quot;id&amp;quot;: &amp;quot;&amp;lt;sender_id&amp;gt;&amp;quot;, &amp;quot;info_hash&amp;quot;: &amp;quot;&amp;lt;torrent_hash&amp;gt;&amp;quot;, &amp;quot;port&amp;quot;: &amp;lt;port&amp;gt;, ...}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;{&amp;quot;id&amp;quot;: &amp;quot;&amp;lt;responder_id&amp;gt;&amp;quot;}&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;客户端主要使用 &lt;code&gt;find_node&lt;/code&gt; 和 &lt;code&gt;get_peers&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;用 &lt;code&gt;find_node&lt;/code&gt; 尽可能填充 &lt;code&gt;routing table&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;用 &lt;code&gt;get_peers&lt;/code&gt; 获取 &lt;code&gt;info_hash&lt;/code&gt; 对应的 &lt;code&gt;peers&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;思路和我之前实现的&lt;a href=&#34;https://www.lyyyuna.com/2016/05/14/dht-sniffer/&#34;&gt;DHT 公网嗅探器实现（DHT 爬虫）&lt;/a&gt;类似，需要：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;self._bootstrap_nodes = [&#xA;    (&amp;quot;67.215.246.10&amp;quot;, 6881),  # router.bittorrent.com&#xA;    (&amp;quot;87.98.162.88&amp;quot;, 6881),  # dht.transmissionbt.com&#xA;    (&amp;quot;82.221.103.244&amp;quot;, 6881)  # router.utorrent.com&#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;作为初始节点，通过它们来启动第一次 &lt;code&gt;find_node&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h3&gt;基于 Python asyncio 的 udp rpc 服务如何设计&lt;/h3&gt;&#xA;&lt;p&gt;Python 标准库提供了 &lt;code&gt;asyncio.DatagramProtocol&lt;/code&gt; 来实现 asyncio udp rpc 服务，主结构如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;class KRPCProtocol(asyncio.DatagramProtocol):&#xA;    # 父类调用&#xA;    def connection_made(self, transport):&#xA;        self.transport = transport&#xA;&#xA;    # 父类调用&#xA;    def datagram_received(self, data, addr):&#xA;        pass&#xA;&#xA;    # 使用者调用&#xA;    async def call_rpc(self, msg, addr):&#xA;        self.transport.sendto(msg, addr)&#xA;&#xA;# 使用&#xA;# 初始化&#xA;loop = asyncio.get_event_loop()&#xA;_, protocol = await loop.create_datagram_endpoint(&#xA;    lambda: KRPCProtocol(self._ids),&#xA;    local_addr=self.bind&#xA;)&#xA;&#xA;# 发送请求，并等待数据&#xA;await protocol.call_rpc()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://bittorrent.org/beps/bep_0005.html&#34;&gt;BEP-5&lt;/a&gt; 指出，krpc 的每一对请求与响应之间通过 &lt;code&gt;tid&lt;/code&gt; 来串联。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;call_rpc&lt;/code&gt; 是由使用者调用，发送 udp rpc 请求后阻塞，直到对应的 udp rpc 响应返回。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;datagram_received&lt;/code&gt; 是父类 &lt;code&gt;asyncio.DatagramProtocol&lt;/code&gt; 在收到 udp 消息后触发的回调。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;我们可以通过 &lt;code&gt;asyncio.Future&lt;/code&gt; 来实现上述的异步阻塞功能：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;维护一个 futures 字典，key 是已发送的 &lt;code&gt;tid&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;self.transport.sendto&lt;/code&gt; 之后创建一个 Future 对象，存入 futures 字典。&lt;/li&gt;&#xA;&lt;li&gt;对应的 &lt;code&gt;call_rpc&lt;/code&gt; 阻塞于 Future 对象上。&lt;/li&gt;&#xA;&lt;li&gt;收到 udp 裸消息后，解析其中 &lt;code&gt;tid&lt;/code&gt;，查询 futures 字典，取出 Future 对象标记 done。&lt;/li&gt;&#xA;&lt;li&gt;对应的 &lt;code&gt;call_rpc&lt;/code&gt; 唤醒。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;代码大致为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;class KRPCProtocol(asyncio.DatagramProtocol):&#xA;    def __init__(self, node_id: bytes=None):&#xA;        self.futures: Dict[bytes, asyncio.Future] = {}&#xA;        self.transaction_id = 1&#xA;&#xA;    def datagram_received(self, data, addr):&#xA;        msg = decode(data)&#xA;        tid: bytes = msg[b&#39;t&#39;]&#xA;&#xA;        future = self.futures.pop(tid)&#xA;        future.set_result(msg)&#xA;&#xA;    async call_rpc(self, msg, addr):&#xA;        future = asyncio.Future()&#xA;        tid = self._get_transaction_id()       &#xA;        self.futures[tid] = future&#xA;&#xA;        self.transport.sendto(msg, addr)&#xA;&#xA;        return await asyncio.wait_for(future, timeout=timeout)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;Peer 交互过程&lt;/h2&gt;&#xA;&lt;p&gt;官方的 &lt;a href=&#34;https://bittorrent.org/beps/bep_0003.html&#34;&gt;BEP-3&lt;/a&gt; 关于消息介绍的很简单，大家可以参考 &lt;a href=&#34;https://wiki.theory.org/BitTorrentSpecification#Messages&#34;&gt;https://wiki.theory.org/BitTorrentSpecification#Messages&lt;/a&gt; 去了解详细的消息用途。&lt;/p&gt;&#xA;&lt;h3&gt;消息的解析&lt;/h3&gt;&#xA;&lt;p&gt;消息遵循固定格式的前缀&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;| len(4 bytes) | id(1 byte) |&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;收到 tcp 流后，每次读取前 5 个字节可判断消息的类型，和消息的边界（长度），解析起来比较简单：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;async def parse_one_message(reader: asyncio.StreamReader):&#xA;    length_bytes = await reader.readexactly(4)&#xA;    length = struct.unpack(&#39;&amp;gt;I&#39;, length_bytes)[0]&#xA;    &#xA;    id_bytes = await reader.readexactly(1)&#xA;    id = struct.unpack(&#39;&amp;gt;b&#39;, id_bytes)[0]&#xA;&#xA;    data = await reader.readexactly(length - 1)&#xA;&#xA;    match id:&#xA;        case PeerMessage.Choke.value:&#xA;            pass&#xA;        case PeerMessage.Unchoke.value:&#xA;            pass&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;连接过程&lt;/h3&gt;&#xA;&lt;p&gt;首先客户端向 peer 建立 tcp 连接后，会进入如下的握手过程：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;              Handshake&#xA;    client --&amp;gt; peer    发送 Handshake 请求&#xA;&#xA;              Handshake&#xA;    client &amp;lt;-- peer    接收 Handshake 响应，比较其中的 info_hash 是否一致&#xA;&#xA;              BitField&#xA;    client &amp;lt;-- peer    peer 可能发送 BitField，表明自己拥有哪些 piece&#xA;&#xA;             Interested&#xA;    client --&amp;gt; peer    发送 Interested，表明自己想要下载&#xA;&#xA;              Unchoke&#xA;    client &amp;lt;-- peer    peer 解除客户端阻塞状态&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;BitField&lt;/code&gt; 消息是一个二进制长串，其 bit 的个数等于 piece 的个数，而 bit 的次序和文件 piece 的次序一致。如果某 bit 为 1，那表明 peer 拥有对应次序的 piece。如果 peer 在连接过程，逐步获取到了某些新 piece，它也可以通过 &lt;code&gt;Have&lt;/code&gt; 消息告知本客户端。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;BitField&lt;/code&gt;，一次性告知文件的 piece 拥有情况。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Have&lt;/code&gt;，告知单个 piece 的拥有情况。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;code&gt;Interested&lt;/code&gt;，&lt;code&gt;Not Interested&lt;/code&gt;，&lt;code&gt;Choke&lt;/code&gt;，&lt;code&gt;Unchoke&lt;/code&gt; 用于控制网络传输，确保 P2P 网络上传/下载的公平，本次实现只把它们作为状态转换的标志位。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Request&lt;/code&gt; 与 &lt;code&gt;Piece&lt;/code&gt; 消息成对出现，&lt;code&gt;index+offset&lt;/code&gt; 相关联，代表了下载请求与响应。用类似上文 udp rpc 中 &lt;code&gt;asyncio.Future&lt;/code&gt; 对象，即可将这对请求与响应转换成同步方法：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;self.futures : Dict[str, asyncio.Future] = {}&#xA;&#xA;async run(self):&#xA;    async for msg in self.read():&#xA;        match msg:&#xA;            case Piece():&#xA;                index = msg.index&#xA;                offset = msg.begin&#xA;                key = f&#39;{index}-{offset}&#39;&#xA;&#xA;                future = self.futures.pop(key)&#xA;                if future and not future.done():&#xA;                    future.set_result(msg.block)&#xA;&#xA;async def get_piece(self, piece_index: int, offset: int, length: int=2**14) -&amp;gt; bytes:&#xA;    data = message.Request(piece_index, offset, length).encode()&#xA;    self.writer.write(data)&#xA;    await self.writer.drain()&#xA;&#xA;    future = asyncio.Future()&#xA;    self.futures[f&#39;{piece_index}-{offset}&#39;] = future&#xA;&#xA;    return await asyncio.wait_for(future)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;最后的 &lt;code&gt;Keep Alive&lt;/code&gt; 消息也非常重要，协议规定如果 2 分钟内 peer 没有收到新消息就会断开连接。实际测试发现，有的 peer 下载非常慢，一对 &lt;code&gt;Request&lt;/code&gt; 与 &lt;code&gt;Piece&lt;/code&gt; 消息经常超过 2 分钟，容易触发断连，这时候就需要客户端周期性的发送 &lt;code&gt;Keep Alive&lt;/code&gt; 消息以保活。&lt;/p&gt;&#xA;&lt;h2&gt;客户端主流程&lt;/h2&gt;&#xA;&lt;p&gt;讲到这里，一个最小化的 bittorrent 客户端所涉及的关键技术均已介绍，剩下的就是如何组织并设计出一个高并发的下载模型。尽管本文用的是 &lt;a href=&#34;https://github.com/lyyyuna/torrent-cli/blob/v0.0.1/zhongzi/client.py&#34;&gt;Python asyncio&lt;/a&gt;，你应该很容易切换到 Go 来实现。&lt;/p&gt;&#xA;&lt;p&gt;主程序由多个协程构成：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;peers 收集协程：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用 DHT 协议获取新的 peers，当 peers 数量满足后暂停，按需再次启动。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;各 peer 内信息维护协程：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;接收 &lt;code&gt;Bitfield&lt;/code&gt; 和 &lt;code&gt;Have&lt;/code&gt; 消息，标记各个 peer 拥有哪些 piece。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;下载协程：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;解析 torrent 文件，将待下载 piece 塞入 &lt;code&gt;piece_download_queue&lt;/code&gt; 队列。&lt;/li&gt;&#xA;&lt;li&gt;启动一组下载协程池，读取 &lt;code&gt;piece_download_queue&lt;/code&gt; 队列，拿到待下载 piece 后，选择一个有效的 peer 进行下载。&lt;/li&gt;&#xA;&lt;li&gt;将下载到的 piece 塞入 &lt;code&gt;piece_saver_queue&lt;/code&gt; 队列。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;保存协程：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;读取 &lt;code&gt;piece_saver_queue&lt;/code&gt; 队列，将接收到的 piece 按位置存入文件中。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;后记&lt;/h2&gt;&#xA;&lt;p&gt;诚如开头所说，现在只是一个小的进展，代码也有很多不完善的地方。&lt;/p&gt;&#xA;&lt;p&gt;后续会加入多文件、流控、磁力链接的支持，而像上传、NAT 打洞、LSD 等其他 &lt;a href=&#34;https://www.bittorrent.org/beps/bep_0000.html&#34;&gt;BEP&lt;/a&gt; 协议会慢慢研究。期待最后能实现一个完整的 bittorrent 客户端/服务端。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/05/25/bittorrent-one-small-step/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>k6 阈值的使用</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/05/12/grafana-k6-5/</id>
    <content type="html">&lt;p&gt;阈值（Threshold）是为测试指标定义的通过或失败标准。如果被测系统（SUT）的性能未达到阈值设定的条件，&lt;strong&gt;测试将以失败状态结束&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;测试人员通常通过阈值来编码其服务水平目标（SLO）。例如，可以为以下场景创建阈值：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;错误率限制：不到 1% 的请求返回错误；&lt;/li&gt;&#xA;&lt;li&gt;响应时间分布：95% 的请求响应时间低于 200 毫秒；&lt;/li&gt;&#xA;&lt;li&gt;长尾优化：99% 的请求响应时间低于 400 毫秒；&lt;/li&gt;&#xA;&lt;li&gt;关键接口保障：特定接口始终在 300 毫秒内响应；&lt;/li&gt;&#xA;&lt;li&gt;自定义指标规则：针对自定义指标设定的任何条件。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;HTTP 错误和响应时间的阈值示例&lt;/h2&gt;&#xA;&lt;p&gt;下面的示例脚本定义了两个阈值：一个阈值用于评估 HTTP 错误率（基于 &lt;code&gt;http_req_failed&lt;/code&gt; 指标）；另一个阈值用于判断 95% 的响应是否在指定时长内完成（基于 &lt;code&gt;http_req_duration&lt;/code&gt; 指标）。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;&#xA;export const options = {&#xA;  thresholds: {&#xA;    http_req_failed: [&#39;rate&amp;lt;0.01&#39;],   // http 错误率小于 1%&#xA;    http_req_duration: [&#39;p(95)&amp;lt;200&#39;], // 95% 的请求响应时间小于 200ms&#xA;  },&#xA;};&#xA;&#xA;export default function () {&#xA;  http.get(&#39;https://quickpizza.grafana.com&#39;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;换句话说，当你定义阈值时，需要为&lt;code&gt;通过&lt;/code&gt;标准指定一个表达式。如果测试结束时该表达式评估为 &lt;code&gt;false&lt;/code&gt;，k6 会将整个测试视为&lt;code&gt;失败&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;执行该脚本后，k6 会输出类似以下内容：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;  █ THRESHOLDS&#xA;&#xA;    http_req_duration&#xA;    ✓ &#39;p(95)&amp;lt;200&#39; p(95)=148.21ms&#xA;&#xA;    http_req_failed&#xA;    ✓ &#39;rate&amp;lt;0.01&#39; rate=0.05%&#xA;&#xA;  █ TOTAL RESULTS&#xA;&#xA;    HTTP&#xA;    http_req_duration..............: avg=151.06ms min=151.06ms med=151.06ms max=151.06ms p(90)=151.06ms p(95)=151.06ms&#xA;       { expected_response:true }..: avg=151.06ms min=151.06ms med=151.06ms max=151.06ms p(90)=151.06ms p(95)=151.06ms&#xA;    http_req_failed................: 0.00%  ✓ 0 ✗ 1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;此测试满足了两项阈值，故 k6 判定本次测试通过，且 exit code 为 0。&lt;/p&gt;&#xA;&lt;p&gt;如果任何阈值未通过，指标名称（&lt;code&gt;http_req_failed&lt;/code&gt;、&lt;code&gt;http_req_duration&lt;/code&gt;）旁的绿色对勾 ✓ 将显示为红色叉号 ✗，同时 k6 的 exit code 是非 0。&lt;/p&gt;&#xA;&lt;h2&gt;阈值语法&lt;/h2&gt;&#xA;&lt;p&gt;按照以下步骤操作使用阈值：&lt;/p&gt;&#xA;&lt;p&gt;首先在 &lt;code&gt;options&lt;/code&gt; 对象的 &lt;code&gt;thresholds&lt;/code&gt; 属性中，使用要设置阈值的指标名称作为键名&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;export const options = {&#xA;  thresholds: {&#xA;    /* ... */&#xA;  },&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;然后定义至少一个阈值表达式。表达式有以下两种形式：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;简短格式将所有阈值表达式以字符串形式放入数组中。&lt;/li&gt;&#xA;&lt;li&gt;详细格式则将每个阈值封装为独立对象，并包含可中止测试的额外属性。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;export const options = {&#xA;  thresholds: {&#xA;    //short format&#xA;    METRIC_NAME1: [&#39;THRESHOLD_EXPRESSION&#39;, `...`],&#xA;    //long format&#xA;    METRIC_NAME2: [&#xA;      {&#xA;        threshold: &#39;THRESHOLD_EXPRESSION&#39;,&#xA;        abortOnFail: true, // boolean&#xA;        delayAbortEval: &#39;10s&#39;, // string&#xA;      },&#xA;    ], // full format&#xA;  },&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;P.S. 请注意，&lt;code&gt;METRIC_NAME1&lt;/code&gt; 和 &lt;code&gt;THRESHOLD_EXPRESSION&lt;/code&gt; 均为占位符，实际使用时需替换为具体的指标名称和阈值表达式。&lt;/p&gt;&#xA;&lt;p&gt;该声明用于配置 &lt;code&gt;metric_name1&lt;/code&gt; 和 &lt;code&gt;metric_name2&lt;/code&gt; 这两个指标的阈值。脚本将通过评估 &lt;code&gt;&#39;threshold_expression&#39;&lt;/code&gt; 表达式来判断阈值是否通过。&lt;/p&gt;&#xA;&lt;h3&gt;阈值表达式语法&lt;/h3&gt;&#xA;&lt;p&gt;阈值表达式结果为布尔值 &lt;code&gt;true&lt;/code&gt; 或 &lt;code&gt;false&lt;/code&gt;。阈值表达式必须是以下的形式：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;&amp;lt;aggregation_method&amp;gt; &amp;lt;operator&amp;gt; &amp;lt;value&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;比如：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;avg &amp;lt; 200&lt;/code&gt; // 平均耗时必须小于 200 毫秒&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;count &amp;gt;= 500&lt;/code&gt; // 请求次数必须大于等于 500 次&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;p(90) &amp;lt; 300&lt;/code&gt; // 90% 的样本数据必须低于 300&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;按类型划分的聚合方法&lt;/h3&gt;&#xA;&lt;p&gt;k6 根据指标类型进行数据聚合，这些聚合方法将构成阈值表达式的一部分。&lt;/p&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;&lt;strong&gt;指标类型&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;聚合方法&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Counter&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;count&lt;/code&gt; 和 &lt;code&gt;rate&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Gauge&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;value&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Rate&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;rate&lt;/code&gt;&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Trend&lt;/td&gt;&#xA;&lt;td&gt;&lt;code&gt;avg&lt;/code&gt;, &lt;code&gt;min&lt;/code&gt;, &lt;code&gt;max&lt;/code&gt;, &lt;code&gt;med&lt;/code&gt; 和 &lt;code&gt;p(N)&lt;/code&gt;，其中 &lt;code&gt;N&lt;/code&gt; 指定百分位阈值（数值范围为 0.0 至 100）。例如 &lt;code&gt;p(99.99)&lt;/code&gt; 表示第 99.99 百分位数。所有数值均以毫秒为单位。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;这个示例脚本使用了所有不同类型的指标，并为每种指标设置了不同的阈值类型：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;import { Trend, Rate, Counter, Gauge } from &#39;k6/metrics&#39;;&#xA;import { sleep } from &#39;k6&#39;;&#xA;&#xA;export const TrendRTT = new Trend(&#39;RTT&#39;);&#xA;export const RateContentOK = new Rate(&#39;ContentOK&#39;);&#xA;export const GaugeContentSize = new Gauge(&#39;ContentSize&#39;);&#xA;export const CounterErrors = new Counter(&#39;Errors&#39;);&#xA;export const options = {&#xA;  thresholds: {&#xA;    // Count: 错误内容出现次数不能超过 99 次&#xA;    Errors: [&#39;count&amp;lt;100&#39;],&#xA;    // Gauge: 返回内容必须小于 4000 字节&#xA;    ContentSize: [&#39;value&amp;lt;4000&#39;],&#xA;    // Rate: 内容必须正常（OK）的次数不低于 95 次&#xA;    ContentOK: [&#39;rate&amp;gt;0.95&#39;],&#xA;    // Trend: 百分位数、平均值、中位数及最小值均需保持在指定的毫秒级范围内&#xA;    RTT: [&#39;p(99)&amp;lt;300&#39;, &#39;p(70)&amp;lt;250&#39;, &#39;avg&amp;lt;200&#39;, &#39;med&amp;lt;150&#39;, &#39;min&amp;lt;100&#39;],&#xA;  },&#xA;};&#xA;&#xA;export default function () {&#xA;  const res = http.get(&#39;https://quickpizza.grafana.com/api/json?name=Bert&#39;);&#xA;  const contentOK = res.json(&#39;name&#39;) === &#39;Bert&#39;;&#xA;&#xA;  TrendRTT.add(res.timings.duration);&#xA;  RateContentOK.add(contentOK);&#xA;  GaugeContentSize.add(res.body.length);&#xA;  CounterErrors.add(!contentOK);&#xA;&#xA;  sleep(1);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;请勿通过重复相同对象键名的方式为同一指标设置多个阈值。由于阈值是作为 JavaScript 对象的属性来定义的，因此不能使用相同的属性名来指定多个阈值。&lt;/p&gt;&#xA;&lt;p&gt;错误示范：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;export const options = {&#xA;  thresholds: {&#xA;    metric_name: [&#39;count&amp;lt;100&#39;],&#xA;    metric_name: [&#39;rate&amp;lt;50&#39;],&#xA;  },&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;后面的配置将被忽略。如需为同一指标设置多个阈值，请改用数组形式指定相同键名对应的值。&lt;/p&gt;&#xA;&lt;h2&gt;可直接复制粘贴的阈值配置示例&lt;/h2&gt;&#xA;&lt;p&gt;使用内置指标是快速设置阈值的首选方式。以下提供几个可直接复制的配置示例，可立即投入使用。&lt;/p&gt;&#xA;&lt;h3&gt;在指定时间内完成特定百分比的请求&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;import { sleep } from &#39;k6&#39;;&#xA;&#xA;export const options = {&#xA;  thresholds: {&#xA;    // 90% 的请求需在 400ms 内完成&#xA;    http_req_duration: [&#39;p(90) &amp;lt; 400&#39;],&#xA;  },&#xA;};&#xA;&#xA;export default function () {&#xA;  http.get(&#39;https://quickpizza.grafana.com&#39;);&#xA;  sleep(1);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;错误率需低于 1%&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;import { sleep } from &#39;k6&#39;;&#xA;&#xA;export const options = {&#xA;  thresholds: {&#xA;    // 在整个测试执行期间，错误率必须始终低于 1%&#xA;    http_req_failed: [&#39;rate&amp;lt;0.01&#39;],&#xA;  },&#xA;};&#xA;&#xA;export default function () {&#xA;  http.get(&#39;https://quickpizza.grafana.com&#39;);&#xA;  sleep(1);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;单个指标的多个阈值&lt;/h3&gt;&#xA;&lt;p&gt;你也可以为单个指标设置多个阈值。该阈值针对不同请求百分位设有不同的耗时要求。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;import { sleep } from &#39;k6&#39;;&#xA;&#xA;export const options = {&#xA;  thresholds: {&#xA;    // 90% 的请求必须在 400ms 内完成，95% 的请求需在 800ms 内完成，99.9% 的请求则应在 2s 内完成。&#xA;    http_req_duration: [&#39;p(90) &amp;lt; 400&#39;, &#39;p(95) &amp;lt; 800&#39;, &#39;p(99.9) &amp;lt; 2000&#39;],&#xA;  },&#xA;};&#xA;&#xA;export default function () {&#xA;  const res1 = http.get(&#39;https://quickpizza.grafana.com&#39;);&#xA;  sleep(1);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;分组耗时阈值&lt;/h3&gt;&#xA;&lt;p&gt;你可以按组设置阈值。此代码中包含针对单个请求和批量请求的分组设置，每个组可配置不同的阈值标准。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;import { group, sleep } from &#39;k6&#39;;&#xA;&#xA;export const options = {&#xA;  thresholds: {&#xA;    &#39;group_duration{group:::individualRequests}&#39;: [&#39;avg &amp;lt; 400&#39;],&#xA;    &#39;group_duration{group:::batchRequests}&#39;: [&#39;avg &amp;lt; 200&#39;],&#xA;  },&#xA;  vus: 1,&#xA;  duration: &#39;10s&#39;,&#xA;};&#xA;&#xA;export default function () {&#xA;  group(&#39;individualRequests&#39;, function () {&#xA;    http.get(&#39;https://quickpizza.grafana.com/api/json?letter=a&#39;);&#xA;    http.get(&#39;https://quickpizza.grafana.com/api/json?letter=b&#39;);&#xA;    http.get(&#39;https://quickpizza.grafana.com/api/json?letter=c&#39;);&#xA;  });&#xA;&#xA;  group(&#39;batchRequests&#39;, function () {&#xA;    http.batch([&#xA;      [&#39;GET&#39;, &#39;https://quickpizza.grafana.com/api/json?letter=a&#39;],&#xA;      [&#39;GET&#39;, &#39;https://quickpizza.grafana.com/api/json?letter=b&#39;],&#xA;      [&#39;GET&#39;, &#39;https://quickpizza.grafana.com/api/json?letter=c&#39;],&#xA;    ]);&#xA;  });&#xA;&#xA;  sleep(1);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;为特定标签设置阈值&lt;/h2&gt;&#xA;&lt;p&gt;为单个 URL 或特定标签设置阈值通常非常实用。在 k6 中，带有标签的请求会生成子指标，可直接用于阈值配置：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;export const options = {&#xA;  thresholds: {&#xA;    &#39;metric_name{tag_name:tag_value}&#39;: [&#39;threshold_expression&#39;],&#xA;  },&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这里有个完整的例子：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;import { sleep } from &#39;k6&#39;;&#xA;import { Rate } from &#39;k6/metrics&#39;;&#xA;&#xA;export const options = {&#xA;  thresholds: {&#xA;    &#39;http_req_duration{type:API}&#39;: [&#39;p(95)&amp;lt;500&#39;], // 仅针对 API 请求的阈值&#xA;    &#39;http_req_duration{type:staticContent}&#39;: [&#39;p(95)&amp;lt;200&#39;], // 仅针对静态内容的阈值&#xA;  },&#xA;};&#xA;&#xA;export default function () {&#xA;  const res1 = http.get(&#39;https://quickpizza.grafana.com/api/headers&#39;, {&#xA;    tags: { type: &#39;API&#39; },&#xA;  });&#xA;  const res2 = http.get(&#39;https://quickpizza.grafana.com/api/json&#39;, {&#xA;    tags: { type: &#39;API&#39; },&#xA;  });&#xA;&#xA;  const responses = http.batch([&#xA;    [&#xA;      &#39;GET&#39;,&#xA;      &#39;https://quickpizza.grafana.com/favicon.ico&#39;,&#xA;      null,&#xA;      { tags: { type: &#39;staticContent&#39; } },&#xA;    ],&#xA;    [&#39;GET&#39;, &#39;https://quickpizza.grafana.com/admin&#39;, null, { tags: { type: &#39;staticContent&#39; } }],&#xA;  ]);&#xA;&#xA;  sleep(1);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;当超过阈值时中止测试&lt;/h2&gt;&#xA;&lt;p&gt;若需在超过阈值时立即中止测试，可将 &lt;code&gt;abortOnFail&lt;/code&gt; 属性设为 &lt;code&gt;true&lt;/code&gt;。启用该参数后，一旦阈值被突破，测试将立即终止。&lt;/p&gt;&#xA;&lt;p&gt;有时候，测试可能在初期就触发阈值导致中止，而此时尚未生成足够数据。为避免该情况，可通过 &lt;code&gt;delayAbortEval&lt;/code&gt; 参数延迟中止判定。如本脚本所示，将 &lt;code&gt;abortOnFail&lt;/code&gt; 延迟 10 秒生效 —— 即测试仅在持续 10 秒仍无法满足 &lt;code&gt;p(99) &amp;lt; 10&lt;/code&gt; 阈值时才会中止。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;export const options = {&#xA;  thresholds: {&#xA;    metric_name: [&#xA;      {&#xA;        threshold: &#39;p(99) &amp;lt; 10&#39;, // string&#xA;        abortOnFail: true, // boolean&#xA;        delayAbortEval: &#39;10s&#39;, // string&#xA;        /*...*/&#xA;      },&#xA;    ],&#xA;  },&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;各字段定义如下：&lt;/p&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;&lt;strong&gt;名称&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;类型&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;描述&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;threshold&lt;/td&gt;&#xA;&lt;td&gt;string&lt;/td&gt;&#xA;&lt;td&gt;阈值表达式字符串，用于指定需要评估的阈值条件&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;abortOnFail&lt;/td&gt;&#xA;&lt;td&gt;boolean&lt;/td&gt;&#xA;&lt;td&gt;当测试未完成时若阈值评估为 false，是否中止测试&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;delayAbortEval&lt;/td&gt;&#xA;&lt;td&gt;string&lt;/td&gt;&#xA;&lt;td&gt;若需延迟阈值评估以收集足够的指标样本，可使用相对时间字符串（如 &lt;code&gt;10s&lt;/code&gt;、&lt;code&gt;1m&lt;/code&gt; 等）指定延迟时长&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;例子如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;&#xA;export const options = {&#xA;  vus: 30,&#xA;  duration: &#39;2m&#39;,&#xA;  thresholds: {&#xA;    http_req_duration: [{ threshold: &#39;p(99) &amp;lt; 10&#39;, abortOnFail: true }],&#xA;  },&#xA;};&#xA;&#xA;export default function () {&#xA;  http.get(&#39;https://quickpizza.grafana.com&#39;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;使用检查使负载测试失败&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.lyyyuna.com/2025/04/10/grafana-k6-4/&#34;&gt;检查&lt;/a&gt;适用于将断言规则代码化，但与阈值不同，检查项不会影响 k6 的退出状态。&lt;/p&gt;&#xA;&lt;p&gt;若仅依赖检查项验证系统行为，则无法基于检查结果使整个测试运行失败。通常最佳实践是结合使用检查项与阈值，从而兼得二者优势：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;import { check, sleep } from &#39;k6&#39;;&#xA;&#xA;export const options = {&#xA;  vus: 50,&#xA;  duration: &#39;10s&#39;,&#xA;  thresholds: {&#xA;    // 检查的成功率应高于 90%。&#xA;    checks: [&#39;rate&amp;gt;0.9&#39;],&#xA;  },&#xA;};&#xA;&#xA;export default function () {&#xA;  const res = http.get(&#39;https://quickpizza.grafana.com/api/status/500&#39;);&#xA;&#xA;  check(res, {&#xA;    &#39;status is 500&#39;: (r) =&amp;gt; r.status == 500,&#xA;  });&#xA;&#xA;  sleep(1);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在此示例中，阈值基于检查项指标（checks metric）配置，要求检查项成功率必须高于 90%。&lt;/p&gt;&#xA;&lt;p&gt;此外，你还可以为检查项添加标签，以便针对特定检查项或检查项组设置独立阈值。例如：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;import { check, sleep } from &#39;k6&#39;;&#xA;&#xA;export const options = {&#xA;  vus: 50,&#xA;  duration: &#39;10s&#39;,&#xA;  thresholds: {&#xA;    &#39;checks{myTag:hola}&#39;: [&#39;rate&amp;gt;0.9&#39;],&#xA;  },&#xA;};&#xA;&#xA;export default function () {&#xA;  let res;&#xA;&#xA;  res = http.get(&#39;https://quickpizza.grafana.com/api/status/500&#39;);&#xA;  check(res, {&#xA;    &#39;status is 500&#39;: (r) =&amp;gt; r.status == 500,&#xA;  });&#xA;&#xA;  res = http.get(&#39;https://quickpizza.grafana.com/api/status/200&#39;);&#xA;  check(&#xA;    res,&#xA;    {&#xA;      &#39;status is 200&#39;: (r) =&amp;gt; r.status == 200,&#xA;    },&#xA;    { myTag: &#39;hola&#39; }&#xA;  );&#xA;&#xA;  sleep(1);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/05/12/grafana-k6-5/" rel="alternate"></link>
    <summary type="html">阈值 -&gt; Thresholds</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>k6 检查的使用</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/04/10/grafana-k6-4/</id>
    <content type="html">&lt;h2&gt;检查&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;检查&lt;/code&gt;用于验证测试用例中布尔条件是否成立。测试人员通过检查验证系统是否返回预期内容。例如，某个检查可以确认 POST 请求的响应状态码是否为 201，或者响应体的大小是否符合预期。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;检查&lt;/code&gt;和许多测试框架中的&lt;code&gt;断言&lt;/code&gt;（assert）类似，但在 k6 中，失败的检查不会导致测试中断。相反，k6 会在测试持续运行过程中记录检查的失败率。&lt;/p&gt;&#xA;&lt;h3&gt;检查 HTTP 响应码&lt;/h3&gt;&#xA;&lt;p&gt;检查功能非常适合针对HTTP请求和响应制定断言规范。例如，以下代码片段可确保HTTP响应码为 200：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import { check } from &#39;k6&#39;;&#xA;import http from &#39;k6/http&#39;;&#xA;&#xA;export default function () {&#xA;  const res = http.get(&#39;http://test.k6.io/&#39;);&#xA;  check(res, {&#xA;    &#39;is status 200&#39;: (r) =&amp;gt; r.status === 200,&#xA;  });&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;检查 HTTP 响应体&lt;/h3&gt;&#xA;&lt;p&gt;有时，即使HTTP 200响应中也可能包含错误信息。在这种情况下，建议添加一个检查来验证响应体，例如：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import { check } from &#39;k6&#39;;&#xA;import http from &#39;k6/http&#39;;&#xA;&#xA;export default function () {&#xA;  const res = http.get(&#39;http://test.k6.io/&#39;);&#xA;  check(res, {&#xA;    &#39;verify homepage text&#39;: (r) =&amp;gt;&#xA;      r.body.includes(&#39;Collection of simple web-pages suitable for load testing&#39;),&#xA;  });&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;检查 HTTP 响应大小&lt;/h3&gt;&#xA;&lt;p&gt;要验证响应体的大小，可以使用如下检查：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import { check } from &#39;k6&#39;;&#xA;import http from &#39;k6/http&#39;;&#xA;&#xA;export default function () {&#xA;  const res = http.get(&#39;http://test.k6.io/&#39;);&#xA;  check(res, {&#xA;    &#39;body size is 11,105 bytes&#39;: (r) =&amp;gt; r.body.length == 11105,&#xA;  });&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;查看检查的通过率&lt;/h3&gt;&#xA;&lt;p&gt;当脚本包含检查时，汇总报告会显示测试的检查中有多少通过：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ k6 run script.js&#xA;&#xA;  ...&#xA;    ✓ is status 200&#xA;&#xA;  ...&#xA;  checks.........................: 100.00% ✓ 1        ✗ 0&#xA;  data_received..................: 11 kB   12 kB/s&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;添加多个检查&lt;/h3&gt;&#xA;&lt;p&gt;你还可以在单个 &lt;code&gt;check()&lt;/code&gt; 语句中添加多个检查条件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import { check } from &#39;k6&#39;;&#xA;import http from &#39;k6/http&#39;;&#xA;&#xA;export default function () {&#xA;  const res = http.get(&#39;http://test.k6.io/&#39;);&#xA;  check(res, {&#xA;    &#39;is status 200&#39;: (r) =&amp;gt; r.status === 200,&#xA;    &#39;body size is 11,105 bytes&#39;: (r) =&amp;gt; r.body.length == 11105,&#xA;  });&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当执行此测试时，输出结果会大致如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;$ k6 run checks.js&#xA;&#xA;  ...&#xA;    ✓ is status 200&#xA;    ✓ body size is 11,105 bytes&#xA;&#xA;  ...&#xA;  checks.........................: 100.00% ✓ 2        ✗ 0&#xA;  data_received..................: 11 kB   20 kB/s&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当检查失败时，脚本将继续成功执行，并不会返回‘失败’的退出状态。若需根据检查结果让整个测试失败，必须将检查与&lt;strong&gt;阈值&lt;/strong&gt;结合使用。这一功能在特定场景下特别有用，例如将 k6 集成到持续集成（CI）管道中，或在安排性能测试时接收告警。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/04/10/grafana-k6-4/" rel="alternate"></link>
    <summary type="html">检查 -&gt; Checks</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>k6 指标的使用</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/04/09/grafana-k6-3/</id>
    <content type="html">&lt;h2&gt;指标&lt;/h2&gt;&#xA;&lt;p&gt;指标用于衡量系统在测试条件下的表现。默认情况下，k6 会自动收集内置指标。除此之外还可以创建自定义指标。&lt;/p&gt;&#xA;&lt;p&gt;指标主要分四类：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;计数器指标&lt;/strong&gt;（Counters）用于累加数值。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;仪表指标&lt;/strong&gt;（Gauges）跟踪最小值、最大值和最新值。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;速率指标&lt;/strong&gt;（Rates）记录非零值的发生频率。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;趋势指标&lt;/strong&gt;（Trends）计算多组值的统计信息（如平均值、众数或百分位数）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;若要让测试因未满足特定条件而失败，可以通过基于指标条件编写阈值（Threshold）实现（具体表达式形式取决于指标类型）。要筛选指标，可使用标签（Tags）和分组（groups）。你还可以将指标以多种汇总或精细格式导出。&lt;/p&gt;&#xA;&lt;h2&gt;内置指标&lt;/h2&gt;&#xA;&lt;p&gt;每个 k6 测试都会生成内置和自定义指标。每个支持的协议也都有其特定的指标。&lt;/p&gt;&#xA;&lt;h3&gt;标准内置指标&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;&lt;strong&gt;指标名称&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;类型&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;描述&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;checks&lt;/td&gt;&#xA;&lt;td&gt;Rate&lt;/td&gt;&#xA;&lt;td&gt;成功检查的比率。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;data_received&lt;/td&gt;&#xA;&lt;td&gt;Counter&lt;/td&gt;&#xA;&lt;td&gt;接收到的数据量。此示例说明如何跟踪单个 URL 的数据。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;data_sent&lt;/td&gt;&#xA;&lt;td&gt;Counter&lt;/td&gt;&#xA;&lt;td&gt;发送的数据量。跟踪单个 URL 的数据以监控其发送数据情况。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;dropped_iterations&lt;/td&gt;&#xA;&lt;td&gt;Counter&lt;/td&gt;&#xA;&lt;td&gt;由于虚拟用户（VU）不足（针对 arrival-rate 调度器）或时间超限（针对基于迭代的调度器的 maxDuration 过期）而未启动的迭代次数。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;iteration_duration&lt;/td&gt;&#xA;&lt;td&gt;Trend&lt;/td&gt;&#xA;&lt;td&gt;完成一次完整迭代所需的时间（包括 setup 和 teardown 阶段）。若需计算特定场景下迭代函数本身的持续时间，可参考此方法。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;iterations&lt;/td&gt;&#xA;&lt;td&gt;Counter&lt;/td&gt;&#xA;&lt;td&gt;虚拟用户执行 JS 脚本（默认函数）的总次数。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;vus&lt;/td&gt;&#xA;&lt;td&gt;Gauge&lt;/td&gt;&#xA;&lt;td&gt;当前活跃虚拟用户数。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;vus_max&lt;/td&gt;&#xA;&lt;td&gt;Gauge&lt;/td&gt;&#xA;&lt;td&gt;最大可能虚拟用户数（虚拟用户资源是预先分配的，以避免在增加负载时影响性能）。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3&gt;HTTP 专用内置指标&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;&lt;strong&gt;指标名称&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;类型&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;描述&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;http_req_blocked&lt;/td&gt;&#xA;&lt;td&gt;Trend&lt;/td&gt;&#xA;&lt;td&gt;在发起请求前因等待空闲的 TCP 连接槽而被阻塞的时间（单位：浮点数）。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;http_req_connecting&lt;/td&gt;&#xA;&lt;td&gt;Trend&lt;/td&gt;&#xA;&lt;td&gt;建立与远程主机 TCP 连接所消耗的时间（单位：浮点数）。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;http_req_duration&lt;/td&gt;&#xA;&lt;td&gt;Trend&lt;/td&gt;&#xA;&lt;td&gt;请求的总耗时。等于 &lt;code&gt;http_req_sending + http_req_waiting + http_req_receiving&lt;/code&gt;，即远程服务器处理请求并响应的时间（不含 DNS 解析和初始连接时间）。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;http_req_failed&lt;/td&gt;&#xA;&lt;td&gt;Rate&lt;/td&gt;&#xA;&lt;td&gt;根据 &lt;code&gt;setResponseCallback&lt;/code&gt; 定义的失败请求比率。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;http_req_receiving&lt;/td&gt;&#xA;&lt;td&gt;Trend&lt;/td&gt;&#xA;&lt;td&gt;从远程主机接收响应数据所消耗的时间（单位：浮点数）。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;http_req_sending&lt;/td&gt;&#xA;&lt;td&gt;Trend&lt;/td&gt;&#xA;&lt;td&gt;向远程主机发送请求数据所消耗的时间（单位：浮点数）。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;http_req_tls_handshaking&lt;/td&gt;&#xA;&lt;td&gt;Trend&lt;/td&gt;&#xA;&lt;td&gt;与远程主机进行 TLS 握手所消耗的时间（单位：浮点数）。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;http_req_waiting&lt;/td&gt;&#xA;&lt;td&gt;Trend&lt;/td&gt;&#xA;&lt;td&gt;等待远程主机响应的时间（即“首字节时间”，Time To First Byte，TTFB）（单位：浮点数）。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;http_reqs&lt;/td&gt;&#xA;&lt;td&gt;Counter&lt;/td&gt;&#xA;&lt;td&gt;k6 生成的总 HTTP 请求次数。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;对于所有 &lt;code&gt;http_req_*&lt;/code&gt; 指标，其时间戳会在请求结束时记录。换句话说，当 k6 接收到响应体末尾或请求超时时，就会生成该时间戳。&lt;/p&gt;&#xA;&lt;h3&gt;内置 WebSocket 指标&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;&lt;strong&gt;指标名称&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;类型&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;描述&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;ws_connecting&lt;/td&gt;&#xA;&lt;td&gt;Trend&lt;/td&gt;&#xA;&lt;td&gt;建立 WebSocket 连接请求的总耗时（单位：浮点数）。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;ws_msgs_received&lt;/td&gt;&#xA;&lt;td&gt;Counter&lt;/td&gt;&#xA;&lt;td&gt;接收到的消息总数。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;ws_msgs_sent&lt;/td&gt;&#xA;&lt;td&gt;Counter&lt;/td&gt;&#xA;&lt;td&gt;发送的消息总数。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;ws_ping&lt;/td&gt;&#xA;&lt;td&gt;Trend&lt;/td&gt;&#xA;&lt;td&gt;从发送 ping 请求到接收 pong 响应的时间间隔（单位：浮点数）。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;ws_session_duration&lt;/td&gt;&#xA;&lt;td&gt;Trend&lt;/td&gt;&#xA;&lt;td&gt;WebSocket 会话的持续时间。从连接开始到虚拟用户（VU）执行结束的时间间隔（单位：浮点数）。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;ws_sessions&lt;/td&gt;&#xA;&lt;td&gt;Counter&lt;/td&gt;&#xA;&lt;td&gt;启动的 WebSocket 会话总数。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3&gt;内置 gRPC 指标&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;&lt;thead&gt;&#xA;&lt;tr&gt;&#xA;&lt;th&gt;&lt;strong&gt;指标名称&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;类型&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;th&gt;&lt;strong&gt;描述&lt;/strong&gt;&lt;/th&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/thead&gt;&#xA;&lt;tbody&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;grpc_req_duration&lt;/td&gt;&#xA;&lt;td&gt;Trend&lt;/td&gt;&#xA;&lt;td&gt;从发送请求到接收远程主机响应的总耗时（单位：浮点数）。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;grpc_streams&lt;/td&gt;&#xA;&lt;td&gt;Counter&lt;/td&gt;&#xA;&lt;td&gt;启动的 gRPC 流总数。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;grpc_streams_msgs_received&lt;/td&gt;&#xA;&lt;td&gt;Counter&lt;/td&gt;&#xA;&lt;td&gt;通过流接收到的消息总数。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;grpc_streams_msgs_sent&lt;/td&gt;&#xA;&lt;td&gt;Counter&lt;/td&gt;&#xA;&lt;td&gt;通过流发送的消息总数。&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2&gt;自定义指标&lt;/h2&gt;&#xA;&lt;p&gt;除了内置指标外，你还可以创建自定义指标。每种指标类型都有一个用于创建自定义指标的构造函数，该构造函数会生成声明类型的指标对象，每种类型都提供 add 方法来实现指标测量。&lt;/p&gt;&#xA;&lt;h3&gt;创建自定义指标&lt;/h3&gt;&#xA;&lt;p&gt;自定义指标必须在初始化阶段创建。这一限制既控制了内存占用，又能确保 k6 验证所有阈值时对应的指标均已正确定义。下面是详细步骤：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;// 1. 导入 k6/metrics 模块。也可以通过命名导入的方式指定要创建的指标类型&#xA;import { Trend } from &#39;k6/metrics&#39;;&#xA;&#xA;// 2. 创建自定义趋势指标 myTrend，在结果输出中对应的指标名称显示为 waiting_time&#xA;const myTrend = new Trend(&#39;waiting_time&#39;);&#xA;&#xA;export default function () {&#xA;  const r = http.get(&#39;https://quickpizza.grafana.com/&#39;);&#xA;  // 3. 使用 add 方法，将数据加入指标中&#xA;  myTrend.add(r.timings.waiting);&#xA;  console.log(myTrend.name); // waiting_time&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;查看自定义指标结果&lt;/h3&gt;&#xA;&lt;p&gt;自定义指标会出现在测试结果输出中，既包含测试结束时的总结，也包含详细的数据点。每种指标类型都有特定的聚合方法。你还可以为自定义指标的任意值添加标签，这些标签可用于筛选测试结果。&lt;/p&gt;&#xA;&lt;p&gt;以下是前面脚本的输出可能在测试结束摘要中的显示方式。由于该指标是趋势型指标，k6 会根据数值数量及其总和计算各类趋势数据。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ k6 run script.js&#xA;&#xA;  ...&#xA;  INFO[0001] waiting_time                                  source=console&#xA;&#xA;  ...&#xA;  iteration_duration.............: avg=1.15s    min=1.15s    med=1.15s    max=1.15s    p(90)=1.15s    p(95)=1.15s&#xA;  iterations.....................: 1     0.864973/s&#xA;  waiting_time...................: avg=265.245396 min=265.245396 med=265.245396 max=265.245396 p(90)=265.245396 p(95)=265.245396&#xA;``&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/04/09/grafana-k6-3/" rel="alternate"></link>
    <summary type="html">指标 -&gt; metrics</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>在 k6 中发送 HTTP 请求</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/04/08/grafana-k6-2/</id>
    <content type="html">&lt;h2&gt;发送 HTTP 请求&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;k6/http&lt;/code&gt; 模块可处理各种类型的 HTTP 请求和方法。比如最常见的 GET 请求可以通过下面的方式发送：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;&#xA;export default function () {&#xA;  http.get(&#39;http://test.k6.io&#39;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;比如发送 POST 请求，带上请求体，并加上特定的 HTTP header：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;&#xA;export default function () {&#xA;  const url = &#39;http://test.k6.io/login&#39;;&#xA;  const payload = JSON.stringify({&#xA;    email: &#39;aaa&#39;,&#xA;    password: &#39;bbb&#39;,&#xA;  });&#xA;&#xA;  const params = {&#xA;    headers: {&#xA;      &#39;Content-Type&#39;: &#39;application/json&#39;,&#xA;      &#39;Authorization&#39;: &#39;abced&#39;,&#xA;    },&#xA;  };&#xA;&#xA;  http.post(url, payload, params);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;跟随重定向&lt;/h2&gt;&#xA;&lt;p&gt;默认情况下，k6 会在停止并返回最后一个响应之前自动跟随一定数量的重定向。你可以通过以下方式自定义设置：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用 &lt;code&gt;maxRedirects&lt;/code&gt; 选项全局设置重定向次数上限。&lt;/li&gt;&#xA;&lt;li&gt;使用 &lt;code&gt;Params.redirects&lt;/code&gt; 属性为特定请求设置重定向次数，该属性会覆盖 &lt;code&gt;maxRedirects&lt;/code&gt; 选项。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;HTTP 请求的标签&lt;/h2&gt;&#xA;&lt;p&gt;k6 会自动给 HTTP 请求添加标签。你可以使用这些标签来过滤测试结果，并对分析内容进行分类整理：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;expected_response&lt;/code&gt;，默认情况下，状态响应码在 200～399 之间的话，为 &lt;code&gt;true&lt;/code&gt;。默认行为可以通过 &lt;code&gt;setResponseCallback&lt;/code&gt; 来改变。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;group&lt;/code&gt;，请求可以分组，这里为组名。默认组为空。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;name&lt;/code&gt;，默认为请求的 URL。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;method&lt;/code&gt;，请求的类型。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;scenario&lt;/code&gt;，当请求属于某个场景时，这里为场景的名字。默认值为 &lt;code&gt;default&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;status&lt;/code&gt;，响应状态码。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;url&lt;/code&gt;，默认为请求的 URL。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;以下 JSON 示例展示了测试结果数据点的日志记录方式。可以看到，标签是通过 &lt;code&gt;tags&lt;/code&gt; 来组织数据的。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{&#xA;  &amp;quot;type&amp;quot;: &amp;quot;Point&amp;quot;,&#xA;  &amp;quot;metric&amp;quot;: &amp;quot;http_req_duration&amp;quot;,&#xA;  &amp;quot;data&amp;quot;: {&#xA;    &amp;quot;time&amp;quot;: &amp;quot;2017-06-02T23:10:29.52444541+02:00&amp;quot;,&#xA;    &amp;quot;value&amp;quot;: 586.831127,&#xA;    &amp;quot;tags&amp;quot;: {&#xA;      &amp;quot;expected_response&amp;quot;: &amp;quot;true&amp;quot;,&#xA;      &amp;quot;group&amp;quot;: &amp;quot;&amp;quot;,&#xA;      &amp;quot;method&amp;quot;: &amp;quot;GET&amp;quot;,&#xA;      &amp;quot;name&amp;quot;: &amp;quot;http://test.k6.io&amp;quot;,&#xA;      &amp;quot;scenario&amp;quot;: &amp;quot;default&amp;quot;,&#xA;      &amp;quot;status&amp;quot;: &amp;quot;200&amp;quot;,&#xA;      &amp;quot;url&amp;quot;: &amp;quot;http://test.k6.io&amp;quot;&#xA;    }&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;读者可能对上面提到的 &lt;code&gt;group&lt;/code&gt; 和 &lt;code&gt;scenario&lt;/code&gt; 不太熟悉，这里介绍一下。&lt;/p&gt;&#xA;&lt;p&gt;group 可以将相关的测试步骤分组，方便在测试结果中按组分析性能数据（如响应时间内、错误率等）。如按下面的方式分组：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;&#xA;export default function() {&#xA;  // 登录相关的操作分组&#xA;  const loginGroup = group(&#39;用户登录&#39;, () =&amp;gt; {&#xA;    http.get(&#39;https://api.example.com/login&#39;);&#xA;  });&#xA;&#xA;  // 数据查询操作分组&#xA;  group(&#39;数据查询&#39;, () =&amp;gt; {&#xA;    http.get(&#39;https://api.example.com/data&#39;);&#xA;  });&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;scenario 则是定义虚拟用户（VU）的行为模式、负载策略和资源分配，模拟不同用户角色或负载场景。场景就定义在&lt;a href=&#34;https://www.lyyyuna.com/2025/03/12/grafana-k6-1/&#34;&gt;Grafana k6 入门示例&lt;/a&gt;中介绍的配置项中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;export let options = {&#xA;  scenarios: {&#xA;    // 场景1：模拟 100 个恒定并发用户执行登录操作&#xA;    login_scenario: {&#xA;      executor: &#39;constant-vus&#39;,&#xA;      vus: 100,&#xA;      duration: &#39;30s&#39;,&#xA;      exec: &#39;login&#39;,&#xA;    },&#xA;&#xA;    // 场景2：模拟注册用户行为，逐步增加并发&#xA;    register_scenario: {&#xA;      executor: &#39;ramping-vus&#39;,&#xA;      startVUs: 10,&#xA;      stages: [&#xA;        { target: 50, duration: &#39;20s&#39; },&#xA;        { target: 100, duration: &#39;30s&#39; },&#xA;      ],&#xA;      exec: &#39;register&#39;,&#xA;    },&#xA;  },&#xA;};&#xA;&#xA;// 定义场景执行的函数&#xA;export function login() {&#xA;  http.get(&#39;https://api.example.com/login&#39;);&#xA;}&#xA;&#xA;export function register() {&#xA;  http.post(&#39;https://api.example.com/register&#39;, { username: &#39;test&#39; });&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;合并标签&lt;/h3&gt;&#xA;&lt;p&gt;上文提到，&lt;code&gt;name&lt;/code&gt; 标签默认是完整的请求 URL。以下代码会访问 100 个不同的 URL：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;&#xA;export default function() {&#xA;  // 生成并访问100个不同路径的URL&#xA;  for (let i = 1; i &amp;lt;= 100; i++) {&#xA;    http.get(`https://api.example.com/data/${i}`);&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;测试结果会产生一大批唯一的 URL。每次请求的 name 标签都会记录完整的URL（如 /data/1、/data/2 等），这会导致：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;数据分散&lt;/strong&gt;：指标会被分散到100个不同的标签组中，难以聚合分析整体性能。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;存储压力&lt;/strong&gt;：大量唯一标签会增加指标存储的负担。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;这个问题可以通过自定义标签覆盖默认行为，例如将 name 赋值为固定值：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;&#xA;export default function () {&#xA;  for (let id = 1; id &amp;lt;= 100; id++) {&#xA;    http.get(`http://example.com/posts/${id}`, {&#xA;      tags: { name: &#39;PostsItemURL&#39; },&#xA;    });&#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/04/08/grafana-k6-2/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>How to use Ginkgo label in your test</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/04/07/ginkgo-label-en-tutorial/</id>
    <content type="html">&lt;h2&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;Many testing frameworks provide capabilities to group test cases, such as &lt;code&gt;pytest&lt;/code&gt;&#39;s &lt;code&gt;mark&lt;/code&gt;, &lt;code&gt;Robot Framework&lt;/code&gt;&#39;s &lt;code&gt;tag&lt;/code&gt;, and &lt;code&gt;TestNG&lt;/code&gt;&#39;s &lt;code&gt;groups&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;In &lt;code&gt;Ginkgo v1&lt;/code&gt;, there was no such functionality, so we had to embed &lt;code&gt;labels&lt;/code&gt; into string-based titles and use &lt;code&gt;--focus&lt;/code&gt; to filter test cases. However, string-based implementations have drawbacks like potential conflicts, duplication, and lack of type safety, &lt;code&gt;Ginkgo v1&lt;/code&gt; is inadequate for large-scale test suites.&lt;/p&gt;&#xA;&lt;p&gt;In &lt;code&gt;Ginkgo v2&lt;/code&gt;, the official solution &lt;code&gt;Label&lt;/code&gt; is introduced, let&#39;s explore it together.&lt;/p&gt;&#xA;&lt;p&gt;P.S. This article is based on &lt;code&gt;Ginkgo v2.13.2&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;h2&gt;Basic Usage&lt;/h2&gt;&#xA;&lt;h3&gt;Adding Labels to Test Cases&lt;/h3&gt;&#xA;&lt;p&gt;Labels are defined using the &lt;code&gt;Label&lt;/code&gt; decorator and can be applied to any node type:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;Describe(&amp;quot;Upload&amp;quot;, Label(&amp;quot;integration&amp;quot;, &amp;quot;storage&amp;quot;), func() {&#xA;    It(&amp;quot;Form upload&amp;quot;, Label(&amp;quot;network&amp;quot;, &amp;quot;slow&amp;quot;, &amp;quot;library storage&amp;quot;), func() {&#xA;        // Final labels [integration, storage, network, slow, library storage]&#xA;    })&#xA;&#xA;    Context(&amp;quot;Chunked upload&amp;quot;, Label(&amp;quot;network&amp;quot;, &amp;quot;library storage&amp;quot;), func() {&#xA;        It(&amp;quot;1 chunk&amp;quot;, Label(&amp;quot;slow&amp;quot;) func() {&#xA;            // Final labels [integration, storage, network, slow, library storage]&#xA;        })&#xA;&#xA;        It(&amp;quot;2 chunks&amp;quot;, Label(&amp;quot;quick&amp;quot;, &amp;quot;storage&amp;quot;) func() {&#xA;            // Final labels [integration, storage, network, quick, library storage]&#xA;        })&#xA;    })&#xA;&#xA;    DescribeTable(&amp;quot;s3 protocol&amp;quot;, Label(&amp;quot;quick&amp;quot;), func(count int) {&#xA;        &#xA;    },&#xA;        Entry(&amp;quot;PUT upload&amp;quot;, Label(&amp;quot;local&amp;quot;), 17), // Final labels [integration, storage, quick, local]&#xA;        Entry(&amp;quot;COPY upload&amp;quot;, 20), // Final labels [integration, storage, quick]&#xA;    )&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Key points:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Labels are just strings.&lt;/li&gt;&#xA;&lt;li&gt;Child nodes inherit parent node labels (e.g., &lt;code&gt;It&lt;/code&gt; inherits from &lt;code&gt;Context/Describe&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;li&gt;Labels are automatically deduplicated.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Entry&lt;/code&gt; can also have labels, they will not be treated as parameters.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3&gt;Filtering&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo v1&lt;/code&gt; already supports filtering via &lt;code&gt;--focus-file&lt;/code&gt;, &lt;code&gt;--skip-file&lt;/code&gt; (by filename/line number) and &lt;code&gt;--focus&lt;/code&gt;, &lt;code&gt;--skip&lt;/code&gt; (by title regex). However, test cases written for testing environments versus production environments may be scattered across various directories, files, and different test structures. Additionally, regular expressions are not intuitive and can lead to cumbersome command-line syntax.&lt;/p&gt;&#xA;&lt;p&gt;The new label-based filtering provides a more intuitive syntax, &lt;code&gt;Ginkgo v2&lt;/code&gt; use &lt;code&gt;--label-filter=QUERY&lt;/code&gt; with these rules:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;label1 &amp;amp;&amp;amp; label2&lt;/code&gt;, both labels match&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;label1 || label2&lt;/code&gt;, either label matches&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;!label1&lt;/code&gt; excludes cases with this label&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;,&lt;/code&gt; acts like &lt;code&gt;||&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;()&lt;/code&gt; can group expressions (e.g., &lt;code&gt;label1 &amp;amp;&amp;amp; (label2 || label3)&lt;/code&gt;)&lt;/li&gt;&#xA;&lt;li&gt;case-sensitive&lt;/li&gt;&#xA;&lt;li&gt;whitespace around labels is ignored.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;For instance, if we are testing a cloud storage product, we have 4 test cases:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;test case 1: product, local, cn-east-1, slow&lt;/li&gt;&#xA;&lt;li&gt;test case 2: local, cn-east-1, ap-southeast-1&lt;/li&gt;&#xA;&lt;li&gt;test case 3: local, ap-southeast-1&lt;/li&gt;&#xA;&lt;li&gt;test case 4: product, slow&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;where&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;product indicates the test case can run in the production environment, while local indicates it can run in the testing environment.&lt;/li&gt;&#xA;&lt;li&gt;cn-east-1 means the test case can run in the East China region, and ap-southeast-1 indicates it can run in the Southeast Asia region.&lt;/li&gt;&#xA;&lt;li&gt;slow signifies the test case takes a long time to execute.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;If using the following filter expressions:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;product&lt;/code&gt;: Selects all test cases that can run in the production environment. This would execute Case 1 and Case 4.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;!local&lt;/code&gt;: Selects test cases that cannot run in the testing environment. This would only execute Case 4.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;product &amp;amp;&amp;amp; cn-east-1&lt;/code&gt;: Selects test cases that run in the production environment in the East China region. This would execute only Case 1.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;cn-east-1 || ap-southeast-1&lt;/code&gt;: Selects test cases that can run in either the East China or Southeast Asia regions. This would execute Cases 1, 2, and 3.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;!slow&lt;/code&gt;: Excludes test cases that take a long time to execute. This would execute Cases 2 and 3.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;It becomes evident that the new filtering syntax is more intuitive, allowing users to quickly construct the desired test case combinations.&lt;/p&gt;&#xA;&lt;h3&gt;Combined Usage&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo v2&lt;/code&gt; retains previous filtering mechanisms:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;If a test case is marked as &lt;code&gt;Pending&lt;/code&gt;, it will never execute, regardless of other conditions.&lt;/li&gt;&#xA;&lt;li&gt;If a test case calls the &lt;code&gt;Skip()&lt;/code&gt; function, it will be skipped even if it matches the filter criteria.&lt;/li&gt;&#xA;&lt;li&gt;If a test case is marked with &lt;code&gt;Focus&lt;/code&gt;, only that test case will run (all others are excluded).&lt;/li&gt;&#xA;&lt;li&gt;If multiple filters are used in the command line (&lt;code&gt;--label-filter&lt;/code&gt;, &lt;code&gt;--focus-file/--skip-file&lt;/code&gt;, or &lt;code&gt;--focus/--skip&lt;/code&gt;), a test case must satisfy all conditions simultaneously to execute.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3&gt;Test Reports&lt;/h3&gt;&#xA;&lt;p&gt;Labels in Ginkgo&#39;s built-in &lt;code&gt;JUnit Report&lt;/code&gt; are not standalone attributes but are appended to the test case title. For example:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Kodo e2e Suite.[It] Test s3 Chunked upload [module=bucket, KODO-18044, unstable, id=c522c, id=be25c]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The section [xxx, yyy, zzz] following the title lists all labels associated with the test case.&lt;/p&gt;&#xA;&lt;h2&gt;Advanced Usage&lt;/h2&gt;&#xA;&lt;h3&gt;Composing Labels&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo&lt;/code&gt; provides the &lt;code&gt;Label()&lt;/code&gt; function to define the &lt;code&gt;Labels&lt;/code&gt; type, with the following relationship:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func Label(labels ...string) Labels {&#xA;&#x9;return Labels(labels)&#xA;}&#xA;&#xA;type Labels = internal.Labels&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;While the default &lt;code&gt;Label()&lt;/code&gt; function works for basic use cases, it lacks flexibility for complex scenarios. For example, when testing a cloud storage product with four regions:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;cn-east-1 (East China)&lt;/li&gt;&#xA;&lt;li&gt;cn-north-1 (North China)&lt;/li&gt;&#xA;&lt;li&gt;cn-northwest-1 (Northwest China)&lt;/li&gt;&#xA;&lt;li&gt;ap-southeast-2 (Southeast Asia)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;You might define labels to indicate which regions a test case can run in:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var ZCnEast1 = Label(&amp;quot;cn-east-1&amp;quot;)&#xA;&#xA;var ZCnNorth1 = Label(&amp;quot;cn-north-1&amp;quot;)&#xA;&#xA;var ZCnNorthWest1 = Label(&amp;quot;cn-northwest-1&amp;quot;)&#xA;&#xA;var ZApSouthEast2 = Label(&amp;quot;ap-southeast-2&amp;quot;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;However, manually adding all 4 labels to each test case can become cumbersome. To address this, you can define a composite label like ZAll to represent &lt;strong&gt;it can be run in all regions&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var ZAll = Label(&amp;quot;cn-east-1&amp;quot;, &amp;quot;cn-north-1&amp;quot;, &amp;quot;cn-northwest-1&amp;quot;, &amp;quot;ap-southeast-2&amp;quot;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;To avoid string-based errors and enhance flexibility, you can create helper functions to combine or modify labels:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func combine(labels ...Labels) Labels {&#xA;&#x9;mapl := make(map[string]bool)&#xA;&#xA;&#x9;for _, ls := range labels {&#xA;&#x9;&#x9;for _, l := range ls {&#xA;&#x9;&#x9;&#x9;mapl[l] = true&#xA;&#x9;&#x9;}&#xA;&#x9;}&#xA;&#xA;&#x9;out := make([]string, 0)&#xA;&#x9;for k := range mapl {&#xA;&#x9;&#x9;out = append(out, k)&#xA;&#x9;}&#xA;&#xA;&#x9;return Label(out...)&#xA;}&#xA;&#xA;// all region&#xA;var ZAll = combine(ZCnEast1, ZCnNorth1, ZCnNorthWest1, ZApSouthEast2)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Similarly, if a test case cannot run in the &lt;code&gt;ap-southeast-2&lt;/code&gt; (Southeast Asia region), you can define a &lt;code&gt;remove(Labels, ...Labels) Labels&lt;/code&gt; function to exclude specific labels:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func remove(all Labels, remove ...Labels) Labels {&#xA;&#x9;labelNeedsDel := make(map[string]bool)&#xA;&#xA;&#x9;for _, labels2 := range remove {&#xA;&#x9;&#x9;for _, l := range labels2 {&#xA;&#x9;&#x9;&#x9;labelNeedsDel[l] = true&#xA;&#x9;&#x9;}&#xA;&#x9;}&#xA;&#xA;&#x9;out := make([]string, 0)&#xA;&#x9;for _, l := range all {&#xA;&#x9;&#x9;if _, ok := labelNeedsDel[l]; !ok {&#xA;&#x9;&#x9;&#x9;out = append(out, l)&#xA;&#x9;&#x9;}&#xA;&#x9;}&#xA;&#xA;&#x9;return Label(out...)&#xA;}&#xA;&#xA;// can only run in China&#xA;var ZChina = remove(ZAll, ZApSouthEast2)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;Automatic Filtering&lt;/h3&gt;&#xA;&lt;h4&gt;Configuration File-Based Filtering&lt;/h4&gt;&#xA;&lt;p&gt;Many applications use configuration files to define environment-specific settings (e.g., production, staging, or local environments). You can automatically apply label filters based on these configurations.&lt;/p&gt;&#xA;&lt;p&gt;Modify the Ginkgo entry function to inject labels dynamically:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func TestE2E(t *testing.T) {  &#xA;    RegisterFailHandler(Fail)  &#xA;&#xA;    // Retrieve current configuration  &#xA;    suiteConfig, reportConfig := GinkgoConfiguration()  &#xA;&#xA;    // Add &amp;quot;product&amp;quot; label filter (combined with existing filters via logical AND)  &#xA;    suiteConfig.LabelFilter = fmt.Sprintf(&amp;quot;(%v) &amp;amp;&amp;amp; (%v)&amp;quot;,  &#xA;        suiteConfig.LabelFilter,  &#xA;        &amp;quot;product&amp;quot;,  &#xA;    )  &#xA;&#xA;    // Run tests with updated configuration  &#xA;    RunSpecs(t, &amp;quot;e2e Suite&amp;quot;, suiteConfig, reportConfig)  &#xA;}  &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Explanation:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;The &lt;code&gt;product&lt;/code&gt; label is automatically added to &lt;code&gt;--label-filter&lt;/code&gt;, ensuring only production-ready test cases run by default.&lt;/li&gt;&#xA;&lt;li&gt;Existing command-line filters (e.g., &lt;code&gt;--label-filter=region=us-east-1&lt;/code&gt;) are preserved via the logical &lt;code&gt;AND&lt;/code&gt; relationship.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4&gt;Manually Filering&lt;/h4&gt;&#xA;&lt;p&gt;Some test cases cannot be fully automated and require manual execution (e.g., UI validation or human-in-the-loop steps). In &lt;code&gt;Ginkgo v1&lt;/code&gt;, these cases had to be manually commented/uncommented by &lt;code&gt;Skip()&lt;/code&gt;. With labels, you can define a &lt;code&gt;manual&lt;/code&gt; label, and exclude it in Ginkgo entry point:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var Manual = Label(&amp;quot;manual&amp;quot;)  &#xA;&#xA;func TestE2E(t *testing.T) {  &#xA;    RegisterFailHandler(Fail)  &#xA;&#xA;    suiteConfig, reportConfig := GinkgoConfiguration()  &#xA;&#xA;    // Automatically exclude manual tests unless explicitly included  &#xA;    if !strings.Contains(suiteConfig.LabelFilter, &amp;quot;manual&amp;quot;) {  &#xA;        suiteConfig.LabelFilter += &amp;quot; &amp;amp;&amp;amp; (!manual)&amp;quot;  &#xA;    }  &#xA;&#xA;    RunSpecs(t, &amp;quot;e2e Suite&amp;quot;, suiteConfig, reportConfig)  &#xA;}  &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Behavior:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Default&lt;/strong&gt;: All tests with the &lt;code&gt;manual&lt;/code&gt; label are skipped (due to &lt;code&gt;!manual&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Override&lt;/strong&gt;: Run manual tests by adding &lt;code&gt;--label-filter=manual&lt;/code&gt; to the command line.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/04/07/ginkgo-label-en-tutorial/" rel="alternate"></link>
    <summary type="html">A Ginkgo label tutorial</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Grafana k6 入门示例</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/03/12/grafana-k6-1/</id>
    <content type="html">&lt;h2&gt;安装&lt;/h2&gt;&#xA;&lt;p&gt;k6 提供了适用于 Linux、Mac 和 Windows 的安装包。此外也可以使用 Docker 容器或独立的二进制文件，甚至是源码安装。&lt;/p&gt;&#xA;&lt;h3&gt;Linux&lt;/h3&gt;&#xA;&lt;p&gt;Debian/Ubuntu&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo gpg -k&#xA;sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69&#xA;echo &amp;quot;deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main&amp;quot; | sudo tee /etc/apt/sources.list.d/k6.list&#xA;sudo apt-get update&#xA;sudo apt-get install k6&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Fedora/Centos&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo dnf install https://dl.k6.io/rpm/repo.rpm&#xA;sudo dnf install k6&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;MacOS&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install k6&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;Windows&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;choco install k6&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;Docker&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker pull grafana/k6&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;二进制安装&lt;/h3&gt;&#xA;&lt;p&gt;可以在 &lt;a href=&#34;https://github.com/grafana/k6/releases&#34;&gt;GitHub Releases&lt;/a&gt; 页面中看到预编译好的二进制文件，将对应系统的 k6 放入 &lt;code&gt;PATH&lt;/code&gt; 目录中即可使用。&lt;/p&gt;&#xA;&lt;h3&gt;源码安装&lt;/h3&gt;&#xA;&lt;p&gt;源码安装其实是我推荐的方式，我们后续扩展 k6 时依赖于此。后续文章将详细介绍，这里按下不表。&lt;/p&gt;&#xA;&lt;h2&gt;写下你的第一个测试脚本&lt;/h2&gt;&#xA;&lt;p&gt;k6 是一款性能测试工具。它能帮助开发者模拟真实的用户行为，并测试系统在这些行为下的表现。通过使用 k6 编写测试脚本，可以在问题（如响应缓慢或系统故障）在生产环境中发生之前，提前发现潜在问题。&lt;/p&gt;&#xA;&lt;p&gt;大家的测试目标各不相同：性能、可靠性或可扩展性。基于此，脚本需要不同的配置，例如模拟大量用户或长时间运行。&lt;/p&gt;&#xA;&lt;p&gt;为了确保 k6 的通用性和灵活性，所有的测试脚本都遵循统一的结构设计。这种一致的结构不仅使脚本易于理解和维护，还能让开发者快速上手，轻松编写出高效的性能测试脚本，它有四个主要模块：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;默认函数：这是测试逻辑的核心部分。它定义了测试的内容以及测试在执行期间的行为。该函数需要在脚本中作为默认函数导出。&lt;/li&gt;&#xA;&lt;li&gt;导入模块：可以导入额外的 k6 模块或 JavaScript 库（jslibs）来扩展脚本的功能，例如发送 HTTP 请求或模拟浏览器交互。&lt;/li&gt;&#xA;&lt;li&gt;选项（这个模块本身也是可选的）：允许配置测试的执行方式，例如定义虚拟用户的数量、测试持续时间或设置性能阈值。&lt;/li&gt;&#xA;&lt;li&gt;生命周期操作（可选）：这些代码可以作为预定义函数或在特定的代码范围内执行，在测试执行的不同阶段运行（例如测试开始前从文件中解析数据或从 Amazon S3 下载文件）。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;现在有这样一个测试场景：向一个 URL 发送 10 次 &lt;code&gt;GET&lt;/code&gt; HTTP 请求，并在每次请求之间等待 1 秒钟。&lt;/p&gt;&#xA;&lt;p&gt;首先创建一个名为 &lt;code&gt;script.js&lt;/code&gt; 的 JavaScript 文件。&lt;/p&gt;&#xA;&lt;p&gt;为了发送 HTTP 请求，导入 &lt;code&gt;k6/http&lt;/code&gt; 模块的 &lt;code&gt;http&lt;/code&gt; 函数，为了模拟每个请求之间的延迟，导入 &lt;code&gt;k6&lt;/code&gt; 模块的 &lt;code&gt;sleep&lt;/code&gt; 函数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;// script.js&#xA;import http from &#39;k6/http&#39;;&#xA;import { sleep } from &#39;k6&#39;;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们不会在脚本中写一个 for 循环发送 10 次，来实现发送 10 次 &lt;code&gt;GET&lt;/code&gt; HTTP 请求。而应该定义一个 &lt;code&gt;options&lt;/code&gt; 代码块，将迭代次数设置为 10，让 k6 来自动控制循环次数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;import { sleep } from &#39;k6&#39;;&#xA;&#xA;export const options = {&#xA;  // 设置测试的迭代次数&#xA;  iterations: 10,&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;默认导出的函数就是测试脚本的入口点。本测试向一个 URL 发起 GET 请求，并在请求之间引入 1 秒的延迟：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;import { sleep } from &#39;k6&#39;;&#xA;&#xA;export const options = {&#xA;  iterations: 10,&#xA;};&#xA;&#xA;export default function () {&#xA;  http.get(&#39;https://www.baidu.com&#39;);&#xA;  sleep(1);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;运行 k6&lt;/h2&gt;&#xA;&lt;p&gt;用以下命令运行上一节的脚本 &lt;code&gt;script.js&lt;/code&gt;，：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ k6 run script.js&#xA;&#xA;&#xA;         /\      Grafana   /‾‾/  &#xA;    /\  /  \     |\  __   /  /   &#xA;   /  \/    \    | |/ /  /   ‾‾\ &#xA;  /          \   |   (  |  (‾)  |&#xA; / __________ \  |_|\_\  \_____/ &#xA;&#xA;     execution: local&#xA;        script: script.js&#xA;        output: -&#xA;&#xA;     scenarios: (100.00%) 1 scenario, 1 max VUs, 10m30s max duration (incl. graceful stop):&#xA;              * default: 10 iterations shared among 1 VUs (maxDuration: 10m0s, gracefulStop: 30s)&#xA;&#xA;&#xA;     data_received..................: 20 kB  1.8 kB/s&#xA;     data_sent......................: 1.5 kB 138 B/s&#xA;     http_req_blocked...............: avg=16.08ms  min=10.45µs med=13.3µs   max=160.72ms p(90)=16.09ms  p(95)=88.4ms  &#xA;     http_req_connecting............: avg=4.42ms   min=0s      med=0s       max=44.22ms  p(90)=4.42ms   p(95)=24.32ms &#xA;     http_req_duration..............: avg=51.54ms  min=43.7ms  med=48.77ms  max=77.04ms  p(90)=57.23ms  p(95)=67.14ms &#xA;       { expected_response:true }...: avg=51.54ms  min=43.7ms  med=48.77ms  max=77.04ms  p(90)=57.23ms  p(95)=67.14ms &#xA;     http_req_failed................: 0.00%  0 out of 10&#xA;     http_req_receiving.............: avg=179.21µs min=82.12µs med=170.89µs max=252.88µs p(90)=227.39µs p(95)=240.13µs&#xA;     http_req_sending...............: avg=55.41µs  min=28.53µs med=40.17µs  max=185.76µs p(90)=83.54µs  p(95)=134.65µs&#xA;     http_req_tls_handshaking.......: avg=10.22ms  min=0s      med=0s       max=102.23ms p(90)=10.22ms  p(95)=56.22ms &#xA;     http_req_waiting...............: avg=51.3ms   min=43.4ms  med=48.56ms  max=76.85ms  p(90)=57.06ms  p(95)=66.95ms &#xA;     http_reqs......................: 10     0.935633/s&#xA;     iteration_duration.............: avg=1.06s    min=1.04s   med=1.04s    max=1.21s    p(90)=1.09s    p(95)=1.15s   &#xA;     iterations.....................: 10     0.935633/s&#xA;     vus............................: 1      min=1       max=1&#xA;     vus_max........................: 1      min=1       max=1&#xA;&#xA;&#xA;running (00m10.7s), 0/1 VUs, 10 complete and 0 interrupted iterations&#xA;default ✓ [======================================] 1 VUs  00m10.7s/10m0s  10/10 shared iters&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们会得到一个聚合过的测试报告，包含各种 http 参数的：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;中位值和平均值&lt;/li&gt;&#xA;&lt;li&gt;最小值和最大值&lt;/li&gt;&#xA;&lt;li&gt;P90、P95 值&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;除了这些统计指标外，我们还注意到，这次测试持续了 10秒，和脚本中的“10 个迭代，每次持续 1秒”能对应上。JMeter 有虚拟用户数（即用户并发数）的概念，在 k6 中等价的是 &lt;code&gt;VUs&lt;/code&gt;，设置 VUs 就是设置并发数量：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ k6 run script.js --vus 10&#xA;&#xA;         /\      Grafana   /‾‾/  &#xA;    /\  /  \     |\  __   /  /   &#xA;   /  \/    \    | |/ /  /   ‾‾\ &#xA;  /          \   |   (  |  (‾)  |&#xA; / __________ \  |_|\_\  \_____/ &#xA;&#xA;     execution: local&#xA;        script: script.js&#xA;        output: -&#xA;&#xA;     scenarios: (100.00%) 1 scenario, 10 max VUs, 10m30s max duration (incl. graceful stop):&#xA;              * default: 10 iterations shared among 10 VUs (maxDuration: 10m0s, gracefulStop: 30s)&#xA;&#xA;...&#xA;&#xA;running (00m01.6s), 00/10 VUs, 10 complete and 0 interrupted iterations&#xA;default ✓ [======================================] 10 VUs  00m01.6s/10m0s  10/10 shared iters&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这次测试报告显示，并发为 10，但只花了 1s 就结束了，这意味着所有并发会共同消耗迭代次数。&lt;/p&gt;&#xA;&lt;p&gt;每次在启动命令中指定 VUs 略有不便，可以将其固化在脚本的选项中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;import { sleep } from &#39;k6&#39;;&#xA;export const options = {&#xA;  vus: 10,&#xA;  iterations: 10,&#xA;};&#xA;export default function () {&#xA;  http.get(&#39;http://test.k6.io&#39;);&#xA;  sleep(1);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;除了用迭代次数间接控制性能测试的时长，还可以直接指定测试时长：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;export const options = {&#xA;  vus: 10,&#xA;  durations: &#39;10s&#39;,&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;你可以通过配置 &lt;code&gt;options.stages&lt;/code&gt; 属性来实现虚拟用户（VUs）数量的动态增减（ramping）。这种功能非常适合模拟真实场景中的用户行为，例如逐步增加负载以测试系统的性能极限，或者在测试结束后逐步减少负载。&lt;/p&gt;&#xA;&lt;p&gt;以下是一个典型的 ramping 配置示例，模拟负载逐步增加、保持峰值、然后逐步减少的过程：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import http from &#39;k6/http&#39;;&#xA;&#xA;export const options = {&#xA;  stages: [&#xA;    // 第一阶段：30 秒内逐步增加到 50 个 VUs&#xA;    { duration: &#39;30s&#39;, target: 50 },&#xA;    // 第二阶段：保持 50 个 VUs 持续运行 1 分钟&#xA;    { duration: &#39;1m&#39;, target: 50 },&#xA;    // 第三阶段：30 秒内逐步减少到 0 个 VUs&#xA;    { duration: &#39;30s&#39;, target: 0 },&#xA;  ],&#xA;};&#xA;&#xA;export default function () {&#xA;  http.get(&#39;https://test.k6.io&#39;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;运行结果为：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;第一阶段：在 30 秒内，虚拟用户数从 0 逐步增加到 50。&lt;/li&gt;&#xA;&lt;li&gt;第二阶段：在 1 分钟内，保持 50 个虚拟用户持续运行。&lt;/li&gt;&#xA;&lt;li&gt;第三阶段：在 30 秒内，虚拟用户数从 50 逐步减少到 0。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;结语&lt;/h2&gt;&#xA;&lt;p&gt;在本文中，我们简要浏览了 k6 的基本功能，并进行了初步尝试。可以发现，k6 使用起来非常简单，对于具备编程能力的开发者来说尤为友好。在接下来的文章中，我们将深入探讨 k6 的各个细节，帮助大家更好地掌握这一强大工具。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/03/12/grafana-k6-1/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>20250307 - 一点绝对真理的想法</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/03/07/diary7/</id>
    <content type="html">&lt;p&gt;曾经我认为数学是这个宇宙绝对的真理，即使换个宇宙也会诞生一模一样的数学。但最近想了下，可能不是这样。&lt;/p&gt;&#xA;&lt;p&gt;什么是数学，它最初的功能是数数，数自然数，伴随着人类社会几千年的发展和数学的三次危机，人类在自然数的基础上逐渐构建了逻辑严密的体系。&lt;/p&gt;&#xA;&lt;p&gt;那假如有一个宇宙，它所有的事物，不管微观宏观，都是概率，没东西可数，那自然就发展不出现在这样以自然数为基础的数学。噢，实际上人类早就发现了“超越数”，它们数不出来，且“数量”比我们的整数多，若那个宇宙是以超越数为基础，那会是一个完全不同的数学体系，和我们完全无法互通。&lt;/p&gt;&#xA;&lt;p&gt;或许从哲学上来讲，数学只不过是人脑意识的游戏，不是绝对真理。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/03/07/diary7/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>20250305 - 一点集体无意识的想法</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/03/05/diary6/</id>
    <content type="html">&lt;p&gt;最近看的书介绍了&lt;strong&gt;集体无意识&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;我们从小培养的思维模式，习惯了机械式地思考世界（至少是现代教育体系下的人类），我们会认为生活中的万事万物是必然具有因果关系的。&lt;/p&gt;&#xA;&lt;p&gt;事情有因才有果，有始才有终，有先才有后。&lt;/p&gt;&#xA;&lt;p&gt;是这样吗？&lt;/p&gt;&#xA;&lt;p&gt;荣格的治疗过程中遇到了很多时间上倒果为因的“巧合”（或许患有精神疾病的人更容易激发出共时性）。而我熟知的拉马努金，他就说过那些奇妙的数学公式是女神纳玛姬莉直接告诉他的，并不是他推导出来的。&lt;/p&gt;&#xA;&lt;p&gt;或许我们也要向内探索，才能窥一窥世界的全貌。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/03/05/diary6/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Grafana k6 是什么</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/02/18/grafana-k6-0/</id>
    <content type="html">&lt;p&gt;Grafana k6 是一款现代的开源性能测试工具。什么样的特性才能叫现代，为什么又要学习一款新的工具？让我们先分析一下传统的性能测试工具：JMeter 和 Locust。&lt;/p&gt;&#xA;&lt;p&gt;JMeter 历史悠久，由 Java 开发，是 Apacahe 软件基金会的一部分。从设计角度来看，它主要面向手工测试人员 - 测试脚本是在 UI 上按模块填写的（对使用者的开发能力要求不高）。它自创了许多概念：元件、监听器、定时器、前置后置处理器等，这使得它的曲线不低，要配置出复杂的测试场景可能有一定难度。即使是纯开发人员面对这些概念也会有一定的挫败感，他们更习惯用代码来组织出复杂的场景。JMeter 有一个无可比拟的优势：社区庞大，你想要测试的协议几乎都能在社区中找到。阿里云、腾讯云的云压测产品，可以直接解析 JMeter 脚本，对于有历史测试脚本沉淀的公司来说非常方便。&lt;/p&gt;&#xA;&lt;p&gt;Locust 则相对年轻。它没有选择自创一套 DSL，而是直接使用 Python 来编写测试脚本，测试、测开、开发都愿意参与其中，可以编写出一定复杂逻辑的测试流程。&lt;/p&gt;&#xA;&lt;p&gt;JMeter 和 Locust 都支持分布式来提高并发量，但各有一些缺点：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;JMeter 因为 JVM 虚拟机和线程实现并发的原因，单机的资源消耗较高。&lt;/li&gt;&#xA;&lt;li&gt;JMeter 是主从架构，添加从节点需要修改主节点配置，水平扩展不便。&lt;/li&gt;&#xA;&lt;li&gt;Locust 使用 Python，同样有单机性能问题。&lt;/li&gt;&#xA;&lt;li&gt;Locust 使用内置的 ZeroMQ 来实现主从架构，水平扩展方便，但内置的消息队列会成为性能瓶颈。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;JMeter 和 Locust 的监控报告都是内置的，满足小团队快速验证，但大企业多是在 Grafana 之类的平台上观测及分析历史数据，需要额外的开发来适配。&lt;/p&gt;&#xA;&lt;p&gt;Grafana k6 是如何解决上面这些不足呢？&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;开发者优先&#xA;&lt;ol&gt;&#xA;&lt;li&gt;使用 JavaScript 作为脚本语言，对开发友好。&lt;/li&gt;&#xA;&lt;li&gt;代码即测试，方便版本控制和持续集成。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;轻量性能高，JavaScript 解释器是由 Go 编写，底层由 goroutine 轻松支持高并发负载。&lt;/li&gt;&#xA;&lt;li&gt;测试场景丰富&#xA;&lt;ol&gt;&#xA;&lt;li&gt;多种复杂负载类型（逐步加压、峰值测试）&lt;/li&gt;&#xA;&lt;li&gt;支持统计响应时间、错误率等指标。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;扩展方便，可以用 JavaScript 和 Go 扩展协议。&lt;/li&gt;&#xA;&lt;li&gt;直接对接 Grafana，通过 Grafana 查看和分析性能数据。&lt;/li&gt;&#xA;&lt;li&gt;云原生友好，通过 k6 operater 直接在 k8s 上水平伸缩。&#xA;&lt;ol&gt;&#xA;&lt;li&gt;非主从架构，因为直接由 Grafana 收集性能数据，不需要主节点来协调和通信。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;还有一个大优势，k6 有 &lt;a href=&#34;https://grafana.com/&#34;&gt;Grafana&lt;/a&gt; 在背后做支持。&lt;/p&gt;&#xA;&lt;p&gt;总的来说，Grafana k6 的核心理念是 “性能测试即代码”，通过现代化的技术栈和开发者友好的设计，填补了传统工具在自动化、云原生集成和易用性上的不足。对于追求敏捷和自动化的团队，k6 是更符合现代软件工程实践的解决方案。&lt;/p&gt;&#xA;&lt;p&gt;下面，就跟着本系列一起，从入门到精通 Grafana k6 吧。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/02/18/grafana-k6-0/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>20250217</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/02/17/diary5/</id>
    <content type="html">&lt;p&gt;从我有限的高中物理知识来看，宏观世界是机械的，可预测的，微观世界是随机的，充满概率的。但是人的意识却是一个随机的东西（我指一个人下一步要做什么，有时候很难预料），这实在是很神奇。&lt;/p&gt;&#xA;&lt;p&gt;假如宇宙重新开始演化，还会诞生一个我，并且意识和现在一样吗？&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/02/17/diary5/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>20250213</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/02/13/diary4/</id>
    <content type="html">&lt;p&gt;我认为 &lt;code&gt;Rust&lt;/code&gt; 并不是一个好的语言，一个奇怪的综合体。&lt;/p&gt;&#xA;&lt;p&gt;抽象 + 约束 + 乱七八糟的目标，会让这个语言最终被撕裂。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/02/13/diary4/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>BitTorrent 协议简单分析</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/02/11/bittorrent-summary/</id>
    <content type="html">&lt;p&gt;大约十年之前，我分析并实现了部分的 &lt;code&gt;DHT&lt;/code&gt; 协议，记录在 &lt;a href=&#34;https://www.lyyyuna.com/2016/03/26/dht01/&#34;&gt;DHT 协议 - 译&lt;/a&gt; 和 &lt;a href=&#34;https://www.lyyyuna.com/2016/05/14/dht-sniffer/&#34;&gt;DHT 公网嗅探器实现（DHT 爬虫）&lt;/a&gt; 中。去年，我看到了 &lt;a href=&#34;https://app.codecrafters.io/courses/bittorrent/overview&#34;&gt;Build your own BitTorrent&lt;/a&gt; 的挑战，就想着也实现一个 torrent 下载器，中间来来回回、断断续续，一直没坚持下来。这次春节我仔细做了实验，比较了几个开源的实现，终于能得出一个初步的结论：要想做一个实用的 torrent 下载器，&lt;a href=&#34;https://app.codecrafters.io/courses/bittorrent/overview&#34;&gt;Build your own BitTorrent&lt;/a&gt; 介绍的远远不够，以我的能力和空闲时间，可能要持续投入一年。&lt;/p&gt;&#xA;&lt;p&gt;首先是几个开源项目的分析：&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Go&lt;/code&gt; 实现的 &lt;a href=&#34;https://github.com/veggiedefender/torrent-client/&#34;&gt;torrent-client&lt;/a&gt;，只实现了 &lt;a href=&#34;https://bittorrent.org/beps/bep_0003.html&#34;&gt;BEP-3&lt;/a&gt;，并且还存在错误的假设 Tracker 都会主动返回 Bitfield 响应。但优点是代码结构还算比较清晰，加上 &lt;code&gt;Go&lt;/code&gt; 的并发比较方便，并发的逻辑不会太干扰主流程的理解。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Python&lt;/code&gt; 实现的 &lt;a href=&#34;https://github.com/eliasson/pieces&#34;&gt;pieces&lt;/a&gt;，也是只实现了 &lt;a href=&#34;https://bittorrent.org/beps/bep_0003.html&#34;&gt;BEP-3&lt;/a&gt;，协议交互上没太大问题。问题主要是源码实现有点绕，在块下载管理器和底层协议上代码混在了一起，没有做好分层。这么实现固然能在当时的 &lt;code&gt;asyncio&lt;/code&gt; 框架上做到比较高效，但我怀疑之后会非常难以扩展其他 BEP 协议？&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Elixir&lt;/code&gt; 实现的 &lt;a href=&#34;https://github.com/ryotsu/torrex&#34;&gt;torrex&lt;/a&gt;，和上面两个差不多。&lt;/p&gt;&#xA;&lt;p&gt;总的来说，这几个项目，都不实用：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;只实现了 &lt;a href=&#34;https://bittorrent.org/beps/bep_0003.html&#34;&gt;BEP-3&lt;/a&gt; ，用这个协议能找到的 peers 很有限，下载速度提升不上去。&lt;/li&gt;&#xA;&lt;li&gt;没有考虑多文件的情况。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;以上只是我的抱怨，或许我该去参考参考较完善的开源项目:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cenkalti/rain/tree/master/torrent&#34;&gt;rain&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/anacrolix/torrent&#34;&gt;torrent&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/jackpal/Taipei-Torrent&#34;&gt;Taipei-Torrent&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;不过我会尽量先用 &lt;code&gt;Python&lt;/code&gt; 实现。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/02/11/bittorrent-summary/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>20250211</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/02/11/diary3/</id>
    <content type="html">&lt;p&gt;会有灵魂吗？&lt;/p&gt;&#xA;&lt;p&gt;一个人的自我意识会受制于物理世界？比如长期生病，他的性格或多或少会受到影响。比如长得漂亮，他应该会非常自信。&lt;/p&gt;&#xA;&lt;p&gt;假如灵魂脱离肉体，那这个灵魂会是生前的那种心理状态吗？没有了肉体，感觉会是个完全不一样的人。那还能期待再与逝去的人相遇吗？&lt;/p&gt;&#xA;&lt;p&gt;又或者，灵魂的意识是肉体状态的延续，那这样的话，没有生前内心的锤炼，身后的灵魂会失去归宿。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/02/11/diary3/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>20250205</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/02/05/diary2/</id>
    <content type="html">&lt;p&gt;昔人已乘黄鹤去，此地空余黄鹤楼。&lt;/p&gt;&#xA;&lt;p&gt;黄鹤一去不复返，白云千载空悠悠。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/02/05/diary2/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>20250124</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/01/24/diary1/</id>
    <content type="html">&lt;p&gt;练得身形似鹤形，千株松下两函经。&lt;/p&gt;&#xA;&lt;p&gt;我来问道无余说，云在青天水在瓶。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/01/24/diary1/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>20250123</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/01/23/diary0/</id>
    <content type="html">&lt;p&gt;人与人的交流是靠文字、语言，甚至我们的思考也受影响。我回忆我以前面对问题的过程，好像是在心里与自己对话。按理说，人脑运算速度极快，我们其实能以更快的速度思考？&lt;/p&gt;&#xA;&lt;p&gt;这样的沟通交流不免在人与人之间形成一道天然的屏障。我想起以前与朋友的交流，肯定是多多少少传递了错误的本意，语言无法百分百的传递我的想法。&lt;/p&gt;&#xA;&lt;p&gt;那这是我们人类的缺陷吗？可能未必。屏障维护了自身个体的独立性。如果我们像三体人一样，自身的想法情绪能够直接传入别人的大脑，那在我难过、愤怒的时候，别人是无法抵御住这些的，最后或许整个社会会统一成一个抽象的个体，像蚁群一样。&lt;/p&gt;&#xA;&lt;p&gt;现在社会，短视频这种直接传递想法的媒介越来越普遍，《攻壳机动队》中“stand alone complex - 在群体中独立出来的灵魂”迟早要到来。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/01/23/diary0/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>大侦探波洛读后感 - 斯泰尔斯庄园奇案</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/01/20/hercule-poirot-1/</id>
    <content type="html">&lt;p&gt;黑斯廷斯，因病从前线返乡，回到了幼时待过的斯泰尔斯庄园，结果-_-，庄园老主人艾米丽·英格尔索普被毒杀，就此拉开了精彩的大侦探波洛的破案之旅。&lt;/p&gt;&#xA;&lt;p&gt;背景是一战，查了查数据，英国的伤亡人数在百万以上，不过故事中战争的氛围不是很浓烈。阿婆一战时在医院做过志愿者，估计因此累积了丰富的毒药经验：）此案凶手就巧妙地使用了延迟毒杀的方法，成功为自己制造了不在场证明。比利时夹在法国和德国中间，和法国关系紧密，是一战重要的战场，波洛被波及，避难到英国也很符合历史。&lt;/p&gt;&#xA;&lt;p&gt;我第一遍读小说时，感到略微不协调的点，就是霍华德小姐对阿尔弗雷德过于激动和反理智的举动。霍华德小姐是个 40 岁左右的老管家，又能在离职后迅速应聘上护士，可见其有着冷静职业的头脑，这么反常，心理学上说不通。果然后面就是凶手之一。&lt;/p&gt;&#xA;&lt;p&gt;另外一个有趣的是阿婆详细描写了欧洲那块的司法流程：验尸、聆讯、陪审团、起诉、审判等等，对现在的中国人来说，这也是一个新奇的体验。我感叹欧美法治社会源远流长，不过也嘀咕，面对这种奇案，欧美司法也是束手无策，只是把流程做的漂亮，好像没啥用。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/01/20/hercule-poirot-1/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>大侦探波洛读后感 - 序</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2025/01/09/hercule-poirot-0/</id>
    <content type="html">&lt;p&gt;为读后感写个序-_-&lt;/p&gt;&#xA;&lt;p&gt;波洛的知名度没有福尔摩斯高，但却更吸引我。福尔摩斯像是一个侠客，他的探案是侠客之旅，而波洛的探案则是让我看到了那个百年前的社会。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2025/01/09/hercule-poirot-0/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Ginkgo 并发测试教程</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2023/12/29/ginkgo-concurrency-test/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo CLI&lt;/code&gt; 加上 &lt;code&gt;--nodes xxx&lt;/code&gt; 或 &lt;code&gt;--procs yyy&lt;/code&gt; 参数后，就能让原本顺序执行的测试用例变成并发执行。&lt;/p&gt;&#xA;&lt;p&gt;但好奇的你，可能会有如下问题：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;集测并发的顺序是固定的还是随机的？&lt;/li&gt;&#xA;&lt;li&gt;集测之间的共享变量会有并发安全问题吗？&lt;/li&gt;&#xA;&lt;li&gt;有一些需要独占资源的测试用例，如何在并发中控制它们的顺序？&lt;/li&gt;&#xA;&lt;li&gt;xxx&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;下面，我们就来一一解答。&lt;/p&gt;&#xA;&lt;p&gt;P.S. 本文基于 &lt;code&gt;Ginkgo v2.13.2&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h2&gt;并发模型&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo&lt;/code&gt; 是 &lt;code&gt;Go&lt;/code&gt; 语言编写的集测框架，还兼容 &lt;code&gt;go test&lt;/code&gt;，不免想当然认为，&lt;code&gt;Ginkgo&lt;/code&gt; 是基于 goroutine 实现的多并发。但是恰恰相反，经过&lt;a href=&#34;/2022/05/12/inside-the-ginkgo/&#34;&gt;Ginkgo 测试框架实现解析&lt;/a&gt;的分析，&lt;code&gt;Ginkgo&lt;/code&gt; 其实是多进程模型，每个进程会使用&lt;strong&gt;相同的随机数种子&lt;/strong&gt;打乱用例，得到次序一致的随机序列。&lt;/p&gt;&#xA;&lt;p&gt;这样，&lt;code&gt;Ginkgo&lt;/code&gt; 就实现了：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;每次运行用例顺序随机。&lt;/li&gt;&#xA;&lt;li&gt;借助进程得到并发隔离。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;那么，单个进程内共享变量是安全的吗？看下面这个例子：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;Context(&amp;quot;test&amp;quot;, Id(&amp;quot;27838&amp;quot;), func() {&#xA;    var global int&#xA;&#xA;    It(&amp;quot;a&amp;quot;, func() {&#xA;        global++&#xA;        fmt.Println(&amp;quot;a&amp;quot;, global)&#xA;    })&#xA;&#xA;    It(&amp;quot;b&amp;quot;, func() {&#xA;        global++&#xA;        fmt.Println(&amp;quot;b&amp;quot;, global)&#xA;    })&#xA;&#xA;    It(&amp;quot;c&amp;quot;, func() {&#xA;        global++&#xA;        fmt.Println(&amp;quot;c&amp;quot;, global)&#xA;    })&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;假设并发 1，实际结果为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;a 1&#xA;b 2&#xA;c 3&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;假设并发 2，实际结果为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;a 1&#xA;b 1&#xA;c 2&#xA;&#xA;或&#xA;&#xA;a 1&#xA;b 2&#xA;c 1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;假设并发 3，实际结果为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;a 1&#xA;b 1&#xA;c 1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;两个用例如果被分配在同一个进程中，去访问同一个变量，就会互相干扰，应使用 &lt;code&gt;BeforeEach&lt;/code&gt; 对变量显式初始化：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;Context(&amp;quot;test&amp;quot;, Id(&amp;quot;27838&amp;quot;), func() {&#xA;    var global int&#xA;&#xA;    BeforeEach(func() {&#xA;        global = 0&#xA;    })&#xA;&#xA;    It(&amp;quot;a&amp;quot;, func() {&#xA;        global++&#xA;    ....&#xA;    })&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;BeforeEach&lt;/code&gt; 会互相干扰吗？&lt;strong&gt;不会&lt;/strong&gt;，同一个进程中同一个时刻只会有一个测试用例在运行。&lt;/p&gt;&#xA;&lt;h2&gt;并发集测的初始化&lt;/h2&gt;&#xA;&lt;p&gt;多进程不像 goroutine 那样容易实现并发同步，这给那些只需要做一遍的集测初始化步骤带来了挑战（比如，在集测开始之前，往数据库中导入测试数据）。&lt;/p&gt;&#xA;&lt;p&gt;为此，&lt;code&gt;Ginkgo&lt;/code&gt; 提供了以下的解决方案：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// 集测并发开始前执行&#xA;func SynchronizedBeforeSuite(&#xA;    process1 func() []byte,&#xA;    allProcesses func([]byte),&#xA;)&#xA;&#xA;// 集测并发结束后执行&#xA;func SynchronizedAfterSuite(&#xA;    allProcesses func(),&#xA;    process1 func(),&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;SynchronizedBeforeSuite&lt;/code&gt; 有两个参数：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;其中 &lt;code&gt;process1&lt;/code&gt; 只在第 1 个进程内运行，&lt;code&gt;allProcesses&lt;/code&gt; 会在所有进程内运行。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;process1&lt;/code&gt; 运行结束后才会运行 &lt;code&gt;allProcesses&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;process1&lt;/code&gt; 的返回值会作为参数传递给 &lt;code&gt;allProcesses&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;举个例子，有一个云存储上传测试场景，并发为 5，需要在测试前创建存储空间，空间名用 &lt;code&gt;bucketid&lt;/code&gt; 来标识，在 &lt;code&gt;Ginkgo&lt;/code&gt; 中可以这么做：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// 全局变量存储空间名&#xA;var bucketId string&#xA;&#xA;func SynchronizedBeforeSuite(&#xA;    // process1&#xA;    func() []byte {&#xA;        // 创建存储空间，得到空间名&#xA;        id := CreateBucket()&#xA;        // 向后传递空间名&#xA;        return []byte(id)&#xA;    },&#xA;    // allProcesses&#xA;    func(rId []byte) {&#xA;        // 得到空间名&#xA;        bucketId = string(rId)&#xA;    },&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;process1&lt;/code&gt; 负责创建该存储空间，将空间名以字节形式传递给其他并发进程。&lt;/li&gt;&#xA;&lt;li&gt;其他并发进程将收到的字节转化为字符串，再赋值给全局变量 &lt;code&gt;bucketId&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;集测并发开始后，全局变量 &lt;code&gt;bucketId&lt;/code&gt; 就拿到了初始化后的空间名。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;一定要&lt;strong&gt;注意&lt;/strong&gt;，这里 &lt;code&gt;process1&lt;/code&gt; 和 &lt;code&gt;allProcesses&lt;/code&gt; 虽然写在一起，但其实是在&lt;strong&gt;不同阶段&lt;/strong&gt;和&lt;strong&gt;不同进程&lt;/strong&gt;内执行的，不能认为它们能够共享全局变量。同时，初始化进程和并发进程之间只能传递字节数据，不能直接传递变量对象（受限于进程间通信），如果要传递复杂的对象，可以使用 &lt;code&gt;json&lt;/code&gt; 做序列化反序列化。下面的例子中，&lt;code&gt;info&lt;/code&gt; 变量在每个并发进程内都拿到了初始化后的空间名和用户名：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type testinfo struct {&#xA;    bucketId string `json:&amp;quot;bucket_id&amp;quot;`&#xA;    userId string `json:&amp;quot;user_id&amp;quot;`&#xA;}&#xA;&#xA;// 全局变量&#xA;var info testinfo&#xA;&#xA;func SynchronizedBeforeSuite(&#xA;    // process1&#xA;    func() []byte {&#xA;        info := SetupTestInfo()&#xA;        // 序列化&#xA;        data, _  := json.Marshal(&amp;amp;info)&#xA;        return data&#xA;    },&#xA;    // allProcesses&#xA;    func(data []byte) {&#xA;        // 反序列化&#xA;        json.Unmarshal(data, &amp;amp;info)&#xA;    },&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;SynchronizedAfterSuite&lt;/code&gt; 的工作原理类似，不再赘述。&lt;/p&gt;&#xA;&lt;p&gt;从我个人角度来看，&lt;code&gt;Ginkgo&lt;/code&gt; 这种机制并不直观，幸好集测初始化一般是由团队中的测试架构者来设计，能够避免初学者误用。&lt;/p&gt;&#xA;&lt;h2&gt;控制并发中的顺序&lt;/h2&gt;&#xA;&lt;h3&gt;排它执行&lt;/h3&gt;&#xA;&lt;p&gt;有一些测试，运行的时候不能有其他测试的干扰，例如：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;某个接口的性能测试。&lt;/li&gt;&#xA;&lt;li&gt;测试独占资源。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo&lt;/code&gt; 提供了 &lt;code&gt;Serial&lt;/code&gt; 装饰器：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;Describe(&amp;quot;空间&amp;quot;, Serial, func() {&#xA;    It(&amp;quot;创建空间性能测试&amp;quot;, func() {&#xA;        ...&#xA;    })&#xA;&#xA;    It(&amp;quot;测试空间 id 是否单调递增&amp;quot;, func() {&#xA;        ...&#xA;    })&#xA;&#xA;    It(&amp;quot;修改空间为私有&amp;quot;, func() {&#xA;        ...&#xA;    })&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo&lt;/code&gt; 会等待所有并发用例结束后，在第一个进程内运行 &lt;code&gt;Serial&lt;/code&gt; 用例。&lt;/p&gt;&#xA;&lt;h3&gt;顺序执行&lt;/h3&gt;&#xA;&lt;p&gt;假设如下场景需要按顺序执行：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;创建一个存储空间。&lt;/li&gt;&#xA;&lt;li&gt;先测试上传文件。&lt;/li&gt;&#xA;&lt;li&gt;然后测试下载文件，下载的文件可以使用步骤 2 中成功上传的文件。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;用例 3 必须等待用例 2 执行完毕。&#xA;（你可能会觉得上述的三个用例可以合并为单个用例中的三个步骤，这里只是为了演示，面对复杂的多场景测试，最好还是拆分成多个用例）&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo&lt;/code&gt; 提供了 &lt;code&gt;Ordered&lt;/code&gt; 装饰器：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;Describe(&amp;quot;空间&amp;quot;, Ordered, func() {&#xA;    It(&amp;quot;创建空间&amp;quot;, func() {&#xA;        ...&#xA;    })&#xA;&#xA;    It(&amp;quot;上传文件&amp;quot;, func() {&#xA;        ...&#xA;    })&#xA;&#xA;    It(&amp;quot;下载文件&amp;quot;, func() {&#xA;        ...&#xA;    })&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo&lt;/code&gt; 会保证同一个 &lt;code&gt;Ordered&lt;/code&gt; 容器内的测试用例按顺序执行。和 &lt;code&gt;Serial&lt;/code&gt; 不一样，&lt;code&gt;Ordered&lt;/code&gt; 容器内外的用例会并发执行，并且可以放在任意一个并发进程内，不会局限在第一个进程。&lt;/p&gt;&#xA;&lt;h4&gt;一次性初始化&lt;/h4&gt;&#xA;&lt;p&gt;原本的初始化 &lt;code&gt;BeforeEach&lt;/code&gt; 节点在 &lt;code&gt;Ordered&lt;/code&gt; 容器内仍然有效，含义不变：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;Describe(&amp;quot;空间&amp;quot;, func() {&#xA;    BeforeEach(func() {&#xA;        fmt.Println(&amp;quot;a&amp;quot;)&#xA;    })&#xA;&#xA;    Context(&amp;quot;&amp;quot;, Ordered, func() {&#xA;        BeforeEach(func() {&#xA;            fmt.Println(&amp;quot;b&amp;quot;)&#xA;        })&#xA;&#xA;        It(&amp;quot;创建空间&amp;quot;, func() {&#xA;            // 执行 BeforeEach a&#xA;            // 执行 BeforeEach b&#xA;        })&#xA;&#xA;        It(&amp;quot;上传文件&amp;quot;, func() {&#xA;            // 执行 BeforeEach a&#xA;            // 执行 BeforeEach b&#xA;        })&#xA;&#xA;        It(&amp;quot;下载文件&amp;quot;, func() {&#xA;            // 执行 BeforeEach a&#xA;            // 执行 BeforeEach b&#xA;        })&#xA;    })&#xA;&#xA;    It(&amp;quot;列举文件&amp;quot;, func () {&#xA;        // 只执行 BeforeEach a&#xA;    })&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果 &lt;code&gt;Ordered&lt;/code&gt; 内的用例，只想执行一次初始化该怎么做呢？对于 &lt;code&gt;Ordered&lt;/code&gt; 容器&lt;strong&gt;外&lt;/strong&gt;初始化，&lt;code&gt;Ginkgo&lt;/code&gt; 提供了 &lt;code&gt;OncePerOrdered&lt;/code&gt; 装饰器：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;Describe(&amp;quot;空间&amp;quot;, func() {&#xA;    BeforeEach(OncePerOrdered, func() {&#xA;        fmt.Println(&amp;quot;a&amp;quot;)&#xA;    })&#xA;&#xA;    Context(&amp;quot;&amp;quot;, Ordered, func() {&#xA;        // 只执行一次 BeforeEach a&#xA;        BeforeEach(func() {&#xA;            fmt.Println(&amp;quot;b&amp;quot;)&#xA;        })&#xA;&#xA;        It(&amp;quot;创建空间&amp;quot;, func() {&#xA;            // 执行 BeforeEach b&#xA;        })&#xA;&#xA;        It(&amp;quot;上传文件&amp;quot;, func() {&#xA;            // 执行 BeforeEach b&#xA;        })&#xA;&#xA;        It(&amp;quot;下载文件&amp;quot;, func() {&#xA;            // 执行 BeforeEach b&#xA;        })&#xA;    })&#xA;&#xA;    It(&amp;quot;列举文件&amp;quot;, func () {&#xA;        // 只执行 BeforeEach a&#xA;    })&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;对于 &lt;code&gt;Ordered&lt;/code&gt; 容器&lt;strong&gt;内&lt;/strong&gt;初始化，&lt;code&gt;Ginkgo&lt;/code&gt; 提供了 &lt;code&gt;BeforeAll&lt;/code&gt; 和 &lt;code&gt;AfterAll&lt;/code&gt; 节点来替换 &lt;code&gt;BeforeEach&lt;/code&gt; 和 &lt;code&gt;AfterEach&lt;/code&gt; 节点：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;Describe(&amp;quot;空间&amp;quot;, func() {&#xA;    // a&#xA;    BeforeEach(OncePerOrdered, func() {&#xA;        fmt.Println(&amp;quot;a&amp;quot;)&#xA;    })&#xA;&#xA;    Context(&amp;quot;&amp;quot;, Ordered, func() {&#xA;        // 只执行一次 BeforeEach a&#xA;        // 只执行一次 BeforeEach b&#xA;        BeforeAll(func() {&#xA;            fmt.Println(&amp;quot;b&amp;quot;)&#xA;        })&#xA;&#xA;        It(&amp;quot;创建空间&amp;quot;, func() {&#xA;        })&#xA;&#xA;        It(&amp;quot;上传文件&amp;quot;, func() {&#xA;        })&#xA;&#xA;        It(&amp;quot;下载文件&amp;quot;, func() {&#xA;        })&#xA;    })&#xA;&#xA;    It(&amp;quot;列举文件&amp;quot;, func () {&#xA;        // 只执行 BeforeEach a&#xA;    })&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这样，&lt;code&gt;Ordered&lt;/code&gt; 容器内的三个创建空间、上传文件、下载文件用例只会初始化一次 a 和 b，而 &lt;code&gt;Ordered&lt;/code&gt; 容器外的列举文件用例，仍然会执行初始化 a。&lt;/p&gt;&#xA;&lt;h4&gt;错误机制&lt;/h4&gt;&#xA;&lt;p&gt;默认情况下 &lt;code&gt;Ordered&lt;/code&gt; 容器内的用例只要出错，剩下的用例便会跳过，直接执行 &lt;code&gt;AfterAll&lt;/code&gt; 节点做清理工作，在测试报告中，这些未执行的用例也会显示成 &lt;code&gt;Skip&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;如果 &lt;code&gt;Ordered&lt;/code&gt; 容器内的用例并没有依赖关系，只是单纯组合在一起，那这种默认行为就不合适了，你可以使用 &lt;code&gt;ContinueOnFailure&lt;/code&gt; 装饰器修改成继续执行剩余用例。&lt;/p&gt;&#xA;&lt;h4&gt;重试机制&lt;/h4&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo run --flake-attempts [int]&lt;/code&gt; 命令可将集测设置成重试模式。对于 &lt;code&gt;Ordered&lt;/code&gt; 容器内的用例，重试不包括 &lt;code&gt;BeforeAll&lt;/code&gt; 和 &lt;code&gt;AfterAll&lt;/code&gt; 内的步骤。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2023/12/29/ginkgo-concurrency-test/" rel="alternate"></link>
    <summary type="html">如何正确编写并发测试用例？</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Ginkgo Label 标签的使用教程</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2023/12/24/ginkgo-label-tutorial/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;很多测试框架都提供了对测试用例分组的能力，比如 &lt;code&gt;pytest&lt;/code&gt; 中的 &lt;code&gt;mark&lt;/code&gt;，&lt;code&gt;Robot Framework&lt;/code&gt; 中的 &lt;code&gt;tag&lt;/code&gt;，&lt;code&gt;TestNG&lt;/code&gt; 中的 &lt;code&gt;groups&lt;/code&gt; 等等。&lt;/p&gt;&#xA;&lt;p&gt;在 &lt;code&gt;Ginkgo v1&lt;/code&gt; 中，并没有类似的功能，在七牛，我们不得不将&lt;strong&gt;标签&lt;/strong&gt;嵌入在字符串标题中，配合 &lt;code&gt;--focus&lt;/code&gt; 来过滤用例。但基于字符串的实现并不完美，很容易出现冲突、重复，更不能提供类型安全，导致在海量集测用例面前，&lt;code&gt;Ginkgo v1&lt;/code&gt; 用起来总感觉力不从心。&lt;/p&gt;&#xA;&lt;p&gt;到了 &lt;code&gt;Ginkgo v2&lt;/code&gt;，官方终于给出了 &lt;code&gt;Label&lt;/code&gt; 这个解决方案，下面，我们来看看它都有哪些使用方法。&lt;/p&gt;&#xA;&lt;p&gt;P.S. 本文基于 &lt;code&gt;Ginkgo v2.13.2&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h2&gt;基础使用方法&lt;/h2&gt;&#xA;&lt;h3&gt;给用例添加标签&lt;/h3&gt;&#xA;&lt;p&gt;标签用 &lt;code&gt;Label&lt;/code&gt; 装饰器定义，并且可以定义在任意一种节点之上，例如：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;Describe(&amp;quot;上传&amp;quot;, Label(&amp;quot;integration&amp;quot;, &amp;quot;storage&amp;quot;), func() {&#xA;    It(&amp;quot;表单上传&amp;quot;, Label(&amp;quot;network&amp;quot;, &amp;quot;slow&amp;quot;, &amp;quot;library storage&amp;quot;), func() {&#xA;        // 最终获得的标签 [integration, storage, network, slow, library storage]&#xA;    })&#xA;&#xA;    Context(&amp;quot;分片上传&amp;quot;, Label(&amp;quot;network&amp;quot;, &amp;quot;library storage&amp;quot;), func() {&#xA;        It(&amp;quot;1 个分片&amp;quot;, Label(&amp;quot;slow&amp;quot;) func() {&#xA;            // 最终获得的标签 [integration, storage, network, slow, library storage]&#xA;        })&#xA;&#xA;        It(&amp;quot;2 个分片&amp;quot;, Label(&amp;quot;quick&amp;quot;, &amp;quot;storage&amp;quot;) func() {&#xA;            // 最终获得的标签 [integration, storage, network, quick, library storage]&#xA;        })&#xA;    })&#xA;&#xA;    DescribeTable(&amp;quot;s3 协议&amp;quot;, Label(&amp;quot;quick&amp;quot;), func(count int) {&#xA;        &#xA;    },&#xA;        Entry(&amp;quot;put 上传&amp;quot;, Label(&amp;quot;local&amp;quot;), 17), // 最终获得的标签 [integration, storage, quick, local]&#xA;        Entry(&amp;quot;拷贝上传&amp;quot;, 20), // 最终获得的标签 [integration, storage, quick]&#xA;    )&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;总结一下：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;标签本质是一个字符串。&lt;/li&gt;&#xA;&lt;li&gt;子节点会继承父节点定义的标签，即 &lt;code&gt;It&lt;/code&gt; 会继承 &lt;code&gt;Context&lt;/code&gt; 和 &lt;code&gt;Describe&lt;/code&gt; 上的标签。&lt;/li&gt;&#xA;&lt;li&gt;标签会自动去重，子节点不用担心标签重复。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Entry&lt;/code&gt; 上也可以定义标签，不会被当作参数。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3&gt;过滤&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo&lt;/code&gt; 已经有很多过滤用例的方法：首先是 &lt;code&gt;--focus-file&lt;/code&gt; 和 &lt;code&gt;--skip-file&lt;/code&gt;，可以根据文件名和行号来过滤用例；然后是 &lt;code&gt;--focus&lt;/code&gt; 和 &lt;code&gt;--skip&lt;/code&gt;，可以根据用例的标题来过滤用例。这两个都支持正则表达式。但用例分类并不一定会集中于特定的目录中，比如为测试环境和线上环境各自编写的用例，这些用例会分散在各个目录、各个文件、各种用例中。而且，正则表达式并不直观，如果基于标题写正则表达式，恐怕这个命令行会非常&lt;strong&gt;糟糕&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;而标签真正的威力，就在于其更易用的过滤语法。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo&lt;/code&gt; 使用 &lt;code&gt;--label-filter=QUERY&lt;/code&gt; 可以传入基于标签的查询语句，其规则规则一目了然：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;标签1 &amp;amp;&amp;amp; 标签2&lt;/code&gt; ，用例同时含有两个标签，即符合条件。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;标签1 || 标签2&lt;/code&gt;，用例只需拥有一个标签，即符合条件。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;!标签1&lt;/code&gt;，有标签1的用例不符合条件。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;,&lt;/code&gt; 的逻辑和 &lt;code&gt;||&lt;/code&gt; 相同。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;()&lt;/code&gt; 可以用来组合表达式。例如 &lt;code&gt;标签1 &amp;amp;&amp;amp; (标签2 || 标签3)&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;标签是大小写敏感的。&lt;/li&gt;&#xA;&lt;li&gt;标签前后的空白会自动去除。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;举例来说，我们正在测试一个云存储产品，我们有以下 4 个测试用例，分别是：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;用例1: product, local, cn-east-1, slow&lt;/li&gt;&#xA;&lt;li&gt;用例2: local, cn-east-1, ap-southeast-1&lt;/li&gt;&#xA;&lt;li&gt;用例3: local, ap-southeast-1&lt;/li&gt;&#xA;&lt;li&gt;用例4: product, slow&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;其中&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;product 代表用例能在线上跑，local 代表用例能在测试环境跑。&lt;/li&gt;&#xA;&lt;li&gt;cn-east-1 代表用例能在华东区域跑，ap-southeast-1 代表用例能在东南亚区域跑。&lt;/li&gt;&#xA;&lt;li&gt;slow 代表用例运行时间较长。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;如果使用以下过滤语句：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;product&lt;/code&gt;，即挑选所有能在线上跑的用例，那用例1和用例4会执行。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;!local&lt;/code&gt;，即挑选所有不能在测试环境跑的用例，那只有用例4会执行。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;product &amp;amp;&amp;amp; cn-east-1&lt;/code&gt;，即挑选线上华东区域的所有用例，那只有用例1会执行。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;cn-east-1 || ap-south-east-1&lt;/code&gt;，即挑选能同时在华东和东南亚区域运行的用例，那用例1、2、3会执行。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;!slow&lt;/code&gt;，即排除时间过长的用例，那用例2、3会执行。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;可以发现，新的过滤语法更为直观，使用者能快速组合出想要的用例。（如果上述过滤语法仍不满足要求，可以用 &lt;code&gt;/REGEXP/&lt;/code&gt; 来使用正则表达式）&lt;/p&gt;&#xA;&lt;h3&gt;组合使用&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo v2&lt;/code&gt; 并没有删去 &lt;code&gt;Ginkgo v1&lt;/code&gt; 已有的过滤功能，而是可以组合使用：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果用例被标记为 &lt;code&gt;Pending&lt;/code&gt;，那无论如何都不会运行。&lt;/li&gt;&#xA;&lt;li&gt;如果用例中调用了 &lt;code&gt;Skip()&lt;/code&gt; 函数，即使命中了过滤语句，仍然会被忽略。&lt;/li&gt;&#xA;&lt;li&gt;如果用例被标记为 &lt;code&gt;Focus&lt;/code&gt;，那只会运行该用例。&lt;/li&gt;&#xA;&lt;li&gt;如果命令行同时有 &lt;code&gt;--label-filter&lt;/code&gt;, &lt;code&gt;--focus-file/--skip-file&lt;/code&gt;, &lt;code&gt;--focus/--skip&lt;/code&gt;，那最终用例必须同时符合这些条件。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3&gt;测试报告&lt;/h3&gt;&#xA;&lt;p&gt;标签在官方自带的 &lt;code&gt;JUnit Report&lt;/code&gt; 报告中，不是一个单独的属性，而是附在标题中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Kodo e2e Suite.[It] 测试 s3 分片上传 [module=bucket, KODO-18044, unstable, id=c522c, id=be25c]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;后面 &lt;code&gt;[xxx, yyy, zzz]&lt;/code&gt; 便是该用例所有的标签。&lt;/p&gt;&#xA;&lt;h2&gt;高级使用&lt;/h2&gt;&#xA;&lt;h3&gt;组合标签&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo&lt;/code&gt; 提供了 &lt;code&gt;Label()&lt;/code&gt; 函数来定义标签类型 &lt;code&gt;Labels&lt;/code&gt;，它们的关系如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func Label(labels ...string) Labels {&#xA;&#x9;return Labels(labels)&#xA;}&#xA;&#xA;type Labels = internal.Labels&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;默认的 &lt;code&gt;Label()&lt;/code&gt; 函数在面对多标签时并不灵活，举个例子，假设我们测试云存储产品，它有 4 个存储区域：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;cn-east-1&lt;/code&gt; 华东&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;cn-north-1&lt;/code&gt; 华北&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;cn-northwest-1&lt;/code&gt; 西北&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;ap-southeast-2&lt;/code&gt; 东南亚&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;我们可能会定义以下四个标签来标注用例是否可以在对应区域运行：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var ZCnEast1 = Label(&amp;quot;cn-east-1&amp;quot;)&#xA;&#xA;var ZCnNorth1 = Label(&amp;quot;cn-north-1&amp;quot;)&#xA;&#xA;var ZCnNorthWest1 = Label(&amp;quot;cn-northwest-1&amp;quot;)&#xA;&#xA;var ZApSouthEast2 = Label(&amp;quot;ap-southeast-2&amp;quot;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;但若每个用例都要标注4个标签，写起来比较繁琐，你可能会定义一个全区域标签来表示该用例可以在任意区域运行：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var ZAll = Label(&amp;quot;cn-east-1&amp;quot;, &amp;quot;cn-north-1&amp;quot;, &amp;quot;cn-northwest-1&amp;quot;, &amp;quot;ap-southeast-2&amp;quot;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;直接使用字符串会有类型安全问题，所以可以定义一个辅助函数来组合已有标签。&lt;/p&gt;&#xA;&lt;p&gt;因为标签本质是 &lt;code&gt;Labels&lt;/code&gt; 类型，只要定义一个 &lt;code&gt;combine([]Labels) Labels&lt;/code&gt; 的函数即可：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func combine(labels ...Labels) Labels {&#xA;&#x9;mapl := make(map[string]bool)&#xA;&#xA;&#x9;for _, ls := range labels {&#xA;&#x9;&#x9;for _, l := range ls {&#xA;&#x9;&#x9;&#x9;mapl[l] = true&#xA;&#x9;&#x9;}&#xA;&#x9;}&#xA;&#xA;&#x9;out := make([]string, 0)&#xA;&#x9;for k := range mapl {&#xA;&#x9;&#x9;out = append(out, k)&#xA;&#x9;}&#xA;&#xA;&#x9;return Label(out...)&#xA;}&#xA;&#xA;// 全球运行&#xA;var ZAll = combine(ZCnEast1, ZCnNorth1, ZCnNorthWest1, ZApSouthEast2)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;同理，如果一个用例只是在 &lt;code&gt;ap-southeast-2&lt;/code&gt; 东南亚无法运行，可以定义一个 &lt;code&gt;remove(Labels, ...Labels) Labels&lt;/code&gt; 的函数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func remove(all Labels, remove ...Labels) Labels {&#xA;&#x9;labelNeedsDel := make(map[string]bool)&#xA;&#xA;&#x9;for _, labels2 := range remove {&#xA;&#x9;&#x9;for _, l := range labels2 {&#xA;&#x9;&#x9;&#x9;labelNeedsDel[l] = true&#xA;&#x9;&#x9;}&#xA;&#x9;}&#xA;&#xA;&#x9;out := make([]string, 0)&#xA;&#x9;for _, l := range all {&#xA;&#x9;&#x9;if _, ok := labelNeedsDel[l]; !ok {&#xA;&#x9;&#x9;&#x9;out = append(out, l)&#xA;&#x9;&#x9;}&#xA;&#x9;}&#xA;&#xA;&#x9;return Label(out...)&#xA;}&#xA;&#xA;// 只能在国内运行&#xA;var ZChina = remove(ZAll, ZApSouthEast2)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;自动过滤&lt;/h3&gt;&#xA;&lt;h4&gt;根据配置文件过滤&lt;/h4&gt;&#xA;&lt;p&gt;配置文件天然含有过滤信息，例如线上环境配置、灰度环境配置、本地环境配置。那 &lt;code&gt;Ginkgo&lt;/code&gt; 能不能自动添加过滤语句呢？当然可以。&lt;/p&gt;&#xA;&lt;p&gt;回到 &lt;code&gt;Ginkgo&lt;/code&gt; 的启动函数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func TestE2E(t *testing.T) {&#xA;&#x9;RegisterFailHandler(Fail)&#xA;&#xA;&#x9;RunSpecs(t, &amp;quot;e2e Suite&amp;quot;)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;RunSpecs&lt;/code&gt; 可以接受额外的参数：&lt;code&gt;SuiteConfig&lt;/code&gt; 和 &lt;code&gt;ReporterConfig&lt;/code&gt;，其中 &lt;code&gt;SuiteConfig&lt;/code&gt; 可以定制 &lt;code&gt;Ginkgo CLI&lt;/code&gt; 启动参数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var EnvProduct = Label(&amp;quot;product&amp;quot;)&#xA;&#xA;suiteConfig, reportConfig := GinkgoConfiguration()&#xA;// 与已有的逻辑是与的关系&#xA;suiteConfig.LabelFilter = fmt.Sprintf(&amp;quot;(%v) &amp;amp;&amp;amp; (%v)&amp;quot;, suiteConfig.LabelFilter, &amp;quot;product&amp;quot;)&#xA;&#xA;RunSpecs(t, &amp;quot;e2e Suite&amp;quot;, suiteConfig, reportConfig)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这样，&lt;code&gt;product&lt;/code&gt; 标签就被添加到了 &lt;code&gt;--label-filter&lt;/code&gt; 中，和已有的过滤逻辑是&lt;strong&gt;与&lt;/strong&gt;的关系。&lt;/p&gt;&#xA;&lt;h4&gt;手动用例&lt;/h4&gt;&#xA;&lt;p&gt;有可能存在这样一些用例，它们不能完全自动化，验收的时候需要手动执行，人工验证。这些用例在 &lt;code&gt;Ginkgo v1&lt;/code&gt; 中，只能被标注为 &lt;code&gt;Skip&lt;/code&gt;，每次执行的时候需要将 &lt;code&gt;Skip&lt;/code&gt; 装饰器去掉再运行，十分麻烦。&lt;/p&gt;&#xA;&lt;p&gt;而借助灵活的标签过滤语法，就能在不修改集测代码的情况下运行它，例如：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var Manual = Label(&amp;quot;manual&amp;quot;)&#xA;&#xA;// 如果已经有 manual 就不再加 !manual 标签&#xA;if !strings.Contains(suiteConfig.LabelFilter, &amp;quot;manual&amp;quot;) {&#xA;    suiteConfig.LabelFilter += &amp;quot; &amp;amp;&amp;amp; (!manual)&amp;quot; // 强制排除 manual 标签&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;平时执行集测回归时，会自动添加 &lt;code&gt;!manual&lt;/code&gt;，忽略所有的手动用例。&lt;/li&gt;&#xA;&lt;li&gt;而一旦命令行添加 &lt;code&gt;manual&lt;/code&gt; 后，便会过滤出对应的手动用例。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2023/12/24/ginkgo-label-tutorial/" rel="alternate"></link>
    <summary type="html">如何更有效的组织用例？</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>锤子与钉子</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2023/12/05/chuizi-dingzi/</id>
    <content type="html">&lt;p&gt;思考问题让人着迷，但我却只能做到“手里有锤子，看什么都像钉子”的程度。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2023/12/05/chuizi-dingzi/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>随机数生成策略对集测性能的影响</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2023/10/29/one-example-of-ginkgo-e2e-test-enhancement/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;七牛的测试机房需要搬迁，在 CI 系统迁移之后，发现新机房的集测总是多花 5-10min。一开始没怎么注意，以为只是新机器网络、磁盘慢之类的原因。但深入看了集测日志后，却发现，多出来的时间集中在集测之始，那就有必要好好分析一下了。&lt;/p&gt;&#xA;&lt;h2&gt;Ginkgo 表面之下&lt;/h2&gt;&#xA;&lt;p&gt;本篇需要一些前置知识，可参考：&lt;a href=&#34;https://www.lyyyuna.com/2022/05/12/inside-the-ginkgo&#34;&gt;Ginkgo 测试框架实现解析&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Ginkgo&lt;/code&gt; 作为 Go 语言中比较流行的集测框架，它其实有不少隐含行为，做优化时不得不知：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;Ginkgo&lt;/code&gt; 是&lt;strong&gt;两阶段&lt;/strong&gt;，先执行 &lt;code&gt;Describe/Context&lt;/code&gt; 代码，解析出用例树，然后执行 &lt;code&gt;It&lt;/code&gt; 用例。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Ginkgo&lt;/code&gt; 并发是多进程模型，且每个进程都需要完整地执行&lt;strong&gt;第一阶段&lt;/strong&gt;。只有第二阶段才在各进程内有区别。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;基于这两点，我们合理猜测，着多出来的 5-10min 是阻塞在了用例树生成阶段。&lt;/p&gt;&#xA;&lt;h2&gt;分析过程&lt;/h2&gt;&#xA;&lt;p&gt;在本地调试单进程，其实也能发现轻微的阻塞，但阻塞时间并不长（5s 左右），若把并发加到了 20，阻塞时间指数级增加，出现了和 CI 机器一样的现象。（长期没关注这个问题和我们的开发习惯有关，写测试用例的时候很少会开多并发执行）&lt;/p&gt;&#xA;&lt;p&gt;加上 &lt;code&gt;--cpuprofile&lt;/code&gt; 参数再次多并发执行用例，得到性能图：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/ginkgo/ginkgo-cpupprof1.png&#34; alt=&#34;top&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/ginkgo/ginkgo-cpupprof2.png&#34; alt=&#34;graph&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;其中 &lt;code&gt;randutil.StringRange&lt;/code&gt; 是第三方库，内部使用了 &lt;code&gt;crypto/rand&lt;/code&gt; 来生成随机数，可以看到大部分性能被随机数生成吃掉了。为什么用例有这么多随机数？这和我们的云存储用例逻辑有关，其中需要创建随机命名的空间，上传随机命名的文件。&lt;/p&gt;&#xA;&lt;p&gt;Go 有两种随机数生成函数：&lt;code&gt;math/rand&lt;/code&gt; 和 &lt;code&gt;crypto/rand&lt;/code&gt;。前者是纯数学方法生成的伪随机数，后者是通过系统调用 &lt;code&gt;unix.GetRandom&lt;/code&gt; 获取：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func getRandom(p []byte) error {&#xA;    n, err := unix.GetRandom(p, 0)&#xA;    if err != nil {&#xA;        return err&#xA;    }&#xA;    if n != len(p) {&#xA;        return syscall.EIO&#xA;    }&#xA;    return nil&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;而第二个参数 0 意味着 &lt;code&gt;GRND_RANDOM&lt;/code&gt;，以阻塞的方式读取 &lt;code&gt;/dev/random&lt;/code&gt; 真随机值设备。该设备有一种叫&lt;code&gt;熵&lt;/code&gt;的值代表可用的随机值，熵会来源于键盘、鼠标和磁盘 IO 等的数据，它的储备数量是有限的，生成速度也不快。在 Linux 上可以通过 &lt;code&gt;/proc/sys/kernel/random/entropy_avail&lt;/code&gt; 查看&lt;code&gt;熵&lt;/code&gt;。一旦无&lt;code&gt;熵&lt;/code&gt;可用，进程便会阻塞。&lt;/p&gt;&#xA;&lt;h2&gt;破案结果&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;Ginkgo&lt;/code&gt; 推荐在 &lt;code&gt;BeforeEach/BeforeAll&lt;/code&gt; 中初始化变量，但七牛过去的用例书写并不规范，大量变量在定义时便被初始化。&lt;/li&gt;&#xA;&lt;li&gt;定义时初始化的变量会在每个并发的进程中被执行。（如果在 &lt;code&gt;BeforeEach/BeforeAll&lt;/code&gt; 中初始化，则只在需要的进程中执行）&lt;/li&gt;&#xA;&lt;li&gt;一个 20 字节长度的字符串，就需要执行 20 次随机数生成。&lt;/li&gt;&#xA;&lt;li&gt;云存储累积了近 5000 个用例，每个用例约 20 个随机数，并发 20，那就需要 2000000 次随机数生成。&lt;/li&gt;&#xA;&lt;li&gt;观察新机房机器上储备的熵，稳定在 4000 个左右。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;所以，当我们的集测执行，进入第一阶段解析用例树时，随机数会被瞬间耗尽，然后阻塞在 &lt;code&gt;unix.GetRandom&lt;/code&gt; 上。&lt;/p&gt;&#xA;&lt;p&gt;这个问题可以说从很早就存在了，那为什么原来没发现呢？之前的机器已经不在了，只能猜测是之前的随机数生成比较快，所以没人注意。&lt;/p&gt;&#xA;&lt;h2&gt;解决&lt;/h2&gt;&#xA;&lt;p&gt;解决方法其实很简单，把 &lt;code&gt;crypto/rand&lt;/code&gt; 换成 &lt;code&gt;math/rand&lt;/code&gt;。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2023/10/29/one-example-of-ginkgo-e2e-test-enhancement/" rel="alternate"></link>
    <summary type="html">一个 Ginkgo 集测优化案例</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Ginkgo 测试框架实现解析</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2022/05/12/inside-the-ginkgo/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;先看一段典型的 Ginkgo 测试代码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var _ = Describe(&amp;quot;Book&amp;quot;, func() {&#xA;    Context(&amp;quot;my&amp;quot;, func() {&#xA;        It(&amp;quot;1&amp;quot;, func() {&#xA;        })&#xA;&#xA;        It(&amp;quot;2&amp;quot;, func() {&#xA;        })&#xA;&#xA;        It(&amp;quot;3&amp;quot;, func() {&#xA;        })&#xA;    })&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;习惯了 pytest, Junit, TestNG, go 自带单元测试等等测试框架后，会觉得 Ginkgo 的测试用例 &lt;code&gt;It&lt;/code&gt; 怎么这么奇怪？是嵌套在 &lt;code&gt;func(){}&lt;/code&gt; 中的函数？难道上面的三个用例是顺序执行的三个函数调用？&lt;/p&gt;&#xA;&lt;p&gt;类似这样的疑问还有很多，本文会选择一些我感兴趣的问题，并试图解答：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Ginkgo 的测试用例是如何组织起来的？&lt;code&gt;Context&lt;/code&gt;/&lt;code&gt;Describe&lt;/code&gt; 中的其他语句如何与 &lt;code&gt;It&lt;/code&gt; 区分开来？&lt;/li&gt;&#xA;&lt;li&gt;Ginkgo 写的测试用例为什么能可以编译成二进制分发？为什么也能用 &lt;code&gt;go test&lt;/code&gt; 执行？&lt;/li&gt;&#xA;&lt;li&gt;Ginkgo 的并发是多进程还是多个 goroutine？&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;本文基于 &lt;a href=&#34;https://github.com/onsi/ginkgo/tree/v2.1.4&#34;&gt;Ginkgo v2.1.4&lt;/a&gt; 源码进行分析。&lt;/p&gt;&#xA;&lt;h2&gt;测试用例&lt;/h2&gt;&#xA;&lt;h3&gt;测试入口&lt;/h3&gt;&#xA;&lt;p&gt;Ginkgo 测试的入口一般长这样：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func TestBooks(t *testing.T) {&#xA;    RegisterFailHandler(Fail)&#xA;    RunSpecs(t, &amp;quot;Books Suite&amp;quot;)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;该函数 &lt;code&gt;TestBooks&lt;/code&gt; 其实是 go test 标准库框架的下的一个测试用例，这也是为什么 &lt;code&gt;go test&lt;/code&gt; 也能识别 Ginkgo 测试用例的原因。Ginkgo 的测试用例和 &lt;code&gt;go test&lt;/code&gt; 的测试用例并不等价，所有 Ginkgo 代码只相当于 &lt;code&gt;go test&lt;/code&gt; 中的一个用例。既然大框架上属于 &lt;code&gt;go test&lt;/code&gt;，那么 Ginkgo 也要遵循标准库测试的规则： 测试入口文件必须是 &lt;code&gt;_test.go&lt;/code&gt; 结尾，否则 Ginkgo 不能识别。&lt;/p&gt;&#xA;&lt;h3&gt;用例容器&lt;/h3&gt;&#xA;&lt;p&gt;在 Ginkgo 中，如本文开头的例子，测试用例 &lt;code&gt;It&lt;/code&gt; 不能单独存在，必须从属于 &lt;code&gt;Describe&lt;/code&gt;/&lt;code&gt;Context&lt;/code&gt; 这样的容器。这两类容器类型分别定义为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;NodeTypeContainer NodeType = 1 &amp;lt;&amp;lt; iota&#xA;NodeTypeIt&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这些用例的容器都有着类似的实现：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func Describe(text string, args ...interface{}) bool {&#xA;&#x9;return pushNode(internal.NewNode(deprecationTracker, types.NodeTypeContainer, text, args...))&#xA;}&#xA;&#xA;func NewNode(deprecationTracker *types.DeprecationTracker, nodeType types.NodeType, text string, args ...interface{}) (Node, []error) {&#xA;...&#xA;&#x9;for _, arg := range args {&#xA;&#x9;&#x9;switch t := reflect.TypeOf(arg); {&#xA;...&#xA;&#x9;&#x9;case t.Kind() == reflect.Func:&#xA;...&#xA;&#x9;&#x9;&#x9;node.Body = arg.(func())&#xA;...&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当我们用 &lt;code&gt;var _ = Describe()&lt;/code&gt; 匿名变量定义顶层容器后， &lt;code&gt;Describe&lt;/code&gt; 会创建一个节点，并将用例所在的 &lt;code&gt;func(){ xxx }&lt;/code&gt; 赋值给节点的 &lt;code&gt;node.Body&lt;/code&gt; 成员。&lt;/p&gt;&#xA;&lt;p&gt;而这个匿名变量是顶层的全局变量，根据 Go 语言的内存模型规则，必须在 &lt;code&gt;main&lt;/code&gt; 函数或者 &lt;code&gt;TestBooks&lt;/code&gt; 测试函数运行之前初始化完毕。这也就意味着运行 &lt;code&gt;RunSpecs()&lt;/code&gt; 之前，Ginkgo 便通过 &lt;code&gt;Describe&lt;/code&gt; 收集到当前测试套件内所有的顶层容器。&lt;/p&gt;&#xA;&lt;p&gt;接着，go 测试函数运行 &lt;code&gt;RunSpecs()&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func RunSpecs(t GinkgoTestingT, description string, args ...interface{}) bool {&#xA;...&#xA;&#x9;err := global.Suite.BuildTree()&#xA;...&#xA;}&#xA;&#xA;func (suite *Suite) BuildTree() error {&#xA;&#x9;suite.phase = PhaseBuildTree&#xA;&#x9;for _, topLevelContainer := range suite.topLevelContainers {&#xA;&#x9;&#x9;err := suite.PushNode(topLevelContainer)&#xA;&#x9;&#x9;if err != nil {&#xA;&#x9;&#x9;&#x9;return err&#xA;&#x9;&#x9;}&#xA;&#x9;}&#xA;&#x9;return nil&#xA;}&#xA;&#xA;func (suite *Suite) PushNode(node Node) error {&#xA;...&#xA;&#x9;if node.NodeType == types.NodeTypeContainer {&#xA;...&#xA;&#x9;&#x9;if suite.phase == PhaseBuildTree {&#xA;&#x9;&#x9;&#x9;parentTree := suite.tree&#xA;&#x9;&#x9;&#x9;suite.tree = &amp;amp;TreeNode{Node: node}&#xA;&#x9;&#x9;&#x9;parentTree.AppendChild(suite.tree)&#xA;&#x9;&#x9;&#x9;&#xA;            node.Body()&#xA;&#xA;&#x9;&#x9;&#x9;suite.tree = parentTree&#xA;&#x9;&#x9;&#x9;return err&#xA;&#x9;&#x9;}&#xA;&#x9;} else {&#xA;&#x9;&#x9;suite.tree.AppendChild(&amp;amp;TreeNode{Node: node})&#xA;&#x9;&#x9;return nil&#xA;&#x9;}&#xA;...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;以上是关键代码，&lt;code&gt;PushNode()&lt;/code&gt; 函数在匿名变量初始化、用例解析阶段多次调用，递归调用后逻辑揉在一起就有点绕，这里总结如下：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;在 &lt;code&gt;PhaseBuildTree&lt;/code&gt; 阶段，将所有顶层容器统一在一棵多叉树下。&lt;/li&gt;&#xA;&lt;li&gt;接着运行 &lt;code&gt;node.Body()&lt;/code&gt;，即包含了各种子容器 &lt;code&gt;Context&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;子容器的定义又会调用 &lt;code&gt;PushNode() --&amp;gt; node.Body()&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;2-3 步骤会循环调用，将所有容器节点加入步骤 1 创建的多叉树内。&lt;/li&gt;&#xA;&lt;li&gt;如果当前节点是 &lt;code&gt;It&lt;/code&gt;，只会将节点加入树的叶子节点，并不会运行 &lt;code&gt;node.Body()&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;最终树如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;        Describe&#xA;       /       \&#xA;  Context    Context&#xA;  /    \        |&#xA;It     It       It&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这里要注意，包含用例逻辑的 &lt;code&gt;It&lt;/code&gt; 并没有被执行，只有各种父级容器运行了 &lt;code&gt;func(){}&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h3&gt;执行用例&lt;/h3&gt;&#xA;&lt;p&gt;当树构造完毕后，&lt;code&gt;RunSpecs&lt;/code&gt; 便会开始遍历树：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func RunSpecs(t GinkgoTestingT, description string, args ...interface{}) bool {&#xA;...&#xA;&#x9;err := global.Suite.BuildTree()&#xA;...&#xA;&#x9;passed, hasFocusedTests := global.Suite.Run(...)&#xA;...&#xA;}&#xA;&#xA;func (suite *Suite) Run(...) (bool, bool) {&#xA;...&#xA;&#x9;success := suite.runSpecs(description, suiteLabels, suitePath, hasProgrammaticFocus, specs)&#xA;...&#xA;}&#xA;&#xA;func (suite *Suite) runSpecs(description string, suiteLabels Labels, suitePath string, hasProgrammaticFocus bool, specs Specs) bool {&#xA;...&#xA;&#x9;newGroup(suite).run(specs.AtIndices(groupedSpecIndices[groupedSpecIdx]))&#xA;...&#xA;}&#xA;&#xA;func (g *group) run(specs Specs) {&#xA;&#x9;g.specs = specs&#xA;&#xA;&#x9;for _, spec := range g.specs {&#xA;        ...&#xA;        g.attemptSpec(attempt == maxAttempts-1, spec)&#xA;        ...&#xA;    }&#xA;    ...&#xA;}&#xA;&#xA;func (g *group) attemptSpec(isFinalAttempt bool, spec Spec) {&#xA;...&#xA;&#x9;for _, node := range nodes {&#xA;...&#xA;&#x9;&#x9;g.suite.currentSpecReport.State, g.suite.currentSpecReport.Failure = g.suite.runNode(node, interruptStatus.Channel, spec.Nodes.BestTextFor(node))&#xA;...&#xA;&#x9;}&#xA;...&#xA;}&#xA;&#xA;func (suite *Suite) runNode(node Node, interruptChannel chan interface{}, text string) (types.SpecState, types.Failure) {&#xA;...&#xA;&#x9;go func() {&#xA;&#x9;&#x9;node.Body()&#xA;&#x9;}()&#xA;...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;而叶子节点 &lt;code&gt;It&lt;/code&gt; 用例本身的内容，只有到了 &lt;code&gt;runNode()&lt;/code&gt; 阶段才会真正运行。&lt;/p&gt;&#xA;&lt;p&gt;回答本文的第一个问题：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;全局匿名函数 &lt;code&gt;var _ = Describe(&amp;quot;&amp;quot;, func(){})&lt;/code&gt; 定义了顶层的测试用例容器。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;RunSpecs&lt;/code&gt; 会运行容器 &lt;code&gt;func(){}&lt;/code&gt; 内的语句，将所有用例统一在一棵树上。&lt;/li&gt;&#xA;&lt;li&gt;接着 &lt;code&gt;RunSpecs&lt;/code&gt; 会运行 &lt;code&gt;It&lt;/code&gt; 内的语句，执行真正的测试用例。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;熟悉了用例的解析原理后，你是否能回答该示例中 0，1，2，3 分别是什么时机打印？分别打印几次？&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var _ = Describe(&amp;quot;Book&amp;quot;, func() {&#xA;    Context(&amp;quot;my&amp;quot;, func() {&#xA;        fmt.Println(0)&#xA;&#xA;        It(&amp;quot;1&amp;quot;, func() {&#xA;            fmt.Println(1)&#xA;        })&#xA;&#xA;        It(&amp;quot;2&amp;quot;, func() {&#xA;            fmt.Println(2)&#xA;        })&#xA;&#xA;        It(&amp;quot;3&amp;quot;, func() {&#xA;            fmt.Println(3)&#xA;        })&#xA;    })&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;ginkgo run&lt;/h2&gt;&#xA;&lt;h3&gt;编译&lt;/h3&gt;&#xA;&lt;p&gt;虽然 Ginkgo 可以直接编译成二进制，但平时用的最多的还是 &lt;code&gt;ginkgo run&lt;/code&gt; 命令来运行用例。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;ginkgo run&lt;/code&gt; 的入口在 &lt;code&gt;ginkgo/run/run_command.go&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func BuildRunCommand() command.Command {&#xA;...&#xA;&#x9;return command.Command{&#xA;...&#xA;&#x9;&#x9;Command: func(args []string, additionalArgs []string) {&#xA;...&#xA;&#x9;&#x9;&#x9;runner.RunSpecs(args, additionalArgs)&#xA;&#x9;&#x9;},&#xA;&#x9;}&#xA;}&#xA;&#xA;func (r *SpecRunner) RunSpecs(args []string, additionalArgs []string) {&#xA;...&#xA;&#x9;opc := internal.NewOrderedParallelCompiler(r.cliConfig.ComputedNumCompilers())&#xA;&#x9;opc.StartCompiling(suites, r.goFlagsConfig)&#xA;...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;从 &lt;code&gt;opc.StartCompiling(suites, r.goFlagsConfig)&lt;/code&gt; 名字来看，run 命令会先对测试用例编译，是 Ginkgo 自己把编译器的活也做了？我们接着看 &lt;code&gt;StartCompiling&lt;/code&gt; 的实现：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (opc *OrderedParallelCompiler) StartCompiling(suites TestSuites, goFlagsConfig types.GoFlagsConfig) {&#xA;...&#xA;&#x9;for compiler := 0; compiler &amp;lt; opc.numCompilers; compiler++ {&#xA;&#x9;&#x9;go func() {&#xA;...&#xA;&#x9;&#x9;&#x9;suite = CompileSuite(suite, goFlagsConfig)&#xA;...&#xA;&#x9;&#x9;}()&#xA;&#x9;}&#xA;...&#xA;}&#xA;&#xA;func CompileSuite(suite TestSuite, goFlagsConfig types.GoFlagsConfig) TestSuite {&#xA;...&#xA;&#x9;path, err := filepath.Abs(filepath.Join(suite.Path, suite.PackageName+&amp;quot;.test&amp;quot;))&#xA;...&#xA;&#x9;args, err := types.GenerateGoTestCompileArgs(goFlagsConfig, path, &amp;quot;./&amp;quot;)&#xA;...&#xA;&#x9;cmd := exec.Command(&amp;quot;go&amp;quot;, args...)&#xA;&#x9;cmd.Dir = suite.Path&#xA;&#x9;output, err := cmd.CombinedOutput()&#xA;...&#xA;}&#xA;&#xA;func GenerateGoTestCompileArgs(...) ([]string, error) {&#xA;...&#xA;&#x9;args := []string{&amp;quot;test&amp;quot;, &amp;quot;-c&amp;quot;, &amp;quot;-o&amp;quot;, destination, packageToBuild}&#xA;...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;看来 Ginkgo 没有另起炉灶，正是用官方的 &lt;code&gt;go test -c&lt;/code&gt; 来编译成二进制的，这也正好回答了本文的第二个疑问。&lt;/p&gt;&#xA;&lt;h3&gt;运行用例&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (r *SpecRunner) RunSpecs(args []string, additionalArgs []string) {&#xA;...&#xA;&#x9;suites[suiteIdx] = internal.RunCompiledSuite(...)&#xA;...&#xA;}&#xA;&#xA;func RunCompiledSuite(...) TestSuite {&#xA;...&#xA;&#x9;suite = runSerial(...)&#xA;...&#xA;}&#xA;&#xA;func runSerial(...) TestSuite {&#xA;...&#xA;&#x9;cmd, buf := buildAndStartCommand(suite, args, true)&#xA;...&#xA;}&#xA;&#xA;func buildAndStartCommand(suite TestSuite, args []string, pipeToStdout bool) (*exec.Cmd, *bytes.Buffer) {&#xA;...&#xA;&#x9;cmd := exec.Command(suite.PathToCompiledTest, args...)&#xA;&#x9;cmd.Dir = suite.Path&#xA;...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;和预想的一致，上一小节编译得到的 &lt;code&gt;xxx.test&lt;/code&gt; 二进制在运行环节会直接调用。&lt;/p&gt;&#xA;&lt;p&gt;这里要注意 &lt;code&gt;cmd.Dir = suite.Path&lt;/code&gt; 这一行，说明测试用例的&lt;strong&gt;当前目录&lt;/strong&gt;，并不是运行 &lt;code&gt;ginkgo run&lt;/code&gt; 所在的目录，而是测试用例所在的目录，我们有时候会在用例中读写文件，明白 Ginkgo &lt;strong&gt;当前目录&lt;/strong&gt;的规则，才能让你无论在哪都能正常运行。&lt;/p&gt;&#xA;&lt;h3&gt;清理&lt;/h3&gt;&#xA;&lt;p&gt;既然每次每次 run 都会编译，那为什么我在本地从来没看到过呢？那必然是有一套清理机制：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (r *SpecRunner) RunSpecs(args []string, additionalArgs []string) {&#xA;...&#xA;&#x9;internal.Cleanup(r.goFlagsConfig, suites...)&#xA;...&#xA;}&#xA;&#xA;func Cleanup(goFlagsConfig types.GoFlagsConfig, suites ...TestSuite) {&#xA;...&#xA;&#x9;for _, suite := range suites {&#xA;&#x9;&#x9;if !suite.Precompiled {&#xA;&#x9;&#x9;&#x9;os.Remove(suite.PathToCompiledTest)&#xA;&#x9;&#x9;}&#xA;&#x9;}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;并发模型&lt;/h2&gt;&#xA;&lt;h3&gt;并发入口&lt;/h3&gt;&#xA;&lt;p&gt;标准库的 &lt;code&gt;go test&lt;/code&gt; 采用多协程来并发执行多个用例。Ginkgo 虽然在 &lt;code&gt;go test&lt;/code&gt; 的大框架下，但本身只作为其中的&lt;strong&gt;一个&lt;/strong&gt;用例，无法在原框架下并发自身的多个 Ginkgo 的用例。&lt;/p&gt;&#xA;&lt;p&gt;Ginkgo 的&lt;a href=&#34;https://onsi.github.io/ginkgo/#mental-model-how-ginkgo-runs-parallel-specs&#34;&gt;文档&lt;/a&gt;中提到：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Ginkgo ensures specs running in parallel are fully isolated from one another. It does this by running the specs in different processes.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;其并发是多进程模型，由于多进程的特点，不同进程间的用例是隔离的。之前我们了解到，Ginkgo 会将用例编译成可执行二进制再运行，那派生出来的多个子进程又是什么？我们看一下运行用例函数 &lt;code&gt;RunCompiledSuite&lt;/code&gt; 在并发场景下是什么流程：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func RunCompiledSuite(...) TestSuite {&#xA;...&#xA;&#x9;if suite.IsGinkgo &amp;amp;&amp;amp; cliConfig.ComputedProcs() &amp;gt; 1 {&#xA;&#x9;&#x9;suite = runParallel(...)&#xA;&#x9;} else if suite.IsGinkgo {&#xA;&#x9;&#x9;suite = runSerial(...)&#xA;&#x9;} &#xA;...&#xA;}&#xA;&#xA;func runParallel(...) TestSuite {&#xA;...&#xA;&#x9;server, err := parallel_support.NewServer(numProcs, reporters.NewDefaultReporter(reporterConfig, formatter.ColorableStdOut))&#xA;...&#xA;&#x9;for proc := 1; proc &amp;lt;= numProcs; proc++ {&#xA;...&#xA;&#x9;&#x9;args, err := types.GenerateGinkgoTestRunArgs(procGinkgoConfig, reporterConfig, procGoFlagsConfig)&#xA;&#x9;&#x9;cmd, buf := buildAndStartCommand(suite, args, false)&#xA;...&#xA;&#x9;}&#xA;...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在并发场景下：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;首先启动一个服务器监听随机端口，有可能是 RPC 服务器，也有可能是 HTTP 服务器，功能相同，只是协议不同。&lt;/li&gt;&#xA;&lt;li&gt;然后按并发数多次调用 &lt;code&gt;buildAndStartCommand&lt;/code&gt;（上面分析过），即启动第一阶段编译好的二进制。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Ginkgo run&lt;/code&gt; CLI 承担了服务器功能，编译后的二进制完成了客户端的工作并执行用例。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;那每个并发进程是如何与其他进程区别的呢？我们手动编译测试用例，并查看其 help 文档：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# ./test.test -h&#xA;Controlling Test Parallelism&#xA;These are set by the Ginkgo CLI, do not set them manually via go test.&#xA;Use ginkgo -p or ginkgo -procs=N instead.&#xA;  --ginkgo.parallel.process [int] (default: 1)&#xA;    This worker process&#39;s (one-indexed) process number.  For running specs in&#xA;    parallel.&#xA;  --ginkgo.parallel.total [int] (default: 1)&#xA;    The total number of worker processes.  For running specs in parallel.&#xA;  --ginkgo.parallel.host [string] (default: set by Ginkgo CLI)&#xA;    The address for the server that will synchronize the processes.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Ginkgo 会为二进制插入三个内置 flag，并且还特地强调了 &lt;strong&gt;do not set them manually via go test&lt;/strong&gt;，仅内部使用，不要为它们赋值。它们分别有以下用途：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;ginkgo.parallel.process，当前是第几个并发进程？相当于唯一 ID。&lt;/li&gt;&#xA;&lt;li&gt;ginkgo.parallel.total，所有进程数。&lt;/li&gt;&#xA;&lt;li&gt;ginkgo.parallel.host，服务器地址。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;并发场景下启动的 &lt;code&gt;buildAndStartCommand&lt;/code&gt; 会为每个并发进程设置好上面三个命令行参数，各自也就有了各自的 ID，并且知道如何与父进程通信（通过 HTTP 或 RPC 服务器）。&lt;/p&gt;&#xA;&lt;h3&gt;并发通信&lt;/h3&gt;&#xA;&lt;p&gt;服务器与并发客户端的通信接口如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Client interface {&#xA;&#x9;Connect() bool&#xA;&#x9;Close() error&#xA;&#xA;&#x9;PostSuiteWillBegin(report types.Report) error&#xA;&#x9;PostDidRun(report types.SpecReport) error&#xA;&#x9;PostSuiteDidEnd(report types.Report) error&#xA;&#x9;PostSynchronizedBeforeSuiteCompleted(state types.SpecState, data []byte) error&#xA;&#x9;BlockUntilSynchronizedBeforeSuiteData() (types.SpecState, []byte, error)&#xA;&#x9;BlockUntilNonprimaryProcsHaveFinished() error&#xA;&#x9;BlockUntilAggregatedNonprimaryProcsReport() (types.Report, error)&#xA;&#x9;FetchNextCounter() (int, error)&#xA;&#x9;PostAbort() error&#xA;&#x9;ShouldAbort() bool&#xA;&#x9;Write(p []byte) (int, error)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;其方法名一目了然，大概能猜测出中心服务器负责任务的派发和最终结果的收集，这里不再一一分析。&lt;/p&gt;&#xA;&lt;h3&gt;随机&lt;/h3&gt;&#xA;&lt;p&gt;Ginkgo 会打乱测试用例书写的顺序，以随机的方式来执行。在服务端代码（即 &lt;code&gt;Ginkgo run&lt;/code&gt;）中，我们没有找到解析用例并随机打乱的流程，难道这部分工作也在客户端中？我们回到本文最开始的 &lt;code&gt;runSpecs&lt;/code&gt; 中寻找答案：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (suite *Suite) runSpecs(description string, suiteLabels Labels, suitePath string, hasProgrammaticFocus bool, specs Specs) bool {&#xA;...&#xA;&#x9;groupedSpecIndices, serialGroupedSpecIndices := OrderSpecs(specs, suite.config)&#xA;&#xA;&#x9;if suite.isRunningInParallel() {&#xA;&#x9;&#x9;nextIndex = suite.client.FetchNextCounter&#xA;&#x9;}&#xA;&#xA;&#x9;for {&#xA;&#x9;&#x9;groupedSpecIdx, err := nextIndex()&#xA;&#x9;&#x9;if err != nil {&#xA;&#x9;&#x9;&#x9;suite.report.SpecialSuiteFailureReasons = append(suite.report.SpecialSuiteFailureReasons, fmt.Sprintf(&amp;quot;Failed to iterate over specs:\n%s&amp;quot;, err.Error()))&#xA;&#x9;&#x9;&#x9;suite.report.SuiteSucceeded = false&#xA;&#x9;&#x9;&#x9;break&#xA;&#x9;&#x9;}&#xA;&#xA;&#x9;&#x9;if groupedSpecIdx &amp;gt;= len(groupedSpecIndices) {&#xA;&#x9;&#x9;&#x9;if suite.config.ParallelProcess == 1 &amp;amp;&amp;amp; len(serialGroupedSpecIndices) &amp;gt; 0 {&#xA;&#x9;&#x9;&#x9;&#x9;groupedSpecIndices, serialGroupedSpecIndices, nextIndex = serialGroupedSpecIndices, GroupedSpecIndices{}, MakeIncrementingIndexCounter()&#xA;&#x9;&#x9;&#x9;&#x9;suite.client.BlockUntilNonprimaryProcsHaveFinished()&#xA;&#x9;&#x9;&#x9;&#x9;continue&#xA;&#x9;&#x9;&#x9;}&#xA;&#x9;&#x9;&#x9;break&#xA;&#x9;&#x9;}&#xA;&#xA;&#x9;&#x9;newGroup(suite).run(specs.AtIndices(groupedSpecIndices[groupedSpecIdx]))&#xA;&#x9;}&#xA;...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;用例每次会通过 &lt;code&gt;FetchNextCounter&lt;/code&gt; RPC/HTTP 方法获取下一个索引，索引由服务器保证全局唯一。&lt;/li&gt;&#xA;&lt;li&gt;每个并发进程根据索引选出要执行的用例，执行其 &lt;code&gt;node.Body()&lt;/code&gt; 方法。&lt;/li&gt;&#xA;&lt;li&gt;索引可能代表一个用例，也可能代表一个用例容器内的一组用例，取决于配置。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;确实如我们猜测的那样，随机打乱是在客户端做的，那每个客户端都做随机，不会重合么？&lt;/p&gt;&#xA;&lt;p&gt;不用担心：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import &amp;quot;math/rand&amp;quot;&#xA;&#xA;func OrderSpecs(specs Specs, suiteConfig types.SuiteConfig) (GroupedSpecIndices, GroupedSpecIndices) {&#xA;...&#xA;&#x9;r := rand.New(rand.NewSource(suiteConfig.RandomSeed))&#xA;...&#xA;&#x9;permutation := r.Perm(len(shufflableGroupingIDs))&#xA;...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这里用的是 &lt;code&gt;math/rand&lt;/code&gt; 伪随机库，只要种子 &lt;code&gt;suiteConfig.RandomSeed&lt;/code&gt; 相同，各个并发客户端得到的随机序列是完全一样的。&lt;/p&gt;&#xA;&lt;h2&gt;结语&lt;/h2&gt;&#xA;&lt;p&gt;至此，本文开始提的三个问题已经获得了答案。有了本文的指引，读者可以接着去探索：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;BeforeEach&lt;/code&gt;, &lt;code&gt;AfterEach&lt;/code&gt; 是如何解析并运行的？&lt;/li&gt;&#xA;&lt;li&gt;DescribeTable 和 Entry 是怎么实现的？为什么 Entry 内参数是在初始化阶段就执行完毕了？&lt;/li&gt;&#xA;&lt;li&gt;report 是如何收集的？并发场景下呢？&lt;/li&gt;&#xA;&lt;li&gt;等等&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2022/05/12/inside-the-ginkgo/" rel="alternate"></link>
    <summary type="html">你是否好奇 Ginkgo 是如何实现 BDD 风格的测试框架呢？</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Go 内存模型</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2022/03/13/go-memory-model/</id>
    <content type="html">&lt;p&gt;并发场景下最讨厌的是对变量的读写操作隐含着违反直觉的结果。这时候，就需要语言的&lt;strong&gt;内存模型&lt;/strong&gt;了。所有语言的内存模型都在讲着一件事情，什么操作才能让写变量的结果被另一个线程/协程读到。&lt;/p&gt;&#xA;&lt;p&gt;幸好 Go 一直是一个设计的很“简单”的语言，它的内存模型需要记住的结论很少，我们很容易就写出基于 goroutine 的并发安全程序。&lt;/p&gt;&#xA;&lt;p&gt;先解释一个经典的名词 &lt;code&gt;happens-before&lt;/code&gt;：如果一个事件的发生在另一个事件之前，那么第一个事件的结果必须影响到第二个事件。&lt;code&gt;happens-before&lt;/code&gt; 听上去理应如此，但由于现代处理器的多核、指令重排，编译器优化等等因素，&lt;code&gt;happens-before&lt;/code&gt; 不是天然成立的。&lt;/p&gt;&#xA;&lt;p&gt;接下来看一下 Go 内存模型规定了哪些操作是确定的：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果包 &lt;code&gt;p&lt;/code&gt; 导入了包 &lt;code&gt;q&lt;/code&gt;，那么包 &lt;code&gt;q&lt;/code&gt; 的 &lt;code&gt;init&lt;/code&gt; 函数 &lt;code&gt;happens-before&lt;/code&gt; 包 &lt;code&gt;p&lt;/code&gt; 的任何代码。&lt;/li&gt;&#xA;&lt;li&gt;所有包的 &lt;code&gt;init&lt;/code&gt; 函数 &lt;code&gt;happens-before&lt;/code&gt; &lt;code&gt;main.main&lt;/code&gt; 函数。&lt;/li&gt;&#xA;&lt;li&gt;用 &lt;code&gt;go&lt;/code&gt; 语句启动新的 &lt;code&gt;goroutine&lt;/code&gt;，该语句本身 &lt;code&gt;happens-before&lt;/code&gt; 启动的这个新 &lt;code&gt;goroutine&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;channel&lt;/code&gt; 上的发送 &lt;code&gt;happens-before&lt;/code&gt; 该 &lt;code&gt;channel&lt;/code&gt; 上的接收。&lt;/li&gt;&#xA;&lt;li&gt;关闭 &lt;code&gt;channel&lt;/code&gt; 的操作 &lt;code&gt;happens-before&lt;/code&gt; 在 &lt;code&gt;channel&lt;/code&gt; 上读到零值（零值意味着 &lt;code&gt;channel&lt;/code&gt; 关闭）。&lt;/li&gt;&#xA;&lt;li&gt;无缓冲 &lt;code&gt;channel&lt;/code&gt; 的接收 &lt;code&gt;happens-before&lt;/code&gt; 该 &lt;code&gt;channel&lt;/code&gt; 上的发送完成。&lt;/li&gt;&#xA;&lt;li&gt;容量为 C 的 &lt;code&gt;channel&lt;/code&gt; 接收到第 k 个元素 &lt;code&gt;happens-before&lt;/code&gt; 该 &lt;code&gt;channel&lt;/code&gt; 第 k+C 个元素发送完成。&lt;/li&gt;&#xA;&lt;li&gt;两个变量 n 和 m，n 出现在 m 的前面，若使用互斥锁 &lt;code&gt;sync.Mutex&lt;/code&gt; 或 &lt;code&gt;sync.RWMutex&lt;/code&gt; 保护，那么变量 n 的 &lt;code&gt;l.Unlock&lt;/code&gt; &lt;code&gt;happens-before&lt;/code&gt; 变量 m 的 &lt;code&gt;l.Lock()&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;如果有多个对 &lt;code&gt;once.Do(f)&lt;/code&gt; 的调用，那么第一个调用 &lt;code&gt;f()&lt;/code&gt; 函数 &lt;code&gt;happens-before&lt;/code&gt; 任何其他 &lt;code&gt;once.Do(f)&lt;/code&gt; 的调用返回。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;sync.Cond&lt;/code&gt; 的 &lt;code&gt;Broadcast&lt;/code&gt; 和 &lt;code&gt;Signal&lt;/code&gt; 调用 &lt;code&gt;happens-before&lt;/code&gt; 阻塞中 &lt;code&gt;Wait&lt;/code&gt; 调用。&lt;/li&gt;&#xA;&lt;li&gt;对于 &lt;code&gt;Sync.Map&lt;/code&gt;，&lt;code&gt;Load&lt;/code&gt;, &lt;code&gt;LoadAndDelete&lt;/code&gt; 和 &lt;code&gt;LoadOrStore&lt;/code&gt; 都是读操作。&lt;code&gt;Delete&lt;/code&gt;, &lt;code&gt;LoadAndDelete&lt;/code&gt; 和 &lt;code&gt;Store&lt;/code&gt; 都是写操作。&lt;code&gt;LoadOrStore&lt;/code&gt; 如果 &lt;code&gt;loaded&lt;/code&gt; 返回 &lt;code&gt;false&lt;/code&gt;，那也是写操作。&lt;code&gt;Sync.Map&lt;/code&gt; 的所有写操作 &lt;code&gt;happens-before&lt;/code&gt; 读操作。&lt;/li&gt;&#xA;&lt;li&gt;对于 &lt;code&gt;Sync.Pool&lt;/code&gt;，&lt;code&gt;Put&lt;/code&gt; &lt;code&gt;happens-before&lt;/code&gt; &lt;code&gt;Get&lt;/code&gt;，&lt;code&gt;New&lt;/code&gt; &lt;code&gt;happens-before&lt;/code&gt; &lt;code&gt;Get&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;对于 &lt;code&gt;Sync.WaitGroup&lt;/code&gt;，&lt;code&gt;Done&lt;/code&gt; &lt;code&gt;happens-before&lt;/code&gt; 任何一个阻塞中的 &lt;code&gt;Wait&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;sync.atomic&lt;/code&gt; 包是一些列原子操作的合集，可用于不同 goroutine 间的同步。如果原子操作 B 的观察到原子操作 A 的结果，那么 A &lt;code&gt;happens-before&lt;/code&gt; B。一旦使用了原子操作，那么程序便拥有了&lt;strong&gt;一致&lt;/strong&gt;的执行顺序。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2022/03/13/go-memory-model/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>如何收集 Go 的实时覆盖率</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2021/12/12/how-to-collect-coverage-in-go/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;接触过 Go 的同学知道，官方没有提供集成测试覆盖率的收集方案。针对集成测试覆盖率的需求，七牛开源了一款工具 goc (&lt;a href=&#34;https://github.com/qiniu/goc&#34;&gt;https://github.com/qiniu/goc&lt;/a&gt;)，能很好地解决这个问题。&lt;/p&gt;&#xA;&lt;p&gt;本文分享了 goc 的使用方法和实现的原理。&lt;/p&gt;&#xA;&lt;h2&gt;Go 单测覆盖率&lt;/h2&gt;&#xA;&lt;p&gt;在深入集测/实时覆盖率之前，先来看看 Go 官方的单测覆盖率是如何收集的。&lt;/p&gt;&#xA;&lt;p&gt;举个例子，有两个文件，被测业务代码 &lt;code&gt;kcp.go&lt;/code&gt; 和单测代码 &lt;code&gt;kcp-test.go&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// kcp.go&#xA;package kcp&#xA;&#xA;func Size(a int) string {&#xA;    switch {&#xA;    case a &amp;lt; 0:&#xA;        return &amp;quot;negative&amp;quot;&#xA;    case a == 0:&#xA;        return &amp;quot;zero&amp;quot;&#xA;    case a &amp;lt; 10:&#xA;        return &amp;quot;small&amp;quot;&#xA;    case a &amp;lt; 100:&#xA;        return &amp;quot;big&amp;quot;&#xA;    case a &amp;lt; 1000:&#xA;        return &amp;quot;huge&amp;quot;&#xA;    }&#xA;    return &amp;quot;enormous&amp;quot;&#xA;}&#xA;&#xA;// kcp_test.go&#xA;package kcp&#xA;&#xA;import &amp;quot;testing&amp;quot;&#xA;&#xA;type Test struct {&#xA;    in  int&#xA;    out string&#xA;}&#xA;&#xA;var tests = []Test{&#xA;    {-1, &amp;quot;negative&amp;quot;},&#xA;    {5, &amp;quot;small&amp;quot;},&#xA;}&#xA;&#xA;func TestSize(t *testing.T) {&#xA;    for i, test := range tests {&#xA;        size := Size(test.in)&#xA;        if size != test.out {&#xA;            t.Errorf(&amp;quot;#%d: Size(%d)=%s; want %s&amp;quot;, i, test.in, size, test.out)&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们用 &lt;code&gt;go test&lt;/code&gt; 工具运行单测，打开 &lt;code&gt;-cover&lt;/code&gt; 选项就可以收集到单测覆盖率，再开启 &lt;code&gt;-coverprofile&lt;/code&gt; 选项，就可以将覆盖率报告输出到本地：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;mode: set&#xA;kcp/kcp/kcp.go:3.25,4.12 1 1&#xA;kcp/kcp/kcp.go:16.5,16.22 1 0&#xA;kcp/kcp/kcp.go:5.16,6.26 1 1&#xA;kcp/kcp/kcp.go:7.17,8.22 1 0&#xA;kcp/kcp/kcp.go:9.17,10.23 1 1&#xA;kcp/kcp/kcp.go:11.18,12.21 1 0&#xA;kcp/kcp/kcp.go:13.19,14.22 1 0&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如何解读这个覆盖率报告？Go 不是对每一行去统计，而是把整个代码拆分成了一个个语句块。覆盖率报告的每一行开头表示该语句块所在的文件名，接着是语句块的起始行和起始列，然后是语句块的结束行、结束列，倒数第二列为语句块内的总行数，最后一列为该语句块在这次测试中被执行到的次数。结合所有的语句数量和执行次数便可计算出整个代码的覆盖率了。&lt;/p&gt;&#xA;&lt;p&gt;但测试不仅仅只有单测，测试同学平时接触最多的反而是手工、集测、系统和自动化测试，对于这些测试手段与被测程序分离、处于不同二进制的情况，需要新的覆盖率收集方法。&lt;/p&gt;&#xA;&lt;h2&gt;传统的集测覆盖率收集方法 vs goc&lt;/h2&gt;&#xA;&lt;p&gt;目前业界的覆盖率收集方案如下：&lt;/p&gt;&#xA;&lt;p&gt;首先在原工程中新增单测代码，添加测试用例 &lt;code&gt;TestMainStart&lt;/code&gt;，在该用例最后调用被测业务 &lt;code&gt;main&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func TestMainStart(t *teing.T){&#xA;    van args[]string&#xA;    for _, arg := range os.Args{&#xA;        if !strings.HasPrefix(arg, &amp;quot;-test&amp;quot;){&#xA;            args = append(args,arg)&#xA;        }&#xA;    }&#xA;    os.Angs = args&#xA;    main()&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;然后使用 &lt;code&gt;go test -c&lt;/code&gt; 选项将测试用例编译成可执行文件 &lt;code&gt;cover.test&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ go test -coverpkg=&amp;quot;./...&amp;quot; -c -o cover.test&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;最后用 &lt;code&gt;-cover.run&lt;/code&gt; 指定运行我们封装过的测试用例 &lt;code&gt;TestMainStart&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ ./cover.test -test.run &amp;quot;TestMainStart&amp;quot; -test.coverprofile=cover.out&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;cover.test&lt;/code&gt; 运行起来后，我们就可以进行各种手工、集测、系统和自动化测试了。由于 &lt;code&gt;cover.test&lt;/code&gt; 这个二进制本质上是一个 &lt;code&gt;go test&lt;/code&gt; 的单测代码，所以当程序退出后会自动输出覆盖率报告，我们也就能得到被测业务的集测覆盖率了。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/goc/legacy-collect-way.png&#34; alt=&#34;传统 Go 集测覆盖率收集方法示意图&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;但该方案有很多缺点：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;工程中需要新增测试代码，如果工程中有多个 &lt;code&gt;main&lt;/code&gt; 函数，就得为每一个 &lt;code&gt;main&lt;/code&gt; 函数编写测试用例。&lt;/li&gt;&#xA;&lt;li&gt;改变了程序启动的方式，必须加上 &lt;code&gt;-test.run&lt;/code&gt; 和 &lt;code&gt;-test.coverprofile&lt;/code&gt; 两个参数。&lt;/li&gt;&#xA;&lt;li&gt;被测程序退出后才能得到覆盖率报告，无法获取实时覆盖率。&lt;/li&gt;&#xA;&lt;li&gt;覆盖率报告只能输出到本地，需要编写脚本集中收集。&lt;/li&gt;&#xA;&lt;li&gt;分布式微服务架构下，需要对每个服务、多份报告合并才能得到整个系统的覆盖率。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;让我们看看 &lt;code&gt;goc&lt;/code&gt; 如何解决这些缺点：&lt;/p&gt;&#xA;&lt;p&gt;如果原工程是用 &lt;code&gt;go build&lt;/code&gt; 命令编译的，那么现在只需替换为 &lt;code&gt;goc build&lt;/code&gt; 命令编译，即可得到一个支持覆盖率收集的可执行文件。原工程代码无须做任何改动。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/goc/image16.gif&#34; alt=&#34;使用 goc 编译示意图&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;而使用 &lt;code&gt;goc&lt;/code&gt; 编译出的二进制，不会破坏原程序的启动方式。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;goc&lt;/code&gt; 方案中被测程序不再需要退出就能收集覆盖率。如下面动图所示。左侧是一个被测的 HTTP 服务。右侧是用 &lt;code&gt;goc&lt;/code&gt; 命令获取的实时覆盖率。上文介绍了报告最后一列代表了语句块执行的次数，当我用 &lt;code&gt;curl&lt;/code&gt; 命令访问了被测 HTTP 服务后，可以看到部分语句块执行次数从 0 变成了 1，整个测试过程被测业务正常运行。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/goc/image20.gif&#34; alt=&#34;goc 获取覆盖率示意图&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;最后覆盖率报告是统一收集、自动合并。如下动图所示，左边是两个被测的 HTTP 服务，一个监听在 5000 端口，另一个监听在 5001 端口。首先访问其中 5000 端口的服务，可以看到部分语句块执行次数从 0 变到了 1。然后访问 5001 端口的服务，语句块执行次数从 1 变成了 2。&lt;code&gt;goc&lt;/code&gt; 所展示的覆盖率报告不再是单个服务的，而是把被测系统看作了一个整体。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/goc/image23.gif&#34; alt=&#34;goc 获取分布式覆盖率示意图&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;另外动图中还展示了 &lt;code&gt;goc&lt;/code&gt; 实时清除/重置覆盖率的能力，测试人员可以结合该能力对某个功能反复测试。&lt;/p&gt;&#xA;&lt;h2&gt;goc 覆盖率收集原理&lt;/h2&gt;&#xA;&lt;p&gt;接下来我们简单介绍一下 Goc 的原理。&lt;/p&gt;&#xA;&lt;p&gt;回顾语句覆盖率的定义：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; 测试时运行被测程序后，程序中被执行到可知性语句的比率。&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;从这个定义出发我们有一个朴素的想法，能不能在每一行运行完后加入一些统计计算的逻辑去统计覆盖率呢？&lt;/p&gt;&#xA;&lt;p&gt;一些语言正是这样做的，比如 Python。Python 是带解释器的动态语言，标准库提供了方法 &lt;code&gt;sys.settrace&lt;/code&gt; 给解释器设置一个回调函数，当解释器每执行一行代码就会调用一次回调函数，传入当前行的行号，最后统计所有执行到的行数，便可得到覆盖率。C++ 没有解释器，所以只能在运行前往代码中插入技术器。但 C++ 认为每一行统计非常低效，对性能损失很大。所以，它把代码分成了很多的基本块，在基本块之间的跳转处插入一个计数器，等待程序结束之后统计这些计数器的结果，便可得到全局的覆盖率。Java 的做法和 C++ 非常类似，但没有在汇编层做插桩，而是在字节码处插桩。Java 虚拟机提供了动态改变字节码的能力，Jacoco 在跳转处插入探针 Probe 做覆盖率收集。&lt;/p&gt;&#xA;&lt;p&gt;我们回到 Go，看一下 &lt;code&gt;go test&lt;/code&gt; 单元测试怎么收集覆盖率的。Go 也是把代码分成了很多语句块。比如说这段代码就分成了三块：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/goc/go-unit-test1.png&#34; alt=&#34;Go 单测语句块&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;但和 C++、Java 在块之间跳转处插桩不同， Go 是在语句块中插入了计数器：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/goc/go-unit-test2.png&#34; alt=&#34;Go 单测语句块计数器&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;上述计数器的定义如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var GoCover = struct {&#xA;    Count     [3]uint32&#xA;    Pos       [3 * 3]uint32&#xA;    NumStmt   [3]uint16&#xA;} {&#xA;    Pos: [3 * 3]uint32{&#xA;       5, 7, 0xc000d, // [0]&#xA;       7, 9, 0x3000c, // [1]&#xA;       9, 11, 0x30008, // [2]&#xA;    }&#xA;    NumStmt: [3]uint16{&#xA;        2, // 0&#xA;        1, // 1&#xA;        1, // 2&#xA;    },&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Count 这个字段代表计数器，Pos 就是代表了语句块起始行、起始列、结束行和结束列，NumStmt 代表了语句块内的语句数。&lt;/p&gt;&#xA;&lt;p&gt;这个方案是源码级的插桩，所以势必会破坏源码。所以 &lt;code&gt;goc&lt;/code&gt; 采取的策略是首先把整个工程拷贝到临时目录：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/goc/goc-temp.png&#34; alt=&#34;goc 临时目录&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;接着使用标准库 &lt;code&gt;ast/parser&lt;/code&gt; 解析出语法树，在每个语句块中插入计数器写入临时目录，最后调用原生的 &lt;code&gt;go build/install/run&lt;/code&gt; 命令去编译插过桩的代码。&lt;/p&gt;&#xA;&lt;p&gt;除了计数器，我们还为每个 main 包注入了一个 HTTP API。调用暴露的 HTTP 接口会计算聚合每个计数器，并返回服务当前的覆盖率。插桩服务启动后，首先会访问 &lt;code&gt;goc server&lt;/code&gt; 这个注册中心，上报自己 ip 地址和 HTTP API 端口。&lt;code&gt;goc server&lt;/code&gt; 注册中心存储了每个被测服务的信息。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/goc/goc-server.png&#34; alt=&#34;goc server 注册中心&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;客户端向 &lt;code&gt;goc server&lt;/code&gt; 注册中心获取覆盖率报告时，中心会拉取所有服务的覆盖率并合并成单份报告，然后返回给客户端。&lt;/p&gt;&#xA;&lt;p&gt;在实际公测中，有用户反馈在云原生场景下集成 &lt;code&gt;goc&lt;/code&gt; 非常不便，比如 &lt;code&gt;docker/k8s&lt;/code&gt; 启动服务必须加 &lt;code&gt;-p&lt;/code&gt; 参数，将外部的端口映射到内部的端口，才能让注册中心 &lt;code&gt;goc server&lt;/code&gt; 访问到被插桩的服务。这个问题的本质是因为 &lt;code&gt;goc server&lt;/code&gt; 注册中心和被插桩服务分属不同网络，它们通过 NAT 实现网络转换。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;goc&lt;/code&gt; 在 v2 版本给出了改进方案，v2 将所有内部通信构建在了 websocket 长连接之上，整个覆盖率收集系统只需保证 &lt;code&gt;goc server&lt;/code&gt; 能被访问即可，对测试系统的部署侵入降到了最低，更适合云原生业务的测试。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/goc/goc-server-ws.png&#34; alt=&#34;goc server ws 注册中心&#34;&gt;&lt;/p&gt;&#xA;&lt;h2&gt;如何利用 goc&lt;/h2&gt;&#xA;&lt;p&gt;由于 &lt;code&gt;goc&lt;/code&gt; 输出的覆盖率报告和 Go 官方的单测覆盖率报告完全一致。一些已有的分析单测覆盖率的系统可以直接用来分析 &lt;code&gt;goc&lt;/code&gt; 收集的集测覆盖率，比如说 SonarQube、Codecov、Covralls。&lt;/p&gt;&#xA;&lt;p&gt;借助 &lt;code&gt;goc&lt;/code&gt; 覆盖率实时收集的能力还可以做精准测试。这里有两个方案：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;goc&lt;/code&gt; v1 版中，&lt;code&gt;cmd: goc profile&lt;/code&gt; 轮询获取全量覆盖率&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;goc&lt;/code&gt; v2 版中，&lt;code&gt;cmd: goc watch&lt;/code&gt; 实时推送增量覆盖率，下图展示的是实时推送的增量覆盖率&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/goc/image34.gif&#34; alt=&#34;goc watch 实时覆盖率&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;最后再展示我们实现的一个 VS Code 插件 demo，动图中随着访问不同的 HTTP API 接口，代码相应的位置被高亮了起来，研发和测试同学可以基于该插件实现精准的白盒测试。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/goc/image35.gif&#34; alt=&#34;VS Code 实时覆盖率&#34;&gt;&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2021/12/12/how-to-collect-coverage-in-go/" rel="alternate"></link>
    <summary type="html">开源一款 Go 实时覆盖率收集工具</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>传入抽象接口，返回具体类型</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2021/12/08/accept-interface-return-struct-in-go/</id>
    <content type="html">&lt;h2&gt;Go 接口的误用&lt;/h2&gt;&#xA;&lt;p&gt;在大多数强类型语言中，接口被用作描述一组类型共有的行为。比如：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Auth interface {&#xA;    GetUser() (User, error)&#xA;}&#xA;type authImpl struct {&#xA;    // ...&#xA;}&#xA;func NewAuth() Auth {&#xA;    return &amp;amp;authImpl&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;使用接口好处多多，可以让不同模块之间更好的解藕，单元测试 mock 的时候也更加方便。Java 程序员太喜欢用接口了，以至于大部分转型成 Go 的程序员认为使用接口理所当然，似乎只要充满了接口，程序架构就上了个档次。真的是这样吗？&lt;/p&gt;&#xA;&lt;p&gt;我们来看一个例子，假设有一个生产者接口 &lt;code&gt;Thinger&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package producer&#xA;&#xA;type Thinger interface { Thing() bool }&#xA;&#xA;type defaultThinger struct{}&#xA;func (t defaultThinger) Thing() bool {}&#xA;&#xA;func NewThinger() Thinger { return defaultThinger{} }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;defaultThinger&lt;/code&gt; 是具体的 &lt;code&gt;Thinger&lt;/code&gt; 生产者，这里初始化函数返回的是一个 &lt;code&gt;Thinger&lt;/code&gt; 接口。&lt;/p&gt;&#xA;&lt;p&gt;然后是消费者代码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package consumer  // consumer.go&#xA;&#xA;func Foo(t Thinger) {&#xA;    t.Thing()&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;消费者调用时使用的是 &lt;code&gt;Thinger&lt;/code&gt; 接口，另外定义 mock，方便实现单元测试：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type mockThinger struct{}&#xA;func (t mockThinger) Thing() bool {}&#xA;&#xA;func NewMock() Thinger { return mockThinger{} }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;然而，这里接口的引入并没有让两个模块彻底解藕，这段代码隐含的问题是生产者接口的任何改动，都会传导至所有的消费者。我们仔细探讨一下。&lt;/p&gt;&#xA;&lt;p&gt;作为消费者的函数 &lt;code&gt;Foo(t Thinger)&lt;/code&gt;，它对接口的需求只是 &lt;code&gt;Thing()&lt;/code&gt; 方法。作为生产者 &lt;code&gt;type Thinger interface&lt;/code&gt; 而言，它可能面对不止一个消费者，所以一旦其他消费者有了新需求，生产者接口必须新增方法。比如：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Thinger interface { &#xA;    Thing() bool &#xA;    AnotherThing() bool&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这个方法并不是 &lt;code&gt;Foo&lt;/code&gt; 所需的，但它也不得不为此改动代码，比如 &lt;code&gt;mockThinger&lt;/code&gt; 类型得实现一个 &lt;code&gt;AnotherThing()&lt;/code&gt; 才能让单测代码编译，尽管 &lt;code&gt;AnotherThing()&lt;/code&gt; 和单测毫无关系。&lt;/p&gt;&#xA;&lt;p&gt;Go 不像 Java 那样在语法层面有机制来确保接口和实现的强关联，可见，误用滥用 Go 的接口并不一定能彻底解藕。&lt;/p&gt;&#xA;&lt;h2&gt;传入抽象接口，返回具体类型&lt;/h2&gt;&#xA;&lt;p&gt;之所以上面举例时要特意用“生产者”和“消费者”这两个名词，是因为解藕的关键就在于理解它们。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;代码中具体功能的提供方为生产者&lt;/li&gt;&#xA;&lt;li&gt;代码中使用功能方为消费者&lt;/li&gt;&#xA;&lt;li&gt;相同的功能可以由多个生产者提供，例如读取输入，可以从网络、磁盘、终端上读取&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;在 Go 中，接口的真正用途是&lt;strong&gt;明确&lt;/strong&gt;消费者是对某个功能的需求，例如 &lt;code&gt;io.Copy&lt;/code&gt; 接口：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func Copy(dst io.Writer, src io.Reader) (written int64, err error)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;它希望 &lt;code&gt;src&lt;/code&gt; 可以调用 &lt;code&gt;Read&lt;/code&gt; 方法，&lt;code&gt;dst&lt;/code&gt; 可以调用 &lt;code&gt;Write&lt;/code&gt; 方法。它可以是一个 &lt;code&gt;net.TCPConn&lt;/code&gt; TCP 连接，也可以是一个 &lt;code&gt;os.File&lt;/code&gt; 文件描述符，它们都是具体的生产者。而 &lt;code&gt;io.Reader&lt;/code&gt; 和 &lt;code&gt;io.Writer&lt;/code&gt; 接口则是随着消费者 &lt;code&gt;io.Copy&lt;/code&gt; 一起定义的，所以 &lt;code&gt;net.TCPConn&lt;/code&gt; 和 &lt;code&gt;os.File&lt;/code&gt; 类型可以放心的提供其他方法而不破坏生产者和消费者之间的约定。&lt;/p&gt;&#xA;&lt;p&gt;小结一下：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;生产者返回具体类型&lt;/li&gt;&#xA;&lt;li&gt;由消费者定义接口&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;示例改进&lt;/h2&gt;&#xA;&lt;p&gt;明确了以上原则之后，回看之前的示例，问题的症结点一是作为生产者不应该自己定义接口把自己框死，初始化函数应改为返回 &lt;code&gt;defaultThinger&lt;/code&gt; 类型：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package producer&#xA;&#xA;type defaultThinger struct{}&#xA;func (t defaultThinger) Thing() bool {}&#xA;func (t defaultThinger) AnotherThing() bool {}&#xA;&#xA;func NewThinger() defaultThinger { return defaultThinger{} }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;然后把接口定义挪入消费者中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package consumer  // consumer.go&#xA;&#xA;type Thinger interface { Thing() bool }&#xA;&#xA;func Foo(t Thinger) {&#xA;    t.Thing()&#xA;}&#xA;&#xA;// mock&#xA;type mockThinger struct{}&#xA;func (t mockThinger) Thing() bool {}&#xA;&#xA;func NewMock() Thinger { return mockThinger{} }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;生产者可以随时新增 &lt;code&gt;AnotherThing()&lt;/code&gt; 方法，而消费者 &lt;code&gt;Foo&lt;/code&gt; 和相关的单测 mock 不受影响。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2021/12/08/accept-interface-return-struct-in-go/" rel="alternate"></link>
    <summary type="html">和 preemptive interface 说再见</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Go 实现 interface 与 struct 强关联</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2021/09/19/go-interface-struct-check/</id>
    <content type="html">&lt;p&gt;在 &lt;a href=&#34;/2021/07/21/from-rust-to-go/&#34;&gt;从 Rust 看 Go&lt;/a&gt; 中，我提到“当修改/增加接口内方法签名时，波及的实现类很难一下找出，只有当这些在使用接口时才会被发现”。&lt;/p&gt;&#xA;&lt;p&gt;确实，Go 在语法层面没有这样的机制来做接口和实现的强关联，但是，可以借助编译器来达到相同的效果。&lt;/p&gt;&#xA;&lt;p&gt;看下面这段的代码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Foo interface {&#xA;&#x9;FuncA()&#xA;}&#xA;&#xA;type Bar struct{}&#xA;&#xA;func (b Bar) FuncA() {}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;代码中，Bar 类型实现了 Foo 接口。这时候还没有用 Bar 类型开发代码，所以一旦 Foo 接口变动，Foo 和 Bar 之间的联系就断了。&lt;/p&gt;&#xA;&lt;p&gt;为此，我们可以添加一行：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Foo interface {&#xA;&#x9;FuncA()&#xA;}&#xA;&#xA;type Bar struct{}&#xA;&#xA;func (b Bar) FuncA() {}&#xA;&#xA;var _ Foo = Bar{}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;var _ Foo = Bar{}&lt;/code&gt; 是一个类赋值给接口的语句，它在 Foo 和 Bar 之间建立了强耦合，编译器若发现 Bar 没有实现 Foo 的某些方法便会报错。而 &lt;code&gt;_&lt;/code&gt; 在 Golang 属于一个丢弃值，所以最终编译所得的二进制不会占用额外的空间。&lt;/p&gt;&#xA;&lt;p&gt;非常巧妙～&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2021/09/19/go-interface-struct-check/" rel="alternate"></link>
    <summary type="html">Go 的 interface 和 struct 是非耦合的，interface 变动后，struct 如何感知呢？</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>exec.Command 中一个有趣的多进程死锁例子</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2021/08/05/deadlock-between-processes/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;前几天，公司开发的一个工具在某个工程中总是卡死，进入容器中再次运行，又能顺利运行，感觉挺有意思，于是便 debug 了一下。&lt;/p&gt;&#xA;&lt;p&gt;这个工具使用 Golang 编写，暂未开源，所以本文只展示部分代码。&lt;/p&gt;&#xA;&lt;h2&gt;问题描述&lt;/h2&gt;&#xA;&lt;p&gt;这个工具大致流程是&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;使用 &lt;code&gt;exec.Command&lt;/code&gt; 调用 &lt;code&gt;go list -json all&lt;/code&gt; 命令&lt;/li&gt;&#xA;&lt;li&gt;读取 &lt;code&gt;stdout&lt;/code&gt; / &lt;code&gt;stderr&lt;/code&gt;，再使用 &lt;code&gt;json.NewDecoder&lt;/code&gt; 解析&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;代码大致为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;cmd := exec.Command(&amp;quot;go&amp;quot;, &amp;quot;list&amp;quot;, &amp;quot;-json&amp;quot;, &amp;quot;all&amp;quot;)&#xA;stdouIn, _ := cmd.StdoutPipe()&#xA;stderrIn, _ := cmd.StderrPipe()&#xA;&#xA;var stderrBuf bytes.Buffer&#xA;&#xA;cmd.Start()&#xA;&#xA;dec := json.NewDecoder(stdouIn)&#xA;dg = &amp;amp;DepGraph{}&#xA;for {&#xA;    var di DepInfo&#xA;    dec.Decode(&amp;amp;di)&#xA;}&#xA;&#xA;_, errStderr := io.Copy(&amp;amp;stderrBuf, stderrIn)&#xA;if errStderr != nil {&#xA;    panic(err)&#xA;}&#xA;&#xA;cmd.Wait()&#xA;&#xA;fmt.Println(&amp;quot;done&amp;quot;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;问题：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;程序未 &lt;code&gt;panic&lt;/code&gt; 异常退出&lt;/li&gt;&#xA;&lt;li&gt;程序未输出 &lt;code&gt;done&lt;/code&gt;，即未正常退出，卡死&lt;/li&gt;&#xA;&lt;li&gt;命令后手动执行 &lt;code&gt;go list -json all&lt;/code&gt; 可正常快速退出&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;好吧-_-，粗看程序一点问题没有，但就是卡了～&lt;/p&gt;&#xA;&lt;h2&gt;调试记录&lt;/h2&gt;&#xA;&lt;h3&gt;怀疑 1，go list 有 bug？&lt;/h3&gt;&#xA;&lt;p&gt;使用 dlv 挂载 go list 进程 &lt;code&gt;dlv attach [pid]&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;查看所有 goroutine 的状态：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(dlv) grs&#xA;  Goroutine 836 - User: /usr/local/go/src/runtime/sema.go:61 internal/poll.runtime_Semacquire (0x447782) [semacquire 450776h20m59.570725376s]&#xA;  Goroutine 837 - User: /usr/local/go/src/runtime/sema.go:61 internal/poll.runtime_Semacquire (0x447782) [semacquire 450776h21m0.466524491s]&#xA;  Goroutine 838 - User: /usr/local/go/src/runtime/proc.go:310 sync.runtime_notifyListWait (0x4489c8) [sync.Cond.Wait 450776h20m57.704548061s]&#xA;  Goroutine 839 - User: /usr/local/go/src/syscall/asm_linux_amd64.s:24 syscall.Syscall (0x4b2efb) (thread 65) [GC assist marking 450776h21m0.664929027s]&#xA;  Goroutine 840 - User: /usr/local/go/src/runtime/sema.go:61 internal/poll.runtime_Semacquire (0x447782) [semacquire 450776h20m59.617378098s]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;839 goroutine&lt;/code&gt; 停在了 &lt;code&gt;syscall.Syscall&lt;/code&gt; 系统调用上，看起来比较可疑，详细查看该 goroutine 的调用栈：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(dlv) gr 839&#xA;Switched from 0 to 839 (thread 65)&#xA;(dlv) bt&#xA;...&#xA;4 0x00000000004d1267 in os.(*File).write&#xA;at /usr/local/go/src/os/file_unix.go:280&#xA;5 0x00000000004d1267 in os.(*File).Write&#xA;at /usr/local/go/src/os/file.go:153&#xA;6 0x00000000004dc125 in fmt.Fprintf&#xA;at /usr/local/go/src/fmt/print.go:205&#xA;7 0x00000000008bae71 in cmd/go/internal/modfetch.DownloadZip.func1&#xA;at /usr/local/go/src/cmd/go/internal/modfetch/fetch.go:176&#xA;8 0x0000000000791043 in cmd/go/internal/par.(*Cache).Do&#xA;at /usr/local/go/src/cmd/go/internal/par/work.go:128&#xA;9 0x00000000008ae283 in cmd/go/internal/modfetch.DownloadZip&#xA;at /usr/local/go/src/cmd/go/internal/modfetch/fetch.go:163&#xA;10 0x00000000008ad8be in cmd/go/internal/modfetch.download&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;查看对应 Golang 版本的 &lt;code&gt;go/src/cmd/go/internal/modfetch/fetch.go:176&lt;/code&gt; &lt;a href=&#34;https://github.com/golang/go/blob/d571a77846dfee8efd076223a882915cd6cb52f4/src/cmd/go/internal/modfetch/fetch.go#L176&#34;&gt;源码&lt;/a&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;if cfg.CmdName != &amp;quot;mod download&amp;quot; {&#xA;&#x9;fmt.Fprintf(os.Stderr, &amp;quot;go: downloading %s %s\n&amp;quot;, mod.Path, mod.Version)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;大致浏览一下上下文，可以知道目前 &lt;code&gt;go list -json all&lt;/code&gt; 正在下载 &lt;code&gt;go mod&lt;/code&gt; 依赖，并把下载结果打印到 &lt;code&gt;os.Stderr&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;而现在输出正卡死在 &lt;code&gt;os.Stderr&lt;/code&gt; 上。这和我们的直觉相违，&lt;code&gt;stdout&lt;/code&gt; / &lt;code&gt;stderr&lt;/code&gt; 这两个应该不会阻塞的呀。&lt;/p&gt;&#xA;&lt;h3&gt;怀疑 2，卡死在工具上？&lt;/h3&gt;&#xA;&lt;p&gt;按照怀疑 1 的调试步骤，查看工具本身的调用栈：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(dlv) gr 1&#xA;Switched from 0 to 1 (thread 25)&#xA;(dlv) bt&#xA;8 0x00000000004f8aeb in encoding/json.(*Decoder).refill&#xA;at /usr/local/go/src/encoding/json/stream.go:165&#xA;9 0x00000000004f887f in encoding/json.(*Decoder).readValue&#xA;at /usr/local/go/src/encoding/json/stream.go:140&#xA;10 0x00000000004f843c in encoding/json.(*Decoder).Decode&#xA;at /usr/local/go/src/encoding/json/stream.go:63&#xA;11 0x000000000067555e in github.com/ma6174/go_dep_search/depgraph.LoadDeps&#xA;at /Users/xxxxx/go/pkg/mod/github.com/ma6174/go_dep_search@v0.0.0-20200721060312-bfd635bcc992/depgraph/depgraph.go:195&#xA;12 0x00000000006a73ef in main.listAndSearch&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;确认，卡死在 &lt;code&gt;dec.Decode(&amp;amp;di)&lt;/code&gt; 上，即卡死在 &lt;code&gt;di io.Reader&lt;/code&gt; 上。&lt;/p&gt;&#xA;&lt;h3&gt;阶段结论&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;go list -json all&lt;/code&gt; 卡死在输出 &lt;code&gt;stderr&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;工具卡死在读 &lt;code&gt;stdin&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;那很明显了，工具进程和 &lt;code&gt;go list&lt;/code&gt; 进程出现了某种死锁。&lt;/p&gt;&#xA;&lt;h2&gt;分析&lt;/h2&gt;&#xA;&lt;p&gt;首先，Golang 中 &lt;code&gt;exec.Command&lt;/code&gt; 会创建一个子进程，在 Linux 系统上，&lt;code&gt;cmd.StderrPipe&lt;/code&gt; 会调用 pipe(管道) 来作为父子进程间通信的方式：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;StderrPipe() -&amp;gt; os.Pipe() -&amp;gt; syscall.Pipe2(p[0:], syscall.O_CLOEXEC)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;然后，&lt;code&gt;go list&lt;/code&gt; 会先使用 &lt;code&gt;go mod download&lt;/code&gt; 下载依赖的包，当一个包下载完成，便会输出一行 &lt;code&gt;go: downloading xxx&lt;/code&gt; 到 &lt;code&gt;stderr&lt;/code&gt; 上。在所有包下载完毕后，才会开始包依赖分析，最后才将分析结果输出到 &lt;code&gt;stdout&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;回看工具的代码，可以看到父子进程间其实是如下的关系：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;父进程(工具) -&amp;gt; 读取 stdout pipe  -&amp;gt; 读取 stderr pipe &#xA;子进程(go list) -&amp;gt; 写到 stderr pipe  -&amp;gt; 写到 stdout pipe &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;两者读写的 pipe 交错了起来，&lt;code&gt;go list&lt;/code&gt; 写完 &lt;code&gt;stderr pipe&lt;/code&gt; 才会写 &lt;code&gt;stdout pipe&lt;/code&gt;，而工具读完 &lt;code&gt;stdout pipe&lt;/code&gt; 才会读 &lt;code&gt;stderr pipe&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;在 Linux 上，pipe 大小是有限的，普通情况下，上面的逻辑并没有暴露问题。但如果下载的依赖包特别多，导致 &lt;code&gt;stderr pipe&lt;/code&gt; 被塞满，&lt;code&gt;go list&lt;/code&gt; 便会阻塞在写 &lt;code&gt;stderr pipe&lt;/code&gt; 上，后续的 &lt;code&gt;stdout pipe&lt;/code&gt; 也就走不到了，而父进程一直在等待 &lt;code&gt;stdout pipe&lt;/code&gt; 输出的数据。。形成一个死锁。&lt;/p&gt;&#xA;&lt;h2&gt;解决方案&lt;/h2&gt;&#xA;&lt;p&gt;解决方案很简单，直接使用标准库提供的 &lt;code&gt;func (c *Cmd) Output() ([]byte, error)&lt;/code&gt; 或 &lt;code&gt;func (c *Cmd) CombinedOutput() ([]byte, error)&lt;/code&gt; 来获取子进程输出。&lt;/p&gt;&#xA;&lt;p&gt;如非必要，不要直接操作 pipe。&lt;/p&gt;&#xA;&lt;h2&gt;联想&lt;/h2&gt;&#xA;&lt;p&gt;pipe 的死锁问题让我联想到另一个经典的 socket 编程死锁案例。socket 编程也是一种多进程/跨机多进程通信方式。&lt;/p&gt;&#xA;&lt;p&gt;创建一个 TCP 链接，一端往另一端发送数据，会死锁吗？答案是会的。看下面的例子：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// 接收端&#xA;func main() {&#xA;&#x9;ln, err := net.Listen(&amp;quot;tcp&amp;quot;, &amp;quot;:12345&amp;quot;)&#xA;&#x9;if err != nil {&#xA;&#x9;&#x9;panic(err)&#xA;&#x9;}&#xA;&#xA;&#x9;for {&#xA;&#x9;&#x9;_, err := ln.Accept()&#xA;&#x9;&#x9;if err != nil {&#xA;&#x9;&#x9;&#x9;panic(err)&#xA;&#x9;&#x9;}&#xA;&#x9;}&#xA;}&#xA;&#xA;// 发送端&#xA;func main() {&#xA;&#x9;conn, err := net.Dial(&amp;quot;tcp&amp;quot;, os.Args[1])&#xA;&#x9;if err != nil {&#xA;&#x9;&#x9;panic(err)&#xA;&#x9;}&#xA;&#x9;i := 0&#xA;&#x9;for {&#xA;&#x9;&#x9;_, err := conn.Write([]byte(&amp;quot;1&amp;quot;))&#xA;&#x9;&#x9;if err != nil {&#xA;&#x9;&#x9;&#x9;panic(err)&#xA;&#x9;&#x9;}&#xA;&#x9;&#x9;i++&#xA;&#x9;&#x9;fmt.Println(i)&#xA;&#x9;}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在我的电脑上，发送端输出如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;1&#xA;2&#xA;...&#xA;2616001&#xA;2616002&#xA;2616003&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;打印到 &lt;code&gt;2616003&lt;/code&gt; 便停止输出卡住了，阻塞在了 &lt;code&gt;conn.Write([]byte(&amp;quot;1&amp;quot;))&lt;/code&gt;。表象和上文 pipe 的例子非常相似。&lt;/p&gt;&#xA;&lt;p&gt;分析一下发送端程序，当调用 &lt;code&gt;conn.Write([]byte(&amp;quot;1&amp;quot;))&lt;/code&gt; 后，函数成功返回，从程序员角度看，似乎接收端这时候应该是已经收到了 &lt;code&gt;1&lt;/code&gt;。但其实接收端调用 &lt;code&gt;ln.Accept()&lt;/code&gt; 之后，并没有去读取连接上的数据。收到的数据去哪了？使用 &lt;code&gt;netstat&lt;/code&gt; 命令看一下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ netstat -anp&#xA;Proto Recv-Q Send-Q  Local Address           Foreign Address         State       PID/Program name&#xA;tcp        0 2548608 127.0.0.1:46196         127.0.0.1:12345         ESTABLISHED 70072/main&#xA;tcp6   67395       0 127.0.0.1:12345         127.0.0.1:46196         ESTABLISHED 69896/main&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到，数据都堆积在了接收队列 &lt;code&gt;Recv-Q&lt;/code&gt; 和发送队列 &lt;code&gt;Send-Q&lt;/code&gt;，而且正好 &lt;code&gt;2548608+67395=2616003&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;P.S. TCP 协议的可靠性，只是保证双方的协议栈能可靠收发数据，应用程序的可靠性需要应用层协议来保证。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2021/08/05/deadlock-between-processes/" rel="alternate"></link>
    <summary type="html">什么情况会在不经意间造成多进程死锁？</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>从 Rust 看 Go</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2021/07/21/from-rust-to-go/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;Rust 是一门着眼于安全、速度和并发的编程语言。&lt;/p&gt;&#xA;&lt;p&gt;程序除了业务问题外，最常见的就是安全问题。从前 C++ 存在着内存管理、数据共享时“野指针”等问题。Go 和 Rust 在改善 C++ 的问题上走了两条完全不同的路。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Go 靠垃圾回收，Java/Python 有垃圾回收+虚拟机&lt;/li&gt;&#xA;&lt;li&gt;Rust 则靠的是&lt;strong&gt;编译器&lt;/strong&gt;与程序员的种种&lt;strong&gt;约定&lt;/strong&gt;规则&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;在七牛，主力语言是 Go，为什么我们还要学习一门新语言 - 他山之石。新的语言，代表着对事物更新的理解和更好的阐述方式，可以帮助我们更好地编写 Go 代码。&lt;/p&gt;&#xA;&lt;p&gt;P.S. Rust 语言学习曲线陡峭，不适合初学者，即使简单的代码也需要融汇贯通所有概念。但本文并不要求你有 Rust 背景。&lt;/p&gt;&#xA;&lt;h2&gt;变量可变性&lt;/h2&gt;&#xA;&lt;p&gt;首先，变量默认是&lt;strong&gt;不可变的&lt;/strong&gt;，意味着如下的代码会报错：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let x = 1;&#xA;x = 2;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果要改变，则需要显式的将变量声明为可变：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let mut x = 1;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这看起来增加了程序员的负担，但在多线程环境下，意味着只读不写，在编译时更易推理出潜在的并发读写问题。&lt;/p&gt;&#xA;&lt;h2&gt;变量所有权&lt;/h2&gt;&#xA;&lt;p&gt;这是 Rust 特有的概念。编程中，我们经常需要把一个对象传来传去，&lt;/p&gt;&#xA;&lt;h3&gt;理解 = 的意义&lt;/h3&gt;&#xA;&lt;p&gt;现在我们从 Rust 的角度重新看待 &lt;code&gt;=&lt;/code&gt; 操作符。&lt;/p&gt;&#xA;&lt;p&gt;Rust 强化了“所有权”的概念：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Rust 每一个值都有一个所有者变量与之绑定&lt;/li&gt;&#xA;&lt;li&gt;是所有者的变量只能有一个&lt;/li&gt;&#xA;&lt;li&gt;当所有着变量离开作用时，绑定解除，值被丢弃&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;我们分两种情况：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Move 语义&#xA;&lt;ul&gt;&#xA;&lt;li&gt;定义变量我们会使用 &lt;code&gt;=&lt;/code&gt; 符号：&lt;code&gt;let x = String::from(&amp;quot;hello&amp;quot;);&lt;/code&gt; 。在 Rust 中这应该理解为：内存中有一个字符串，有变量 x 与之绑定，x 是该字符串的所有者&lt;/li&gt;&#xA;&lt;li&gt;复制时我们也会用 &lt;code&gt;=&lt;/code&gt; 符号：&lt;code&gt;y = x&lt;/code&gt;。在 Rust 中应该理解为：x 放弃对字符串的所有权，转移给 y。也就意味着使用“复制”来形容 &lt;code&gt;=&lt;/code&gt; 符号，不再合适，这里应称为 &lt;code&gt;Move&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Copy 语义&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;=&lt;/code&gt; 符号意味着复制，&lt;code&gt;y = x&lt;/code&gt;，y 得到了一份拷贝，两个变量的所有权互不干扰&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;变量所有权只能有一个，但 Rust 提供“借用”的方法：不可变借用 &lt;code&gt;&amp;amp;&lt;/code&gt; 与可变借用 &lt;code&gt;&amp;amp;mut&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;p&gt;通过借用，可实现变量的共享访问。（Rust 严格规定：在任意时刻，要么只能有一个可变引用，要么只能有多个不可变引用。）&lt;/p&gt;&#xA;&lt;p&gt;所有权、借用、可变不可变如何防止潜在错误呢？让我们看四个例子。&lt;/p&gt;&#xA;&lt;p&gt;例 1：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;struct T(u64);&#xA;&#xA;fn main() {&#xA;    let a = T(42);&#xA;    let b = bar(a);&#xA;    let c = bar(a); // 错误&#xA;}&#xA;&#xA;fn bar(x: T) -&amp;gt; u64 {&#xA;    x.0 * 2&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这里 bar 函数传参数是 &lt;code&gt;Move&lt;/code&gt; 语义，第一次转移后，a 已经不再拥有原值的所有权。&lt;/p&gt;&#xA;&lt;p&gt;例 2：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;struct T(u64);&#xA;&#xA;fn main() {&#xA;    let a = T(42);&#xA;    let b = bar(&amp;amp;a);&#xA;    let c = bar(&amp;amp;a);&#xA;}&#xA;&#xA;fn bar(x: &amp;amp;T) -&amp;gt; u64 {&#xA;    x.0 * 2&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;bar 函数参数是不可变借用，所以可以重复调用。&lt;/p&gt;&#xA;&lt;p&gt;例 3：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;struct T(u64);&#xA;&#xA;fn main() {&#xA;    let a = T(42);&#xA;    let b = bar(&amp;amp;a); &#xA;}&#xA;&#xA;fn bar(x: &amp;amp;T) -&amp;gt; u64 {&#xA;    x.0 += 1 // 错误&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;bar 函数参数是不可变借用，赋值操作改变了值，引起冲突。&lt;/p&gt;&#xA;&lt;p&gt;例 4：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;struct T(u64);&#xA;&#xA;fn main() {&#xA;    let mut a = T(42);&#xA;    let b = bar(&amp;amp;mut a);&#xA;}&#xA;&#xA;fn bar(x: &amp;amp;mut T) -&amp;gt; u64 {&#xA;    x.0 += 1&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;bar 函数参数是可变借用，操作合法。&lt;/p&gt;&#xA;&lt;p&gt;让我们看看 Go 中如下的代码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func main() {&#xA;    arr := []int{1, 2, 3}&#xA;    if IsOdd(arr) == true {&#xA;        fmt.Println(&amp;quot;got&amp;quot;)&#xA;    }&#xA;}&#xA;&#xA;func IsOdd(arr []int) bool {&#xA;    ...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;main 函数中我们调用 &lt;code&gt;IsOdd&lt;/code&gt; 函数来判断数组中是否有奇数，假如 &lt;code&gt;IsOdd&lt;/code&gt; 是外部库引入，或者是由团队内其他同学提供，我们是否有把握数组不会被误更改？可见，变量传递在 Rust 中如此精细，可有效的防止类似的错误。&lt;/p&gt;&#xA;&lt;h3&gt;所有权与并发安全&lt;/h3&gt;&#xA;&lt;p&gt;所有权的强化也促进了并发安全，让我们看看这段 Go 代码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func main() {&#xA;    m := make(map[int]int)&#xA;&#xA;    go func() {&#xA;        for {&#xA;            time.Sleep(time.Millisecond)&#xA;            _, _ = m[1]&#xA;        }&#xA;    }()&#xA;&#xA;    go func() {&#xA;        for {&#xA;            time.Sleep(time.Millisecond)&#xA;            m[1]++&#xA;        }&#xA;    }()&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;两个 goroutine，一个读一个写，存在并发安全问题，需要加互斥锁，或者使用 &lt;code&gt;Sync.Map&lt;/code&gt;。那 Rust 如何避免呢？我们看下等价的 Rust 代码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let mut m: HashMap&amp;lt;u64, u64&amp;gt; = HashMap::new();&#xA;&#xA;tread::spawn(move || loop {&#xA;    thread::sleep(time::Duration::from_millis(1));&#xA;    let _ = m.get(&amp;amp;1); // m 所有权被转移&#xA;})&#xA;&#xA;tread::spawn(move || {&#xA;    let mut i = 0;&#xA;    loop {&#xA;        thread::sleep(time::Duration::from_millis(1));&#xA;        i += 1;&#xA;        m.insert(i, 1); // 已被转移，错误&#xA;    }&#xA;})&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;首先闭包传递要求 &lt;code&gt;Move&lt;/code&gt; 语义，所以字典 m 的所有权会被移入第一个线程。当第二个线程再使用字典 m 时已无所有权，编译器便会报错，阻止你用错误的方法并发访问字典 m。Rust 另有正确方法来并发读写（使用 Arc 和 Mutex），这里不再介绍。&lt;/p&gt;&#xA;&lt;p&gt;Rust 与 Go 相比：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Go 中既可以正确的编写并发代码，也可以错误的编写并发代码，编译器不管&lt;/li&gt;&#xA;&lt;li&gt;Rust 中错误的并发方法无法通过编译&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;资源管理&lt;/h2&gt;&#xA;&lt;h3&gt;传值 vs 传引用&lt;/h3&gt;&#xA;&lt;p&gt;变量专递还存在着经典的“传值 vs 传引用”问题。&lt;/p&gt;&#xA;&lt;p&gt;比如：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;a := 1&#xA;b = a&#xA;b = 6&#xA;fmt.Println(a, b) // 1, 6&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;与&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;a := []int{1, 2, 3}&#xA;b = a&#xA;b[1] = 6&#xA;fmt.Println(a, b) // {1, 6, 3} {1, 6, 3}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Go 初学者分不清区别，老手一不留神也会搞错。&lt;/p&gt;&#xA;&lt;p&gt;这里问题根源和资源管理的方式有关。变量在内存中一般有两种方式：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;栈管理&lt;/li&gt;&#xA;&lt;li&gt;栈 + 堆管理&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3&gt;栈管理&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;函数调用时，会压栈，调用结束返回上一层函数时，会弹栈（处理器支持）&lt;/li&gt;&#xA;&lt;li&gt;对于基础类型/非变长类型的函数内局部变量，可以直接在当前函数栈内分配，这些栈内分配的内存就是资源&lt;/li&gt;&#xA;&lt;li&gt;由于弹栈操作，分配的内存即被回收，无需特殊的逻辑处理&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;栈 + 堆管理&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;对于变长类型（Go 语言的 map/slice，Rust 的 Vec&lt;T&gt; / Map&amp;lt;K, V&amp;gt; 等等）无法在栈内预先分配内存&lt;/li&gt;&#xA;&lt;li&gt;在栈上存放指针，指针本身大小确定，指针指向堆，堆上分配的内存大小可变&lt;/li&gt;&#xA;&lt;li&gt;Go 用垃圾回收释放堆内存&lt;/li&gt;&#xA;&lt;li&gt;Rust 由上文提到的所有权保证离开作用域时释放&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;对 Go 的思考&lt;/h3&gt;&#xA;&lt;p&gt;再来看“传值 vs 传引用”的问题。无论传值还是传引用，都是对栈管理的值（部分值）的拷贝，即：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;所谓传值，栈拷贝复制了值的所有部分&lt;/li&gt;&#xA;&lt;li&gt;所谓传引用，栈拷贝只复制了栈上的指针部分，堆的部分没有复制。两个指针指向同一个堆&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;空值与错误处理&lt;/h2&gt;&#xA;&lt;p&gt;ust 有强大的类型系统，支持 enum + 模板类型。它将空值定义为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;struct Option&amp;lt;T&amp;gt; {&#xA;    Some(T),&#xA;    None,&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;将错误定义为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;enum Result&amp;lt;T, E&amp;gt; {&#xA;   Ok(T),&#xA;   Err(E),&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;空值&lt;/h3&gt;&#xA;&lt;p&gt;Go 在测试与生产环境中难免遇到空指针异常，比如：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type struct A {&#xA;    str *string&#xA;    dic map[int]string&#xA;}&#xA;&#xA;func (a *A) test() {&#xA;    *a.str += &amp;quot;world&amp;quot;&#xA;    a.dic[1] = &amp;quot;hello&amp;quot;&#xA;}&#xA;&#xA;aa = A{}&#xA;aa.test()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;go 会对变量默认初始化，所以 &lt;code&gt;aa.str&lt;/code&gt; 得到的是一个未指向任何 string 的空指针，&lt;code&gt;aa.dic&lt;/code&gt; 是也未指向 map。调用 &lt;code&gt;aa.test()&lt;/code&gt; 就会发生多种空指针异常：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;panic: runtime error: invalid memory address or nil pointer dereference&#xA;&#xA;panic: assignment to entry in nil map&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;类似代码在 Rust 里面会怎么样呢？&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;struct A {&#xA;    ss: Option&amp;lt;Box&amp;lt;String&amp;gt;&amp;gt;,&#xA;    dic: HashMap&amp;lt;i64, String&amp;gt;,&#xA;}&#xA;&#xA;impl A {&#xA;    fn test(&amp;amp;self) {&#xA;        match self.ss {&#xA;            Some(_) =&amp;gt; ...,&#xA;            None =&amp;gt; ...&#xA;        } &#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Rust 要求必须显式初始化，dic 未指向 map 的问题就解了。然后，无论成员变量 ss 初始化为 &lt;code&gt;Some(T)&lt;/code&gt; 还是 &lt;code&gt;None&lt;/code&gt;，match 语法会要求程序员对每种情况都编码，从而避免“空指针”。&lt;/p&gt;&#xA;&lt;h3&gt;错误处理&lt;/h3&gt;&#xA;&lt;p&gt;Go 和 Rust 都没有使用抛异常，而是返回 err 的方式来处理错误。比如 Go：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;result, err := do_something()&#xA;if err != nil {&#xA;    return nil, err&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Go 采用多返回值方式，程序报错返回错误问题，通过判断 &lt;code&gt;err != nil&lt;/code&gt; 来决定程序是否继续执行或终止该逻辑。当然，如果接触过 Go 项目时，会发现程序中大量充斥着 &lt;code&gt;if err != nil&lt;/code&gt; 的代码，判断是手动逻辑，往往我们可能因为疏忽，导致这段逻辑缺失，缺少校验。&lt;/p&gt;&#xA;&lt;p&gt;Rust 里怎么做呢：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn do_something() -&amp;gt; Result&amp;lt;u64&amp;gt; {&#xA;    Ok(4)&#xA;}&#xA;&#xA;let result = do_something();&#xA;match result {&#xA;    Ok(_) =&amp;gt; {},&#xA;    Err(_) =&amp;gt; {},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;首先，有 match 语句保证每个枚举值必须得到处理，否则编译器就会报错。进一步的，无论有没有错误返回，上层逻辑只需要面对一个值（即例子中的 result），多个函数可以实现链式调用。&lt;/p&gt;&#xA;&lt;h2&gt;面向接口编程&lt;/h2&gt;&#xA;&lt;p&gt;Go 的 interface 和 Rust 的 trait 类似，都是面向接口编程，但有些差别：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Go 不需要 struct 显式地指定 interface 实现：它只需要实现接口中定义的所有方法。它们之间是松耦合的关系，靠编译器最终编译时才能串联&lt;/li&gt;&#xA;&lt;li&gt;Rust 需要显式声明 struct 实现某个 trait。而且，Rust 还支持为不是自己定义的类型增加 trait 实现。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;在我看来，Go 这种松耦合关系有几个缺点。&lt;/p&gt;&#xA;&lt;p&gt;首先，通过文档（godoc），很难一眼看出类型是否符合特定接口，比如，&lt;a href=&#34;https://golang.org/pkg/net/#TCPConn&#34;&gt;TCPConn 类型&lt;/a&gt;，初看文档，完全不知道它是否符合 &lt;a href=&#34;https://golang.org/pkg/io/#Writer&#34;&gt;Writer 接口&lt;/a&gt; 和 &lt;a href=&#34;https://golang.org/pkg/io/#Reader&#34;&gt;Reader 接口&lt;/a&gt;，仔细比对方法签名，才能确认。&lt;/p&gt;&#xA;&lt;p&gt;然后就是当修改/增加接口内方法签名时，波及的实现类很难一下找出，只有当这些在使用接口时才会被发现。&lt;/p&gt;&#xA;&lt;p&gt;Rust 的 trait 实现强制声明就很好的解决了上述两个痛点。对于文档，类型所有实现的 trait 都一目了然。而当 trait 变动，而类型定义却没有更改时编译器会报错。&lt;/p&gt;&#xA;&lt;h2&gt;包管理&lt;/h2&gt;&#xA;&lt;p&gt;Go 的包管理器 &lt;code&gt;go mod&lt;/code&gt; 起步太晚，Go 1.13 才迈入生产环境，而且其设计理念过于理想化，在主流语言的包管理中独树一帜，现在讨论它优劣还为时过早，可参考笔者做的相关&lt;a href=&#34;http://www.lyyyuna.com/2020/02/22/go-the-principles-versioning-in-go/&#34;&gt;分享&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;Rust 的包管理 &lt;code&gt;cargo&lt;/code&gt; 很早便有了，它不仅是包管理工具，更是项目组织管理工具，从项目的建立、构建到测试、运行直至部署，为 Rust 项目的管理提供尽可能完整的手段。&lt;/p&gt;&#xA;&lt;h2&gt;总结&lt;/h2&gt;&#xA;&lt;p&gt;我们总结出一些有助于提升 Go 代码安全性的 Tips：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;思考变量是否是可变的&lt;/li&gt;&#xA;&lt;li&gt;思考变量是否是共享的，并加以并发保护&lt;/li&gt;&#xA;&lt;li&gt;思考变量是值传递还是引用传递，避免副作用&lt;/li&gt;&#xA;&lt;li&gt;不要遗漏 err 和 nil&lt;/li&gt;&#xA;&lt;li&gt;涉及接口的变动要慎重&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Rust 特性和编程范式极多，本文不可能一一阐述，有兴趣的同学可以移步&lt;a href=&#34;https://doc.rust-lang.org/book/&#34;&gt;官方教程&lt;/a&gt;。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2021/07/21/from-rust-to-go/" rel="alternate"></link>
    <summary type="html">从 Rust 的设计哲学中可以借鉴什么？</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Golang 官方关于单元测试方法的一些建议</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2021/01/01/go-unit-test-comments/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;本文是翻译+理解+改编自 Go 官方的&lt;a href=&#34;https://github.com/golang/go/wiki/TestComments&#34;&gt;TestComments&lt;/a&gt;，原文是 Go 源码本身开发时&lt;code&gt;Code Review&lt;/code&gt;的注意项。&lt;/p&gt;&#xA;&lt;h2&gt;断言&lt;/h2&gt;&#xA;&lt;p&gt;在测试时避免使用断言库。那些有类似&lt;code&gt;xUnit&lt;/code&gt;测试框架使用背景的 Go 开发者喜欢写如下的代码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;assert.isNotNil(t, &amp;quot;obj&amp;quot;, obj)&#xA;assert.stringEq(t, &amp;quot;obj.Type&amp;quot;, obj.Type, &amp;quot;blogPost&amp;quot;)&#xA;assert.intEq(t, &amp;quot;obj.Comments&amp;quot;, obj.Comments, 2)&#xA;assert.stringNotEq(t, &amp;quot;obj.Body&amp;quot;, obj.Body, &amp;quot;&amp;quot;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;但有的断言库会过早的终止测试用例（如果断言中调用了&lt;code&gt;t.Fatalf&lt;/code&gt;或者&lt;code&gt;panic&lt;/code&gt;），有的会漏掉测试如何通过的关键信息。测试应该是精确的，能够一眼看出哪些部分导致用例失败，哪些部分是正确的。不仅如此，放着 Go 的语法不用，断言库却常常创造自己的一整套语法来做非空判断（&lt;code&gt;isNotNil&lt;/code&gt;）、字符串比较（&lt;code&gt;stringEq&lt;/code&gt;）、表达式求值等等。&lt;/p&gt;&#xA;&lt;p&gt;综上，上面那个例子应该改写为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;if obj == nil || obj.Type != &amp;quot;blogPost&amp;quot; || obj.Comments != 2 || obj.Body == &amp;quot;&amp;quot; {&#xA;    t.Errorf(&amp;quot;AddPost() = %+v&amp;quot;, obj)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;使用可读性高的子测试用例名&lt;/h2&gt;&#xA;&lt;p&gt;当使用&lt;code&gt;t.Run&lt;/code&gt;来创建子测试时，第一个参数是用例的名字。为了确保测试结果在日志上具备高可读性，用例名应该描述要测试的场景，并保证在转义后仍可读（测试用例执行时，会将空格转换为下划线，并转义不可打印的字符）。&lt;/p&gt;&#xA;&lt;p&gt;也可以在子测试的函数体中使用&lt;code&gt;t.Log&lt;/code&gt;打印子测试用例名，或者包含在失败信息中，这两个地方用例名都不会被转义。&lt;/p&gt;&#xA;&lt;h2&gt;直接比较结构体&lt;/h2&gt;&#xA;&lt;p&gt;如果函数返回的是结构体，不推荐一个一个字段的比较，而是构造出你预期的结果，用下文提到的&lt;a href=&#34;#%E7%9B%B8%E7%AD%89%E6%80%A7%E6%AF%94%E8%BE%83%E5%92%8Cdiff&#34;&gt;cmp 方法&lt;/a&gt;直接比较。该规则同样适用于数组和字典。&lt;/p&gt;&#xA;&lt;p&gt;如果结构体之间是某种语义上的相等，或者某些字段不支持比较操作（比如类型为&lt;code&gt;io.Reader&lt;/code&gt;的字段），那你可以在&lt;a href=&#34;https://godoc.org/github.com/google/go-cmp/cmp#Diff&#34;&gt;cmp.Diff&lt;/a&gt;和&lt;a href=&#34;https://godoc.org/github.com/google/go-cmp/cmp#Equal&#34;&gt;cmp.Equal&lt;/a&gt;的参数中传入类型为&lt;a href=&#34;https://godoc.org/github.com/google/go-cmp/cmp/cmpopts&#34;&gt;cmpopts&lt;/a&gt;的&lt;a href=&#34;https://godoc.org/github.com/google/go-cmp/cmp/cmpopts#IgnoreInterfaces&#34;&gt;cmpopts.IgnoreInterfaces&lt;/a&gt;来忽略它们。要是还不行，那，就自由发挥吧。&lt;/p&gt;&#xA;&lt;p&gt;如果函数返回多个结果，逐个比较并打印，不必拼成一个结构体。&lt;/p&gt;&#xA;&lt;h2&gt;只比较稳定的结果&lt;/h2&gt;&#xA;&lt;p&gt;如果被测函数依赖的外部包不受控制，导致输出结果不稳定，就该避免在测试中使用该结果。相反，应该去比较那些在语义上稳定的信息。&lt;/p&gt;&#xA;&lt;p&gt;那些输出格式化/序列化字符串的功能，不该假设其输出的字符串一尘不变。举个实际的例子，&lt;code&gt;json.Marshal&lt;/code&gt;并不保证输出的字节流永远是相同的，历史上该函数的实现变动过。如果从字符串是否相等的角度去测试&lt;code&gt;json&lt;/code&gt;库，那测试用的执行结果无法稳定。而鲁棒性的做法应去解析 JSON 字符串，然后比较其中的每个对象。&lt;/p&gt;&#xA;&lt;h2&gt;相等性比较和diff&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;==&lt;/code&gt;操作符会按照&lt;a href=&#34;https://golang.org/ref/spec#Comparison_operators&#34;&gt;Go 语言规范&lt;/a&gt;定义的行为执行相等比较。数字、字符串和指针可以执行比较操作，结构体的每个字段如果都是以上三种类型，那结构体也可做比较。其中指针比较特别，只支持相等操作。&lt;/p&gt;&#xA;&lt;p&gt;使用&lt;a href=&#34;https://godoc.org/github.com/google/go-cmp/cmp&#34;&gt;cmp&lt;/a&gt;包的&lt;a href=&#34;https://godoc.org/github.com/google/go-cmp/cmp#Equal&#34;&gt;cmp.Equal&lt;/a&gt;可直接比较两个任意的对象，使用&lt;a href=&#34;https://godoc.org/github.com/google/go-cmp/cmp#Diff&#34;&gt;cmp.Diff&lt;/a&gt;则会输出这两个对象间的差异，而且可读性非常高。&lt;/p&gt;&#xA;&lt;p&gt;虽然&lt;code&gt;cmp&lt;/code&gt;不在标准库中，但它是由 Go 官方维护的，和每一版的 Go 兼容，适用于大部分对象间的比较需求。&lt;/p&gt;&#xA;&lt;p&gt;老旧的代码中会使用&lt;code&gt;reflect.DeepEqual&lt;/code&gt;函数来比较复杂的结构体，现在建议用&lt;code&gt;cmp&lt;/code&gt;包来代替，因为&lt;code&gt;reflect.DeepEqual&lt;/code&gt;对一些未导出的字段和实现细节的变动非常敏感。&lt;/p&gt;&#xA;&lt;p&gt;（&lt;code&gt;cmp&lt;/code&gt;包使用时添加&lt;code&gt;cmp.Compare(proto.Equal)&lt;/code&gt;选项即可直接用于 protocol buffer 消息的比较。）&lt;/p&gt;&#xA;&lt;h2&gt;不仅打印期望值，也要打印实际值&lt;/h2&gt;&#xA;&lt;p&gt;测试结果在打印期望结果之前，应该打印函数的实际结果。通常我们会将测试结果格式化为：&lt;code&gt;YourFunc(%v) = %v, want %v&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;对于 diff 的输出，期望结果和实际结果谁前谁后不明显，这时需要加入额外信息帮助理解。这两个什么顺序并不重要，重要的是整个工程应该具有一致性。&lt;/p&gt;&#xA;&lt;h2&gt;标识函数名&lt;/h2&gt;&#xA;&lt;p&gt;在大部分测试中，失败消息应该包含所在函数名，即使该消息显而易见来自测试函数。&lt;/p&gt;&#xA;&lt;p&gt;优先使用：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;t.Errorf(&amp;quot;YourFunc(%v) = %v, want %v&amp;quot;, in, got, want)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;而不是：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;t.Errorf(&amp;quot;got %v, want %v&amp;quot;, got, want)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;标识输入&lt;/h2&gt;&#xA;&lt;p&gt;在大部分测试中，函数输入参数也应该包含在失败消息中。如果输入参数的相关属性不明显（比如，参数较大或晦涩难懂），你应该在测试名中描述本测试的内容，并且将描述信息放入错误消息中。&lt;/p&gt;&#xA;&lt;p&gt;对于表格驱动型测试，不要将序号作为测试名的一部分。在测试用例失败后，没人希望回到表格中一个个数来找出失败来自哪个用例。&lt;/p&gt;&#xA;&lt;h2&gt;失败继续执行&lt;/h2&gt;&#xA;&lt;p&gt;即使测试用例遇到了失败，它也应尽可能地继续执行，以便能在一次运行中打印出所有失败检查点。这样，如果有人要依照测试结果修复代码时，不用一遍遍重复执行用例来找出下一个 bug。&lt;/p&gt;&#xA;&lt;p&gt;从实际角度出发，优先使用&lt;code&gt;t.Error&lt;/code&gt;而不是&lt;code&gt;t.Fatal&lt;/code&gt;。当比较函数的多个输出时，对每一个分别使用&lt;code&gt;t.Error&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;t.Fatal&lt;/code&gt;适合在 setup 中使用，因为 setup 一旦失败，其余的步骤便没有再执行的必要。表格驱动的测试中，&lt;code&gt;t.Fatal&lt;/code&gt;适合在所有子测试开始前使用。表格中的每一测试用例若遇到不可恢复的错误，如何处理要分具体情况：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果你没有使用&lt;code&gt;t.Run&lt;/code&gt;运行子测试，那应该使用&lt;code&gt;t.Error&lt;/code&gt;并使用&lt;code&gt;conitnue&lt;/code&gt;语句直接跳转到下一项用例。&lt;/li&gt;&#xA;&lt;li&gt;如果你使用&lt;code&gt;t.Run&lt;/code&gt;运行子测试，那&lt;code&gt;t.Fatal&lt;/code&gt;只会中断当前用例，其余子测试会继续执行。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;标记测试辅助函数&lt;/h2&gt;&#xA;&lt;p&gt;辅助函数常用于 setup 和 teardown 任务中，比如构造一个测试数据。&lt;/p&gt;&#xA;&lt;p&gt;在辅助函数中调用&lt;a href=&#34;https://godoc.org/testing#T.Helper&#34;&gt;t.Helper&lt;/a&gt;后，如果辅助函数中某个判断出错，那在测试日志中的错误提示会忽略该辅助函数的调用栈，标记出错的行会焦点在测试用例中，而非在辅助函数中。有点绕，看个例子便一目了然。&lt;/p&gt;&#xA;&lt;p&gt;例如未使用&lt;code&gt;t.Helper&lt;/code&gt;之前：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main&#xA;&#xA;import &amp;quot;testing&amp;quot;&#xA;&#xA;func testHelper(t *testing.T) {&#xA;&#x9;t.Helper()&#xA;&#x9;t.Fatal()&#xA;}&#xA;&#xA;func TestHelloWorld(t *testing.T) {&#xA;&#x9;testHelper(t)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;出错信息为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; FAIL: TestHelloWorld (0.00s)&#xA;    main_test.go:6:&#xA;FAIL&#xA;FAIL&#x9;test.test&#x9;0.001s&#xA;FAIL&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;标记代码后：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main&#xA;&#xA;import &amp;quot;testing&amp;quot;&#xA;&#xA;func testHelper(t *testing.T) {&#xA;&#x9;t.Helper()&#xA;&#x9;t.Fatal()&#xA;}&#xA;&#xA;func TestHelloWorld(t *testing.T) {&#xA;&#x9;testHelper(t)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;出错信息为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; FAIL: TestHelloWorld (0.00s)&#xA;    main_test.go:11:&#xA;FAIL&#xA;FAIL&#x9;test.test&#x9;0.002s&#xA;FAIL&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到，显示出错的第几行不一样。显然若&lt;code&gt;testHelper&lt;/code&gt;被多个测试用例调用，后者的测试日志更易排查。&lt;/p&gt;&#xA;&lt;h2&gt;打印 diff&lt;/h2&gt;&#xA;&lt;p&gt;如果函数返回的输出比较长，而出错的地方只是其中一小段，那很难一眼看出区别。这对调试不友好，建议直接输出期望和实际结果的 diff 值。&lt;/p&gt;&#xA;&lt;h2&gt;表格驱动测试 vs 多个测试函数&lt;/h2&gt;&#xA;&lt;p&gt;当多个测试用例有着相同的测试逻辑，只是输入数据不同时，就应该使用&lt;a href=&#34;https://github.com/golang/go/wiki/TableDrivenTests&#34;&gt;表格驱动测试&lt;/a&gt;方法。&lt;/p&gt;&#xA;&lt;p&gt;而当每个测试用例需用不同的方法验证时，表格驱动就显得不合适，因为那样就不得不写一堆控制变量放入表格中，将原本的测试逻辑淹没其中，降低了用例的可读性和表格的可维护性。&lt;/p&gt;&#xA;&lt;p&gt;实际测试两种方法需结合使用。比如可以写两个表格驱动测试方法，一个测试函数的正常返回结果，另一个测试不同错误消息。&lt;/p&gt;&#xA;&lt;h2&gt;测试错误语义&lt;/h2&gt;&#xA;&lt;p&gt;单元测试避免使用字符串比较或者是&lt;code&gt;reflect.DeepEqual&lt;/code&gt;去检查函数的错误输出。错误消息若随着业务成长需要经常变动，你会不得不经常修改单元测试用例。&lt;/p&gt;&#xA;&lt;p&gt;而依赖库中的错误消息则相对稳定，拿来做字符串比较是可接受的。&lt;/p&gt;&#xA;&lt;p&gt;我们应该区分哪些是为了提高排查效率增添的错误消息，哪些只是用于内部编程，而多用&lt;code&gt;fmt.Errorf&lt;/code&gt;恰恰会打破内部的稳定性，应尽量少用。&lt;/p&gt;&#xA;&lt;p&gt;许多人并不关心他们的 API 返回具体什么错误消息，这种情况下，单元测试中只做错误非空判断就可以了。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2021/01/01/go-unit-test-comments/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Golang 与子测试</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2020/12/14/go-testing-in-go-subtests/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;表格驱动测试可谓是最受欢迎的测试方法了，它抽取了相似用例的公共步骤，结构清晰，维护简单，比如：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func TestOlder(t *testing.T) {&#xA;&#x9;cases := []struct {&#xA;&#x9;&#x9;age1     int&#xA;&#x9;&#x9;age2     int&#xA;&#x9;&#x9;expected bool&#xA;&#x9;}{&#xA;        // 第一个测试用例&#xA;&#x9;&#x9;{&#xA;&#x9;&#x9;&#x9;age1:     1,&#xA;&#x9;&#x9;&#x9;age2:     2,&#xA;&#x9;&#x9;&#x9;expected: false,&#xA;&#x9;&#x9;},&#xA;        // 第二个测试用例&#xA;&#x9;&#x9;{&#xA;&#x9;&#x9;&#x9;age1:     2,&#xA;&#x9;&#x9;&#x9;age2:     1,&#xA;&#x9;&#x9;&#x9;expected: true,&#xA;&#x9;&#x9;},&#xA;&#x9;}&#xA;&#xA;&#x9;for _, c := range cases {&#xA;&#x9;&#x9;_, p1 := NewPerson(c.age1)&#xA;&#x9;&#x9;_, p2 := NewPerson(c.age2)&#xA;&#xA;&#x9;&#x9;got := p1.older(p2)&#xA;&#xA;&#x9;&#x9;if got != c.expected {&#xA;&#x9;&#x9;&#x9;t.Errorf(&amp;quot;Expected %v &amp;gt; %v, got %v&amp;quot;, p1.age, p2.age, got)&#xA;        }&#xA;    } &#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;但是这种写法有着一个致命的缺陷，你无法像之前一样选择某个用例执行，即不支持 &lt;code&gt;go test -run regex&lt;/code&gt; 命令行来选择只执行第一个或第二个测试用例。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Go 1.7&lt;/code&gt; 中加入了子测试的概念，以解决该问题。&lt;/p&gt;&#xA;&lt;h2&gt;什么是 Go 的子测试&lt;/h2&gt;&#xA;&lt;p&gt;子测试在 &lt;code&gt;testing&lt;/code&gt; 包中由 &lt;a href=&#34;https://golang.org/pkg/testing/#T.Run&#34;&gt;Run 方法&lt;/a&gt; 提供，它有俩个参数：子测试的名字和子测试函数，其中名字是子测试的标识符。&lt;/p&gt;&#xA;&lt;p&gt;子测试和其他普通的测试函数一样，是在独立的 goroutine 中运行，测试结果也会计入测试报告，所有子测试运行完毕后，父测试函数才会结束。&lt;/p&gt;&#xA;&lt;h2&gt;如何使用&lt;code&gt;t.Run&lt;/code&gt;&lt;/h2&gt;&#xA;&lt;p&gt;使用&lt;code&gt;t.Run&lt;/code&gt;重构前言中的测试代码，代码变动了不少：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func TestOlder(t *testing.T) {&#xA;&#x9;cases := []struct {&#xA;&#x9;&#x9;name     string&#xA;&#x9;&#x9;age1     int&#xA;&#x9;&#x9;age2     int&#xA;&#x9;&#x9;expected bool&#xA;&#x9;}{&#xA;&#x9;&#x9;{&#xA;&#x9;&#x9;&#x9;name:     &amp;quot;FirstOlderThanSecond&amp;quot;,&#xA;&#x9;&#x9;&#x9;age1:     1,&#xA;&#x9;&#x9;&#x9;age2:     2,&#xA;&#x9;&#x9;&#x9;expected: false,&#xA;&#x9;&#x9;},&#xA;&#x9;&#x9;{&#xA;&#x9;&#x9;&#x9;name:     &amp;quot;SecondOlderThanFirst&amp;quot;,&#xA;&#x9;&#x9;&#x9;age1:     2,&#xA;&#x9;&#x9;&#x9;age2:     1,&#xA;&#x9;&#x9;&#x9;expected: true,&#xA;&#x9;&#x9;},&#xA;&#x9;}&#xA;&#xA;&#x9;for _, c := range cases {&#xA;&#x9;&#x9;t.Run(c.name, func(t *testing.T) {&#xA;&#x9;&#x9;&#x9;_, p1 := NewPerson(c.age1)&#xA;&#x9;&#x9;&#x9;_, p2 := NewPerson(c.age2)&#xA;&#xA;&#x9;&#x9;&#x9;got := p1.older(p2)&#xA;&#xA;&#x9;&#x9;&#x9;if got != c.expected {&#xA;&#x9;&#x9;&#x9;&#x9;t.Errorf(&amp;quot;Expected %v &amp;gt; %v, got %v&amp;quot;, p1.age, p2.age, got)&#xA;&#x9;&#x9;&#x9;}&#xA;&#x9;&#x9;})&#xA;&#x9;}&#xA;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;首先我们修改了定义用例的结构体，加入了&lt;code&gt;string&lt;/code&gt;类型的&lt;code&gt;name&lt;/code&gt;属性。这样每个用例都有了自己的名字来标示自己。例如，第一个用例由于参数&lt;code&gt;arg1&lt;/code&gt;大于参数&lt;code&gt;arg2&lt;/code&gt;，所以被命名称&lt;code&gt;FirstOlderThanSecond&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;然后在&lt;code&gt;for&lt;/code&gt;循环中，我们把整个测试逻辑包裹在&lt;code&gt;t.Run&lt;/code&gt;块中，并把用例名作为第一个参数。&lt;/p&gt;&#xA;&lt;p&gt;运行该测试，可得：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ go test -v -count=1&#xA;=== RUN   TestOlder&#xA;=== RUN   TestOlder/FirstOlderThanSecond&#xA;=== RUN   TestOlder/SecondOlderThanFirst&#xA; PASS: TestOlder (0.00s)&#xA;     PASS: TestOlder/FirstOlderThanSecond (0.00s)&#xA;     PASS: TestOlder/SecondOlderThanFirst (0.00s)&#xA;PASS&#xA;ok  &#x9;person&#x9;0.004s&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;从结果中我们发现，&lt;code&gt;TestOlder&lt;/code&gt;派生出另外两个子测试函数：&lt;code&gt;TestOlder/FirstOlderThanSecond&lt;/code&gt; 和 &lt;code&gt;TestOlder/SecondOlderThanFirst&lt;/code&gt;。在这两个子测试结束之前，&lt;code&gt;TestOlder&lt;/code&gt;都不会结束。&lt;/p&gt;&#xA;&lt;p&gt;子测试函数的测试结果在终端里是缩进的，且测试用例的名字都以&lt;code&gt;TestOlder&lt;/code&gt;开头，这些都用来凸显测试用例之间的父子关系。&lt;/p&gt;&#xA;&lt;h2&gt;&lt;code&gt;go test&lt;/code&gt;选择子测试运行&lt;/h2&gt;&#xA;&lt;p&gt;在调试特定测试用例或复现某个 bug 时我们常用&lt;code&gt;go test -run=regex&lt;/code&gt;来指定。子测试&lt;code&gt;regex&lt;/code&gt;的命名规则和上一节中测试结果一致：&lt;code&gt;父测试名/子测试名&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;比如可用以下命令执行子测试&lt;code&gt;FirstOlderThenSecond&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ go test -v -count=1 -run=&amp;quot;TestOlder/FirstOlderThanSecond&amp;quot;&#xA;=== RUN   TestOlder&#xA;=== RUN   TestOlder/FirstOlderThanSecond&#xA; PASS: TestOlder (0.00s)&#xA;     PASS: TestOlder/FirstOlderThanSecond (0.00s)&#xA;PASS&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果要执行某个父测试下的所有子测试，可键入：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ go test -v -count=1 -run=&amp;quot;TestOlder&amp;quot;&#xA;=== RUN   TestOlder&#xA;=== RUN   TestOlder/FirstOlderThanSecond&#xA;=== RUN   TestOlder/SecondOlderThanFirst&#xA; PASS: TestOlder (0.00s)&#xA;     PASS: TestOlder/FirstOlderThanSecond (0.00s)&#xA;     PASS: TestOlder/SecondOlderThanFirst (0.00s)&#xA;PASS&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;Setup 和 Teardown 和 TestMain&lt;/h2&gt;&#xA;&lt;p&gt;使用过其他测试框架的同学一定不会对&lt;code&gt;Setup&lt;/code&gt;和&lt;code&gt;Teardown&lt;/code&gt;陌生，这几乎是测试框架的标配。而 &lt;code&gt;testing&lt;/code&gt; 包长期以来在这块是缺失的，我们无法为所有的测试用例添加一些公共的初始化和结束步骤。引入&lt;code&gt;t.Run&lt;/code&gt;之后，我们便可以实现缺失的功能。&lt;/p&gt;&#xA;&lt;p&gt;请看下面的例子，在子测试开始时，先调用&lt;code&gt;setupSubtest(t)&lt;/code&gt;做初始化工作，然后使用&lt;code&gt;defer teardownSubtest(t)&lt;/code&gt;保证在&lt;code&gt;t.Run&lt;/code&gt;结束前执行清理工作。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func setupSubtest(t *testing.T) {&#xA;&#x9;t.Logf(&amp;quot;[SETUP] Hello 👋!&amp;quot;)&#xA;}&#xA;&#xA;func teardownSubtest(t *testing.T) {&#xA;&#x9;t.Logf(&amp;quot;[TEARDOWN] Bye, bye 🖖!&amp;quot;)&#xA;}&#xA;&#xA;func TestOlder(t *testing.T) {&#xA;......&#xA;&#x9;for _, c := range cases {&#xA;&#x9;&#x9;t.Run(c.name, func(t *testing.T) {&#xA;            // setup&#xA;            setupSubtest(t)&#xA;            // teardown&#xA;&#x9;&#x9;&#x9;defer teardownSubtest(t)&#xA;&#xA;&#x9;&#x9;&#x9;_, p1 := NewPerson(c.age1)&#xA;&#x9;&#x9;&#x9;_, p2 := NewPerson(c.age2)&#xA;&#xA;&#x9;&#x9;&#x9;got := p1.older(p2)&#xA;&#xA;&#x9;&#x9;&#x9;t.Logf(&amp;quot;[TEST] Hello from subtest %s \n&amp;quot;, c.name)&#xA;&#x9;&#x9;&#x9;if got != c.expected {&#xA;&#x9;&#x9;&#x9;&#x9;t.Errorf(&amp;quot;Expected %v &amp;gt; %v, got %v&amp;quot;, p1.age, p2.age, got)&#xA;&#x9;&#x9;&#x9;}&#xA;&#x9;&#x9;})&#xA;&#x9;}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;运行测试后，可以看到&lt;code&gt;Setup&lt;/code&gt;和&lt;code&gt;Teardown&lt;/code&gt;在每个子测试中都会被调用：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ go test -v -count=1 -run=&amp;quot;TestOlder&amp;quot;&#xA;=== RUN   TestOlder&#xA;=== RUN   TestOlder/FirstOlderThanSecond&#xA;=== RUN   TestOlder/SecondOlderThanFirst&#xA; PASS: TestOlder (0.00s)&#xA;     PASS: TestOlder/FirstOlderThanSecond (0.00s)&#xA;        person_test.go:33: [SETUP] Hello 👋!&#xA;        person_test.go:71: [TEST] Hello from subtest FirstOlderThanSecond&#xA;        person_test.go:37: [TEARDOWN] Bye, bye 🖖!&#xA;     PASS: TestOlder/SecondOlderThanFirst (0.00s)&#xA;        person_test.go:33: [SETUP] Hello 👋!&#xA;        person_test.go:71: [TEST] Hello from subtest SecondOlderThanFirst&#xA;        person_test.go:37: [TEARDOWN] Bye, bye 🖖!&#xA;PASS&#xA;ok  &#x9;person&#x9;0.005s&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;进一步的，每个包的测试文件其实都包含一个“隐藏”的&lt;code&gt;TestMain(m *testing.M)&lt;/code&gt;函数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func TestMain(m *testing.M) {&#xA;&#x9;os.Exit(m.Run())&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;若重写该函数，在&lt;code&gt;m.Run&lt;/code&gt;上下加入&lt;code&gt;Setup&lt;/code&gt;和&lt;code&gt;Teardown&lt;/code&gt;后便得到了全局的初始化和清理函数。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func setupSubtest() {&#xA;&#x9;fmt.Println(&amp;quot;[SETUP] Hello 👋!&amp;quot;)&#xA;}&#xA;&#xA;func teardownSubtest() {&#xA;&#x9;fmt.Println(&amp;quot;[TEARDOWN] Bye, bye 🖖!&amp;quot;)&#xA;}&#xA;&#xA;func TestMain(m *testing.M) {&#xA;    setupSubtest()&#xA;    code := m.Run()&#xA;    teardownSubtest(t)&#xA;    os.Exit(code)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2020/12/14/go-testing-in-go-subtests/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Linux 性能分析 - 如何理解系统平均负载</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2020/06/25/perftest-analysis-load-average/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;之前的文章已经详细讨论了平均负载的含义，并尝试解释其合理性，现在我们来看一下大佬 Brendan Gregg 对该指标的看法。&lt;/p&gt;&#xA;&lt;p&gt;本文大部分内容翻译、删减并理解自&lt;a href=&#34;http://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html&#34;&gt;Linux Load Averages: Solving the Mystery&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://www.lyyyuna.com/2020/05/29/perftest-analysis-cpu1/&#34;&gt;第一篇文章&lt;/a&gt;，uptime 的 man 帮助文档有个未解之谜：为什么 Linux 上平均负载不仅关注可运行的任务，也关注&lt;strong&gt;不可中断睡眠&lt;/strong&gt;状态的任务？我从未看到过官方的解释（也许有，但我没找到）。本文将解答这一问题，让每个开发者都能理解并运用这一指标。&lt;/p&gt;&#xA;&lt;p&gt;Linux 的平均负载是&lt;strong&gt;系统平均负载&lt;/strong&gt;，它显示的是系统对运行和等待线程（任务）数量的需求。既然这个指标是需求，那它有可能比系统正处理的任务数量多。大部分工具会显示三个数值，分别是 1 分钟，5 分钟和 15 分钟的平均负载：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ uptime&#xA; 16:48:24 up  4:11,  1 user,  load average: 25.25, 23.40, 23.46&#xA;&#xA;top - 16:48:42 up  4:12,  1 user,  load average: 25.25, 23.14, 23.37&#xA;&#xA;$ cat /proc/loadavg &#xA;25.72 23.19 23.35 42/3411 43603&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;对指标的解释：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果平均值是 0.0，那说明系统处于空闲状态。&lt;/li&gt;&#xA;&lt;li&gt;如果 1 分钟内的平均负载高于 5 分钟和 15 分钟，那说明负载正在升高。&lt;/li&gt;&#xA;&lt;li&gt;如果 1 分钟内的平均负载低于 5 分钟和 15 分钟，那说明负载正在降低。&lt;/li&gt;&#xA;&lt;li&gt;如果数值高于 CPU 数量，那可能有性能问题。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;由这三个数值，你可以判断出负载在升高或降低。单个数值也有参考意义，比如企业云服务的伸缩可以据此作参考。单个数值&lt;code&gt;23-25&lt;/code&gt;没有意义，有了其他信息比如 CPU 数量，你才能判断 CPU 是否处于瓶颈。分析性能，我通常会用一些其它指标来辅助分析，而不是在平均负载这一数值上死磕。&lt;/p&gt;&#xA;&lt;h2&gt;历史&lt;/h2&gt;&#xA;&lt;p&gt;最原始的平均负载只计算对 CPU 的需求：运行进程数量+就绪进程数量。在 1973 年 8 月的&lt;a href=&#34;https://tools.ietf.org/html/rfc546&#34;&gt;RFC 546 TENEX Load Averages&lt;/a&gt;有一个漂亮的解释：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;[1] The TENEX load average is a measure of CPU demand. The load average is an average of the number of runnable processes over a given time period. For example, an hourly load average of 10 would mean that (for a single CPU system) at any time during that hour one could expect to see 1 process running and 9 others ready to run (i.e., not blocked for I/O) waiting for the CPU.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;翻译：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;TENEX 平均负载是对 CPU 需求的度量。平均负载是一段时间内可运行进程的平均数量。例如在单核系统上，一小时内平均负载是 10，说明在这一小时内的任意的时刻都可以看到有 1 个进程在运行，另外 9 个处于就绪态（就绪不是指阻塞于 I/O）。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;这个版本的&lt;a href=&#34;https://tools.ietf.org/html/rfc546&#34;&gt;RFC 546&lt;/a&gt;有一张来自 1973.7 的扫描手绘图，显示系统负载指标已经使用了数十年：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/perf-cpu/rfc546.jpg&#34; alt=&#34;手绘图&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/PDP-10/tenex&#34;&gt;TENEX的源码&lt;/a&gt;现在还能找到，以下是一段 DEC 汇编语言的摘录：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;NRJAVS==3               ;平均负载的数量&#xA;GS RJAV,NRJAVS          ;活跃进程的指数平均值&#xA;[...]&#xA;;更新可运行任务的平均数量&#xA;&#xA;DORJAV: MOVEI 2,^D5000&#xA;        MOVEM 2,RJATIM          ;指定下次更新的时刻&#xA;        MOVE 4,RJTSUM           ;当前时刻 NBPROC+NGPROC 的积分值，对于离散函数，此处积分为求和&#xA;        SUBM 4,RJAVS1           ;与上个值的差值&#xA;        EXCH 4,RJAVS1&#xA;        FSC 4,233               ;FLOAT IT&#xA;        FDVR 4,[5000.0]         ;过去 5000ms 内的平均值&#xA;[...]&#xA;;指数计算数组 EXP(-T/C)，其中 T=5s&#xA;&#xA;EXPFF:  EXP 0.920043902 ;C = 1 MIN&#xA;        EXP 0.983471344 ;C = 5 MIN&#xA;        EXP 0.994459811 ;C = 15 MIN&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Linux 源码里也硬编码了 1 分钟、5 分钟和 15 分钟的常量。以下是&lt;a href=&#34;https://github.com/torvalds/linux/blob/master/include/linux/sched/loadavg.h&#34;&gt;include/linux/sched/loadavg.h&lt;/a&gt;的代码摘录：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;#define EXP_1           1884            /* 1/exp(5sec/1min) as fixed-point */&#xA;#define EXP_5           2014            /* 1/exp(5sec/5min) */&#xA;#define EXP_15          2037            /* 1/exp(5sec/15min) */&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;三个数值&lt;/h2&gt;&#xA;&lt;p&gt;这三个数值代表公式会分别计算 1 分钟、5 分钟和 15 分钟内的平均负载，采样间隔为 5 秒。可换算成公式后，你会发现它们不是真的在计算平均值，更不需要连续采样 1 分钟、5 分钟和 15 分钟。汇编可读性差，让我们换成等价的 python 伪代码就一目了然：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;e_1 = 0.920043902  &#xA;e_5 = 0.983471344&#xA;e_15 = 0.994459811&#xA;&#xA;e = e_1&#xA;&#xA;s = 0&#xA;ls = [0]&#xA;for i in range(num):&#xA;    s = (1-e) * 1 + e * s&#xA;    ls.append(s)&#xA;&#xA;print(ls[-1])&#xA;# 如果 num = 12，即 12*5=60s&#xA;# 那 ls[-1] == 0.6321230185169127&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这是一种离散化的&lt;strong&gt;指数平滑法&lt;/strong&gt;，1, 5, 15 仅是在公式计算不同的指数常量，公式每个采样周期迭代计算，所得是估计值。&lt;/p&gt;&#xA;&lt;p&gt;拿一个单核空闲系统做实验，从 0 时刻起启动一个单线程 CPU 跑满的任务，那 60 秒后， 1 分钟平均负载显示约为 0.62，与上述伪代码理论计算值 0.63 相当。如果负载一直持续，最终 1 分钟平均负载为 1。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/perf-cpu/loadavg.png&#34; alt=&#34;系统负载实验 - 指数衰减可视化图&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;更多公式和实验的讨论，请参考 Dr. Neil Gunther 的文章 &lt;a href=&#34;http://www.teamquest.com/import/pdfs/whitepaper/ldavg1.pdf&#34;&gt;How It Works&lt;/a&gt;，也可以参考 Linux 源码中的&lt;a href=&#34;https://github.com/torvalds/linux/blob/master/kernel/sched/loadavg.c&#34;&gt;注释&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h2&gt;Linux 不可中断任务&lt;/h2&gt;&#xA;&lt;p&gt;当平均负载指标第一次出现在 Linux 上时，和其它操作系统一样，它只反映了系统对 CPU 的需求。然而不久之后，Linux 把处于不可中断状态（&lt;code&gt;TASK_UNINTERRUPTIBLE&lt;/code&gt;或&lt;code&gt;nr_uninterruptible&lt;/code&gt;）的任务数量也纳入其中。阻塞于磁盘 I/O 和某些锁的进程即为不可中断进程，这些进程不能被信号量打断。在&lt;code&gt;ps&lt;/code&gt;和&lt;code&gt;top&lt;/code&gt;命令中，这些进程被标注为&lt;code&gt;D&lt;/code&gt;状态，ps(1) 帮助文档中称之为“不可中断睡眠（通常是IO）”。&lt;/p&gt;&#xA;&lt;p&gt;加入不可中断状态意味着若磁盘（或者 NFS）I/O 工作负载升高，测量的系统负载也会升高。对来自其它操作系统阵营的使用者，这无疑会给他们误解。&lt;/p&gt;&#xA;&lt;p&gt;为什么？为什么 Linux 要这么做？&lt;/p&gt;&#xA;&lt;p&gt;有数不清的文章指出了 Linux 系统负载的多面性，但无一解释这么做的动机。我猜测，Linux 这么做是想从总体上反映系统需求。&lt;/p&gt;&#xA;&lt;h2&gt;不可中断任务的起源&lt;/h2&gt;&#xA;&lt;p&gt;该改动早于 2005 年，2005 年以前，Linux 并不是由 git 管理的，所以没有 git commit history 来确认当时合入的动机。我在 &lt;a href=&#34;http://oldlinux.org/Linux.old/mail-archive/&#34;&gt;oldlinux.org&lt;/a&gt; 备份的邮件列表中翻到了这么一封邮件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;From: Matthias Urlichs &amp;lt;urlichs@smurf.sub.org&amp;gt;&#xA;Subject: Load average broken ?&#xA;Date: Fri, 29 Oct 1993 11:37:23 +0200&#xA;&#xA;&#xA;The kernel only counts &amp;quot;runnable&amp;quot; processes when computing the load average.&#xA;I don&#39;t like that; the problem is that processes which are swapping or&#xA;waiting on &amp;quot;fast&amp;quot;, i.e. noninterruptible, I/O, also consume resources.&#xA;&#xA;It seems somewhat nonintuitive that the load average goes down when you&#xA;replace your fast swap disk with a slow swap disk...&#xA;&#xA;Anyway, the following patch seems to make the load average much more&#xA;consistent WRT the subjective speed of the system. And, most important, the&#xA;load is still zero when nobody is doing anything. ;-)&#xA;&#xA; kernel/sched.c.orig Fri Oct 29 10:31:11 1993&#xA;+++ kernel/sched.c  Fri Oct 29 10:32:51 1993&#xA;@@ -414,7 +414,9 @@&#xA;    unsigned long nr = 0;&#xA;&#xA;    for(p = &amp;amp;LAST_TASK; p &amp;gt; &amp;amp;FIRST_TASK; --p)&#xA;-       if (*p &amp;amp;&amp;amp; (*p)-&amp;gt;state == TASK_RUNNING)&#xA;+       if (*p &amp;amp;&amp;amp; ((*p)-&amp;gt;state == TASK_RUNNING) ||&#xA;+                  (*p)-&amp;gt;state == TASK_UNINTERRUPTIBLE) ||&#xA;+                  (*p)-&amp;gt;state == TASK_SWAPPING))&#xA;            nr += FIXED_1;&#xA;    return nr;&#xA; }&#xA;--&#xA;Matthias Urlichs        \ XLink-POP N|rnberg   | EMail: urlichs@smurf.sub.org&#xA;Schleiermacherstra_e 12  \  Unix+Linux+Mac     | Phone: ...please use email.&#xA;90491 N|rnberg (Germany)  \   Consulting+Networking+Programming+etc&#39;ing      42&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;改动是由 Matthias 引入，最终在&lt;code&gt;Linux 0.99.14&lt;/code&gt;中合入。从邮件中可以确认，平均负载的这一改动就是为了反映对系统资源的总体需求：即 CPU 平均负载 --&amp;gt; 系统资源负载。&lt;/p&gt;&#xA;&lt;p&gt;27 年前，Matthias 用慢速 swap 磁盘做例子是合理的：swap 磁盘拖慢了系统性能，那平均负载这一指标理应升高，然而按当时的计算方法，平均负载反而会降低，因为该指标只计入了处于可运行状态的任务，而慢速 swap 磁盘导致的大量任务不可运行没有被统计在内。这显然有悖常理，所以 Matthias 提交了这一补丁。&lt;/p&gt;&#xA;&lt;h2&gt;如今的不可中断任务&lt;/h2&gt;&#xA;&lt;p&gt;除了磁盘 I/O, CPU 外还有别的原因会导致 Linux 平均负载升高吗？是的，虽然我猜测在 1993 年时，还没有其它代码路径会设置 &lt;code&gt;TASK_UNINTERRUPTIBLE&lt;/code&gt;。在&lt;code&gt;Linux 0.99.14&lt;/code&gt;，有 13 条代码路径会直接设置&lt;code&gt;TASK_UNINTERRUPTIBLE&lt;/code&gt;或&lt;code&gt;TASK_SWAPPING&lt;/code&gt;（后来 Linux 移除了 swap 状态）。而在 2017 年的&lt;code&gt;Linux 4.12&lt;/code&gt;，则有 400 多种可能会设置&lt;code&gt;TASK_UNINTERRUPTIBLE&lt;/code&gt;，包括一些锁原语。&lt;/p&gt;&#xA;&lt;p&gt;既然可能性如此之多，是不是每种都和系统负载有关？本文作者给 Matthias 发邮件询问了此事，Matthias 则回复：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&amp;quot;The point of &amp;quot;load average&amp;quot; is to arrive at a number relating how busy the system is from a human point of view. TASK_UNINTERRUPTIBLE means (meant?) that the process is waiting for something like a disk read which contributes to system load. A heavily disk-bound system might be extremely sluggish but only have a TASK_RUNNING average of 0.1, which doesn&#39;t help anybody.&amp;quot;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;翻译如下：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;“平均负载”的意义在于从人的角度描述系统的繁忙程度。TASK_UNINTERRUPTIBLE 意味着（过去意味着？）进程在等待某些资源，比如读磁盘，这些行为会增加系统负载。疯狂读磁盘的系统性能奇差，但此刻 TASK_RUNNING 任务的平均数量只有 0.1，单看这个值也就没参考意义了。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Matthias 仍认为这么计算是对的，不过给出的解释仍和 93 年相同。&lt;/p&gt;&#xA;&lt;p&gt;但是现在有更多的情况会让任务处于&lt;code&gt;TASK_UNITERRUPTIBLE&lt;/code&gt;状态，是否应该改进计算平均负载的算法，剪去多余分支呢？Linux 调度器维护者 Peter Zijstra 给出了一种解法：用&lt;code&gt;task_struct-&amp;gt;in_iowait&lt;/code&gt;替换&lt;code&gt;TASK_UNITERRUPTIBLE&lt;/code&gt;，这样平均负载仍然反映对 CPU 和磁盘的需求。&lt;/p&gt;&#xA;&lt;p&gt;但绕了这么一大圈，真的测到我们想要的了吗？我们是要反映对系统线程的需求，还是反映对物理资源的需求？如果是前者，那由于不可中断锁而阻塞的线程也应纳入统计，因为系统需要这些线程，它们并不是空闲的。&lt;/p&gt;&#xA;&lt;p&gt;为了更好地理解不可中断的代码路径，首先我们需要一种度量进程各阶段实际耗时的方法，然后才能量化每个场景所花的时间，检验平均负载这一指标能否切合实际。&lt;/p&gt;&#xA;&lt;h2&gt;测量不可中断任务&lt;/h2&gt;&#xA;&lt;p&gt;下图是一个生产环境服务器的 off-CPU 火焰图（On-CPU 是任务在CPU上运行的消耗，off-CPU 就是任务由于某种原因阻塞的消耗，如等待IO，等待锁，等待定时器，等待内存页面的swap等），测量持续了 60 秒，并过滤出了处于&lt;code&gt;TASK_UNINTERRUPTIBLE&lt;/code&gt;的任务的内核栈：&lt;/p&gt;&#xA;&lt;p&gt;&lt;object type=&#34;image/svg+xml&#34; data=&#34;/img/posts/perf-cpu/out.offcputime_unint02.svg&#34;&gt;&lt;/object&gt;&lt;/p&gt;&#xA;&lt;p&gt;完整的栈显示出来就像一把火焰，你可以点击放大查看火焰图的细节。x 轴上的长度正比于阻塞 off-CPU 的时间，顺序是随机的。上图显示 60s 内只有 926ms 的时间处于不可中断睡眠，只给平均负载增加了 0.015。其中大部分是 cgroup 调用，系统本身并没有太多磁盘 I/O。&lt;/p&gt;&#xA;&lt;p&gt;接下来这张图更有趣，测量只持续了 10 秒：&lt;/p&gt;&#xA;&lt;p&gt;&lt;object type=&#34;image/svg+xml&#34; data=&#34;/img/posts/perf-cpu/out.offcputime_unint01.svg&#34;&gt;&lt;/object&gt;&lt;/p&gt;&#xA;&lt;p&gt;图中用洋红色高亮的栈帧均是&lt;code&gt;rwsem_down_read_failed()&lt;/code&gt;，加起来增加了 0.3 的平均负载。让我们摘录&lt;code&gt;rwsem_down_read_failed()&lt;/code&gt;的部分代码，可以看到其在获取锁时给任务设置了&lt;code&gt;TASK_UNINTERRUPTIBLE&lt;/code&gt;状态。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;    /* wait to be given the lock */&#xA;    while (true) {&#xA;        set_task_state(tsk, TASK_UNINTERRUPTIBLE);&#xA;        if (!waiter.task)&#xA;            break;&#xA;        schedule();&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Linux 锁有不可中断(mutex_lock(), down())和可中断(mutex_lock_interruptible(), down_interruptible())两个版本，可中断版本允许信号绕过锁机制唤醒阻塞的任务。通常不可中断锁的睡眠时间很短，一般不影响平均负载，但在这个例子中，增加了 0.30。如果该值在上一个数量级，那就有必要做深入的性能分析，以减少锁竞争来降低平均负载。&lt;/p&gt;&#xA;&lt;p&gt;这么看来，那些阻塞于不可中断锁上的线程也会造成 Linux 软件资源的紧缺，计算负载时不能只关注硬件资源（CPU，磁盘I/O）。&lt;/p&gt;&#xA;&lt;h2&gt;分解 Linux 平均负载&lt;/h2&gt;&#xA;&lt;p&gt;平均负载只是一个数，能否分解出其中的各个部分呢？看这个例子：在一个 8 核的系统上，用&lt;code&gt;tar&lt;/code&gt;解压文件，一共用时数分钟，大部分时间阻塞于读磁盘。然后用&lt;code&gt;pidstat&lt;/code&gt;, &lt;code&gt;iostat&lt;/code&gt;, &lt;code&gt;uptime&lt;/code&gt;在三个窗口同时收集性能信息：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;terma$ pidstat -p `pgrep -x tar` 60&#xA;Linux 4.9.0-rc5-virtual (bgregg-xenial-bpf-i-0b7296777a2585be1)     08/01/2017  _x86_64_    (8 CPU)&#xA;&#xA;10:15:51 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command&#xA;10:16:51 PM     0     18468    2.85   29.77    0.00   32.62     3  tar&#xA;&#xA;termb$ iostat -x 60&#xA;[...]&#xA;avg-cpu:  %user   %nice %system %iowait  %steal   %idle&#xA;           0.54    0.00    4.03    8.24    0.09   87.10&#xA;&#xA;Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util&#xA;xvdap1            0.00     0.05   30.83    0.18   638.33     0.93    41.22     0.06    1.84    1.83    3.64   0.39   1.21&#xA;xvdb            958.18  1333.83 2045.30  499.38 60965.27 63721.67    98.00     3.97    1.56    0.31    6.67   0.24  60.47&#xA;xvdc            957.63  1333.78 2054.55  499.38 61018.87 63722.13    97.69     4.21    1.65    0.33    7.08   0.24  61.65&#xA;md0               0.00     0.00 4383.73 1991.63 121984.13 127443.80    78.25     0.00    0.00    0.00    0.00   0.00   0.00&#xA;&#xA;termc$ uptime&#xA; 22:15:50 up 154 days, 23:20,  5 users,  load average: 1.25, 1.19, 1.05&#xA;[...]&#xA;termc$ uptime&#xA; 22:17:14 up 154 days, 23:21,  5 users,  load average: 1.19, 1.17, 1.06&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;最后是 60 秒内的 off-CPU 火焰图：&lt;/p&gt;&#xA;&lt;p&gt;&lt;object type=&#34;image/svg+xml&#34; data=&#34;/img/posts/perf-cpu/out.offcputime_unint08.svg&#34;&gt;&lt;/object&gt;&lt;/p&gt;&#xA;&lt;p&gt;uptime 显示倒数一分钟时系统负载为 1.25，最后一分钟的平均负载为 1.19。&lt;/p&gt;&#xA;&lt;p&gt;让我们来尝试分解：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;0.33 来自 tar 的 CPU 时间(pidstat)&lt;/li&gt;&#xA;&lt;li&gt;41164/60000=0.69 来自 tar 的不可中断磁盘读（火焰图）&lt;/li&gt;&#xA;&lt;li&gt;(3684+3102)/60000=0.11 来自内核的不可中断磁盘I/O - 刷新磁盘（火焰图的最左两个高峰）&lt;/li&gt;&#xA;&lt;li&gt;0.04 来自其它任务（iostat 统计出总的 user+system 时间 - tar 的 CPU 时间）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;代入指数平滑算法：&lt;code&gt;(0.33+0.69+0.11+0.04)*0.62 + 1.25*0.38 = 1.17*0.62 + 1.25*0.38 = 1.2&lt;/code&gt;。非常接近 uptime 测得的 1.19。&lt;/p&gt;&#xA;&lt;p&gt;这个系统只有一个主要线程 tar，和其它一些辅助和内核线程，Linux 报告 平均负载 1.19 是合理的。如果只测量&lt;strong&gt;CPU 平均负载&lt;/strong&gt;，那就是&lt;code&gt;0.33+0.04=0.37&lt;/code&gt;，并没有反馈出系统压力真正的来源。&lt;/p&gt;&#xA;&lt;h2&gt;让 Linux 平均负载有意义&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;在 Linux 系统上，平均负载是&lt;strong&gt;系统平均负载&lt;/strong&gt;，统计的对象多种多样：运行状态的线程和因为某些原因等待运行的线程（CPU、磁盘、不可中断锁）。优点是能对整个系统做度量，方便使用者从整体把握性能状态。&lt;/li&gt;&#xA;&lt;li&gt;在其它操作系统上，平均负载是&lt;strong&gt;CPU 平均负载&lt;/strong&gt;，测量的是可运行线程数量。优点是易于理解，看到指标就知道问题在哪。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;什么是“好”或“坏”的平均负载&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;平均负载对系统监控有参考意义：当数值超过某一绝对值时，应用延迟必定很高，性能会出现瓶颈，但这个绝对值不具备通用性。&lt;/li&gt;&#xA;&lt;li&gt;平均负载是一段时间内（&amp;gt; 1min）的平均值，同样 1 的平均负载即可能是持续稳定的负载，也可能是一个突发的高负载。&lt;/li&gt;&#xA;&lt;li&gt;其它操作系统中的 CPU 平均负载可以按这个公式归一化：&lt;code&gt;CPU 平均负载/CPU 个数&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;不同应用场景对系统延迟的容忍度不同。比如双核 CPU 邮件服务器的归一化值约为 11-16，但邮件协议不是即时通信协议，实时性不高，用户不会抱怨。（而其它应用用户所能容忍的归一化值不会高于 2）&lt;/li&gt;&#xA;&lt;li&gt;在 Linux 中，平均负载包含&lt;code&gt;TASK_UNINTERRUPTIBLE&lt;/code&gt;，所以不能使用归一化的值。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;更好的指标&lt;/h2&gt;&#xA;&lt;p&gt;在 Linux 系统上，光靠平均负载不能定位问题，这里介绍介绍一些其它指标。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;查看每个 CPU 的利用率，&lt;code&gt;mpstat -P ALL 1&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;查看每个进程的 CPU 利用率，&lt;code&gt;top&lt;/code&gt;, &lt;code&gt;pidstat 1&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;查看每个线程的调度延迟，&lt;code&gt;/proc/PID/schedstats&lt;/code&gt;,&lt;code&gt;delaystats&lt;/code&gt;, &lt;code&gt;perf sched&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;查看 CPU 调度队列的长度，&lt;code&gt;vmstat 1&lt;/code&gt;的&lt;code&gt;r&lt;/code&gt;列&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;结论&lt;/h2&gt;&#xA;&lt;p&gt;在 1993 年，一位 Linux 工程师发现原先的平均负载斌不直观，随即将定义从“CPU 平均负载”永远地改成了“系统平均负载”。新算法把不可中断任务也纳入其中，以便反映出对磁盘资源的需求。算法仍然使用指数平滑法估计 1, 5 和 15 分钟内的负载，通过这三个值可以判断负载升高还是降低。&lt;/p&gt;&#xA;&lt;p&gt;随着 Linux 内核的发展，不可中断的代码路径不断丰富，现在还包含了不可中断锁原语等。但 93 年的算法不需要改变，因为系统负载含义丰富了，多出来的代码路径正好能覆盖这些负载。&lt;/p&gt;&#xA;&lt;p&gt;本文删减了作者的原文，一些定位系统负载问题的方法可以翻阅上两篇文章。&lt;/p&gt;&#xA;&lt;h2&gt;参考文献&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Saltzer, J., and J. Gintell. “&lt;a href=&#34;http://web.mit.edu/Saltzer/www/publications/instrumentation.html&#34;&gt;The Instrumentation of Multics&lt;/a&gt;,” CACM, August 1970 (explains exponentials).&lt;/li&gt;&#xA;&lt;li&gt;Multics &lt;a href=&#34;http://web.mit.edu/multics-history/source/Multics/doc/privileged/system_performance_graph.info&#34;&gt;system_performance_graph&lt;/a&gt; command reference (mentions the 1 minute average).&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/PDP-10/tenex&#34;&gt;TENEX&lt;/a&gt; source code (load average code is in SCHED.MAC).&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://tools.ietf.org/html/rfc546&#34;&gt;RFC 546&lt;/a&gt; &amp;quot;TENEX Load Averages for July 1973&amp;quot; (explains measuring CPU demand).&lt;/li&gt;&#xA;&lt;li&gt;Bobrow, D., et al. “TENEX: A Paged Time Sharing System for the PDP-10,” Communications of the ACM, March 1972 (explains the load average triplet).&lt;/li&gt;&#xA;&lt;li&gt;Gunther, N. &amp;quot;UNIX Load Average Part 1: How It Works&amp;quot; &lt;a href=&#34;http://www.teamquest.com/import/pdfs/whitepaper/ldavg1.pdf&#34;&gt;PDF&lt;/a&gt; (explains the exponential calculations).&lt;/li&gt;&#xA;&lt;li&gt;Linus&#39;s email about &lt;a href=&#34;http://www.linuxmisc.com/30-linux-announce/4543def681c7f27b.htm&#34;&gt;Linux 0.99 patchlevel 14&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;The load average change email is on &lt;a href=&#34;http://oldlinux.org/Linux.old/mail-archive/&#34;&gt;oldlinux.org&lt;/a&gt; (in alan-old-funet-lists/kernel.1993.gz, and not in the linux directories, which I searched first).&lt;/li&gt;&#xA;&lt;li&gt;The Linux kernel/sched.c source before and after the load average change: &lt;a href=&#34;http://kernelhistory.sourcentral.org/linux-0.99.13/?f=/linux-0.99.13/S/449.html%23L332&#34;&gt;0.99.13&lt;/a&gt;, &lt;a href=&#34;http://kernelhistory.sourcentral.org/linux-0.99.14/?f=/linux-0.99.14/S/323.html%23L412&#34;&gt;0.99.14&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Tarballs for Linux 0.99 releases are on &lt;a href=&#34;https://www.kernel.org/pub/linux/kernel/Historic/v0.99/&#34;&gt;kernel.org&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;The current Linux load average code: &lt;a href=&#34;https://github.com/torvalds/linux/blob/master/kernel/sched/loadavg.c&#34;&gt;loadavg.c&lt;/a&gt;, &lt;a href=&#34;https://github.com/torvalds/linux/blob/master/include/linux/sched/loadavg.h&#34;&gt;loadavg.h&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;The bcc analysis tools includes my &lt;a href=&#34;http://www.brendangregg.com/blog/2016-01-20/ebpf-offcpu-flame-graph.html&#34;&gt;offcputime&lt;/a&gt;, used for tracing TASK_UNINTERRUPTIBLE.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.brendangregg.com/flamegraphs.html&#34;&gt;Flame Graphs&lt;/a&gt; were used for visualizing uninterruptible paths.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2020/06/25/perftest-analysis-load-average/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Linux 性能分析 - 上下文切换</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2020/06/18/perftest-analysis-cpu2/</id>
    <content type="html">&lt;h1&gt;前言&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;/2020/05/29/perftest-analysis-cpu1/&#34;&gt;上一篇文章&lt;/a&gt;中提到，处于可运行状态的进程越多，平均负载也越高。&lt;/p&gt;&#xA;&lt;p&gt;有人可能会有疑问，这种计算方法合理吗？同样是 100% 的 CPU 使用率，有 10 个可运行进程的系统的平均负载，是有 1 个可运行进程系统的负载的 10 倍？本文就试图从 CPU 上下文切换的角度来解释这一指标的合理性。&lt;/p&gt;&#xA;&lt;h1&gt;上下文切换定义&lt;/h1&gt;&#xA;&lt;h2&gt;CPU 上下文切换&lt;/h2&gt;&#xA;&lt;p&gt;虽然系统的 CPU 个数有限，但能支持同时运行个任务。当然这种同时只是宏观上的假象，如果从微观角度观察，会发现系统在不停轮流切换任务，使得每个任务都能获得运行的机会。&lt;/p&gt;&#xA;&lt;p&gt;CPU 是状态 + 存储的模型，其符合图灵机这种理想设备：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;内存&lt;/li&gt;&#xA;&lt;li&gt;PC 指针指向下一条待运行的指令（状态）&lt;/li&gt;&#xA;&lt;li&gt;计算规则&lt;/li&gt;&#xA;&lt;li&gt;其他辅助计算的寄存器（状态）&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;多任务的每个任务都有自己的状态。当任务 1 切出，任务 2 切入时，CPU 的状态也要切换成任务 2 上一次切出时的状态，这样任务 2 才能继续运行。这些状态即是 CPU 上下文，CPU 上下文切换即保存和恢复 PC 和辅助计算的寄存器。&lt;/p&gt;&#xA;&lt;h2&gt;进程上下文切换&lt;/h2&gt;&#xA;&lt;p&gt;CPU 中的寄存器似乎一只手就数的过来，切换的成本非常小，为什么会造成系统负载显著升高呢？Linux 操作系统中的任务有进程和线程，切换的主要成本来自于进程/线程的上下文切换。&lt;/p&gt;&#xA;&lt;p&gt;第一点，现代处理器有很多个运行等级。比如在 x86 的保护模式中，有四种特权等级。Linux 使用 Ring 0 和 Ring 3：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/perf-cpu/450px-Priv_rings.svg.png&#34; alt=&#34;x86 保护模式下特权等级&#34;&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Ring 0 是内核空间，具有最高权限，可访问所有硬件资源&lt;/li&gt;&#xA;&lt;li&gt;Ring 3 是用户空间，权限最低，无法直接访问硬件资源&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;用户态权限有限，无法直接操作所有寄存器，进程的切换只能由内核态来管理和调度，所以必然发生用户态 &amp;lt;-&amp;gt; 内核态的频繁转换。而每个特权等级运行的代码不同，所以在切换用户态 &amp;lt;-&amp;gt; 内核态时，内核/用户空间本身的 CPU 上下文也需要互相切换。&lt;/p&gt;&#xA;&lt;p&gt;第二点，进程本身的数据结构庞大。Linux 中使用数据结构 &lt;code&gt;task_struct&lt;/code&gt; 来描述进程所有的资源，其主要成员有进程状态、内核栈信息、进程使用状态、PID、优先级、锁、时间片、队列、信号量、内存管理信息、文件列表等等与进程管理、调度密切相关的信息。当切换进程运行，这些数据结构也需要保存和恢复。&lt;/p&gt;&#xA;&lt;p&gt;第三点，虚拟内存。内核为每个进程提供了一个假象：进程都是独占地使用内存，这种独占是无法感知也无法使用其它进程的内存。&lt;/p&gt;&#xA;&lt;p&gt;虚拟内存和实际的物理内存之间映射不是一个地址一个地址的映射，而是通过页表机制来实现。一页通常是 4096KB，这样的映射关系即为页表数据，为了减少页表数据的大小，会采用多级页表，比如 Linux 为了让进程支持 256T 内存，采用了四级页表。页表机制会带来额外的问题，页表本身也是存在内存里的，四级页表最坏情况下需要 5 次内存 IO 才能获取一个真正的内存数据。&lt;/p&gt;&#xA;&lt;p&gt;为了让操作系统更快地操作虚拟内存，x86 处理器专门提供了 TLB(Translation Lookaside Buffer) 来管理虚拟内存到物理内存的映射关系。它可以理解为一个专用缓存，特点就是快，但缺点是存储的数据少，缓存有可能不命中。当系统发生进程切换，从进程 A 切换到进程 B，TLB 也必须刷新，那在刷新后，进程 B 必然会出现 TLB 不命中的情况，导致虚拟内存访问变慢。&lt;/p&gt;&#xA;&lt;p&gt;由以上三点可见，进程上下文切换开销巨大，根据 &lt;a href=&#34;https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html&#34;&gt;Tsuna&lt;/a&gt;的测试报告，这一过程会持续数千纳秒。如果进程切换频繁，系统真正运行进程的时间便不够了。&lt;/p&gt;&#xA;&lt;h2&gt;线程上下文切换&lt;/h2&gt;&#xA;&lt;p&gt;在 Linux 的实现中，系统调度的基本单位其实是线程，进程是线程的集合，同一个进程的线程看到的虚拟内存是共享的，所以：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果切换的两个线程分属不同的进程，因为资源不共享，其切换成本等同于进程上下文切换。&lt;/li&gt;&#xA;&lt;li&gt;如果切换的两个线程属于同一个进程，因为虚拟内存是共享的，刷新 TLB 没有必要，切换成本也就少。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;中断上下文切换&lt;/h2&gt;&#xA;&lt;p&gt;为了快速响应硬件事件，Linux 中发生中断也会打断进程的正常执行，这时候就会发生中断上下文切换。&lt;/p&gt;&#xA;&lt;p&gt;中断程序执行于内核空间，与任何进程无关，故用户态进程程序切换到中断处理程序时，没有虚拟内存切换的成本，保持 TLB 不变即可。&lt;/p&gt;&#xA;&lt;h2&gt;上下文切换的时机&lt;/h2&gt;&#xA;&lt;p&gt;切换分两种，自愿和非自愿：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;自愿上下文切换(voluntary context switches)。比如当前进程所需资源未满足时，便会挂起等待。又比如调用睡眠函数 sleep 这样的方法将自己主动挂起。&lt;/li&gt;&#xA;&lt;li&gt;非自愿上下文切换(non voluntary context switches)。操作系统为保证调度的公平性，会将时间分片，轮流分给每个进程。进程若在自己的时间片内未执行完，便会被系统强制切出 CPU。Linux 系统还支持带优先级的进程，高优先级进程可以打断低优先级进程。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;有一点需要强调，虽然用&lt;code&gt;ps aux&lt;/code&gt;能看到数百个进程，但并非意味着 Linux 需要在这数百个进程上切换。它们大部分处于睡眠状态，操作系统只会对处于可运行态的进程间作上下文切换。&lt;/p&gt;&#xA;&lt;h1&gt;实验&lt;/h1&gt;&#xA;&lt;h2&gt;工具&lt;/h2&gt;&#xA;&lt;p&gt;vmstat 命令帮助文档虽然说是 Report virtual memory statistics，但其实它还能统计 CPU/中断/IO/缺页等使用情况。&lt;/p&gt;&#xA;&lt;p&gt;以下是该命令每隔 1 秒输出一次统计数据，输出 10 次（第一次的输出不可信）：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;➜  ~ vmstat 1 10&#xA;procs --memory- swap-- --io- -system-- cpu--&#xA; r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st&#xA; 0  0    524 2010216 1195432 10930004    0    0     0    50    1    2  4  2 92  3  0&#xA; ...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们需要关心的是：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;r，可运行进程的个数（运行和就绪的进程）&lt;/li&gt;&#xA;&lt;li&gt;b，不可中断进程的个数&lt;/li&gt;&#xA;&lt;li&gt;in，每秒中断次数，包括时钟&lt;/li&gt;&#xA;&lt;li&gt;cs，每秒 CPU 上下文切换次数&lt;/li&gt;&#xA;&lt;li&gt;us，执行用户代码的时间&lt;/li&gt;&#xA;&lt;li&gt;sy，执行内核代码的时间&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;vmstat 命令还不够，&lt;a href=&#34;/2020/05/29/perftest-analysis-cpu1/&#34;&gt;上一篇文章&lt;/a&gt;中介绍的 pidstat 可以看到进程上下文切换的数据：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;➜  ~ pidstat -w 5&#xA;Linux 4.15.0-96-generic (work) &#x9;06/20/2020 &#x9;_x86_64_&#x9;(2 CPU)&#xA;&#xA;11:46:00 PM   UID       PID   cswch/s nvcswch/s  Command&#xA;11:46:05 PM     0         1      1.00      0.00  systemd&#xA;11:46:05 PM     0         7     12.38      0.00  ksoftirqd/0&#xA;11:46:05 PM     0         8    132.93      0.00  rcu_sched&#xA;11:46:05 PM     0        11      0.20      0.00  watchdog/0&#xA;11:46:05 PM     0        14      0.20      0.00  watchdog/1&#xA;11:46:05 PM     0        16     12.97      0.00  ksoftirqd/1&#xA;11:46:05 PM     0       207     25.15      0.00  usb-storage&#xA;11:46:05 PM     0       209      7.98      0.00  kworker/0:1H&#xA;11:46:05 PM     0       330      2.00      0.00  jbd2/sda2-8&#xA;11:46:05 PM     0       333      0.40      0.00  kworker/1:1H&#xA;11:46:05 PM     0       436      2.00      1.00  systemd-udevd&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;其中：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;cswch/s，每秒自愿上下文切换次数&lt;/li&gt;&#xA;&lt;li&gt;nvcswch/s，每秒非自愿上下文切换次数&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;如果要看到线程上下文切换的信息，还需要加上 -t 参数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;➜  ~ pidstat -w 5 -t&#xA;Linux 4.15.0-96-generic (work) &#x9;06/20/2020 &#x9;_x86_64_&#x9;(2 CPU)&#xA;&#xA;11:50:28 PM   UID      TGID       TID   cswch/s nvcswch/s  Command&#xA;11:50:33 PM     0      4588         -      0.20      0.20  pili-themisd&#xA;11:50:33 PM     0         -      4588      0.20      0.20  |__pili-themisd&#xA;11:50:33 PM     0         -      4589     13.44      0.20  |__pili-themisd&#xA;11:50:33 PM     0         -      4590      1.98      0.00  |__pili-themisd&#xA;11:50:33 PM     0         -      4594      3.75      0.00  |__pili-themisd&#xA;11:50:33 PM     0         -      4596      4.55      1.19  |__pili-themisd&#xA;11:50:33 PM     0         -      4650      3.95      0.40  |__pili-themisd&#xA;11:50:33 PM     0         -      4674      2.96      0.40  |__pili-themisd&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;进程和线程的实验&lt;/h2&gt;&#xA;&lt;h3&gt;stress 进程切换实验&lt;/h3&gt;&#xA;&lt;p&gt;我们回到最开始的问题，为什么同样是 100% 的 CPU 使用率，有 10 个可运行进程的系统的平均负载，是有 1 个可运行进程系统的负载的 10 倍？&lt;/p&gt;&#xA;&lt;p&gt;首先看一下 100% CPU，1 个可运行进程的上下文切换次数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;➜  ~ stress -c 1 -t 600&#xA;stress: info: [6800] dispatching hogs: 1 cpu, 0 io, 0 vm, 0 hdd&#xA;&#xA;➜  ~ vmstat 1 20&#xA;procs --memory- swap-- --io- -system-- cpu--&#xA; r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st&#xA; 1  0      0 294216 274960 2234876    0    0     0    24 2714 7362 54  1 45  0  0&#xA; 2  0      0 294208 274960 2234876    0    0     0    68 2327 6601 59  2 39  1  0&#xA; 2  0      0 294216 274960 2234880    0    0     0   116 1555 4465 53  2 45  0  1&#xA;&#xA;➜  ~ pidstat -w 1&#xA;Average:      UID       PID   cswch/s nvcswch/s  Command&#xA;Average:        0      9258      0.00     64.39  stress&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;首先看一下 100% CPU，10 个可运行进程的上下文切换次数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;➜  ~ stress -c 10 -t 600&#xA;stress: info: [7024] dispatching hogs: 10 cpu, 0 io, 0 vm, 0 hdd&#xA;&#xA;➜  ~ vmstat 1 20&#xA;procs --memory- swap-- --io- -system-- cpu--&#xA; r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st&#xA;10  0      0 294972 274976 2234964    0    0     0    28 2097 5976 99  2  0  0  0&#xA;13  0      0 294900 274976 2234976    0    0     0   176 2256 6545 98  2  0  0  0&#xA;10  0      0 295040 274976 2234976    0    0     0    28 2254 6835 99  1  0  0  1&#xA;&#xA;➜  ~ pidstat -w 1&#xA;Average:      UID       PID   cswch/s nvcswch/s  Command&#xA;Average:        0      7025      0.00    160.97  stress&#xA;Average:        0      7026      0.00    125.14  stress&#xA;Average:        0      7027      0.00    136.82  stress&#xA;Average:        0      7028      0.00    162.62  stress&#xA;Average:        0      7029      0.00    121.83  stress&#xA;Average:        0      7030      0.00    170.89  stress&#xA;Average:        0      7031      0.00    114.99  stress&#xA;Average:        0      7032      0.00    130.54  stress&#xA;Average:        0      7033      0.00    165.38  stress&#xA;Average:        0      7034      0.00    163.51  stress&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;光看 CPU 上下文切换次数似乎差不多，但进程被动上下文切换次数明显上升。我们之前了解到，CPU 切换的成本较小，进程的切换成本最高，这就是系统负载升高的原因。&lt;/p&gt;&#xA;&lt;h3&gt;sysbench 线程切换实验&lt;/h3&gt;&#xA;&lt;p&gt;stress 命令只能模拟多进程的系统压力，模拟多线程需要 sysbench 工具。&lt;/p&gt;&#xA;&lt;p&gt;运行以下命令模拟 10 个线程竞争：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;➜  ~ sysbench --threads=10 --max-time=300 threads run&#xA;&#xA;➜  ~ uptime&#xA; 08:41:12 up 69 days,  5:33,  2 users,  load average: 6.32, 6.32, 6.73&#xA;&#xA;➜  ~ vmstat 1 20&#xA;procs --memory- swap-- --io- -system-- cpu--&#xA; r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st&#xA; 8  0      0 292580 275072 2237844    0    0     0    28 15202 1234282 30 69  2  0  0&#xA; 8  0      0 292332 275072 2237848    0    0     0   224 18851 1221323 31 68  1  0  1&#xA; 8  0      0 292280 275072 2237848    0    0     0    28 16822 1177891 32 66  2  0  0&#xA;&#xA;➜  ~ pidstat -w -t 1 (需要加上 -t，否则不会统计线程的切换信息)&#xA;Average:        0         -     11743  19613.96  96288.49  |__sysbench&#xA;Average:        0         -     11744  20440.57  93726.42  |__sysbench&#xA;Average:        0         -     11745  20680.38  99453.02  |__sysbench&#xA;Average:        0         -     11746  19855.47  89219.06  |__sysbench&#xA;Average:        0         -     11747  18738.49  97730.38  |__sysbench&#xA;Average:        0         -     11748  14536.04  99870.75  |__sysbench&#xA;Average:        0         -     11749  15928.11 103604.72  |__sysbench&#xA;Average:        0         -     11750  18082.26  94775.66  |__sysbench&#xA;Average:        0         -     11751  20995.66  89222.64  |__sysbench&#xA;Average:        0         -     11752  20588.30  94581.89  |__sysbench&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在多线程下，每秒 CPU 上下文切换次数达到了近 120 万，任务的自愿和非自愿切换同时升高。当然系统负载自然也就高了。&lt;/p&gt;&#xA;&lt;h3&gt;两者的不同&lt;/h3&gt;&#xA;&lt;p&gt;同样是调度 10 个任务，stress 和 sysbench 为什么切换次数区别如此之大？可以从两方面解释：&lt;/p&gt;&#xA;&lt;p&gt;第一、同一个进程的线程间切换成本小，切换的频率可以升高。&lt;/p&gt;&#xA;&lt;p&gt;第二、sysbench 和 stress 模拟压力的方式不同：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;➜  ~ sysbench threads help&#xA;sysbench 1.0.11 (using system LuaJIT 2.1.0-beta3)&#xA;&#xA;threads options:&#xA;  --thread-yields=N number of yields to do per request [1000]&#xA;  --thread-locks=N  number of locks per thread [8]&#xA;&#xA;➜  ~ stress --help&#xA;`stress&#39; imposes certain types of compute stress on your system&#xA;&#xA;Usage: stress [OPTION [ARG]] ...&#xA; -c, --cpu N        spawn N workers spinning on sqrt()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;sysbench 用线程同步方式 (lock) 和主动让出 CPU (yield) 来产生系统压力，属于自愿上下文切换，统计数据中自愿切换的次数非 0。&lt;/li&gt;&#xA;&lt;li&gt;stress 用 CPU 密集型操作 (求根 sqrt()) 来产生系统压力，属于非自愿上下文切换，统计数据中自愿切换的次数为 0。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1&gt;结论&lt;/h1&gt;&#xA;&lt;p&gt;在 CPU 跑满，系统平均负载均很高的情况下，需要具体情况具体分析：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;自愿上下文切换变多，说明被调度任务在等待资源，有可能发生了 IO 或任务间同步情况&lt;/li&gt;&#xA;&lt;li&gt;非自愿上下文切换变多，说明被调度的任务被强制打断，任务在争抢使用 CPU&lt;/li&gt;&#xA;&lt;li&gt;如果上下文切换次数离奇的高，说明有可能是多线程场景&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2020/06/18/perftest-analysis-cpu2/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Linux 性能分析 - 如何理解 CPU 平均负载</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2020/05/29/perftest-analysis-cpu1/</id>
    <content type="html">&lt;h2&gt;平均负载的定义&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;uptime&lt;/code&gt;是最简单的性能分析命令之一，它的输出非常简单，比如：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ uptime&#xA; 16:08:29 up 42 days,  5:11,  2 users,  load average: 0.33, 0.22, 0.22&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;前面几列易于理解，分别是当前时间，系统已运行时间，登录的用户数。可是最后的平均负载是什么？查看&lt;code&gt;uptime&lt;/code&gt;帮助文档对其的定义：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;System load averages is the average number of processes that are either in a runnable or uninterruptable state. A  process in a runnable state is either using the CPU or waiting to use the CPU. A process in uninterruptable state is waiting for some I/O access, eg waiting for disk. The averages are taken over the three time intervals. Load averages are not normalized for the number of CPUs in a system, so a load average of 1 means a single CPU system is loaded all the time while on a 4 CPU system it means it was idle 75% of the time.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;大概翻译过来就是：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;系统的平均负载是指处于可运行和不可中断状态的进程平均数量。所谓可运行状态是指正在使用或等待使用 CPU，而不可中断状态是指进程正执行某种 I/O 操作，比如读写磁盘。平均负载会计算 1 分钟、5 分钟和 15 分钟内的该指标。不过需要注意的是，该数据没有针对 CPU 个数作归一化处理，所以平均负载 1 在单核系统上意味满负载运行，而在 4 核系统上意味着只使用了 25% 的负载。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2&gt;进程的状态&lt;/h2&gt;&#xA;&lt;h3&gt;操作系统进程的基本状态&lt;/h3&gt;&#xA;&lt;p&gt;在操作系统的概念中，进程会不断改变其运行状态，其必须有以下三种基本状态：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;就绪：进程所需要的资源都已经获得，但是还没有分配到 CPU 来运行&lt;/li&gt;&#xA;&lt;li&gt;运行：进程分配到 CPU 在运行&lt;/li&gt;&#xA;&lt;li&gt;阻塞：进程的某些资源还没有满足，比如缓冲区申请未分配，等待 I/O 完成&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3&gt;Linux 进程的基本状态&lt;/h3&gt;&#xA;&lt;p&gt;相比于标准的操作系统概念，Linux 中对于状态有自己的划分：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;D 不可中断睡眠，最常见的是正在访问硬件设备，若中断会导致磁盘数据和进程数据不一致&lt;/li&gt;&#xA;&lt;li&gt;R 运行和就绪，对，Linux 上这两个状态是被统计在一起的&lt;/li&gt;&#xA;&lt;li&gt;S 可中断睡眠，比如进程正在等待信号唤醒&lt;/li&gt;&#xA;&lt;li&gt;T 停止，是处于调试状态的进程&lt;/li&gt;&#xA;&lt;li&gt;Z 僵尸进程，即父进程未等待子进程退出&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;理解定义&lt;/h2&gt;&#xA;&lt;p&gt;由上述 Linux 的进程定义，所谓可运行和不可中断状态就是活跃的进程，即正在使用 CPU/等待 CPU/等待 IO 的进程，而平均负载可理解为单位时间内活跃进程的数量。&lt;/p&gt;&#xA;&lt;p&gt;如果每个核上都正好跑着一个进程，则说明 CPU 被充分的利用。那么平均负载为 4 在一个四核处理器上就是 CPU 刚好被完全占用，而在单核处理器上，意味着有 3 个进程得不到 CPU，只能干等。&lt;/p&gt;&#xA;&lt;h3&gt;平均负载与 CPU 利用率&lt;/h3&gt;&#xA;&lt;p&gt;在未看过本文之前，你很可能将平均负载和 CPU 利用率划上等号，事实上，这是两个独立的概念。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;对于 CPU 密集型进程，因为大量利用了 CPU，故而平均负载升高&lt;/li&gt;&#xA;&lt;li&gt;对于 I/O 密集型进程，虽然 CPU 利用率不高，但是大量进程都阻塞住，使得活跃进程数量增加，所以平均负载也会升高&lt;/li&gt;&#xA;&lt;li&gt;对于有大量等待调度的进程，这些进程都处于就绪态，平均负载也高。而且由于上下文切换，进程数量多，切换的机会也多，这无形中也增加了负载&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;实验&lt;/h2&gt;&#xA;&lt;p&gt;我们就上文提到的三个场景，分别做实验来模拟。&lt;/p&gt;&#xA;&lt;p&gt;我们实验所用的系统是 ubuntu 18，机器配置为 2 CPU/16 GB。&lt;/p&gt;&#xA;&lt;h3&gt;工具介绍&lt;/h3&gt;&#xA;&lt;p&gt;工欲善其事，必先利其器。有很多现成的工具可以模拟负载，监控和分析系统性能。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;stress&lt;/code&gt;可以用来对系统施加指定类型的系统压力，它并不是一个基准测试工具&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;mpstat&lt;/code&gt;是一个多核的 CPU 性能分析工具，可以统计每个 CPU 的性能&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;pidstat&lt;/code&gt;是一个多进程性能分析工具，可以统计每个进程的性能&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;实验开始时首先查看一下系统的负载情况：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ uptime&#xA; 15:23:16 up 51 days,  4:26,  1 user,  load average: 0.15, 0.30, 0.31&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;确认一下系统的是否是 2 核：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ cat /proc/cpuinfo | grep processor&#xA;2&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;CPU 密集型&lt;/h3&gt;&#xA;&lt;p&gt;我们利用&lt;code&gt;stress&lt;/code&gt;模拟一个 CPU 跑满的场景：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ stress --cpu 1 --timeout 600&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;过两分钟后查看&lt;code&gt;uptime&lt;/code&gt;查看平均负载：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ uptime&#xA; 15:41:09 up 51 days,  4:44,  2 users,  load average: 1.18, 0.77, 0.49&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到系统负载越升越高，1 分钟内的平均负载高于 5 分钟内平均负载。&lt;/p&gt;&#xA;&lt;p&gt;使用&lt;code&gt;mpstat&lt;/code&gt;查看 CPU 利用率的情况：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# ALL 表示输出所有 CPU 的情况，5 表示每隔 5s 输出一次&#xA;$ mpstat -P ALL 5&#xA;03:42:26 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle&#xA;03:42:31 PM  all   51.96    0.00    1.01    0.81    0.00    0.10    0.00    0.00    0.00   46.12&#xA;03:42:31 PM    0    3.44    0.00    2.02    1.62    0.00    0.20    0.00    0.00    0.00   92.71&#xA;03:42:31 PM    1  100.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到其中一个 CPU 利用率飙到了 100%，这个是平均负载升高的直接原因。&lt;/p&gt;&#xA;&lt;p&gt;使用&lt;code&gt;pidstat&lt;/code&gt;查看具体是哪个进程占用了 CPU：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# 5 表示每隔 5s 输出一次&#xA;$ pidstat -u 5&#xA;Linux 4.15.0-96-generic (work) &#x9;06/07/2020 &#x9;_x86_64_&#x9;(2 CPU)&#xA;&#xA;03:46:19 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command&#xA;03:46:24 PM     0     10766    0.20    0.20    0.00    0.60    0.40     0  redis-server&#xA;03:46:24 PM  1000     27225   99.80    0.00    0.00    0.00   99.80     1  stress&#xA;03:46:24 PM  1000     27583    0.00    0.20    0.00    0.00    0.20     0  pidstat&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;虽然输出有很多行，但我们很容易就发现是&lt;code&gt;stress&lt;/code&gt;这个进程使用了 100% 的 CPU。&lt;/p&gt;&#xA;&lt;h3&gt;I/O 密集型&lt;/h3&gt;&#xA;&lt;p&gt;我们还是使用&lt;code&gt;stress&lt;/code&gt;模拟 I/O 压力&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ stress -i 1 --timeout 600&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;过两分钟后查看&lt;code&gt;uptime&lt;/code&gt;查看平均负载：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ uptime&#xA; 15:53:43 up 51 days,  4:57,  2 users,  load average: 1.09, 0.94, 0.85&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;平均负载果然升高了。&lt;/p&gt;&#xA;&lt;p&gt;同时我们看一下 CPU 利用率的情况：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;03:54:43 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle&#xA;03:54:48 PM  all    2.57    0.00    3.81   29.35    0.00    1.75    0.00    0.00    0.00   62.51&#xA;03:54:48 PM    0    2.49    0.00    3.53   45.95    0.00    3.33    0.00    0.00    0.00   44.70&#xA;03:54:48 PM    1    2.86    0.00    4.09   12.88    0.00    0.20    0.00    0.00    0.00   79.96&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到两个 CPU 都没有被占满。但是&lt;code&gt;%iowait&lt;/code&gt;这一项和上一小节有明显的差异，&lt;code&gt;%iowait&lt;/code&gt;即是反映 I/O 压力的情况。&lt;/p&gt;&#xA;&lt;p&gt;我们接着用&lt;code&gt;pidstat&lt;/code&gt;查看具体是哪个进程导致的&lt;code&gt;%iowait&lt;/code&gt;升高：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ pidstat -u 5&#xA;Linux 4.15.0-96-generic (work) &#x9;06/07/2020 &#x9;_x86_64_&#x9;(2 CPU)&#xA;&#xA;03:59:31 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command&#xA;03:59:36 PM     0         7    0.00    0.20    0.00    0.00    0.20     0  ksoftirqd/0&#xA;03:59:36 PM     0         8    0.00    0.20    0.00    0.20    0.20     0  rcu_sched&#xA;03:59:36 PM     0       209    0.00    1.20    0.00    0.00    1.20     0  kworker/0:1H&#xA;03:59:36 PM   112      2047    0.20    0.20    0.00    0.00    0.40     1  beam.smp&#xA;03:59:36 PM     0      9976    0.00    0.20    0.00    0.00    0.20     1  supervisord&#xA;03:59:36 PM     0      9981    0.40    0.00    0.00    0.00    0.40     1  mongod&#xA;03:59:36 PM     0     10071    0.40    0.00    0.00    0.00    0.40     1  mongod&#xA;03:59:36 PM     0     10072    0.40    0.00    0.00    0.00    0.40     0  mongod&#xA;03:59:36 PM     0     10073    0.40    0.20    0.00    0.00    0.60     0  mongod&#xA;03:59:36 PM     0     10765    0.20    0.00    0.00    0.00    0.20     1  redis-server&#xA;03:59:36 PM     0     10766    0.20    0.20    0.00    0.60    0.40     0  redis-server&#xA;03:59:36 PM     0     10821    0.20    0.00    0.00    0.00    0.20     1  redis-server&#xA;03:59:36 PM  1000     27741    0.00    7.19    0.00    1.40    7.19     0  stress&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到&lt;code&gt;%wait&lt;/code&gt;这一项高的还是&lt;code&gt;stress&lt;/code&gt;进程。&lt;/p&gt;&#xA;&lt;h3&gt;大量等待调度的进程&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;stress&lt;/code&gt;可以模拟出处于运行态的进程，以下模拟出 10 个待调度的进程：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ stress -c 10 --timeout 600&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;过两分钟后查看&lt;code&gt;uptime&lt;/code&gt;查看平均负载：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ uptime&#xA; 16:09:20 up 51 days,  5:12,  2 users,  load average: 9.38, 4.54, 2.35&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;平均负载又升高了，而且远高于以上两个实验，这也是当然的，根据平均负载的定义，这里有 10 个处于可运行的进程，那么平均负载的值肯定会接近 10。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ pidstat -u 5&#xA;Linux 4.15.0-96-generic (work) &#x9;06/07/2020 &#x9;_x86_64_&#x9;(2 CPU)&#xA;&#xA;04:11:59 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command&#xA;04:12:04 PM     0         8    0.00    0.20    0.00    0.20    0.20     0  rcu_sched&#xA;04:12:04 PM     0      9976    0.20    0.00    0.00    0.00    0.20     1  supervisord&#xA;04:12:04 PM     0      9981    0.60    0.00    0.00    0.00    0.60     1  mongod&#xA;04:12:04 PM     0     10071    0.20    0.00    0.00    0.00    0.20     1  mongod&#xA;04:12:04 PM     0     10072    0.20    0.00    0.00    0.00    0.20     0  mongod&#xA;04:12:04 PM     0     10073    0.20    0.00    0.00    0.00    0.20     0  mongod&#xA;04:12:04 PM     0     10260    0.40    0.20    0.00    0.00    0.60     1  mongod&#xA;04:12:04 PM     0     10261    0.40    0.00    0.00    0.00    0.40     1  mongod&#xA;04:12:04 PM     0     10262    0.20    0.00    0.00    0.00    0.20     1  mongod&#xA;04:12:04 PM     0     10763    0.20    0.00    0.00    0.20    0.20     1  redis-server&#xA;04:12:04 PM     0     10764    0.20    0.00    0.00    0.20    0.20     1  redis-server&#xA;04:12:04 PM     0     10766    0.20    0.20    0.00    0.80    0.40     0  redis-server&#xA;04:12:04 PM     0     10820    0.20    0.00    0.00    0.00    0.20     1  redis-server&#xA;04:12:04 PM  1000     28242   19.48    0.00    0.00   80.12   19.48     0  stress&#xA;04:12:04 PM  1000     28243   19.28    0.00    0.00   80.12   19.28     1  stress&#xA;04:12:04 PM  1000     28244   19.28    0.00    0.00   80.12   19.28     0  stress&#xA;04:12:04 PM  1000     28245   19.28    0.00    0.00   79.72   19.28     1  stress&#xA;04:12:04 PM  1000     28246   19.48    0.00    0.00   80.12   19.48     0  stress&#xA;04:12:04 PM  1000     28247   19.28    0.00    0.00   79.92   19.28     0  stress&#xA;04:12:04 PM  1000     28248   19.48    0.00    0.00   79.92   19.48     1  stress&#xA;04:12:04 PM  1000     28249   19.48    0.00    0.00   80.52   19.48     1  stress&#xA;04:12:04 PM  1000     28250   19.48    0.00    0.00   80.12   19.48     1  stress&#xA;04:12:04 PM  1000     28251   19.48    0.00    0.00   80.52   19.48     0  stress&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到有 10 个&lt;code&gt;stress&lt;/code&gt;进程在抢 2 个 CPU。&lt;/p&gt;&#xA;&lt;h2&gt;小结&lt;/h2&gt;&#xA;&lt;p&gt;通过本文我们了解到：平均负载与 CPU 利用率没有必然联系。而当发现负载升高后，需要综合使用&lt;code&gt;uptime&lt;/code&gt;, &lt;code&gt;mpstat&lt;/code&gt;, &lt;code&gt;pidstat&lt;/code&gt;等工具来分析是上述哪三个场景，从而找到负载升高的来源。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2020/05/29/perftest-analysis-cpu1/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Golang 并发模式 - Context</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2020/05/25/go-concurrency-pattern-context/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;本文翻译+删选+理解自 &lt;a href=&#34;https://blog.golang.org/context&#34;&gt;Go Concurrency Patterns: Context&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;在使用 Go 编写的服务器程序中，每个请求都由一个 goroutine 来处理，通常这些请求又会启动额外的 goroutines 来访问后台数据库或者调用 RPC 服务。这些与同一个请求相关的 goroutines，常常需要访问同一个特定的资源，比如用户标识，认证 token 等等。当请求取消或者超时时，所有相关的 goroutines 都应该快速退出，这样系统才能回收不用的资源。&lt;/p&gt;&#xA;&lt;p&gt;为此，Google 公司开发了&lt;a href=&#34;https://golang.org/pkg/context&#34;&gt;context&lt;/a&gt;包。该库可以跨越 API 边界，给所有 goroutines 传递请求相关的值、取消信号和超时时间。这篇文章会介绍如何使用&lt;a href=&#34;https://golang.org/pkg/context&#34;&gt;context&lt;/a&gt;库，并给出一个完整的例子。&lt;/p&gt;&#xA;&lt;h2&gt;Context&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;context&lt;/code&gt;包的核心是&lt;code&gt;Context&lt;/code&gt;结构体：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// A Context carries a deadline, cancelation signal, and request-scoped values&#xA;// across API boundaries. Its methods are safe for simultaneous use by multiple&#xA;// goroutines.&#xA;type Context interface {&#xA;    // Done returns a channel that is closed when this Context is canceled&#xA;    // or times out.&#xA;    Done() &amp;lt;-chan struct{}&#xA;&#xA;    // Err indicates why this context was canceled, after the Done channel&#xA;    // is closed.&#xA;    Err() error&#xA;&#xA;    // Deadline returns the time when this Context will be canceled, if any.&#xA;    Deadline() (deadline time.Time, ok bool)&#xA;&#xA;    // Value returns the value associated with key or nil if none.&#xA;    Value(key interface{}) interface{}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;Done&lt;/code&gt;方法返回一个 channel，它会给&lt;code&gt;Context&lt;/code&gt;上所有的函数发送取消信号，当 channel 关闭时，这些函数应该终止剩余流程立即返回。&lt;code&gt;Err&lt;/code&gt;方法返回的错误指出了&lt;code&gt;Context&lt;/code&gt;为什么取消。&lt;a href=&#34;https://blog.golang.org/pipelines&#34;&gt;Pipelines and Cancelation&lt;/a&gt;中讨论了&lt;code&gt;Done&lt;/code&gt;的具体用法。&lt;/p&gt;&#xA;&lt;p&gt;由于接收和发送信号的通常不是同一个函数，&lt;code&gt;Context&lt;/code&gt;并没有提供&lt;code&gt;Cancel&lt;/code&gt;方法，基于相同的理由，&lt;code&gt;Done&lt;/code&gt;channel 只负责接收。尤其当父操作开启 goroutines 执行子操作时，子操作肯定不能取消父操作。作为替代，&lt;code&gt;WithCancel&lt;/code&gt;函数可以用来取消&lt;code&gt;Context&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Context&lt;/code&gt;对 goroutines 来说是并发安全的，你可以将单个&lt;code&gt;Context&lt;/code&gt;传递给任意数量的 goroutines，然后取消该&lt;code&gt;Context&lt;/code&gt;给这些 goroutines 同时发送信号。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Deadline&lt;/code&gt;方法用于判断函数究竟要不要运行，比如截止时间将近时，运行也就没必要了。代码可依此为 I/O 操作设置超时时间。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Value&lt;/code&gt;方法则为&lt;code&gt;Context&lt;/code&gt;存储了请求所有的数据，访问这些数据必须是并发安全的。&lt;/p&gt;&#xA;&lt;h2&gt;Context 派生&lt;/h2&gt;&#xA;&lt;p&gt;使用&lt;code&gt;Context&lt;/code&gt;包提供的方法可以从已有的&lt;code&gt;Context&lt;/code&gt;值派生出新值。这些派生出的值逻辑上构成了一棵树：当根&lt;code&gt;Context&lt;/code&gt;取消，其派生出的子&lt;code&gt;Context&lt;/code&gt;也会跟着取消。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Background&lt;/code&gt;是所有&lt;code&gt;Context&lt;/code&gt;树的根，它永远不会被取消：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Background returns an empty Context. It is never canceled, has no deadline,&#xA;// and has no values. Background is typically used in main, init, and tests,&#xA;// and as the top-level Context for incoming requests.&#xA;func Background() Context&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;WithCancel&lt;/code&gt;和&lt;code&gt;WithTimeout&lt;/code&gt;函数返回的派生&lt;code&gt;Context&lt;/code&gt;值，可以先于父值取消。当请求的回调函数返回后，与请求相关的&lt;code&gt;Context&lt;/code&gt;即可被取消。当有多个备份后台程序同时提供服务时，&lt;code&gt;WithCancel&lt;/code&gt;可用于去除多余的请求。&lt;code&gt;WithTimeout&lt;/code&gt;则可用于为请求设置超时时间。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// WithCancel returns a copy of parent whose Done channel is closed as soon as&#xA;// parent.Done is closed or cancel is called.&#xA;func WithCancel(parent Context) (ctx Context, cancel CancelFunc)&#xA;&#xA;// A CancelFunc cancels a Context.&#xA;type CancelFunc func()&#xA;&#xA;// WithTimeout returns a copy of parent whose Done channel is closed as soon as&#xA;// parent.Done is closed, cancel is called, or timeout elapses. The new&#xA;// Context&#39;s Deadline is the sooner of now+timeout and the parent&#39;s deadline, if&#xA;// any. If the timer is still running, the cancel function releases its&#xA;// resources.&#xA;func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;WithValue&lt;/code&gt;则在&lt;code&gt;Context&lt;/code&gt;上存储了请求相关的值：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// WithValue returns a copy of parent whose Value method returns val for key.&#xA;func WithValue(parent Context, key interface{}, val interface{}) Context&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;例子：谷歌网页搜索&lt;/h2&gt;&#xA;&lt;p&gt;本例子提供一个 HTTP 服务器，接收类似&lt;code&gt;/search?q=golang&amp;amp;timeout=1s&lt;/code&gt;的 GET 请求，并把查询参数值&amp;quot;golang&amp;quot;转推到&lt;a href=&#34;https://developers.google.com/web-search/docs/&#34;&gt;谷歌网页搜索API&lt;/a&gt;。参数&lt;code&gt;timeout&lt;/code&gt;告诉服务器如果谷歌 API 超时就取消请求。&lt;/p&gt;&#xA;&lt;p&gt;代码分为三个包：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.golang.org/context/server/server.go&#34;&gt;server&lt;/a&gt;提供 main 函数，处理&lt;code&gt;/search&lt;/code&gt;来的请求。&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.golang.org/context/userip/userip.go&#34;&gt;userip&lt;/a&gt;提供的函数将用户 IP 地址绑定到一个&lt;code&gt;Context&lt;/code&gt;值上。&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.golang.org/context/google/google.go&#34;&gt;google&lt;/a&gt;提供 Search 函数将请求转发到谷歌。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;server 程序&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.golang.org/context/server/server.go&#34;&gt;server&lt;/a&gt;中，请求回调创建了一个名为&lt;code&gt;ctx&lt;/code&gt;的&lt;code&gt;Context&lt;/code&gt;值，当回调退出时，延迟函数&lt;code&gt;defer cancel()&lt;/code&gt;即执行取消操作。如果请求的 URL 带有 timeout 参数，那超时后&lt;code&gt;Context&lt;/code&gt;会自动取消：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func handleSearch(w http.ResponseWriter, req *http.Request) {&#xA;    // ctx is the Context for this handler. Calling cancel closes the&#xA;    // ctx.Done channel, which is the cancellation signal for requests&#xA;    // started by this handler.&#xA;    var (&#xA;        ctx    context.Context&#xA;        cancel context.CancelFunc&#xA;    )&#xA;    timeout, err := time.ParseDuration(req.FormValue(&amp;quot;timeout&amp;quot;))&#xA;    if err == nil {&#xA;        // The request has a timeout, so create a context that is&#xA;        // canceled automatically when the timeout expires.&#xA;        ctx, cancel = context.WithTimeout(context.Background(), timeout)&#xA;    } else {&#xA;        ctx, cancel = context.WithCancel(context.Background())&#xA;    }&#xA;    defer cancel() // Cancel ctx as soon as handleSearch returns.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;回调函数从请求中获取参数信息，并调用&lt;code&gt;userip&lt;/code&gt;包获取客户端 IP 地址。由于后台服务中会使用到客户端 IP 地址，故需要将此存储于&lt;code&gt;ctx&lt;/code&gt;中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;    // Check the search query.&#xA;    query := req.FormValue(&amp;quot;q&amp;quot;)&#xA;    if query == &amp;quot;&amp;quot; {&#xA;        http.Error(w, &amp;quot;no query&amp;quot;, http.StatusBadRequest)&#xA;        return&#xA;    }&#xA;&#xA;    // Store the user IP in ctx for use by code in other packages.&#xA;    userIP, err := userip.FromRequest(req)&#xA;    if err != nil {&#xA;        http.Error(w, err.Error(), http.StatusBadRequest)&#xA;        return&#xA;    }&#xA;    ctx = userip.NewContext(ctx, userIP)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;传入&lt;code&gt;ctx&lt;/code&gt;和&lt;code&gt;query&lt;/code&gt;参数调用&lt;code&gt;google.Search&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;    // Run the Google search and print the results.&#xA;    start := time.Now()&#xA;    results, err := google.Search(ctx, query)&#xA;    elapsed := time.Since(start)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果搜索成功，会渲染出结果：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;    if err := resultsTemplate.Execute(w, struct {&#xA;        Results          google.Results&#xA;        Timeout, Elapsed time.Duration&#xA;    }{&#xA;        Results: results,&#xA;        Timeout: timeout,&#xA;        Elapsed: elapsed,&#xA;    }); err != nil {&#xA;        log.Print(err)&#xA;        return&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;userip 包&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.golang.org/context/userip/userip.go&#34;&gt;userip&lt;/a&gt;包提供了解析用户 IP 地址函数的包，同时会将 IP 地址存储于一个&lt;code&gt;Context&lt;/code&gt;值中。&lt;code&gt;Context&lt;/code&gt;提供了键值对存储，键值都是&lt;code&gt;interface{}&lt;/code&gt;类型，键必须可比较，值必须是并发安全。&lt;code&gt;userip&lt;/code&gt;包屏蔽了实现上的细节，并以强类型方式访问&lt;code&gt;Context&lt;/code&gt;值。&lt;/p&gt;&#xA;&lt;p&gt;为了避免键冲突，&lt;code&gt;userip&lt;/code&gt;包首先定义一个非导出类型&lt;code&gt;key&lt;/code&gt;，然后用该类型定义的值作为&lt;code&gt;Context&lt;/code&gt;的键：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// The key type is unexported to prevent collisions with context keys defined in&#xA;// other packages.&#xA;type key int&#xA;&#xA;// userIPkey is the context key for the user IP address.  Its value of zero is&#xA;// arbitrary.  If this package defined other context keys, they would have&#xA;// different integer values.&#xA;const userIPKey key = 0&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;FromRequest&lt;/code&gt;从&lt;code&gt;http.Request&lt;/code&gt;解析出客户端 IP 地址&lt;code&gt;userIP&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func FromRequest(req *http.Request) (net.IP, error) {&#xA;    ip, _, err := net.SplitHostPort(req.RemoteAddr)&#xA;    if err != nil {&#xA;        return nil, fmt.Errorf(&amp;quot;userip: %q is not IP:port&amp;quot;, req.RemoteAddr)&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;NewContext&lt;/code&gt;将&lt;code&gt;userIP&lt;/code&gt;存储于新建的&lt;code&gt;Context&lt;/code&gt;中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func NewContext(ctx context.Context, userIP net.IP) context.Context {&#xA;    return context.WithValue(ctx, userIPKey, userIP)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;FromContext&lt;/code&gt;则相反，从&lt;code&gt;Context&lt;/code&gt;取出 IP 地址：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func FromContext(ctx context.Context) (net.IP, bool) {&#xA;    // ctx.Value returns nil if ctx has no value for the key;&#xA;    // the net.IP type assertion returns ok=false for nil.&#xA;    userIP, ok := ctx.Value(userIPKey).(net.IP)&#xA;    return userIP, ok&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;google 包&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;google.Search&lt;/code&gt;函数对谷歌 API 发起 HTTP 请求，并解析 JSON 结果。该函数同时接收一个&lt;code&gt;Context&lt;/code&gt;参数&lt;code&gt;ctx&lt;/code&gt;，如果请求处理时，&lt;code&gt;ctx.Done&lt;/code&gt;关闭了，则立即退出。&lt;/p&gt;&#xA;&lt;p&gt;谷歌 API 会将搜索内容和用户 IP 地址&lt;code&gt;userIP&lt;/code&gt;作为请求参数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func Search(ctx context.Context, query string) (Results, error) {&#xA;    // Prepare the Google Search API request.&#xA;    req, err := http.NewRequest(&amp;quot;GET&amp;quot;, &amp;quot;https://ajax.googleapis.com/ajax/services/search/web?v=1.0&amp;quot;, nil)&#xA;    if err != nil {&#xA;        return nil, err&#xA;    }&#xA;    q := req.URL.Query()&#xA;    q.Set(&amp;quot;q&amp;quot;, query)&#xA;&#xA;    // If ctx is carrying the user IP address, forward it to the server.&#xA;    // Google APIs use the user IP to distinguish server-initiated requests&#xA;    // from end-user requests.&#xA;    if userIP, ok := userip.FromContext(ctx); ok {&#xA;        q.Set(&amp;quot;userip&amp;quot;, userIP.String())&#xA;    }&#xA;    req.URL.RawQuery = q.Encode()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;Search&lt;/code&gt;使用了辅助函数&lt;code&gt;httpDo&lt;/code&gt;来发起和取消 HTTP 请求，辅助函数参数有一个是处理 HTTP 响应的闭包：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;    var results Results&#xA;    err = httpDo(ctx, req, func(resp *http.Response, err error) error {&#xA;        if err != nil {&#xA;            return err&#xA;        }&#xA;        defer resp.Body.Close()&#xA;&#xA;        // Parse the JSON search result.&#xA;        // https://developers.google.com/web-search/docs/#fonje&#xA;        var data struct {&#xA;            ResponseData struct {&#xA;                Results []struct {&#xA;                    TitleNoFormatting string&#xA;                    URL               string&#xA;                }&#xA;            }&#xA;        }&#xA;        if err := json.NewDecoder(resp.Body).Decode(&amp;amp;data); err != nil {&#xA;            return err&#xA;        }&#xA;        for _, res := range data.ResponseData.Results {&#xA;            results = append(results, Result{Title: res.TitleNoFormatting, URL: res.URL})&#xA;        }&#xA;        return nil&#xA;    })&#xA;    // httpDo waits for the closure we provided to return, so it&#39;s safe to&#xA;    // read results here.&#xA;    return results, err&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;httpDo&lt;/code&gt;函数会在新的 goroutine 中处理 HTTP 请求和响应，同时如果&lt;code&gt;ctx.Done&lt;/code&gt;提前关闭，函数会直接退出。&lt;/p&gt;&#xA;&lt;h2&gt;为 Context 作代码适配&lt;/h2&gt;&#xA;&lt;p&gt;许多服务器框架已经存储了请求相关值，我们可以实现&lt;code&gt;Context&lt;/code&gt;接口的所有方法，来为&lt;code&gt;Context&lt;/code&gt;参数适配这些现有框架。而框架的使用者在调用代码时则需要多传入一个&lt;code&gt;Context&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;参考实现：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.golang.org/context/gorilla/gorilla.go&#34;&gt;gorilla.go&lt;/a&gt;适配了 Gorilla 的&lt;a href=&#34;http://www.gorillatoolkit.org/pkg/context&#34;&gt;github.com/gorilla/context&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.golang.org/context/tomb/tomb.go&#34;&gt;tomb.go&lt;/a&gt;适配了&lt;a href=&#34;https://godoc.org/gopkg.in/tomb.v2&#34;&gt;Tomb&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2020/05/25/go-concurrency-pattern-context/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>client-go informer 解析</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2020/02/22/k8s-client-go-tutorial-01/</id>
    <link href="https://www.lyyyuna.com/2020/02/22/k8s-client-go-tutorial-01/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Golang 的版本管理原则</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2020/02/22/go-the-principles-versioning-in-go/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;本文翻译+删选+理解自 &lt;a href=&#34;https://research.swtch.com/vgo-principles&#34;&gt;The Principles of Versioning in Go&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2&gt;为什么需要版本？&lt;/h2&gt;&#xA;&lt;p&gt;让我们先看下传统基于&lt;code&gt;GOPATH&lt;/code&gt;的&lt;code&gt;go get&lt;/code&gt;是如何导致版本管理失败的。&lt;/p&gt;&#xA;&lt;p&gt;假设有一个全新安装的 Go 环境，我们需要写一个程序导入&lt;code&gt;D&lt;/code&gt;，因此运行&lt;code&gt;go get D&lt;/code&gt;。记住现在是基于&lt;code&gt;GOPATH&lt;/code&gt;的&lt;code&gt;go get&lt;/code&gt;，不是 &lt;code&gt;go mod&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ go get D&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/vgo-why-1@1.5x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;该命令会寻找并下载最新版本的&lt;code&gt;D 1.0&lt;/code&gt;，并假设现在能成功构建。&lt;/p&gt;&#xA;&lt;p&gt;几个月后我们需要一个新的库&lt;code&gt;C&lt;/code&gt;，我们接着运行&lt;code&gt;go get C&lt;/code&gt;，该库的版本为 1.8。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ go get C&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/vgo-why-2@1.5x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;C&lt;/code&gt;导入&lt;code&gt;D&lt;/code&gt;，但是&lt;code&gt;go get&lt;/code&gt;发现当前环境内已经下载过&lt;code&gt;D&lt;/code&gt;库了，所以 Go 会重复使用该库。不幸的是，本地的&lt;code&gt;D&lt;/code&gt;版本是 1.0，而&lt;code&gt;C&lt;/code&gt;对&lt;code&gt;D&lt;/code&gt;有版本依赖，必须是 1.4 以上（有可能 1.4 有一些 bugfix 或者新 feature）。&lt;/p&gt;&#xA;&lt;p&gt;显而易见这里&lt;code&gt;C&lt;/code&gt;会构建失败。我们再次运行&lt;code&gt;go get -u C&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ go get -u C&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/vgo-why-3@2x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;不幸的是，（假设）一小时前&lt;code&gt;D&lt;/code&gt;的作者发布了&lt;code&gt;D 1.6&lt;/code&gt;，该版本又引入了一个缺陷。因为&lt;code&gt;go get -u&lt;/code&gt;一直使用最新的依赖，所以使用 1.6 的&lt;code&gt;C&lt;/code&gt;又构建失败了。&lt;/p&gt;&#xA;&lt;p&gt;由这个例子可以看出，基于&lt;code&gt;GOPATH&lt;/code&gt;的&lt;code&gt;go get&lt;/code&gt;缺乏版本管理，会导致两种问题，要么版本过低，要么版本过高。我们需要一种机制，&lt;code&gt;C&lt;/code&gt;和&lt;code&gt;D&lt;/code&gt;的作者能够一起开发和测试。&lt;/p&gt;&#xA;&lt;p&gt;自从&lt;code&gt;goinstall/go get&lt;/code&gt;推出之后，Go 程序员就对版本管理有着强烈的诉求，过去几年间，很多第三方的工具被开发出来。然而，这些工具对版本控制的细节有着不同的实现和理解，这会导致不同的库若使用不同的工具，库之间仍然无法协同工作。&lt;/p&gt;&#xA;&lt;h2&gt;软件工程中的版本&lt;/h2&gt;&#xA;&lt;p&gt;过去两年间（2019），官方试图在&lt;code&gt;go&lt;/code&gt;命令中引入&lt;code&gt;Go moduless&lt;/code&gt;的概念来支持版本管理。&lt;code&gt;Go moduless&lt;/code&gt;带来新的库导入语法——即语义化导入版本(Semantic import versioning)，而在选择版本时，使用了新的算法——即最小版本选择算法。&lt;/p&gt;&#xA;&lt;p&gt;你可能会问：为什么不使用其他语言的现成经验？Java 有&lt;code&gt;Maven&lt;/code&gt;，Node 有&lt;code&gt;NPM&lt;/code&gt;，Ruby 有&lt;code&gt;Bundler&lt;/code&gt;，Rust 有&lt;code&gt;Cargo&lt;/code&gt;，他们解决版本依赖的思路不好么？&lt;/p&gt;&#xA;&lt;p&gt;你可能还会问：Go 团队在 2018 早些时候引入了一个试验性的工具&lt;code&gt;Dep&lt;/code&gt;，该工具实现上与&lt;code&gt;Bundler&lt;/code&gt;和&lt;code&gt;Cargo&lt;/code&gt;一致，现在为啥又变卦了？&lt;/p&gt;&#xA;&lt;p&gt;答案是我们从使用&lt;code&gt;Bundler&lt;/code&gt;/&lt;code&gt;Cargo&lt;/code&gt;/&lt;code&gt;Dep&lt;/code&gt;的经验中发现，它们所谓处理依赖的方法，只会使项目越来越复杂，&lt;code&gt;go modules&lt;/code&gt;决定另辟蹊径。&lt;/p&gt;&#xA;&lt;h2&gt;三原则&lt;/h2&gt;&#xA;&lt;p&gt;回到一个很基础的问题：什么是软件工程？软件工程和编程有什么区别？原作者 Russ Cox 使用了这个定义：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Software engineering is what happens to programming&#xA;when you add time and other programmers.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;为了简化软件工程，&lt;code&gt;Dep&lt;/code&gt;和&lt;code&gt;Go moduless&lt;/code&gt;在原则上有三个显著的改变，它们是兼容性、可重复性和可合作性。本文余下部分会详细阐述这三个指导思想。&lt;/p&gt;&#xA;&lt;h3&gt;原则 #1：兼容性&lt;/h3&gt;&#xA;&lt;p&gt;第一原则是兼容性，或者称之为稳定性，程序中&lt;strong&gt;名字&lt;/strong&gt;的意义不能随着时间改变。一年前一个名字的含义和今年、后年应该完全一致。&lt;/p&gt;&#xA;&lt;p&gt;例如，程序员经常会对标准库&lt;code&gt;string.Split&lt;/code&gt;的细节困扰。我们期望在&lt;code&gt;&amp;quot;hello world&amp;quot;&lt;/code&gt;调用后产生两个字符串&lt;code&gt;&amp;quot;hello&amp;quot;&lt;/code&gt;和&lt;code&gt;&amp;quot;world&lt;/code&gt;。但是如果函数输入有前、后或着重复的空格，输出结果也会包含空字符串：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Example: strings.Split(x, &amp;quot; &amp;quot;)&#xA;&#xA;&amp;quot;hello world&amp;quot;  =&amp;gt; {&amp;quot;hello&amp;quot;, &amp;quot;world&amp;quot;}&#xA;&amp;quot;hello  world&amp;quot; =&amp;gt; {&amp;quot;hello&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;world&amp;quot;}&#xA;&amp;quot; hello world&amp;quot; =&amp;gt; {&amp;quot;&amp;quot;, &amp;quot;hello&amp;quot;, &amp;quot;world&amp;quot;}&#xA;&amp;quot;hello world &amp;quot; =&amp;gt; {&amp;quot;hello&amp;quot;, &amp;quot;world&amp;quot;, &amp;quot;&amp;quot;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;假设我们决定改变这一行为，去除所有空字符串，可以么？&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;不&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;因为我们已经在旧版&lt;code&gt;string.Split&lt;/code&gt;的文档和实现上达成一致。有无数的程序依赖于这一行为，改变它会破话兼容性原则。&lt;/p&gt;&#xA;&lt;p&gt;对于新的行为，正确的做法是给一个新的名字。事实上也是如此，我们没有重新定义&lt;code&gt;strings.Split&lt;/code&gt;，几年前，标准库引入了&lt;code&gt;strings.Fields&lt;/code&gt;函数。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Example: strings.Fields(x)&#xA;&#xA;&amp;quot;hello world&amp;quot;  =&amp;gt; {&amp;quot;hello&amp;quot;, &amp;quot;world&amp;quot;}&#xA;&amp;quot;hello  world&amp;quot; =&amp;gt; {&amp;quot;hello&amp;quot;, &amp;quot;world&amp;quot;}&#xA;&amp;quot; hello world&amp;quot; =&amp;gt; {&amp;quot;hello&amp;quot;, &amp;quot;world&amp;quot;}&#xA;&amp;quot;hello world &amp;quot; =&amp;gt; {&amp;quot;hello&amp;quot;, &amp;quot;world&amp;quot;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;遵守兼容性原则可以大大简化软件工程。当程序员理解程序时，你无需把时间纳入考量范围内，2015 年使用的&lt;code&gt;strings.Split&lt;/code&gt;和今年使用的&lt;code&gt;strings.Split&lt;/code&gt;是一样的。工具也是如此，比如重构工具可以随意地将&lt;code&gt;strings.Split&lt;/code&gt;在不同包内移动而不用担心函数含义随着时间发生改变。&lt;/p&gt;&#xA;&lt;p&gt;实际上，Go 1 最重要的特性就是其语言不变性。这一特性在官方文档中得到明确，&lt;a href=&#34;golang.org/doc/go1compat&#34;&gt;golang.org/doc/go1compat&lt;/a&gt;：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;It is intended that programs written to the Go 1 specification will continue to compile and run correctly, unchanged, over the lifetime of that specification. Go programs that work today should continue to work even as future “point” releases of Go 1 arise (Go 1.1, Go 1.2, etc.).&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;所有 Go 1.x 版本的程序在后续版本仍能继续编译，并且正确运行，行为保持不变。今天写了一个 Go 程序，未来它仍能正常工作。Go 官方同样也对标准库中的函数作出了承诺。&lt;/p&gt;&#xA;&lt;p&gt;兼容性和版本有啥管理？当今最火的版本管理方法——&lt;a href=&#34;https://semver.org/&#34;&gt;语义化版本&lt;/a&gt;是鼓励不兼容的，这意味着你可以通过语义化版本号，更轻易地作出不兼容的改变。&lt;/p&gt;&#xA;&lt;p&gt;如何理解？&lt;/p&gt;&#xA;&lt;p&gt;语义化版本有着&lt;code&gt;vMAJOR.MINOR.PATCH&lt;/code&gt;的形式。如果两个版本有着系统的主版本号，那么后一个版本应该向前兼容前一个版本。如果主版本号不同，那他俩就是不兼容的。该方法鼓励包的作者，如果你想作出不兼容的行为，那改变主版本号吧！&lt;/p&gt;&#xA;&lt;p&gt;对于 Go 程序来说，光改变主版本号还不够，两个主版本号如果名字一模一样，阅读代码还是会造成困扰。&lt;/p&gt;&#xA;&lt;p&gt;看起来，情况变得更加糟糕。&lt;/p&gt;&#xA;&lt;p&gt;假设包&lt;code&gt;B&lt;/code&gt;期望使用 V1 版本的&lt;code&gt;string.Split&lt;/code&gt;，而&lt;code&gt;C&lt;/code&gt;期望使用 V2 版本的&lt;code&gt;string.Split&lt;/code&gt;。如果&lt;code&gt;B&lt;/code&gt;和&lt;code&gt;C&lt;/code&gt;是分别构建的，那 OK。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/vgo-why-4@2x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;但如果有一个包&lt;code&gt;A&lt;/code&gt;同时导入了包&lt;code&gt;B&lt;/code&gt;和&lt;code&gt;C&lt;/code&gt;呢？那该如何选择&lt;code&gt;string.Split&lt;/code&gt;的版本？&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/vgo-why-5@2x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;针对&lt;code&gt;Go modules&lt;/code&gt;的设计思想，官方意识到兼容性是最基础的原则，是必须支持、鼓励和遵循的。Go 的 FAQ 中写到：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Packages intended for public use should try to maintain backwards compatibility as they evolve. The Go 1 compatibility guidelines are a good reference here: don’t remove exported names, encourage tagged composite literals, and so on. If different functionality is required, add a new name instead of changing an old one. If a complete break is required, create a new package with a new import path.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;大致意思是如果新旧两个包导入路径相同，那它们就应该被当作是兼容的。&lt;/p&gt;&#xA;&lt;p&gt;这和语义化版本有什么关系呢？兼容性原则要求不同主版本号之间不需要有兼容性上的联系，所以，很自然地要求我们使用不同的导入路径。而&lt;code&gt;Go modules&lt;/code&gt;中的做法是把主版本号放入导入路径，我们称之为语义化导入版本(Semantic import versioning)。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/impver@2x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;在这个例子中，&lt;code&gt;my/thing/v2&lt;/code&gt;表示使用版本 2。如果是版本 1，那就是&lt;code&gt;my/thing&lt;/code&gt;，没有显式在路径指定版本号，所以路径成为了主版本号的一部分，以此类推，版本 3 的导入路径为&lt;code&gt;my/thing/v3&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;如果&lt;code&gt;strings&lt;/code&gt;包是我们开发者自己的模块，我们不想增加新的函数&lt;code&gt;Fields&lt;/code&gt;而是重新定义&lt;code&gt;Split&lt;/code&gt;，那么可以创建两个模块&lt;code&gt;strings&lt;/code&gt;(主版本号 1)和&lt;code&gt;strings/v2&lt;/code&gt;(主版本号 2)，这样可以同时存在两个不同的&lt;code&gt;Split&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/vgo-why-6@2x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;依据此路径规则，&lt;code&gt;A&lt;/code&gt;、&lt;code&gt;B&lt;/code&gt;和&lt;code&gt;C&lt;/code&gt;都能构建成功，整个程序都能正常运行。开发者和各种工具都能明白它们是不同的包，就像&lt;code&gt;crypto/rand&lt;/code&gt;和&lt;code&gt;math/rand&lt;/code&gt;是不同的一样显而易见。&lt;/p&gt;&#xA;&lt;p&gt;让我们回到那个不可构建的程序。把&lt;code&gt;strings&lt;/code&gt;抽象成包&lt;code&gt;D&lt;/code&gt;，，这时候若不使用&lt;em&gt;语义化导入版本方法&lt;/em&gt;，这样就遇到了经典的“钻石依赖问题”：&lt;code&gt;B&lt;/code&gt;和&lt;code&gt;C&lt;/code&gt;单独都能构建，但放在一起就不行。如果尝试构建程序&lt;code&gt;A&lt;/code&gt;，那该如何选择版本&lt;code&gt;D&lt;/code&gt;呢？&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/vgo-why-7@2x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;语义化导入版本切断了“钻石依赖”。因为&lt;code&gt;D&lt;/code&gt;的版本 2.0 有不一样的导入路径，&lt;code&gt;D/v2&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/vgo-why-8@2x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h3&gt;原则 #2：可重复性&lt;/h3&gt;&#xA;&lt;p&gt;第二原则是程序构建必须具有可重复性，一个指定版本包的构建结果不应随时间改变。在该原则下，今天我编译代码的结果和其他程序员明年编译的结果是匹配的。&lt;strong&gt;大部分包管理系统并不保证一点&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;在第一小节我们也看到了，基于&lt;code&gt;GOPATH&lt;/code&gt;的&lt;code&gt;go get&lt;/code&gt;用的不是最新就是最旧的&lt;code&gt;D&lt;/code&gt;。你可能认为，“&lt;code&gt;go get&lt;/code&gt;当然会犯错误：它对版本一无所知”。但其实其他一些包管理工具也会犯同样的错误，这里以&lt;code&gt;Dep&lt;/code&gt;为例。（&lt;code&gt;Cargo&lt;/code&gt;和&lt;code&gt;Bundler&lt;/code&gt;也类似）&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Dep&lt;/code&gt;要求每一个包包含一个&lt;code&gt;manifest&lt;/code&gt;来存放元数据，记录下对所有依赖的要求。当&lt;code&gt;Dep&lt;/code&gt;下载了&lt;code&gt;C&lt;/code&gt;，它读入&lt;code&gt;C&lt;/code&gt;的元数据，知道了&lt;code&gt;C&lt;/code&gt;需要&lt;code&gt;D 1.4&lt;/code&gt;之后的版本。然后&lt;code&gt;Dep&lt;/code&gt;下载了最新版本的&lt;code&gt;D&lt;/code&gt;来满足这一限制。&lt;/p&gt;&#xA;&lt;p&gt;假设在昨天，&lt;code&gt;D&lt;/code&gt;最新版本是 1.5：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/vgo-why-9@2x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;而今天，&lt;code&gt;D&lt;/code&gt;更新为了 1.6：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/vgo-why-10@2x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以看出，该决策方法是不可重复的，会随时间发生改变。&lt;/p&gt;&#xA;&lt;p&gt;当然，&lt;code&gt;Dep&lt;/code&gt;的开发者意识到了这一点，它们引入了第二个元数据文件——lock 文件。如果&lt;code&gt;C&lt;/code&gt;本身是一个完整的程序，当 Go 调用&lt;code&gt;package main&lt;/code&gt;的时候，lock 文件会记录下&lt;code&gt;C&lt;/code&gt;使用依赖的确切版本，而当需要重复构建时，lock 文件内所记录的依赖具有更高的优先级。也就是说，lock 文件同样能保证重复性原则。&lt;/p&gt;&#xA;&lt;p&gt;但 lock 文件只是针对整体程序而言——&lt;code&gt;package main&lt;/code&gt;。如果&lt;code&gt;C&lt;/code&gt;被别的更大程序所使用，lock 文件就无效了，库&lt;code&gt;C&lt;/code&gt;的构建仍会随着时间的改变而改变。&lt;/p&gt;&#xA;&lt;p&gt;而&lt;code&gt;Go modules&lt;/code&gt;的算法非常简单，那就是“最小版本选择算法”——每一个包指定其依赖的最低版本号。比如假设&lt;code&gt;B 1.3&lt;/code&gt;要求最低&lt;code&gt;D 1.3&lt;/code&gt;，&lt;code&gt;C 1.8&lt;/code&gt;要求最低&lt;code&gt;D 1.4&lt;/code&gt;。&lt;code&gt;Go modules&lt;/code&gt;不会选择最新的版本，而是选择最小能满足要求的版本，这样，构建的结果是可重复的。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/vgo-why-12@2x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;如果构建的不同部分有不同最低版本要求，&lt;code&gt;go&lt;/code&gt;命令会使用最近的那个版本。如图所示，&lt;code&gt;A&lt;/code&gt;构建时发现同时有&lt;code&gt;D 1.3&lt;/code&gt;和&lt;code&gt;D 1.4&lt;/code&gt;的依赖，由于 1.4 大于 1.3，所以构建时会选择&lt;code&gt;D 1.4&lt;/code&gt;。&lt;code&gt;D 1.5&lt;/code&gt;或者&lt;code&gt;D 1.6&lt;/code&gt;存在与否并不会影响该决策。&lt;/p&gt;&#xA;&lt;p&gt;在没有 lock 文件的情况下，该算法依然保证了程序和库的可重复性构建。&lt;/p&gt;&#xA;&lt;h3&gt;原则 #3：可合作性&lt;/h3&gt;&#xA;&lt;p&gt;第三原则是可合作性。为了维护 Go 包的生态，我们追求的是一个统一的连贯的系统。相反，我们想避免的是生态分裂，变成一组一组互相之间不可合作的包。&lt;/p&gt;&#xA;&lt;p&gt;若开发者们不合作，无论我们使用的工具有多么精巧，技巧多么高超，整个 Go 开源生态一定会走向分裂。这里隐含的意思是，为了修复不兼容性，必须要合作，我们不应排斥合作。&lt;/p&gt;&#xA;&lt;p&gt;还是拿库&lt;code&gt;C 1.8&lt;/code&gt;举例子，它要求最低版本&lt;code&gt;D 1.4&lt;/code&gt;。由于可重复性原则，&lt;code&gt;C 1.8&lt;/code&gt;构建会使用&lt;code&gt;D 1.4&lt;/code&gt;。如果&lt;code&gt;C 1.8&lt;/code&gt;是被其他更大的程序所依赖，且该程序要求&lt;code&gt;D 1.5&lt;/code&gt;，那根据最小版本选择算法，会选择&lt;code&gt;D 1.5&lt;/code&gt;。这时候构建仍是正确的。&lt;/p&gt;&#xA;&lt;p&gt;现在问题来了，&lt;code&gt;D&lt;/code&gt; 的作者发布了 1.6 版本，但该版本有问题，&lt;code&gt;C 1.8&lt;/code&gt;无法与该版本构建。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/vgo-why-13@2x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;解决的方法是&lt;code&gt;C&lt;/code&gt;和&lt;code&gt;D&lt;/code&gt;的作者合作来发布 fix。解决方法多种多样。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;C&lt;/code&gt; 可以推出 1.9 版本，规避掉&lt;code&gt;D 1.6&lt;/code&gt;中的 bug。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/vgo-why-15@2x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;D&lt;/code&gt; 也可以推出 1.7 版本，修复其存在的 bug。同时，根据兼容性原则，&lt;code&gt;C 1.9&lt;/code&gt;可以指定其要求最低&lt;code&gt;D 1.7&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/posts/version-in-go/vgo-why-14@2x.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;再来复盘一下刚才的故事，最新版本的&lt;code&gt;C&lt;/code&gt;和&lt;code&gt;D&lt;/code&gt;突然不能一起工作了，这打破了 Go 包的生态，两库的作者必须合作来修复 bug。这种合作对生态是良性的。而正由于&lt;code&gt;Go modules&lt;/code&gt;采用的包选择算法/可重复性，那些没有显式指定&lt;code&gt;D 1.6&lt;/code&gt;的库都不会被影响。这给了&lt;code&gt;C&lt;/code&gt;和&lt;code&gt;D&lt;/code&gt;的作者充分的时间来给出最终解决方案。&lt;/p&gt;&#xA;&lt;h2&gt;结论&lt;/h2&gt;&#xA;&lt;p&gt;以上是 Go 版本管理的三原则，也是&lt;code&gt;Go modules&lt;/code&gt;区别于&lt;code&gt;Dep&lt;/code&gt;，&lt;code&gt;Bundler&lt;/code&gt;和&lt;code&gt;Cargo&lt;/code&gt;的根本原因。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;兼容性，程序中所使用的名字不随时间改变。&lt;/li&gt;&#xA;&lt;li&gt;可重复性，指定版本的包构建结果不随时间改变。&lt;/li&gt;&#xA;&lt;li&gt;可合作性，为了维护 Go 包的生态，互相必须易于合作。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;三原则来自于对年复一年软件工程的思考，它们互相巩固，是一个良性的循环：兼容性原则使用的版本选择算法带来了可重复性。而可重复性保证除非开发者显式指定，否则构建不会使用最新的、或是有问题的库，这给了我们时间来修复问题。而这种合作性又能保证兼容性。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;Go 1.13&lt;/code&gt;中，&lt;code&gt;Go modules&lt;/code&gt;已经可用于生成环境，很多公司，包括 Google 已经接纳了它。&lt;code&gt;Go 1.14&lt;/code&gt;和&lt;code&gt;Go 1.15&lt;/code&gt;会带来更多方便开发者的特性，它的最终目标是彻底移除&lt;code&gt;GOPATH&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;具体&lt;code&gt;Go modules&lt;/code&gt;的使用方法，可以参考这个系列博客&lt;a href=&#34;https://blog.golang.org/using-go-modules&#34;&gt;Using Go Modules&lt;/a&gt;。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2020/02/22/go-the-principles-versioning-in-go/" rel="alternate"></link>
    <summary type="html">Go Modules 与其他语言的包管理工具有什么不同？</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>PostgreSQL 中的函数稳定性</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2018/07/06/postgres-function-volatile/</id>
    <content type="html">&lt;h2&gt;定义&lt;/h2&gt;&#xA;&lt;p&gt;PostgreSQL 中函数有三个稳定性状态可选：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;immutable，函数不可以修改数据库的数据,并且在任何情况下调用，只要输入参数一致，返回结果都一致。&lt;/li&gt;&#xA;&lt;li&gt;stable，函数不可以修改数据库的数据，同一个QUERY中，如果需要返回该函数的结果，那么将合并多次运算为一次这个函数。&lt;/li&gt;&#xA;&lt;li&gt;volatile，函数可以修改数据库的数据，输入同样的参数可以返回不同的结果，同一个QUERY中，如果需要返回该函数的结果，那么每一行都会运算一遍这个函数。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;函数的稳定性会影响执行计划。在索引比较的时候，被比较的值只会运算一次，所以 volatile 不能被执行计划选择作为索引的比较条件。&lt;/p&gt;&#xA;&lt;h2&gt;例子&lt;/h2&gt;&#xA;&lt;h3&gt;查看函数的稳定性&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;ddei=# select proname, provolatile from pg_proc where proname in (&#39;now&#39;, &#39;clock_timestamp&#39;);&#xA;     proname     | provolatile &#xA;--+-&#xA; now             | s&#xA; clock_timestamp | v&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;其中 clock_timestamp 是 voatile, now 是 stable。&lt;/p&gt;&#xA;&lt;h3&gt;测试插入语句&lt;/h3&gt;&#xA;&lt;p&gt;创建一个测试表&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;ddei=# create table test(id int, time1 timestamp, time2 timestamp);&#xA;CREATE TABLE&#xA;ddei=# insert into test select generate_series(1,1000),clock_timestamp(), now();&#xA;INSERT 0 1000&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;插入语句，对于 stable 函数 &lt;code&gt;now()&lt;/code&gt; 应该只执行一次：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;ddei=# select count(*),count(distinct time1),count(distinct time2) from test;&#xA; count | count | count &#xA;-+-+-&#xA;  1000 |  1000 |     1&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;测试对索引的影响&lt;/h3&gt;&#xA;&lt;p&gt;在测试表上创建索引，并查看执行计划：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;ddei=# create index test_idx on test(time1);&#xA;CREATE INDEX&#xA;ddei=# &#xA;ddei=# explain select * from test where time1&amp;gt;now();&#xA;                              QUERY PLAN                              &#xA;-&#xA; Index Scan using test_idx on test  (cost=0.00..4.27 rows=1 width=20)&#xA;   Index Cond: (time1 &amp;gt; now())&#xA;(2 rows)&#xA;&#xA;ddei=# explain select * from test where time1&amp;gt;clock_timestamp();&#xA;                       QUERY PLAN                       &#xA;--&#xA; Seq Scan on test  (cost=0.00..22.00 rows=333 width=20)&#xA;   Filter: (time1 &amp;gt; clock_timestamp())&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;对于 volatile 的函数 clock_timestamp 在 where 条件中，不走索引。而 stable 函数 now 在 where 条件中，会走索引。&lt;/p&gt;&#xA;&lt;h2&gt;修改函数稳定性&lt;/h2&gt;&#xA;&lt;p&gt;使用以下语句可修改函数稳定性：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;ddei=# alter function clock_timestamp() strict stable;&#xA;ALTER FUNCTION&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;再次测试 clock_timestamp 的索引情况：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;ddei=# explain select * from test where time1&amp;gt;clock_timestamp();&#xA;                              QUERY PLAN                              &#xA;-&#xA; Index Scan using test_idx on test  (cost=0.00..4.27 rows=1 width=20)&#xA;   Index Cond: (time1 &amp;gt; clock_timestamp())&#xA;(2 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这次 clock_timestamp 在 where 条件中走了索引。&lt;/p&gt;&#xA;&lt;p&gt;不过不要随意修改系统自带函数的稳定性。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2018/07/06/postgres-function-volatile/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>atop 简单使用</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2018/07/04/perftest-atop/</id>
    <content type="html">&lt;p&gt;atop 是一个系统性能监控工具，可以在系统级别监控 CPU、内存、硬盘和网络的使用情况。&lt;/p&gt;&#xA;&lt;p&gt;atop 不仅可以以交互式的方式运行，还可以一一定的频率，将性能数据写入日志中。所以当服务器出现问题之后，便可分析 atop 日志文件来判断是否有进程异常退出、内存和 CPU 方面的异常。&lt;/p&gt;&#xA;&lt;h2&gt;字段含义&lt;/h2&gt;&#xA;&lt;h4&gt;PRC - Process level totals&lt;/h4&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;sys, 内核态下运行时间&lt;/li&gt;&#xA;&lt;li&gt;user, 用户态下运行时间&lt;/li&gt;&#xA;&lt;li&gt;#proc, 当前所有的进程数量&lt;/li&gt;&#xA;&lt;li&gt;#trun, 处于 running 状态下线程数量&lt;/li&gt;&#xA;&lt;li&gt;#zombie，僵尸进程的数量&lt;/li&gt;&#xA;&lt;li&gt;#exit，采样周期内退出的进程数量&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4&gt;CPU - CPU utilization&lt;/h4&gt;&#xA;&lt;p&gt;展示所有 CPU 的使用情况。在多处理器的系统中，会展示每一个独立内核的使用情况。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;sys、usr, CPU 被用于处理进程时，进程在内核态、用户态所占CPU的时间比例&lt;/li&gt;&#xA;&lt;li&gt;irq, CPU 被用于处理中断的时间比例&lt;/li&gt;&#xA;&lt;li&gt;idle, CPU 处在完全空闲状态的时间比例&lt;/li&gt;&#xA;&lt;li&gt;wait, CPU 处在“进程等待磁盘IO 导致 CPU 空闲”状态的时间比例&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4&gt;CPL - CPU load information&lt;/h4&gt;&#xA;&lt;p&gt;展示 CPU 的负载情况。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;avg1、avg5和avg15：过去1分钟、5分钟和15分钟内运行队列中的平均进程数量&lt;/li&gt;&#xA;&lt;li&gt;csw，指示上下文交换次数&lt;/li&gt;&#xA;&lt;li&gt;intr，指示中断发生次数&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4&gt;MEM - Memory occupation&lt;/h4&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;tot，物理内存总量&lt;/li&gt;&#xA;&lt;li&gt;free，空闲内存大小&lt;/li&gt;&#xA;&lt;li&gt;cache，页缓存的内存大小&lt;/li&gt;&#xA;&lt;li&gt;buff，文件系统缓存的内存大小&lt;/li&gt;&#xA;&lt;li&gt;slab，系统内核分配的内存大小&lt;/li&gt;&#xA;&lt;li&gt;dirty，页缓存中脏内存的大小&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4&gt;SWP - Swap occupation and overcommit info&lt;/h4&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;tot，交换区总量&lt;/li&gt;&#xA;&lt;li&gt;free，示空闲交换空间大小&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4&gt;PAG - Paging frequency&lt;/h4&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;swin，换入的页内存数目&lt;/li&gt;&#xA;&lt;li&gt;swout， 换出的页内存数目&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4&gt;DSK/LVM - Disk utilization/Logical volumn&lt;/h4&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;busy，磁盘忙时比例&lt;/li&gt;&#xA;&lt;li&gt;read，读请求数量&lt;/li&gt;&#xA;&lt;li&gt;write，写请求数量&lt;/li&gt;&#xA;&lt;li&gt;KiB/r，每次读的千字节数&lt;/li&gt;&#xA;&lt;li&gt;Kib/w，每次写的千字节数&lt;/li&gt;&#xA;&lt;li&gt;MBr/s，每秒读入兆字节带宽&lt;/li&gt;&#xA;&lt;li&gt;MBw/s，每秒写入兆字节带宽&lt;/li&gt;&#xA;&lt;li&gt;avio，每次传输所需要的毫秒&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4&gt;NET - Network utilization (TCP/IP)&lt;/h4&gt;&#xA;&lt;p&gt;第一行是传输层信息，第二行是 IP 层信息，后面几行是各网卡的信息。&lt;/p&gt;&#xA;&lt;h2&gt;常用快捷键&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;g, 通用输出&lt;/li&gt;&#xA;&lt;li&gt;m, 展示与内存有关的输出&lt;/li&gt;&#xA;&lt;li&gt;d, 展示与硬盘使用有关的输出&lt;/li&gt;&#xA;&lt;li&gt;c, 展示每个进程是由哪个命令行启动的&lt;/li&gt;&#xA;&lt;li&gt;p, 展示进程相关的活动信息&lt;/li&gt;&#xA;&lt;li&gt;C, 按照 CPU 使用排序&lt;/li&gt;&#xA;&lt;li&gt;M, 按照内存使用排序&lt;/li&gt;&#xA;&lt;li&gt;P, 按下后，即可输入正则表达式来搜索对应进程&lt;/li&gt;&#xA;&lt;li&gt;t, 向前一个采样间隔，在分析 atop 日志时使用&lt;/li&gt;&#xA;&lt;li&gt;T, 向后一个采样间隔，在分析 atop 日志时使用&lt;/li&gt;&#xA;&lt;li&gt;v, 输出更详细的进程信息，包括进程的启动时间，进程号，用户和所在组，当前状态。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;atop日志&lt;/h2&gt;&#xA;&lt;p&gt;每个时间点采样页面组合起来就形成了一个atop日志文件，我们可以使用&amp;quot;atop -r XXX&amp;quot;命令对日志文件进行查看。&lt;/p&gt;&#xA;&lt;p&gt;通常日志文件位于 &lt;code&gt;/var/log/&lt;/code&gt;，采样间隔为 10min。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2018/07/04/perftest-atop/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>用 Python 实现一个 ORM</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2018/04/28/python-orm1/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;本文实现一个非常简单的 ORM 初稿：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;完成 Python 类（模型）与数据库表的映射&lt;/li&gt;&#xA;&lt;li&gt;完成类实例与表每行记录的映射&lt;/li&gt;&#xA;&lt;li&gt;完成实例操作与增删改查的 SQL 语句的映射&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;这个初稿不涉及数据库的真正操作，只是在 &lt;code&gt;user.save()&lt;/code&gt; 的时候打印类似 &lt;code&gt;insert into user ...&lt;/code&gt; 的 SQL 语句。本文所有代码基于 Python2。&lt;/p&gt;&#xA;&lt;h2&gt;ORM 为什么需要元类&lt;/h2&gt;&#xA;&lt;p&gt;假设有如下的类：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class User():&#xA;    __table__ = &#39;User_table&#39;&#xA;    student_id = IntegerField(&#39;studentid&#39;, primaryKey=True)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;回想 Django 的 ORM，每个模型都继承了一个 &lt;code&gt;Model&lt;/code&gt; 类，我们也如法炮制。而所谓类与表的映射，就是在 Python 虚拟机启动后，自动寻找类属性，并将 &lt;code&gt;__table__&lt;/code&gt; 转化为表名， &lt;code&gt;student_id&lt;/code&gt; 转化为列名。这种需求类似于运行时自省，而普通类的 &lt;code&gt;__new__&lt;/code&gt; &lt;code&gt;__init__&lt;/code&gt; 都是实例化类时被调用，在这两个方法上做文章没有用处。&lt;/p&gt;&#xA;&lt;p&gt;这时候就该用元类 &lt;code&gt;metaclass&lt;/code&gt; 了。&lt;/p&gt;&#xA;&lt;p&gt;在 &lt;a href=&#34;http://www.lyyyuna.com/2017/12/24/python-internal2-integer-object/&#34;&gt;Python2.7 源码 - 整数对象&lt;/a&gt; 中已经有过介绍，元类 &lt;code&gt;metaclass&lt;/code&gt; 是类的类。除了整数这种内置类型，用户自定义类型也有元类的概念。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;内置类定义在 C 源码中，故虚拟机运行后，就立即存在。&lt;/li&gt;&#xA;&lt;li&gt;而用 &lt;code&gt;class&lt;/code&gt; 语法定义的类，则需要根据元类 &lt;code&gt;metaclass&lt;/code&gt; 来创建。&lt;/li&gt;&#xA;&lt;li&gt;内置类也有元类，最终两者在虚拟机中拥有相同的结构。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;元类 &lt;code&gt;metaclass&lt;/code&gt; 实例化的结果就是我们的普通类，由虚拟机启动时自动执行。在元类实例化的过程中，便可以扫描类定义属性，实现类与表的映射。自定义类默认继承自 &lt;code&gt;object&lt;/code&gt;，获得的元类为 &lt;code&gt;type&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;Python2.x 中，用以下语法&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class C():&#xA;    __metaclass__ = Meta&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以将类 &lt;code&gt;C&lt;/code&gt; 对应的元类替换为 &lt;code&gt;Meta&lt;/code&gt;。这么一看，只要设计自己的元类，并在模型中添加进去就可以了：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class User():&#xA;    __metaclass__ = Meta&#xA;    __table__ = &#39;User_table&#39;&#xA;    student_id = IntegerField(&#39;studentid&#39;, primaryKey=True)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;但这么做，会在产品业务代码中暴露太多复杂的概念。我们可以设计一个公共的父类，并修改此父类的元类，这样所有继承的子类都能获得新的元类：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class ModelType(type):&#xA;    def __new__(cls, name, bases, attrs):&#xA;        return type.__new__(cls, name, bases, attrs)&#xA;&#xA;class Model():&#xA;    __metaclass__ = ModelType&#xA;&#xA;# Application&#xA;class User(Model):&#xA;    __table__ = &#39;User_table&#39;&#xA;&#xA;class Teacher(Model):&#xA;    __table__ = &#39;Teacher_table&#39;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;现在当 &lt;code&gt;User&lt;/code&gt; &lt;code&gt;Teacher&lt;/code&gt; 类在虚拟机中创建时，其行为就由 &lt;code&gt;ModelType&lt;/code&gt; 控制。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;ModelType&lt;/code&gt; 需实现 &lt;code&gt;__new__&lt;/code&gt; 函数，接受 &lt;code&gt;name, bases, attrs&lt;/code&gt; 三个参数，&lt;code&gt;attrs&lt;/code&gt; 是类属性构成的字典。该 &lt;code&gt;__new__&lt;/code&gt; 函数最终需返回 &lt;code&gt;type.__new__(cls, name, bases, attrs)&lt;/code&gt; 的结果，即类在虚拟机中的表示。&lt;/p&gt;&#xA;&lt;p&gt;其中，&lt;code&gt;attrs&lt;/code&gt; 字典由 Python 虚拟机创建类时填入。&lt;/p&gt;&#xA;&lt;h2&gt;扫描表名&lt;/h2&gt;&#xA;&lt;p&gt;由上可知，可在元类的 &lt;code&gt;__new__&lt;/code&gt; 函数中获取 &lt;code&gt;__table__&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class ModelType(type):&#xA;    def __new__(cls, name, bases, attrs):&#xA;        tablename = attrs.get(&#39;__table__&#39;, None) or name&#xA;        print &#39;Get table name&#39;, tablename&#xA;        return type.__new__(cls, name, bases, attrs)&#xA;&#xA;class Model():&#xA;    __metaclass__ = ModelType&#xA;&#xA;class User(Model):&#xA;    __table__ = &#39;User_table&#39;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;输出&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Get table name Model&#xA;Get table name User_table&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;为什么会输出两行？因为父类 &lt;code&gt;Model&lt;/code&gt; 也会被元类 &lt;code&gt;ModelType&lt;/code&gt; 扫描，所以应将父类自身排除出扫描：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class ModelMeta(type):&#xA;    def __new__(cls, name, bases, attrs):&#xA;        if name==&#39;Model&#39;:&#xA;            return type.__new__(cls, name, bases, attrs)&#xA;&#xA;        tablename = attrs.get(&#39;__table__&#39;, None) or name&#xA;        print &#39;Get table name&#39;, tablename&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这次输出没有 &lt;code&gt;Model&lt;/code&gt; ：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Get table name User_table&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;扫描字段&lt;/h2&gt;&#xA;&lt;p&gt;字段的扫描是类似的，我们先完成字段类型的定义，让所有字段继承自 &lt;code&gt;Field&lt;/code&gt; 类。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Field(object):&#xA;    def __init__(self, name, sqlType, primaryKey, default):&#xA;        self.name = name&#xA;        self.sqlType = sqlType&#xA;        self.primaryKey = primaryKey&#xA;        self.default = default&#xA;&#xA;    def __str__(self):&#xA;        return &#39;&amp;lt;%s, %s:%s&amp;gt;&#39; % (self.__class__, self.sqlType, self.name)&#xA;&#xA;&#xA;class StringField(Field):&#xA;    def __init__(self, name=None, sqlType=&#39;character varying(100)&#39;, primaryKey=False, default=&#39;&#39;):&#xA;        super(StringField, self).__init__(name, sqlType, primaryKey, default)&#xA;&#xA;&#xA;class IntegerField(Field):&#xA;    def __init__(self, name=None, sqlType=&#39;integer&#39;, primaryKey=False, default=0):&#xA;        super(IntegerField, self).__init__(name, sqlType, primaryKey, default)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;由于所有表字段类有一个相同的父类，所以可以通过 &lt;code&gt;isinstance(v, Field)&lt;/code&gt; 识别一个类属性是否属于表字段。以下代码在类属性 &lt;code&gt;attrs&lt;/code&gt; 中遍历，找出字段并存储在 &lt;code&gt;mappings&lt;/code&gt; 字典和 &lt;code&gt;fields&lt;/code&gt; 列表中。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;mappings = {}&#xA;fields = []&#xA;primary = None&#xA;for k, v in attrs.iteritems():&#xA;    if isinstance(v, Field):&#xA;        print &#39;Found one field&#39;, k&#xA;        mappings[k] = v&#xA;        if v.primaryKey == True:&#xA;            if primary == None:&#xA;                primary = k&#xA;            else:&#xA;                raise RuntimeError(&amp;quot;Duplicate primary key: %s&amp;quot;, k)&#xA;        else:&#xA;            fields.append(k)&#xA;if primary == None:&#xA;    raise RuntimeError(&amp;quot;No primary key given.&amp;quot;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;将上述代码应用于 &lt;code&gt;User&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class User(Model):&#xA;    __table__ = &#39;User_table&#39;&#xA;    student_id = IntegerField(&#39;studentid&#39;, primaryKey=True)&#xA;    name = StringField(&#39;username&#39;)&#xA;    age = IntegerField(&#39;age&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;输出：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Get table name User_table&#xA;Found one field age&#xA;Found one field name&#xA;Found one field student_id&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;实例属性&lt;/h2&gt;&#xA;&lt;p&gt;在类中需要移除所有的字段属性 &lt;code&gt;attrs.pop(k)&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for k in mappings.keys():&#xA;    attrs.pop(k)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;因为业务代码不需要类属性，每个实例需要访问的是实例属性。比如&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;u2 = User(student_id=3, name=&#39;blue&#39;, age=123)&#xA;print(u2.name)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这里，让父类 &lt;code&gt;Model&lt;/code&gt; 继承 &lt;code&gt;dict&lt;/code&gt; 类，并添加 &lt;code&gt;__getattr__&lt;/code&gt; 和 &lt;code&gt;__setattr__&lt;/code&gt; 方法：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Model(dict):&#xA;    __metaclass__ = ModelMeta&#xA;    __table__ = &#39;Should not show&#39;&#xA;&#xA;    def __init__(self, **kw):&#xA;        super(Model, self).__init__(**kw)&#xA;&#xA;    def __getattr__(self, key):&#xA;        try:&#xA;            return self[key]&#xA;        except:&#xA;            raise AttributeError(r&amp;quot;&#39;Dict&#39; object has no attribute &#39;%s&#39;&amp;quot; % key)&#xA;&#xA;    def __setattr__(self, key, value):&#xA;        self[key] = value&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;访问 &lt;code&gt;u2.name&lt;/code&gt; 便等价于 &lt;code&gt;u2[name]&lt;/code&gt;，而 &lt;code&gt;User&lt;/code&gt; 间接继承自字典，&lt;code&gt;User(student_id=3, name=&#39;blue&#39;, age=123)&lt;/code&gt;初始化后，便能访问字典元素&lt;code&gt;u2[name]&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h2&gt;与 SQL 语句的映射&lt;/h2&gt;&#xA;&lt;p&gt;我们可以在元类 &lt;code&gt;ModelMeta&lt;/code&gt; 中预先定义一些 SQL 语句的模板，并存储在类属性 &lt;code&gt;attrs&lt;/code&gt; 中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    attrs[&#39;__select__&#39;] = &amp;quot;select &#39;%s&#39;, %s from &#39;%s&#39;&amp;quot; % (primary, &#39;,&#39;.join(escaped_fields), tablename)&#xA;    attrs[&#39;__insert__&#39;] = &amp;quot;insert into &#39;%s&#39; (%s, &#39;%s&#39;) values (%s)&amp;quot; % (tablename, &#39;,&#39;.join(escaped_fields), primary, create_args_string(len(escaped_fields)+1))&#xA;    attrs[&#39;__update__&#39;] = &amp;quot;update &#39;%s&#39; set %s where &#39;%s&#39; =?&amp;quot; % (tablename, &#39;,&#39;.join(map(lambda x: &amp;quot;&#39;%s&#39;=?&amp;quot; % (mappings.get(x).name), fields)), primary)&#xA;    attrs[&#39;__delete__&#39;] = &amp;quot;delete from &#39;%s&#39; where &#39;%s&#39; = ?&amp;quot; % (tablename, primary)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;接着在 &lt;code&gt;Model&lt;/code&gt; 中添加 &lt;code&gt;select&lt;/code&gt; 和 &lt;code&gt;save&lt;/code&gt; 方法。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    @classmethod&#xA;    def select(cls, id):&#xA;        print &amp;quot;%s where &#39;%s&#39; = %s;&amp;quot; % (cls.__select__, cls.__primarykey__, id)&#xA;&#xA;    def getValue(self, k):&#xA;        value = getattr(self, k, None)&#xA;        if value is None:&#xA;            field = self.__mappings__[k]&#xA;            if field.default is not None:&#xA;                value = field.default&#xA;                setattr(self, k, value)&#xA;        return value&#xA;&#xA;    def save(self):&#xA;        args = map(self.getValue, self.__fields__)&#xA;        args.append(self.getValue(self.__primarykey__))&#xA;        print self.__insert__, args&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这两个方法对应于 SQL 中的 &lt;code&gt;SELECT&lt;/code&gt; 和 &lt;code&gt;INSERT&lt;/code&gt; 语句。逻辑也比较简单，从之前存储在 &lt;code&gt;mappings&lt;/code&gt; 和 &lt;code&gt;fields&lt;/code&gt; 的字段名，再结合实例属性，拼接出 SQL 语句。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print &#39;Test select sql command:&#39;&#xA;User.select(id=1)&#xA;print&#xA;&#xA;print &#39;Test insert sql command:&#39;&#xA;u2 = User(student_id=3, name=&#39;blue&#39;, age=123)&#xA;u2.save()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;输出：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;Test select sql command:&#xA;select &#39;student_id&#39;, &#39;age&#39;,&#39;name&#39; from &#39;User_table&#39; where &#39;student_id&#39; = 1;&#xA;&#xA;Test insert sql command:&#xA;insert into &#39;User_table&#39; (&#39;age&#39;,&#39;name&#39;, &#39;student_id&#39;) values (?, ?, ?) [123, &#39;blue&#39;, 3]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;小结&lt;/h2&gt;&#xA;&lt;p&gt;至此，一个简单的 ORM 原型就完成了。详细代码可见：&lt;a href=&#34;https://github.com/lyyyuna/script_collection/tree/master/orm_draft&#34;&gt;https://github.com/lyyyuna/script_collection/tree/master/orm_draft&lt;/a&gt;&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2018/04/28/python-orm1/" rel="alternate"></link>
    <summary type="html">如何用元类控制类的生成？</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>实现基于 HTTPS 代理的中间人攻击</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2018/03/16/http-proxy-https/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;在给产品做 Web 安全测试时，经常会使用代理工具来收集 URL 及相关请求参数。&lt;/p&gt;&#xA;&lt;p&gt;在我之前的文章介绍了 &lt;a href=&#34;http://www.lyyyuna.com/2016/01/16/http-proxy-get1/&#34;&gt;使用 Python 实现一个简单的 HTTP 代理&lt;/a&gt;。但这留下一个问题，如何处理 HTTPS 流量？&lt;/p&gt;&#xA;&lt;h2&gt;HTTP 隧道代理原理&lt;/h2&gt;&#xA;&lt;p&gt;RFC 为这类代理给出了规范，&lt;a href=&#34;https://tools.ietf.org/html/draft-luotonen-web-proxy-tunneling-01&#34;&gt;Tunneling TCP based protocols through Web proxy servers&lt;/a&gt;。简单来讲就是通过 Web 代理服务器用隧道方式传输基于 TCP 的协议。HTTP 协议正文部分为客户端发送的原始 TCP 流量，代理发送给远端服务器后，将接收到的 TCP 流量原封不动返回给浏览器。&lt;/p&gt;&#xA;&lt;p&gt;下面这张图片来自于《HTTP 权威指南》，展示了 HTTP 隧道代理的原理。&#xA;&lt;img src=&#34;/img/blog/201803/connect.png&#34; alt=&#34;HTTP 隧道&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;浏览器首先发起 CONNECT 请求：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;CONNECT example.com:443 HTTP/1.1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;代理收到这样的请求后，依据 host 地址与服务器建立 TCP 连接，并响应给浏览器这样一个 HTTP 报文：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;HTTP/1.1 200 Connection Established&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;该报文不需要正文。浏览器一旦收到这个响应报文，就可认为与服务器的 TCP 连接已打通，后续可直接透传。&lt;/p&gt;&#xA;&lt;h2&gt;HTTPS 流量中间人攻击&lt;/h2&gt;&#xA;&lt;p&gt;我们很容易想到，HTTPS 代理本质上就是隧道透传，代理服务器只是透传 TCP 流量，与 GET/POST 代理有本质区别。隧道透传是安全的，代理没有私钥来解密 TLS 流量。&lt;/p&gt;&#xA;&lt;p&gt;这带来一个问题，现在 HTTPS 越来越普遍，测试时不会特意关掉 TLS，做安全测试也就拿不到 URL 及请求参数。那怎么做呢？&lt;/p&gt;&#xA;&lt;p&gt;首先是来看正常的隧道代理示意图：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201803/tls1.png&#34; alt=&#34;TLS 示意图 1&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;在如图红色的透传流量中，插入我们的&lt;strong&gt;中间人&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;用一个 TLS 服务器伪装成远端的真正的服务器，接下浏览器的 TLS 流量，解析成明文。&lt;/li&gt;&#xA;&lt;li&gt;用明文作为原始数据，模拟 �TLS 客户端向远端服务器�转发。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;示意图如下：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201803/tls2.png&#34; alt=&#34;TLS 示意图 2&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;由于中间人拿到了明文，也就能够继续收集 URL 及相关请求参数。&lt;/p&gt;&#xA;&lt;h3&gt;证书问题&lt;/h3&gt;&#xA;&lt;p&gt;大家知道，HTTP 是需要证书的。浏览器会验证服务器发来的证书是否合法。证书若是由合法的 CA 签发，则称为合法的证书。现代浏览器在安装时都会附带全世界所有合法的 CA 证书。由 CA 证书可验证远端服务器的证书是否是合法 CA 签发的。&lt;/p&gt;&#xA;&lt;p&gt;在 TLS 示意图 2 中，浏览器会验证假 TLS 服务器的证书：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;第一验证是否是合法 CA 签发。&lt;/li&gt;&#xA;&lt;li&gt;第二验证该证书 CN 属性是否是所请求的域名。即若浏览器打开 &lt;code&gt;www.example.com&lt;/code&gt;，则返回的证书 CN 属性必须是 &lt;code&gt;www.example.com&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;对于第一点，合法 CA 是不可能为我们签证书的，否则就是重大安全事件了。我们只能自制 CA，并将自制 CA 导入浏览器信任链。&lt;/p&gt;&#xA;&lt;p&gt;对于第二点，需要自制 CA 实时为域名 &lt;code&gt;www.example.com&lt;/code&gt; 签一个假的证书。&lt;/p&gt;&#xA;&lt;h2&gt;Go 实现&lt;/h2&gt;&#xA;&lt;p&gt;不同于之前 &lt;a href=&#34;http://www.lyyyuna.com/2016/01/16/http-proxy-get1/&#34;&gt;Python 实现的 HTTP 代理&lt;/a&gt;，这次的 HTTPS 中间人代理用 Go 实现。源码见 &lt;a href=&#34;https://github.com/lyyyuna/mitm&#34;&gt;https://github.com/lyyyuna/mitm&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;首先是启动一个 http server。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// mitmproxy.go&#xA;func Gomitmproxy(conf *config.Cfg, ch chan bool) {&#xA;&#x9;tlsConfig := config.NewTLSConfig(&amp;quot;gomitmproxy-ca-pk.pem&amp;quot;, &amp;quot;gomitmproxy-ca-cert.pem&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;)&#xA;&#x9;handler := InitConfig(conf, tlsConfig)&#xA;&#x9;server := &amp;amp;http.Server{&#xA;&#x9;&#x9;Addr:         &amp;quot;:&amp;quot; + *conf.Port,&#xA;&#x9;&#x9;ReadTimeout:  1 * time.Hour,&#xA;&#x9;&#x9;WriteTimeout: 1 * time.Hour,&#xA;&#x9;&#x9;Handler:      handler,&#xA;    }&#xA;............&#xA;&#x9;go func() {&#xA;&#x9;&#x9;server.ListenAndServe()&#xA;&#x9;&#x9;ch &amp;lt;- true&#xA;&#x9;}()&#xA;&#xA;&#x9;return&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;handler&lt;/code&gt; 是一个实现了 &lt;code&gt;ServeHTTP&lt;/code&gt; 接口的 &lt;code&gt;Handler&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (handler *HandlerWrapper) ServeHTTP(resp http.ResponseWriter, req *http.Request) {&#xA;&#x9;if req.Method == &amp;quot;CONNECT&amp;quot; {&#xA;&#x9;&#x9;handler.https = true&#xA;&#x9;&#x9;handler.InterceptHTTPS(resp, req)&#xA;&#x9;} else {&#xA;&#x9;&#x9;handler.https = false&#xA;&#x9;&#x9;handler.DumpHTTPAndHTTPS(resp, req)&#xA;&#x9;}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;根据请求不同分为两大类。普通 GET/POST 请求，由于是明文，可直接进行抓包。而 CONNECT 请求，则走 &lt;code&gt;InterceptHTTPS&lt;/code&gt;。我们默认走 CONNECT 隧道的都是 HTTPS 流量，其他 TCP 应用层协议则不予考虑。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (handler *HandlerWrapper) InterceptHTTPS(resp http.ResponseWriter, req *http.Request) {&#xA;&#x9;addr := req.Host&#xA;&#x9;host := strings.Split(addr, &amp;quot;:&amp;quot;)[0]&#xA;&#xA;    // step 1, 为每个域名签发证书&#xA;&#x9;cert, err := handler.FakeCertForName(host)&#xA;&#x9;if err != nil {&#xA;&#x9;&#x9;logger.Fatalln(&amp;quot;Could not get mitm cert for name: %s\nerror: %s&amp;quot;, host, err)&#xA;&#x9;&#x9;respBadGateway(resp)&#xA;&#x9;&#x9;return&#xA;&#x9;}&#xA;&#xA;    // step 2，拿到原始 TCP 连接&#xA;&#x9;connIn, _, err := resp.(http.Hijacker).Hijack()&#xA;&#x9;if err != nil {&#xA;&#x9;&#x9;logger.Fatalln(&amp;quot;Unable to access underlying connection from client: %s&amp;quot;, err)&#xA;&#x9;&#x9;respBadGateway(resp)&#xA;&#x9;&#x9;return&#xA;&#x9;}&#xA;&#xA;&#x9;tlsConfig := copyTlsConfig(handler.tlsConfig.ServerTLSConfig)&#xA;    tlsConfig.Certificates = []tls.Certificate{*cert}&#xA;    // step 3，将 TCP 连接转化为 TLS 连接&#xA;&#x9;tlsConnIn := tls.Server(connIn, tlsConfig)&#xA;&#x9;listener := &amp;amp;mitmListener{tlsConnIn}&#xA;&#x9;httpshandler := http.HandlerFunc(func(resp2 http.ResponseWriter, req2 *http.Request) {&#xA;&#x9;&#x9;req2.URL.Scheme = &amp;quot;https&amp;quot;&#xA;&#x9;&#x9;req2.URL.Host = req2.Host&#xA;&#x9;&#x9;handler.DumpHTTPAndHTTPS(resp2, req2)&#xA;&#x9;})&#xA;&#xA;&#x9;go func() {&#xA;        // step 4，启动一个伪装的 TLS 服务器&#xA;&#x9;&#x9;err = http.Serve(listener, httpshandler)&#xA;&#x9;&#x9;if err != nil &amp;amp;&amp;amp; err != io.EOF {&#xA;&#x9;&#x9;&#x9;logger.Printf(&amp;quot;Error serving mitm&#39;ed connection: %s&amp;quot;, err)&#xA;&#x9;&#x9;}&#xA;&#x9;}()&#xA;&#xA;&#x9;connIn.Write([]byte(&amp;quot;HTTP/1.1 200 Connection Established\r\n\r\n&amp;quot;))&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;第一步通过 &lt;code&gt;FakeCertForName&lt;/code&gt; 为浏览器请求的域名签发证书。签发所使用的 CA 为 &lt;code&gt;gomitmproxy-ca-pk.pem&lt;/code&gt;, &lt;code&gt;gomitmproxy-ca-cert.pem&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;第二步通过 &lt;code&gt;http.Hijacker&lt;/code&gt; 拿到原始的 TCP 连接。&lt;/li&gt;&#xA;&lt;li&gt;第三步通过 &lt;code&gt;tlsConnIn := tls.Server(connIn, tlsConfig)&lt;/code&gt;，将 TCP 连接转换为 TLS 连接。该 TLS 连接已配置有 CA 签发的证书。所谓的 TLS 连接，即 Go 应用程序可直接在该连接上拿到原始明文。&lt;/li&gt;&#xA;&lt;li&gt;第四步通过 &lt;code&gt;http.Serve(listener, httpshandler)&lt;/code&gt; 响应这个 TLS 连接。响应的回调函数所看到的都是明文，即可进行 HTTP 抓包。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2&gt;结语&lt;/h2&gt;&#xA;&lt;p&gt;上述过程即为 Burp Suite, ZAP 和 fiddler 等进行 HTTPS 抓包的原理。&lt;/p&gt;&#xA;&lt;p&gt;我自制 HTTPS 中间人代理，主要是想结合 Sqlmap 做一个自动化 SQL 注入系统。由于目前所在 QA 团队并不具备 SQL 注入测试的经验，最大化的自动化所有过程就成了我的目标。目前还有 csrf token 未解决，主要是 csrf 实现千差万别，没有通用解决方法。。。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2018/03/16/http-proxy-https/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Python 2.7 源码 - 简单对象创建的字节码分析</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2018/01/13/python-internal6-simple-object-create/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;Python 源码编译后，有常量表，符号表。一个作用域运行时会对应一个运行时栈。&lt;/p&gt;&#xA;&lt;p&gt;大部分字节码就是基于常量表、符号表和运行时栈，运算后得到所需结果。&lt;/p&gt;&#xA;&lt;p&gt;本篇就来分析简单对象创建的字节码。以下面这段代码为分析样本：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;i = 1&#xA;s = &#39;python&#39;&#xA;d = {}&#xA;l = []&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;对生成的 pyc 文件解析，可得如下的结构，其中包括字节码反编译的结果：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&#xA;magic 03f30d0a&#xA;moddate 836a595a (Sat Jan 13 10:10:11 2018)&#xA;&amp;lt;code&amp;gt;&#xA;   &amp;lt;argcount&amp;gt; 0 &amp;lt;/argcount&amp;gt;&#xA;   &amp;lt;nlocals&amp;gt; 0&amp;lt;/nlocals&amp;gt;&#xA;   &amp;lt;stacksize&amp;gt; 1&amp;lt;/stacksize&amp;gt;&#xA;   &amp;lt;flags&amp;gt; 0040&amp;lt;/flags&amp;gt;&#xA;   &amp;lt;codeobject&amp;gt; 6400005a00006401005a01006900005a02006700005a030064020053&amp;lt;/codeobject&amp;gt;&#xA;   &amp;lt;dis&amp;gt;&#xA;  1           0 LOAD_CONST               0 (1)&#xA;              3 STORE_NAME               0 (i)&#xA;&#xA;  2           6 LOAD_CONST               1 (&#39;python&#39;)&#xA;              9 STORE_NAME               1 (s)&#xA;&#xA;  3          12 BUILD_MAP                0&#xA;             15 STORE_NAME               2 (d)&#xA;&#xA;  4          18 BUILD_LIST               0&#xA;             21 STORE_NAME               3 (l)&#xA;             24 LOAD_CONST               2 (None)&#xA;             27 RETURN_VALUE&#xA;   &amp;lt;/dis&amp;gt;&#xA;   &amp;lt;names&amp;gt; (&#39;i&#39;, &#39;s&#39;, &#39;d&#39;, &#39;l&#39;)&amp;lt;/names&amp;gt;&#xA;   &amp;lt;varnames&amp;gt; ()&amp;lt;/varnames&amp;gt;&#xA;   &amp;lt;freevars&amp;gt; ()&amp;lt;/freevars&amp;gt;&#xA;   &amp;lt;cellvars&amp;gt; ()&amp;lt;/cellvars&amp;gt;&#xA;   &amp;lt;filename&amp;gt; &#39;.\\test.py&#39;&amp;lt;/filename&amp;gt;&#xA;   &amp;lt;name&amp;gt; &#39;&amp;lt;module&amp;gt;&#39;&amp;lt;/name&amp;gt;&#xA;   &amp;lt;firstlineno&amp;gt; 1&amp;lt;/firstlineno&amp;gt;&#xA;   &amp;lt;consts&amp;gt;&#xA;      1&#xA;      &#39;python&#39;&#xA;      None&#xA;   &amp;lt;/consts&amp;gt;&#xA;   &amp;lt;lnotab&amp;gt; 060106010601&amp;lt;/lnotab&amp;gt;&#xA;&amp;lt;/code&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们清楚的看到 &lt;code&gt;consts&lt;/code&gt; 常量表，&lt;code&gt;names&lt;/code&gt; 符号表，这些表中的元素都是有明确顺序的。&lt;/p&gt;&#xA;&lt;h2&gt;整数赋值&lt;/h2&gt;&#xA;&lt;p&gt;第一条语句 &lt;code&gt;i = 1&lt;/code&gt;。对应的字节码为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;0 LOAD_CONST               0 (1)&#xA;3 STORE_NAME               0 (i)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;LOAD_CONST&lt;/code&gt; 对应的 C 语言源码为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;TARGET(LOAD_CONST)&#xA;{&#xA;    x = GETITEM(consts, oparg); // 从常量表 oparg 位置处取出对象&#xA;    Py_INCREF(x);&#xA;    PUSH(x); // 压入堆栈&#xA;    FAST_DISPATCH();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;该字节码带参，这里参数为 0。表示从常量表第 0 个位置取出整数，并将该数压入运行时栈：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+-+-+&#xA;| stack | f_locals |&#xA;+-+-+&#xA;| 1     |          |&#xA;|       |          |&#xA;|       |          |&#xA;+-+-+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;左侧为运行时栈，右侧为当前作用域内的局部变量。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;STORE_NAME&lt;/code&gt; 所对应的 C 语言源码为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;TARGET(STORE_NAME)&#xA;{&#xA;    w = GETITEM(names, oparg); // 从符号表 oparg 位置处取出符号名&#xA;    v = POP(); // 弹出运行时栈的栈顶元素&#xA;    if ((x = f-&amp;gt;f_locals) != NULL) {&#xA;        if (PyDict_CheckExact(x))&#xA;            err = PyDict_SetItem(x, w, v); // 将符号名作为键，栈顶元素作为值，放入字典中&#xA;        else&#xA;            err = PyObject_SetItem(x, w, v);&#xA;        Py_DECREF(v);&#xA;        if (err == 0) DISPATCH();&#xA;        break;&#xA;    }&#xA;    t = PyObject_Repr(w);&#xA;    if (t == NULL)&#xA;        break;&#xA;    PyErr_Format(PyExc_SystemError,&#xA;                    &amp;quot;no locals found when storing %s&amp;quot;,&#xA;                    PyString_AS_STRING(t));&#xA;    Py_DECREF(t);&#xA;    break;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;该字节码带参，参数为 0。表示从符号表第 0 个位置处取出符号名，即 &lt;code&gt;i&lt;/code&gt;。然后弹出运行时栈的栈顶元素，并将符号名作为键，栈顶元素作为值，放入字典中 &lt;code&gt;f_locals&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+-++&#xA;| stack | f_locals   |&#xA;+-++&#xA;|       | i, &amp;lt;int 1&amp;gt; |&#xA;|       |            |&#xA;|       |            |&#xA;+-++&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;字符串赋值&lt;/h2&gt;&#xA;&lt;p&gt;语句 &lt;code&gt;s = &#39;python&#39;&lt;/code&gt; 所对应的字节码为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;6 LOAD_CONST               1 (&#39;python&#39;)&#xA;9 STORE_NAME               1 (s)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;和整数赋值的字节码完全相同，只是参数不同。这里不再做重复分析，赋值后，运行时栈变为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+-+-+&#xA;| stack | f_locals          |&#xA;+-+-+&#xA;|       | i, &amp;lt;int 1&amp;gt;        |&#xA;|       | s, &amp;lt;str &#39;python&#39;&amp;gt; |&#xA;|       |                   |&#xA;+-+-+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;字典赋值&lt;/h2&gt;&#xA;&lt;p&gt;语句 &lt;code&gt;d = {}&lt;/code&gt; 对应的字节码为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;12 BUILD_MAP                0&#xA;15 STORE_NAME               2 (d)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;BUILD_MAP&lt;/code&gt; 所对应的 C 语言源码为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// ceval.c&#xA;TARGET(BUILD_MAP)&#xA;{&#xA;    x = _PyDict_NewPresized((Py_ssize_t)oparg);&#xA;    PUSH(x);&#xA;    if (x != NULL) DISPATCH();&#xA;    break;&#xA;}&#xA;&#xA;// dictobject.c&#xA;PyObject *&#xA;_PyDict_NewPresized(Py_ssize_t minused)&#xA;{&#xA;    PyObject *op = PyDict_New();&#xA;&#xA;    if (minused&amp;gt;5 &amp;amp;&amp;amp; op != NULL &amp;amp;&amp;amp; dictresize((PyDictObject *)op, minused) == -1) {&#xA;        Py_DECREF(op);&#xA;        return NULL;&#xA;    }&#xA;    return op;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;该字节码带参，参数为 0。而深入 &lt;code&gt;_PyDict_NewPresized&lt;/code&gt; 可以看到，若参数小于 5，实际上创建的是默认大小的字典。创建完毕后，会将该字典对象压入运行时栈。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+--+-+&#xA;| stack  | f_locals          |&#xA;+--+-+&#xA;| &amp;lt;dict&amp;gt; | i, &amp;lt;int 1&amp;gt;        |&#xA;|        | s, &amp;lt;str &#39;python&#39;&amp;gt; |&#xA;|        |                   |&#xA;+--+-+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;最后 &lt;code&gt;STORE_NAME&lt;/code&gt; 将该对象与符号 &lt;code&gt;d&lt;/code&gt; 绑定：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+-+-+&#xA;| stack | f_locals          |&#xA;+-+-+&#xA;|       | i, &amp;lt;int 1&amp;gt;        |&#xA;|       | s, &amp;lt;str &#39;python&#39;&amp;gt; |&#xA;|       | d, &amp;lt;dict&amp;gt;         |&#xA;+-+-+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;列表赋值&lt;/h2&gt;&#xA;&lt;p&gt;语句 &lt;code&gt;l = []&lt;/code&gt; 对应的字节码为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;18 BUILD_LIST               0&#xA;21 STORE_NAME               3 (l)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;BUILD_LIST&lt;/code&gt; 对应的 C 语言源码为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;TARGET(BUILD_LIST)&#xA;{&#xA;    x =  PyList_New(oparg); // 创建空列表&#xA;    if (x != NULL) {&#xA;        for (; --oparg &amp;gt;= 0;) {&#xA;            w = POP(); // 从栈中弹出元素&#xA;            PyList_SET_ITEM(x, oparg, w); // 将弹出的元素放入列表中&#xA;        }&#xA;        PUSH(x); // 将列表对象放入栈中&#xA;        DISPATCH();&#xA;    }&#xA;    break;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;该字节码首先创建一个列表，列表依据参数值预先分配空间。这里不对列表做深入分析，只指出，这里的空间大小不是存放元素所占用的空间，而是 &lt;code&gt;PyObject *&lt;/code&gt; 指针。&lt;/p&gt;&#xA;&lt;p&gt;列表建完后，便会不停从运行时栈中弹出元素，然后将元素放入列表中。这里是空列表，所以 &lt;code&gt;BUILD_LIST&lt;/code&gt; 运行时，栈为空，该字节码的参数也为 0。&lt;/p&gt;&#xA;&lt;p&gt;我们换一个非空列表来看一下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;l = [1, 2, 3]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;编译后&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;  1           0 LOAD_CONST               0 (1)&#xA;              3 LOAD_CONST               1 (2)&#xA;              6 LOAD_CONST               2 (3)&#xA;              9 BUILD_LIST               3&#xA;             12 STORE_NAME               0 (l)&#xA;             15 LOAD_CONST               3 (None)&#xA;             18 RETURN_VALUE&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到，在 &lt;code&gt;BUILD_LIST&lt;/code&gt; 之前会将三个对象压入运行时栈中。&lt;/p&gt;&#xA;&lt;p&gt;回到本文最初的 Python 程序，4 条语句运行完后， &lt;code&gt;f_locals&lt;/code&gt; 为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+-+-+&#xA;| stack | f_locals          |&#xA;+-+-+&#xA;|       | i, &amp;lt;int 1&amp;gt;        |&#xA;|       | s, &amp;lt;str &#39;python&#39;&amp;gt; |&#xA;|       | d, &amp;lt;dict&amp;gt;         |&#xA;|       | l, &amp;lt;list&amp;gt;         |&#xA;+-+-+&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;结束&lt;/h2&gt;&#xA;&lt;p&gt;在最后，我们还看到两行字节码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;24 LOAD_CONST               2 (None)&#xA;27 RETURN_VALUE&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;它们好像与我们的四条赋值语句没有任何关系。原来，Python 在执行了一段 CodeBlock 后，一定要返回一些值，既然如此，那就随便返回一个 &lt;code&gt;None&lt;/code&gt; 好了。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2018/01/13/python-internal6-simple-object-create/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Python 2.7 源码 - pyc 的结构</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2018/01/06/python-internal5-pyc/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;Python 是一门解释性语言，源码执行需要经过：编译-字节码-虚拟机的步骤。本文就介绍一下 &lt;code&gt;.py&lt;/code&gt; 文件编译后的 &lt;code&gt;.pyc&lt;/code&gt; 文件结构。直接运行的代码不会生成 &lt;code&gt;.pyc&lt;/code&gt;，而 Python 的 import 机制会触发 &lt;code&gt;.pyc&lt;/code&gt; 文件的生成。&lt;/p&gt;&#xA;&lt;h2&gt;magic number 和修改时间&lt;/h2&gt;&#xA;&lt;p&gt;我们在导入模块的源码中，能找到 &lt;code&gt;.pyc&lt;/code&gt; 文件的蛛丝马迹：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// Python/import.c&#xA;static void&#xA;write_compiled_module(PyCodeObject *co, char *cpathname, struct stat *srcstat, time_t mtime)&#xA;{&#xA;    ...&#xA;    PyMarshal_WriteLongToFile(pyc_magic, fp, Py_MARSHAL_VERSION);&#xA;    /* First write a 0 for mtime */&#xA;    PyMarshal_WriteLongToFile(0L, fp, Py_MARSHAL_VERSION);&#xA;    PyMarshal_WriteObjectToFile((PyObject *)co, fp, Py_MARSHAL_VERSION);&#xA;    ...&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到，&lt;code&gt;.pyc&lt;/code&gt; 文件包含三个主要内容：magic number，修改时间，和一个 &lt;code&gt;PyCodeObject&lt;/code&gt; 对象。&lt;/p&gt;&#xA;&lt;p&gt;magic number 和 Python 版本有关，magic number 不同能够防止低版本误执行高版本编译后的字节码。修改时间能让编译器决定是否重新编译源文件。&lt;/p&gt;&#xA;&lt;p&gt;我们来读取 &lt;code&gt;.pyc&lt;/code&gt; 的前八字节来验证一下我们的分析，&lt;code&gt;func0.py&lt;/code&gt; 是测试脚本：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;## func0.py&#xA;    f = open(fname, &#39;rb&#39;)&#xA;    magic = f.read(4)&#xA;    moddate = f.read(4)&#xA;    modtime = time.asctime(time.localtime(struct.unpack(&#39;I&#39;, moddate)[0]))&#xA;    print &#39;magic number: %s&#39; % (magic.encode(&#39;hex&#39;))&#xA;    print &#39;moddate %s (%s)&#39; % (moddate.encode(&#39;hex&#39;), modtime)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;被测试源文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# test.py&#xA;def add(a):&#xA;    a=1&#xA;    print a&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;使用以下强制编译成 &lt;code&gt;.pyc&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;python -m py_compile test.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;测试结果：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ python func0.py test.pyc&#xA;magic number: 03f30d0a&#xA;moddate 5e9a4b5a (Tue Jan  2 22:42:38 2018)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;PyCodeObject 对象&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;PyCodeObject&lt;/code&gt; 是一段代码块编译的直接结果。换句话说，一个作用域，对应一个代码，最终对应一个编译后的 &lt;code&gt;PyCodeObject&lt;/code&gt;。&#xA;首先看一下 &lt;code&gt;PyCodeObject&lt;/code&gt; 的结构：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct {&#xA;    PyObject_HEAD&#xA;    int co_argcount;&#x9;&#x9;/* #arguments, except *args */&#xA;    int co_nlocals;&#x9;&#x9;/* #local variables */&#xA;    int co_stacksize;&#x9;&#x9;/* #entries needed for evaluation stack */&#xA;    int co_flags;&#x9;&#x9;/* CO_..., see below */&#xA;    PyObject *co_code;&#x9;&#x9;/* instruction opcodes */&#xA;    PyObject *co_consts;&#x9;/* list (constants used) */&#xA;    PyObject *co_names;&#x9;&#x9;/* list of strings (names used) */&#xA;    PyObject *co_varnames;&#x9;/* tuple of strings (local variable names) */&#xA;    PyObject *co_freevars;&#x9;/* tuple of strings (free variable names) */&#xA;    PyObject *co_cellvars;      /* tuple of strings (cell variable names) */&#xA;    /* The rest doesn&#39;t count for hash/cmp */&#xA;    PyObject *co_filename;&#x9;/* string (where it was loaded from) */&#xA;    PyObject *co_name;&#x9;&#x9;/* string (name, for reference) */&#xA;    int co_firstlineno;&#x9;&#x9;/* first source line number */&#xA;    PyObject *co_lnotab;&#x9;/* string (encoding addr&amp;lt;-&amp;gt;lineno mapping) See&#xA;&#x9;&#x9;&#x9;&#x9;   Objects/lnotab_notes.txt for details. */&#xA;    void *co_zombieframe;     /* for optimization only (see frameobject.c) */&#xA;    PyObject *co_weakreflist;   /* to support weakrefs to code objects */&#xA;} PyCodeObject;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;一段程序不可能只有一个作用域，嵌套的子作用域存在于 &lt;code&gt;co_consts&lt;/code&gt; 之中。&lt;/p&gt;&#xA;&lt;p&gt;我们写个简单的脚本，展现这种嵌套的结构：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# func0.py&#xA;...&#xA;def show_code(code, indent=&#39;&#39;):&#xA;    old_indent = indent  &#xA;    print &amp;quot;%s&amp;lt;code&amp;gt;&amp;quot; % indent  &#xA;    indent += &#39;   &#39;  &#xA;    show_hex(&amp;quot;bytecode&amp;quot;, code.co_code, indent=indent)  &#xA;    print &amp;quot;%s&amp;lt;filename&amp;gt; %r&amp;lt;/filename&amp;gt;&amp;quot; % (indent, code.co_filename)  &#xA;    print &amp;quot;%s&amp;lt;consts&amp;gt;&amp;quot; % indent  &#xA;    for const in code.co_consts:  &#xA;        if type(const) == types.CodeType:  &#xA;            show_code(const, indent+&#39;   &#39;)  &#xA;        else:  &#xA;            print &amp;quot;   %s%r&amp;quot; % (indent, const)  &#xA;    print &amp;quot;%s&amp;lt;/consts&amp;gt;&amp;quot; % indent  &#xA;    print &amp;quot;%s&amp;lt;/code&amp;gt;&amp;quot; % old_indent  &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;被测试的源文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# test.py&#xA;def add(a):&#xA;    a=1&#xA;    print a&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;测试步骤：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;exs $ python func0.py test.pyc&#xA;&amp;lt;code&amp;gt;&#xA;   &amp;lt;bytecode&amp;gt; 6400008400005a000064010053&amp;lt;/bytecode&amp;gt;&#xA;   &amp;lt;filename&amp;gt; &#39;test.py&#39;&amp;lt;/filename&amp;gt;&#xA;   &amp;lt;consts&amp;gt;&#xA;      &amp;lt;code&amp;gt;&#xA;         &amp;lt;bytecode&amp;gt; 6401007d00007c0000474864000053&amp;lt;/bytecode&amp;gt;&#xA;         &amp;lt;filename&amp;gt; &#39;test.py&#39;&amp;lt;/filename&amp;gt;&#xA;         &amp;lt;consts&amp;gt;&#xA;            None&#xA;         &amp;lt;/consts&amp;gt;&#xA;      &amp;lt;/code&amp;gt;&#xA;      None&#xA;   &amp;lt;/consts&amp;gt;&#xA;&amp;lt;/code&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到，函数 &lt;code&gt;add&lt;/code&gt; 作为全局作用域的中一个子作用域，在编译结果中，是以常量形式存在于全局作用域的 &lt;code&gt;PyCodeObject&lt;/code&gt; 中。&lt;/p&gt;&#xA;&lt;h2&gt;查看字节码&lt;/h2&gt;&#xA;&lt;p&gt;Python 提供了 &lt;code&gt;dis&lt;/code&gt; 模块，其中的 &lt;code&gt;disassemble()&lt;/code&gt; 函数可以反编译 &lt;code&gt;PyCodeObject&lt;/code&gt; 对象，以可读的形式展现出来。&#xA;我们修改 &lt;code&gt;func0.py&lt;/code&gt;，将字节码对应的指令打印出来，增加下述代码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    ...&#xA;    show_hex(&amp;quot;bytecode&amp;quot;, code.co_code, indent=indent)  &#xA;    print &amp;quot;%s&amp;lt;dis&amp;gt;&amp;quot; % indent  &#xA;    dis.disassemble(code)  &#xA;    print &amp;quot;%s&amp;lt;/dis&amp;gt;&amp;quot; % indent  &#xA;    ...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;测试结果：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ python func0.py test.pyc&#xA;&amp;lt;code&amp;gt;&#xA;   &amp;lt;bytecode&amp;gt; 6400008400005a000064010053&amp;lt;/bytecode&amp;gt;&#xA;   &amp;lt;dis&amp;gt;&#xA;  3           0 LOAD_CONST               0 (&amp;lt;code object add at 0x109aa1c30, file &amp;quot;test.py&amp;quot;, line 3&amp;gt;)&#xA;              3 MAKE_FUNCTION            0&#xA;              6 STORE_NAME               0 (add)&#xA;              9 LOAD_CONST               1 (None)&#xA;             12 RETURN_VALUE&#xA;   &amp;lt;/dis&amp;gt;&#xA;   &amp;lt;filename&amp;gt; &#39;test.py&#39;&amp;lt;/filename&amp;gt;&#xA;   &amp;lt;consts&amp;gt;&#xA;      &amp;lt;code&amp;gt;&#xA;         &amp;lt;bytecode&amp;gt; 6401007d00007c0000474864000053&amp;lt;/bytecode&amp;gt;&#xA;         &amp;lt;dis&amp;gt;&#xA;  4           0 LOAD_CONST               1 (1)&#xA;              3 STORE_FAST               0 (a)&#xA;&#xA;  5           6 LOAD_FAST                0 (a)&#xA;              9 PRINT_ITEM&#xA;             10 PRINT_NEWLINE&#xA;             11 LOAD_CONST               0 (None)&#xA;             14 RETURN_VALUE&#xA;         &amp;lt;/dis&amp;gt;&#xA;         &amp;lt;filename&amp;gt; &#39;test.py&#39;&amp;lt;/filename&amp;gt;&#xA;         &amp;lt;consts&amp;gt;&#xA;            None&#xA;            1&#xA;         &amp;lt;/consts&amp;gt;&#xA;      &amp;lt;/code&amp;gt;&#xA;      None&#xA;   &amp;lt;/consts&amp;gt;&#xA;&amp;lt;/code&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2018/01/06/python-internal5-pyc/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Python 3.x 源码 - 编译调试之旅</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2018/01/01/python-internal4-lldb/</id>
    <content type="html">&lt;h2&gt;建立环境&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;从 GitHub 上下载源码&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/python/cpython&#xA;$ cd cpython&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;编译之前打开 &lt;code&gt;--with-pydebug&lt;/code&gt; 选项&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ ./configure --with-pydebug&#xA;$ make&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;编译完成之后，会在当前目录看到一个二进制文件 &lt;code&gt;python&lt;/code&gt;。如果你使用的是 macOS，文件名为 &lt;code&gt;python.exe&lt;/code&gt;，此文后续在命令行中请用 &lt;code&gt;python.exe&lt;/code&gt; 代替 &lt;code&gt;python&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h2&gt;用 GDB 调试&lt;/h2&gt;&#xA;&lt;p&gt;我们将使用 &lt;code&gt;gdb&lt;/code&gt; 来追踪 &lt;code&gt;python&lt;/code&gt; 的行为。&lt;/p&gt;&#xA;&lt;p&gt;本小结也是一个 &lt;code&gt;gdb&lt;/code&gt; 入门教程。&lt;/p&gt;&#xA;&lt;h3&gt;GDB 快捷键&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;r (run)，运行程序&lt;/li&gt;&#xA;&lt;li&gt;b (break)，设置断点&lt;/li&gt;&#xA;&lt;li&gt;s (step)，单步运行&lt;/li&gt;&#xA;&lt;li&gt;c (continue)，继续运行程序，在断点处会停止运行&lt;/li&gt;&#xA;&lt;li&gt;l (list)，列出当前程序的源代码&lt;/li&gt;&#xA;&lt;li&gt;ctrl+x，打开 tui 模式&lt;/li&gt;&#xA;&lt;li&gt;ctrl+p，往上&lt;/li&gt;&#xA;&lt;li&gt;ctrl+n，往下&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;GDB 介绍&lt;/h3&gt;&#xA;&lt;p&gt;在编译目录敲入命令 &lt;code&gt;gdb python&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ gdb python&#xA;GNU gdb (GDB) 7.12&#xA;Copyright (C) 2016 Free Software Foundation, Inc.&#xA;License GPLv3+: GNU GPL version 3 or later &amp;lt;http://gnu.org/licenses/gpl.html&amp;gt;&#xA;This is free software: you are free to change and redistribute it.&#xA;There is NO WARRANTY, to the extent permitted by law.  Type &amp;quot;show copying&amp;quot;&#xA;and &amp;quot;show warranty&amp;quot; for details.&#xA;This GDB was configured as &amp;quot;x86_64-pc-linux-gnu&amp;quot;.&#xA;Type &amp;quot;show configuration&amp;quot; for configuration details.&#xA;For bug reporting instructions, please see:&#xA;&amp;lt;http://www.gnu.org/software/gdb/bugs/&amp;gt;.&#xA;Find the GDB manual and other documentation resources online at:&#xA;&amp;lt;http://www.gnu.org/software/gdb/documentation/&amp;gt;.&#xA;For help, type &amp;quot;help&amp;quot;.&#xA;Type &amp;quot;apropos word&amp;quot; to search for commands related to &amp;quot;word&amp;quot;...&#xA;Reading symbols from python...done.&#xA;(gdb) &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在最后一行我们看到 &lt;code&gt;Reading symbols from python...done.&lt;/code&gt;，说明现在我们可以通过 &lt;code&gt;gdb&lt;/code&gt; 来调试 python 了。&lt;/p&gt;&#xA;&lt;p&gt;现在程序还没有运行，调试器在程序最前端停止下来。&lt;/p&gt;&#xA;&lt;p&gt;每一个 C 程序都从 &lt;code&gt;main()&lt;/code&gt; 函数开始运行，所以我们在 &lt;code&gt;main()&lt;/code&gt; 上打一个断点：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(gdb) b main&#xA;Breakpoint 1 at 0x41d1d6: file ./Programs/python.c, line 20.&#xA;(gdb)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;gdb&lt;/code&gt; 会在 &lt;code&gt;Programs/python.c, line 20&lt;/code&gt; 处打上断点。从这条信息可以看出，&lt;code&gt;Python&lt;/code&gt; 的入口点为 &lt;code&gt;Programs/python.c:20&lt;/code&gt;。另外，如果你事先已知晓源码，可以直接：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(gdb) b Programs/python.c:20&#xA;Breakpoint 3 at 0x41d1d6: file ./Programs/python.c, line 20.&#xA;(gdb)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;运行 &lt;code&gt;python&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(gdb) r&#xA;Starting program: /home/grd/Python/cpython/python &#xA;[Thread debugging using libthread_db enabled]&#xA;Using host libthread_db library &amp;quot;/usr/lib/libthread_db.so.1&amp;quot;.&#xA;&#xA;Breakpoint 1, main (argc=1, argv=0x7fffffffdff8) at ./Programs/python.c:20&#xA;20&#x9;{&#xA;(gdb)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们停在了之前设置的断点处，使用 &lt;code&gt;list&lt;/code&gt; 列出源代码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(gdb) l&#xA;15&#x9;}&#xA;16&#x9;#else&#xA;17&#x9;&#xA;18&#x9;int&#xA;19&#x9;main(int argc, char **argv)&#xA;20&#x9;{&#xA;21&#x9;    wchar_t **argv_copy;&#xA;22&#x9;    /* We need a second copy, as Python might modify the first one. */&#xA;23&#x9;    wchar_t **argv_copy2;&#xA;24&#x9;    int i, res;&#xA;(gdb) &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;或者使用 &lt;code&gt;ctrl+x&lt;/code&gt; 调出 &lt;code&gt;tui&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;   ┌──./Programs/python.c─────────────────────────────────────────────────────────┐&#xA;   │15      }                                                                     │&#xA;   │16      #else                                                                 │&#xA;   │17                                                                            │&#xA;   │18      int                                                                   │&#xA;   │19      main(int argc, char **argv)                                           │&#xA;B+&amp;gt;│20      {                                                                     │&#xA;   │21          wchar_t **argv_copy;                                              │&#xA;   │22          /* We need a second copy, as Python might modify the first one. */│&#xA;   │23          wchar_t **argv_copy2;                                             │&#xA;   │24          int i, res;                                                       │&#xA;   │25          char *oldloc;                                                     │&#xA;   │26                                                                            │&#xA;   └──────────────────────────────────────────────────────────────────────────────┘&#xA;multi-thre Thread 0x7ffff7f9de In: main                         L20   PC: 0x41d1d6 &#xA;(gdb)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 &lt;code&gt;tui&lt;/code&gt; 模式，也可以看到我们停在了源代码的第 20 行。&lt;/p&gt;&#xA;&lt;p&gt;继续运行 &lt;code&gt;continue&lt;/code&gt;，将进入 &lt;code&gt;python&lt;/code&gt; 的交互式解释器环境。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(gdb) c&#xA;   │29                                                                                                                                                                                                                                      │&#xA;   │30          argv_copy = (wchar_t **)PyMem_RawMalloc(sizeof(wchar_t*) * (argc+1));                                                                                                                                                       │&#xA;   │31          argv_copy2 = (wchar_t **)PyMem_RawMalloc(sizeof(wchar_t*) * (argc+1));                                                                                                                                                      │&#xA;   │32          if (!argv_copy || !argv_copy2) {                                                                                                                                                                                            │&#xA;   └────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘&#xA;multi-thre Thread 0x7ffff7f9de In: main                                                                                                                                                                                   L20   PC: 0x41d1d6 &#xA;[Thread debugging using libthread_db enabled]&#xA;Using host libthread_db library &amp;quot;/usr/lib/libthread_db.so.1&amp;quot;.&#xA;&#xA;Breakpoint 1, main (argc=1, argv=0x7fffffffdff8) at ./Programs/python.c:20&#xA;(gdb) c&#xA;Continuing.&#xA;Python 3.7.0a0 (default, Feb 22 2017, 22:10:22) &#xA;[GCC 6.3.1 20170109] on linux&#xA;Type &amp;quot;help&amp;quot;, &amp;quot;copyright&amp;quot;, &amp;quot;credits&amp;quot; or &amp;quot;license&amp;quot; for more information.&#xA;&amp;gt;&amp;gt;&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;调试语法分析器&lt;/h2&gt;&#xA;&lt;h3&gt;调试语法分析器&lt;/h3&gt;&#xA;&lt;p&gt;创建一个简单的 python 脚本 &lt;code&gt;test.py&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;a = 100&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;打开 gdb，设置参数，运行 python：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ gdb python&#xA;(gdb) set args test.py&#xA;// 或者&#xA;$ gdb --args python test.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;并在 &lt;code&gt;main&lt;/code&gt; 函数上打断点：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(gdb) b main&#xA;Breakpoint 1 at 0x41d1d6: file ./Programs/python.c, line 20.&#xA;(gdb) r&#xA;Starting program: /home/grd/Python/cpython/python &#xA;[Thread debugging using libthread_db enabled]&#xA;Using host libthread_db library &amp;quot;/usr/lib/libthread_db.so.1&amp;quot;.&#xA;&#xA;Breakpoint 1, main (argc=1, argv=0x7fffffffdff8) at ./Programs/python.c:20&#xA;20&#x9;{Starting program: /home/grd/Python/cpython/python &#xA;[Thread debugging using libthread_db enabled]&#xA;Using host libthread_db library &amp;quot;/usr/lib/libthread_db.so.1&amp;quot;.&#xA;&#xA;Breakpoint 1, main (argc=1, argv=0x7fffffffdff8) at ./Programs/python.c:20&#xA;20&#x9;{&#xA;(gdb) &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4&gt;Program/python.c&lt;/h4&gt;&#xA;&lt;p&gt;如果你仔细查看 &lt;code&gt;Program/python.c&lt;/code&gt; 的源码，会发现 &lt;code&gt;main()&lt;/code&gt; 做了很多事情，核心是调用 &lt;code&gt;Py_Main(argc, argv_copy)&lt;/code&gt; 函数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;    argv_copy2[argc] = argv_copy[argc] = NULL;&#xA;&#xA;    setlocale(LC_ALL, oldloc);&#xA;    PyMem_RawFree(oldloc);&#xA;&#xA;    res = Py_Main(argc, argv_copy);&#xA;&#xA;    /* Force again malloc() allocator to release memory blocks allocated&#xA;       before Py_Main() */&#xA;    (void)_PyMem_SetupAllocators(&amp;quot;malloc&amp;quot;);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4&gt;Modules/main.c&lt;/h4&gt;&#xA;&lt;p&gt;简单来说，&lt;code&gt;Py_Main&lt;/code&gt; 会做如下：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;初始化哈希随机：391&lt;/li&gt;&#xA;&lt;li&gt;重置 Warning 选项：394，395&lt;/li&gt;&#xA;&lt;li&gt;通过 &lt;code&gt;_PyOS_GetOpt()&lt;/code&gt; 解析命令行选项：397&lt;/li&gt;&#xA;&lt;li&gt;通过 &lt;code&gt;Py_Initialize()&lt;/code&gt; 初始化 python：693&lt;/li&gt;&#xA;&lt;li&gt;导入 &lt;code&gt;readline&lt;/code&gt; 模块：723&lt;/li&gt;&#xA;&lt;li&gt;依次执行：&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;run_command()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;RunModule()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;RunInteractiveHook()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;RunMainFromImporter()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;run_file()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;PyRun_AnyFileFlags()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;将断点打在 &lt;code&gt;run_file&lt;/code&gt;，第 793 行，可以用 &lt;code&gt;p filename&lt;/code&gt; 查看当前文件名：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(gdb) b Modules/main.c:793&#xA;(gdb) c&#xA;(gdb) p filename&#xA;$1 = 0x931050 L&amp;quot;test.py&#xA;(gdb) s&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;run_file&lt;/code&gt; 只是一个装饰器，该装饰器会调用 &lt;code&gt;Python/pythonrun.c&lt;/code&gt; 中的 &lt;code&gt;PyRun_InteractiveLoopFlags()&lt;/code&gt; 或 &lt;code&gt;PyRun_PyRun_SimpleFileExFlags&lt;/code&gt;。从名字上就可以看出一个会进入交互式环境，另一个就是带参数的 python 调用。这里，我们带上了参数 &lt;code&gt;test.py&lt;/code&gt;，所以会运行 &lt;code&gt;PyRun_PyRun_SimpleFileExFlags&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h4&gt;Python/pythonrun.c&lt;/h4&gt;&#xA;&lt;p&gt;&lt;code&gt;PyRun_SimpleFileExFlags()&lt;/code&gt; 首先会用 &lt;code&gt;maybe_pyc_file()&lt;/code&gt; 检查所传文件是否是 &lt;code&gt;.pyc&lt;/code&gt; 格式。&lt;/p&gt;&#xA;&lt;p&gt;在我们的例子中，由于是 &lt;code&gt;.py&lt;/code&gt; 文件，所以接着会调用 &lt;code&gt;PyRun_FileExFlags()&lt;/code&gt;。最后调用 &lt;code&gt;PyParser_ASTFromFileObject()&lt;/code&gt; 来建立抽象语法树（AST）。&lt;/p&gt;&#xA;&lt;p&gt;抽象语法树需调用 &lt;code&gt;Parser/parsetok.c&lt;/code&gt; 中的 &lt;code&gt;PyParser_ParseFileObject()&lt;/code&gt; 创建节点，再用 &lt;code&gt;PyAST_FromNodeObject()&lt;/code&gt; 函数从节点构建 AST 树。&lt;/p&gt;&#xA;&lt;h4&gt;Parser/parsetok.c&lt;/h4&gt;&#xA;&lt;p&gt;&lt;code&gt;PyParser_ParseFileObject()&lt;/code&gt; 会从 &lt;code&gt;PyTokenizer_FromFile()&lt;/code&gt; 中获取所有的 toekn，将这些 token 传入 &lt;code&gt;parsetok()&lt;/code&gt; 创建节点。&lt;/p&gt;&#xA;&lt;p&gt;最有趣的部分是其中包含一个无限循环：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;type = PyTokenizer_Get(tok, &amp;amp;a, &amp;amp;b);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;该函数是 &lt;code&gt;tok_get()&lt;/code&gt; 的装饰器，它会返回预定义于 &lt;code&gt;token.h&lt;/code&gt; 中的 token 类型：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// include/token.h&#xA;#define ENDMARKER&#x9;0&#xA;#define NAME&#x9;&#x9;1&#xA;#define NUMBER&#x9;&#x9;2&#xA;#define STRING&#x9;&#x9;3&#xA;#define NEWLINE&#x9;&#x9;4&#xA;#define INDENT&#x9;&#x9;5&#xA;#define DEDENT&#x9;&#x9;6&#xA;#define LPAR&#x9;&#x9;7&#xA;#define RPAR&#x9;&#x9;8&#xA;#define LSQB&#x9;&#x9;9&#xA;...&#xA;#define RARROW          51&#xA;#define ELLIPSIS        52&#xA;/* Don&#39;t forget to update the table _PyParser_TokenNames in tokenizer.c! */&#xA;#define OP&#x9;&#x9;53&#xA;#define AWAIT&#x9;&#x9;54&#xA;#define ASYNC&#x9;&#x9;55&#xA;#define ERRORTOKEN&#x9;56&#xA;#define N_TOKENS&#x9;57&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 for 循环的第一轮，我们在 gdb 中打印上述代码中的 &lt;code&gt;type&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(gdb) p type&#xA;$1 = 1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;根据头文件中的宏，值 1 对应 &lt;code&gt;NAME&lt;/code&gt;，说明该 token 为一个变量名。&lt;/p&gt;&#xA;&lt;p&gt;在第 236 行，&lt;code&gt;str[lbbben] = &#39;\0&#39;&lt;/code&gt; 会储存 token 所对应的字符串，即 &lt;code&gt;a&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(gdb) p str&#xA;$2 = 0x7ffff6eb5a18 &amp;quot;a&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;看起来很有道理，因为我们的源码为 &lt;code&gt;a = 100&lt;/code&gt;，第一个 token 字符串应对应于 &lt;code&gt;a&lt;/code&gt;，类型为 &lt;code&gt;NAME&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;解析器接下来会调用 &lt;code&gt;PyParser_AddToken()&lt;/code&gt;，这会将 token 加入语法树中。&lt;/p&gt;&#xA;&lt;h3&gt;语法生成&lt;/h3&gt;&#xA;&lt;p&gt;语法的文本表示在 &lt;code&gt;Grammar/Grammar&lt;/code&gt; 中，这是用 &lt;code&gt;yacc&lt;/code&gt; 写的，我建议直接忽略。而语法的数字表示在 &lt;code&gt;Python/graminit.c&lt;/code&gt; 中，其中包含了 DFA 数组。&lt;/p&gt;&#xA;&lt;p&gt;修改 &lt;code&gt;test.py&lt;/code&gt; 的内容为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class foo:&#xA;    pass&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;打开 gdb，在 &lt;code&gt;PyParser_AddToken()&lt;/code&gt; 上打断点：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ gdb python&#xA;(gdb) b PyParser_AddToken&#xA;(gdb) r test.py&#xA;[Thread debugging using libthread_db enabled]&#xA;Using host libthread_db library &amp;quot;/usr/lib/libthread_db.so.1&amp;quot;.&#xA;&#xA;Breakpoint 1, PyParser_AddToken (ps=ps@entry=0x9cf4f0, type=type@entry=1, str=str@entry=0x7ffff6eb5a18 &amp;quot;class&amp;quot;, lineno=1, col_offset=0, expected_ret=expected_ret@entry=0x7fffffffdc34) at Parser/parser.c:229&#xA;229&#x9;{&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;为了看到 DFA 的状态变化，在 &lt;code&gt;dfa *d = ps-&amp;gt;p_stack.s_top-&amp;gt;s_dfa&lt;/code&gt; 下一行打上断点：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(gdb) b 244&#xA;Breakpoint 2 at 0x5b5933: file Parser/parser.c, line 244.&#xA;(gdb) c&#xA;Breakpoint 2, PyParser_AddToken (ps=ps@entry=0x9cf4f0, type=type@entry=1, str=str@entry=0x7ffff6eb5a18 &amp;quot;class&amp;quot;, lineno=1, col_offset=0, expected_ret=expected_ret@entry=0x7fffffffdc34) at Parser/parser.c:244&#xA;244&#x9;        state *s = &amp;amp;d-&amp;gt;d_state[ps-&amp;gt;p_stack.s_top-&amp;gt;s_state];&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;然后打印出 &lt;code&gt;d&lt;/code&gt; 的值：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(gdb) p *d&#xA;$6 = {d_type = 269, d_name = 0x606340 &amp;quot;stmt&amp;quot;, d_initial = 0, d_nstates = 2, d_state = 0x8a6a40 &amp;lt;states_13&amp;gt;, d_first = 0x60658c &amp;quot;&amp;quot;}&#xA;(gdb) set print pretty&#xA;(gdb) p *d&#xA;$8 = {&#xA;  d_type = 269,&#xA;  d_name = 0x606340 &amp;quot;stmt&amp;quot;,&#xA;  d_initial = 0,&#xA;  d_nstates = 2,&#xA;  d_state = 0x8a6a40 &amp;lt;states_13&amp;gt;,&#xA;  d_first = 0x60658c &amp;quot;&amp;quot;&#xA;}&#xA;...&#xA;...&#xA;(gdb) p d-&amp;gt;d_name&#xA;&#39;file_input&#39;&#xA;(gdb)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;对比 &lt;code&gt;d_name&lt;/code&gt; 的值，发现它出现在 &lt;code&gt;Grammar/Grammar&lt;/code&gt; 中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# Grammar for Python&#xA;&#xA;single_input: NEWLINE | simple_stmt | compound_stmt NEWLINE&#xA;file_input: (NEWLINE | stmt)* ENDMARKER&#xA;eval_input: testlist NEWLINE* ENDMARKER&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;运行多次，我们会发现 &lt;code&gt;d_name&lt;/code&gt; 按如下的顺序变化：&lt;code&gt;file_input&lt;/code&gt;, &lt;code&gt;stmt&lt;/code&gt;, &lt;code&gt;compound_stmt&lt;/code&gt;, &lt;code&gt;classdef&lt;/code&gt;, &lt;code&gt;classdef&lt;/code&gt;, &lt;code&gt;classdef&lt;/code&gt;, &lt;code&gt;classdef&lt;/code&gt;, &lt;code&gt;suite&lt;/code&gt;, &lt;code&gt;suite&lt;/code&gt;, &lt;code&gt;suite&lt;/code&gt;, &lt;code&gt;stmt&lt;/code&gt;, &lt;code&gt;simple_stmt&lt;/code&gt;, &lt;code&gt;small_stmt&lt;/code&gt;, &lt;code&gt;pass_stmt&lt;/code&gt;, &lt;code&gt;simple_stmt&lt;/code&gt;, &lt;code&gt;suite&lt;/code&gt;, &lt;code&gt;file_input&lt;/code&gt;, &lt;code&gt;file_input&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h3&gt;回顾&lt;/h3&gt;&#xA;&lt;p&gt;查看一下到目前为止的调用栈：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;main()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Py_Main()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;run_file()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;PyRun_AnyFileExFlags()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;PyRun_SimpleFileExFlags()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;PyRun_FileExFlags()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;PyParser_ASTFromFileObject()&lt;/code&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;PyParser_ParseFileObject()&lt;/code&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;parsetok()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;PyParser_AddToken()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;PyAST_FromNodeObject()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;调试抽象语法树（AST）生成器&lt;/h2&gt;&#xA;&lt;p&gt;我们从 &lt;code&gt;PyParser_ParseFileObject()&lt;/code&gt; 构建了语法树，下一步是生成 AST。&lt;/p&gt;&#xA;&lt;p&gt;在此之前，需要介绍一些宏。这些宏定义于 &lt;code&gt;Include/node.h&lt;/code&gt; 中，用于从节点结构中查询数据：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;CHILD(node *, int)&lt;/code&gt;，返回第 n 个节点（从 0 开始）&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;RCHILD(node *, int)&lt;/code&gt;，从右往左返回第 n 个节点，使用负数&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;NCH(node *)&lt;/code&gt;，返回节点总数&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;STR(node *)&lt;/code&gt;，返回节点的字符串表示，比如冒号 token，会返回 &lt;code&gt;:&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;TYPE(node *)&lt;/code&gt;，返回节点的类型，类型定义于 &lt;code&gt;Include/graminit.h&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;REQ(node *, TYPE)&lt;/code&gt;，判断节点类型是否是 &lt;code&gt;TYPE&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;LINENO(node *)&lt;/code&gt;，获取解析规则源码所在的行数，规则定义在 &lt;code&gt;Python/ast.c&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;在 &lt;code&gt;Python/ast.c&lt;/code&gt; 中的 &lt;code&gt;PyAST_FromNodeObject()&lt;/code&gt; 将语法树转换为 AST。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for (i = 0; i &amp;lt; NCH(n) - 1; i++) {&#xA;    ch = CHILD(n, i);&#xA;    if (TYPE(ch) == NEWLINE)&#xA;        continue;&#xA;    REQ(ch, stmt);&#xA;    num = num_stmts(ch);&#xA;    if (num == 1) {&#xA;        s = ast_for_stmt(&amp;amp;c, ch);&#xA;        if (!s)&#xA;            goto out;&#xA;        asdl_seq_SET(stmts, k++, s);&#xA;    }&#xA;    else {&#xA;        ch = CHILD(ch, 0);&#xA;        REQ(ch, simple_stmt);&#xA;        for (j = 0; j &amp;lt; num; j++) {&#xA;            s = ast_for_stmt(&amp;amp;c, CHILD(ch, j * 2));&#xA;            if (!s)&#xA;                goto out;&#xA;            asdl_seq_SET(stmts, k++, s);&#xA;        }&#xA;    }&#xA;}&#xA;res = Module(stmts, arena);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;ast_for_stmt()&lt;/code&gt; 是 &lt;code&gt;ast_for_xx&lt;/code&gt; 的装饰器，其中 &lt;code&gt;xx&lt;/code&gt; 是对应函数处理的语法规则。&lt;/p&gt;&#xA;&lt;h2&gt;调试符号表生成器&lt;/h2&gt;&#xA;&lt;p&gt;回到 &lt;code&gt;Python/pythonrun.c&lt;/code&gt; 中的 &lt;code&gt;PyRun_FileExFlags()&lt;/code&gt;。它会接着将结果 &lt;code&gt;mod&lt;/code&gt; 传入 &lt;code&gt;run_mod()&lt;/code&gt; 函数中。它完成了重要的两步：第一，生成代码对象（&lt;code&gt;PyAST_CompileObject()&lt;/code&gt;），第二，进入解析循环（&lt;code&gt;PyEval_EvalCode()&lt;/code&gt;）。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;PyAST_CompileObject()&lt;/code&gt; 位于 &lt;code&gt;Python/compile.c&lt;/code&gt;。它有两个重要的函数：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;PySumtable_BuildObject()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;compiler_mod()&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;code&gt;Python/symtable.c&lt;/code&gt; 中的 &lt;code&gt;PySumtable_BuildObject()&lt;/code&gt; 用于生成符号表。&lt;/p&gt;&#xA;&lt;p&gt;符号表的结构定义在 &lt;code&gt;Include/symtble.h&lt;/code&gt; 中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;struct _symtable_entry;&#xA;&#xA;struct symtable {&#xA;    PyObject *st_filename;          /* name of file being compiled,&#xA;                                       decoded from the filesystem encoding */&#xA;    struct _symtable_entry *st_cur; /* current symbol table entry */&#xA;    struct _symtable_entry *st_top; /* symbol table entry for module */&#xA;    PyObject *st_blocks;            /* dict: map AST node addresses&#xA;                                     *       to symbol table entries */&#xA;    PyObject *st_stack;             /* list: stack of namespace info */&#xA;    PyObject *st_global;            /* borrowed ref to st_top-&amp;gt;ste_symbols */&#xA;    int st_nblocks;                 /* number of blocks used. kept for&#xA;                                       consistency with the corresponding&#xA;                                       compiler structure */&#xA;    PyObject *st_private;           /* name of current class or NULL */&#xA;    PyFutureFeatures *st_future;    /* module&#39;s future features that affect&#xA;                                       the symbol table */&#xA;    int recursion_depth;            /* current recursion depth */&#xA;    int recursion_limit;            /* recursion limit */&#xA;};&#xA;&#xA;typedef struct _symtable_entry {&#xA;    PyObject_HEAD&#xA;    PyObject *ste_id;        /* int: key in ste_table-&amp;gt;st_blocks */&#xA;    PyObject *ste_symbols;   /* dict: variable names to flags */&#xA;    PyObject *ste_name;      /* string: name of current block */&#xA;    PyObject *ste_varnames;  /* list of function parameters */&#xA;    PyObject *ste_children;  /* list of child blocks */&#xA;    PyObject *ste_directives;/* locations of global and nonlocal statements */&#xA;    _Py_block_ty ste_type;   /* module, class, or function */&#xA;    int ste_nested;      /* true if block is nested */&#xA;    unsigned ste_free : 1;        /* true if block has free variables */&#xA;    unsigned ste_child_free : 1;  /* true if a child block has free vars,&#xA;                                     including free refs to globals */&#xA;    unsigned ste_generator : 1;   /* true if namespace is a generator */&#xA;    unsigned ste_coroutine : 1;   /* true if namespace is a coroutine */&#xA;    unsigned ste_varargs : 1;     /* true if block has varargs */&#xA;    unsigned ste_varkeywords : 1; /* true if block has varkeywords */&#xA;    unsigned ste_returns_value : 1;  /* true if namespace uses return with&#xA;                                        an argument */&#xA;    unsigned ste_needs_class_closure : 1; /* for class scopes, true if a&#xA;                                            closure over __class__&#xA;                                             should be created */&#xA;    int ste_lineno;          /* first line of block */&#xA;    int ste_col_offset;      /* offset of first line of block */&#xA;    int ste_opt_lineno;      /* lineno of last exec or import * */&#xA;    int ste_opt_col_offset;  /* offset of last exec or import * */&#xA;    int ste_tmpname;         /* counter for listcomp temp vars */&#xA;    struct symtable *ste_table;&#xA;} PySTEntryObject;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看出，符号表其实是一个字典结构，每一项是一个符号对应关系。&lt;/p&gt;&#xA;&lt;p&gt;在第 281 行的 for 循环打上断点（&lt;code&gt;for (i = 0; i &amp;lt; asdl_seq_LEN(seq); i++)&lt;/code&gt;），会来到 &lt;code&gt;symtable_visit_stmt()&lt;/code&gt; 函数，该函数生成符号表的每一项。接着打断点：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(gdb) b symtable_visit_stmt&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;就能观察到类似 &lt;code&gt;xx_kind&lt;/code&gt; 的表达式，例如 &lt;code&gt;Name_kind&lt;/code&gt; 会调用 &lt;code&gt;symtable_add_def()&lt;/code&gt; 将一个符号定义加入到符号表中。&lt;/p&gt;&#xA;&lt;h2&gt;调试编译器和字节码生成器&lt;/h2&gt;&#xA;&lt;p&gt;回到函数 &lt;code&gt;PyAST_CompileObject()&lt;/code&gt; 中，下一步是 &lt;code&gt;compiler_mod()&lt;/code&gt;，将抽象语法树转换为上下文无关语法。&lt;/p&gt;&#xA;&lt;p&gt;在此处打断点（&lt;code&gt;b compiler_mod&lt;/code&gt;）。swtich 分支会把我们带进 &lt;code&gt;Module_kind&lt;/code&gt;，里面会调用 &lt;code&gt;compiler_body()&lt;/code&gt; 函数，接着单步调试，就会发现一个 for 循环：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for (; i &amp;lt; asdl_seq_LEN(stmts); i++)&#xA;    VISIT(c, stmt, (stmt)ty)asdl_seq_GET(stmts, i));&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这里，我们在抽象语义描述语言（ASDL）中遍历，调用宏 &lt;code&gt;VISIT&lt;/code&gt;，接着调用 &lt;code&gt;compiler_visit_expr(c, nodeZ)&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;以下宏会产生字节码：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;ADDOP()&lt;/code&gt;，增加一个指定的字节码&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;ADDOP_I()&lt;/code&gt;，增加的字节码是带参数的&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;ADDOP_O(struct compiler *c, int op, PyObject * type, PyObject *obj)&lt;/code&gt;，根据指定 &lt;code&gt;PyObject&lt;/code&gt; 在序列中的位置，增加一个字节码，但是不考虑 name mangling。常用于全局、常量或参数的变量名寻找，因为这种变量名的作用域是未知的。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;ADDOP_NAME()&lt;/code&gt;，和 &lt;code&gt;ADDOP_O&lt;/code&gt; 类似，但是会考虑 name mangling。用于属性加载和导入。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;ADDOP_JABS()&lt;/code&gt;，创建一个绝对跳转&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;ADDOP_JREL()&lt;/code&gt;，创建一个相对跳转&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;为了验证是否生成了正确的字节码，可以在 &lt;code&gt;test.py&lt;/code&gt; 上运行：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ python -m dis test.py&#xA;  1           0 LOAD_CONST               0 (100)&#xA;              2 STORE_NAME               0 (a)&#xA;              4 LOAD_CONST               1 (None)&#xA;              6 RETURN_VALUE&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;调试解析器循环&lt;/h2&gt;&#xA;&lt;p&gt;一旦字节码生成，下一步是由解析器运行程序。回到 &lt;code&gt;Python/pythonrun.c&lt;/code&gt; 文件中，我们接着会调用函数 &lt;code&gt;PyEval_EvalCode()&lt;/code&gt;，这是对 &lt;code&gt;PyEval_EvalCodeEx()/_PyEval_EvalCodeWithName()&lt;/code&gt; 的装饰器函数。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;和 Python2.7 不一样，&lt;code&gt;PyEval_EvalCodeEx&lt;/code&gt; 不会建立函数栈，这一步被移入 &lt;code&gt;_PyEval_EvalCodeWithName&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;栈对象的结构定义于 &lt;code&gt;Include/frameobject.h&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct _frame {&#xA;    PyObject_VAR_HEAD&#xA;    struct _frame *f_back;      /* previous frame, or NULL */&#xA;    PyCodeObject *f_code;       /* code segment */&#xA;    PyObject *f_builtins;       /* builtin symbol table (PyDictObject) */&#xA;    PyObject *f_globals;        /* global symbol table (PyDictObject) */&#xA;    PyObject *f_locals;         /* local symbol table (any mapping) */&#xA;    PyObject **f_valuestack;    /* points after the last local */&#xA;    /* Next free slot in f_valuestack.  Frame creation sets to f_valuestack.&#xA;       Frame evaluation usually NULLs it, but a frame that yields sets it&#xA;       to the current stack top. */&#xA;    PyObject **f_stacktop;&#xA;    PyObject *f_trace;          /* Trace function */&#xA;&#xA;    /* In a generator, we need to be able to swap between the exception&#xA;       state inside the generator and the exception state of the calling&#xA;       frame (which shouldn&#39;t be impacted when the generator &amp;quot;yields&amp;quot;&#xA;       from an except handler).&#xA;       These three fields exist exactly for that, and are unused for&#xA;       non-generator frames. See the save_exc_state and swap_exc_state&#xA;       functions in ceval.c for details of their use. */&#xA;    PyObject *f_exc_type, *f_exc_value, *f_exc_traceback;&#xA;    /* Borrowed reference to a generator, or NULL */&#xA;    PyObject *f_gen;&#xA;&#xA;    int f_lasti;                /* Last instruction if called */&#xA;    /* Call PyFrame_GetLineNumber() instead of reading this field&#xA;       directly.  As of 2.3 f_lineno is only valid when tracing is&#xA;       active (i.e. when f_trace is set).  At other times we use&#xA;       PyCode_Addr2Line to calculate the line from the current&#xA;       bytecode index. */&#xA;    int f_lineno;               /* Current line number */&#xA;    int f_iblock;               /* index in f_blockstack */&#xA;    char f_executing;           /* whether the frame is still executing */&#xA;    PyTryBlock f_blockstack[CO_MAXBLOCKS]; /* for try and loop blocks */&#xA;    PyObject *f_localsplus[1];  /* locals+stack, dynamically sized */&#xA;} PyFrameObject;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 &lt;code&gt;_PyEval_EvalCodeWithName()&lt;/code&gt; 中，会用 &lt;code&gt;_PyFrame_New_NoTrack()&lt;/code&gt; 创建一个栈对象，这个栈是对 C 程序函数栈的模拟，在最后，会调用 &lt;code&gt;PyEval_EvalFrameEx()&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;PyEval_EvalFrameEx()&lt;/code&gt; 然后会在 &lt;code&gt;PyThreadState&lt;/code&gt; 上调用 &lt;code&gt;eval_frame()/_PyEval_EvalFrameDefault()&lt;/code&gt; 函数。这个函数也会被 Python 虚拟机调用。&lt;/p&gt;&#xA;&lt;p&gt;跟踪进入 &lt;code&gt;_PyEval_EvalFrameDefault()&lt;/code&gt;，我们可以观察到第 1054 行有一个无限循环，在不断产生字节码。&lt;/p&gt;&#xA;&lt;h2&gt;调试 Python 对象&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;PyObject&lt;/code&gt; 是通用 Python 对象，定义于 &lt;code&gt;Include/object.h&lt;/code&gt; 中。&lt;/p&gt;&#xA;&lt;h3&gt;简介&lt;/h3&gt;&#xA;&lt;p&gt;每一种 &lt;code&gt;PyObject&lt;/code&gt; 都有着相似的跟踪步骤：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;用 gdb 打开 python&lt;/li&gt;&#xA;&lt;li&gt;在对象创建函数上打断点&lt;/li&gt;&#xA;&lt;li&gt;用交互式命令环境，创建我们想要的对象&lt;/li&gt;&#xA;&lt;li&gt;在断点处，开始一步步跟踪代码&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;例如，我们想单步调试 &lt;code&gt;PyBoolObject&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ gdb python&#xA;(gdb) b bool_newbb&#xA;Breakpoint 1 at 0x44812f: file Objects/boolobject.c, line 44.&#xA;(gdb) r&#xA;[GCC 6.3.1 20170109] on linux&#xA;Type &amp;quot;help&amp;quot;, &amp;quot;copyright&amp;quot;, &amp;quot;credits&amp;quot; or &amp;quot;license&amp;quot; for more information.&#xA;&amp;gt;&amp;gt;&amp;gt; a = bool(1)&#xA;&#xA;Breakpoint 1, bool_new (type=0x87a700 &amp;lt;PyBool_Type&amp;gt;, args=(1,), kwds=0x0) at Objects/boolobject.c:44&#xA;44&#x9;{&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;PyObject&lt;/h3&gt;&#xA;&lt;p&gt;通用 Python 对象定义为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct _object {&#xA;    _PyObject_HEAD_EXTRA&#xA;    Py_ssize_t ob_refcnt;&#xA;    struct _typeobject *ob_type;&#xA;} PyObjecdt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在预处理器展开宏 &lt;code&gt;_PyObject_HEAD_EXTRA&lt;/code&gt; 后，它会变成一个双向列表：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct _object {&#xA;    struct _object *_ob_next;&#xA;    struct _object *_ob_prev;&#xA;    Py_ssize_t ob_refcnt;&#xA;    struct _typeobject *ob_type;&#xA;} PyObjecdt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;该对象包含两个重要元素：引用计数和类型对象。&lt;/p&gt;&#xA;&lt;h3&gt;PyVarObject&lt;/h3&gt;&#xA;&lt;p&gt;Python 也有变长对象，定义为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct {&#xA;    PyObject ob_base;&#xA;    Py_ssize_t ob_size; /* Number of items in variable part */&#xA;} PyVarObject;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;几乎和 &lt;code&gt;PyObject&lt;/code&gt; 一样，但多了一项用于表示对象的长度信息。&lt;/p&gt;&#xA;&lt;h3&gt;PyTypeObject&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;PyTypeObject&lt;/code&gt; 是 Python 对象的类型表示。在 Python 中可以如下表达式获取任何对象的类型信息：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; t = type(1)&#xA;&amp;gt;&amp;gt;&amp;gt; dir(t)&#xA;[&#39;__abs__&#39;, &#39;__add__&#39;, &#39;__and__&#39;, &#39;__bool__&#39;, &#39;__ceil__&#39;, &#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dir__&#39;, &#39;__divmod__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__float__&#39;, &#39;__floor__&#39;, &#39;__floordiv__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__getnewargs__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__index__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__int__&#39;, &#39;__invert__&#39;, &#39;__le__&#39;, &#39;__lshift__&#39;, &#39;__lt__&#39;, &#39;__mod__&#39;, &#39;__mul__&#39;, &#39;__ne__&#39;, &#39;__neg__&#39;, &#39;__new__&#39;, &#39;__or__&#39;, &#39;__pos__&#39;, &#39;__pow__&#39;, &#39;__radd__&#39;, &#39;__rand__&#39;, &#39;__rdivmod__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__rfloordiv__&#39;, &#39;__rlshift__&#39;, &#39;__rmod__&#39;, &#39;__rmul__&#39;, &#39;__ror__&#39;, &#39;__round__&#39;, &#39;__rpow__&#39;, &#39;__rrshift__&#39;, &#39;__rshift__&#39;, &#39;__rsub__&#39;, &#39;__rtruediv__&#39;, &#39;__rxor__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__sub__&#39;, &#39;__subclasshook__&#39;, &#39;__truediv__&#39;, &#39;__trunc__&#39;, &#39;__xor__&#39;, &#39;bit_length&#39;, &#39;conjugate&#39;, &#39;denominator&#39;, &#39;from_bytes&#39;, &#39;imag&#39;, &#39;numerator&#39;, &#39;real&#39;, &#39;to_bytes&#39;]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这些方法都定义在 &lt;code&gt;PyTypeObject&lt;/code&gt; 中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#ifdef Py_LIMITED_API&#xA;typedef struct _typeobject PyTypeObject; /* opaque */&#xA;#else&#xA;typedef struct _typeobject {&#xA;    PyObject_VAR_HEAD&#xA;    const char *tp_name; /* For printing, in format &amp;quot;&amp;lt;module&amp;gt;.&amp;lt;name&amp;gt;&amp;quot; */&#xA;    Py_ssize_t tp_basicsize, tp_itemsize; /* For allocation */&#xA;&#xA;    /* Methods to implement standard operations */&#xA;&#xA;    destructor tp_dealloc;&#xA;    printfunc tp_print;&#xA;    getattrfunc tp_getattr;&#xA;    setattrfunc tp_setattr;&#xA;    PyAsyncMethods *tp_as_async; /* formerly known as tp_compare (Python 2)&#xA;                                    or tp_reserved (Python 3) */&#xA;    reprfunc tp_repr;&#xA;&#xA;    /* Method suites for standard classes */&#xA;&#xA;    PyNumberMethods *tp_as_number;&#xA;    PySequenceMethods *tp_as_sequence;&#xA;    PyMappingMethods *tp_as_mapping;&#xA;&#xA;    /* More standard operations (here for binary compatibility) */&#xA;&#xA;    hashfunc tp_hash;&#xA;    ternaryfunc tp_call;&#xA;    reprfunc tp_str;&#xA;    getattrofunc tp_getattro;&#xA;    setattrofunc tp_setattro;&#xA;&#xA;    /* Functions to access object as input/output buffer */&#xA;    PyBufferProcs *tp_as_buffer;&#xA;&#xA;    /* Flags to define presence of optional/expanded features */&#xA;    unsigned long tp_flags;&#xA;&#xA;    const char *tp_doc; /* Documentation string */&#xA;&#xA;    /* Assigned meaning in release 2.0 */&#xA;    /* call function for all accessible objects */&#xA;    traverseproc tp_traverse;&#xA;&#xA;    /* delete references to contained objects */&#xA;    inquiry tp_clear;&#xA;&#xA;    /* Assigned meaning in release 2.1 */&#xA;    /* rich comparisons */&#xA;    richcmpfunc tp_richcompare;&#xA;&#xA;    /* weak reference enabler */&#xA;    Py_ssize_t tp_weaklistoffset;&#xA;&#xA;    /* Iterators */&#xA;    getiterfunc tp_iter;&#xA;    iternextfunc tp_iternext;&#xA;&#xA;    /* Attribute descriptor and subclassing stuff */&#xA;    struct PyMethodDef *tp_methods;&#xA;    struct PyMemberDef *tp_members;&#xA;    struct PyGetSetDef *tp_getset;&#xA;    struct _typeobject *tp_base;&#xA;    PyObject *tp_dict;&#xA;    descrgetfunc tp_descr_get;&#xA;    descrsetfunc tp_descr_set;&#xA;    Py_ssize_t tp_dictoffset;&#xA;    initproc tp_init;&#xA;    allocfunc tp_alloc;&#xA;    newfunc tp_new;&#xA;    freefunc tp_free; /* Low-level free-memory routine */&#xA;    inquiry tp_is_gc; /* For PyObject_IS_GC */&#xA;    PyObject *tp_bases;&#xA;    PyObject *tp_mro; /* method resolution order */&#xA;    PyObject *tp_cache;&#xA;    PyObject *tp_subclasses;&#xA;    PyObject *tp_weaklist;&#xA;    destructor tp_del;&#xA;&#xA;    /* Type attribute cache version tag. Added in version 2.6 */&#xA;    unsigned int tp_version_tag;&#xA;&#xA;    destructor tp_finalize;&#xA;&#xA;#ifdef COUNT_ALLOCS&#xA;    /* these must be last and never explicitly initialized */&#xA;    Py_ssize_t tp_allocs;&#xA;    Py_ssize_t tp_frees;&#xA;    Py_ssize_t tp_maxalloc;&#xA;    struct _typeobject *tp_prev;&#xA;    struct _typeobject *tp_next;&#xA;#endif&#xA;} PyTypeObject;&#xA;#endif&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;所有的整数对象现在都在 &lt;code&gt;Objects/longobject.c&lt;/code&gt; 中实现，定义为 &lt;code&gt;PyLong_Type&lt;/code&gt; 类型。&lt;code&gt;PyLong_Type&lt;/code&gt; 就是一个 &lt;code&gt;PyTypeObject&lt;/code&gt; 对象。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;PyTypeObject PyLong_Type = {&#xA;    PyVarObject_HEAD_INIT(&amp;amp;PyType_Type, 0)&#xA;    &amp;quot;int&amp;quot;,                                      /* tp_name */&#xA;    offsetof(PyLongObject, ob_digit),           /* tp_basicsize */&#xA;    sizeof(digit),                              /* tp_itemsize */&#xA;    long_dealloc,                               /* tp_dealloc */&#xA;    0,                                          /* tp_print */&#xA;    0,                                          /* tp_getattr */&#xA;    0,                                          /* tp_setattr */&#xA;    0,                                          /* tp_reserved */&#xA;    long_to_decimal_string,                     /* tp_repr */&#xA;    &amp;amp;long_as_number,                            /* tp_as_number */&#xA;    0,                                          /* tp_as_sequence */&#xA;    0,                                          /* tp_as_mapping */&#xA;    (hashfunc)long_hash,                        /* tp_hash */&#xA;    0,                                          /* tp_call */&#xA;    long_to_decimal_string,                     /* tp_str */&#xA;    PyObject_GenericGetAttr,                    /* tp_getattro */&#xA;    0,                                          /* tp_setattro */&#xA;    0,                                          /* tp_as_buffer */&#xA;    Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE |&#xA;        Py_TPFLAGS_LONG_SUBCLASS,               /* tp_flags */&#xA;    long_doc,                                   /* tp_doc */&#xA;    0,                                          /* tp_traverse */&#xA;    0,                                          /* tp_clear */&#xA;    long_richcompare,                           /* tp_richcompare */&#xA;    0,                                          /* tp_weaklistoffset */&#xA;    0,                                          /* tp_iter */&#xA;    0,                                          /* tp_iternext */&#xA;    long_methods,                               /* tp_methods */&#xA;    0,                                          /* tp_members */&#xA;    long_getset,                                /* tp_getset */&#xA;    0,                                          /* tp_base */&#xA;    0,                                          /* tp_dict */&#xA;    0,                                          /* tp_descr_get */&#xA;    0,                                          /* tp_descr_set */&#xA;    0,                                          /* tp_dictoffset */&#xA;    0,                                          /* tp_init */&#xA;    0,                                          /* tp_alloc */&#xA;    long_new,                                   /* tp_new */&#xA;    PyObject_Del,                               /* tp_free */&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;PyLongObject&lt;/h3&gt;&#xA;&lt;p&gt;定义于 &lt;code&gt;Include/longobject.h&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct _longobject PyLongObject; /* Revealed in longintrepr.h */&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;PyBoolObject&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;PyBoolObject&lt;/code&gt; 在 Python 中存储布尔类型，定义于 &lt;code&gt;Include/boolobject.h&lt;/code&gt; 中。&lt;/p&gt;&#xA;&lt;h3&gt;PyFloatObject&lt;/h3&gt;&#xA;&lt;p&gt;在 &lt;code&gt;Include/floatobject.h&lt;/code&gt; 中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct {&#xA;    PyObject_HEAD&#xA;    double ob_fval;&#xA;} PyFloatObject;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;PyListObject&lt;/h3&gt;&#xA;&lt;p&gt;在 &lt;code&gt;Include/listobject.h&lt;/code&gt; 中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct {&#xA;    PyObject_VAR_HEAD&#xA;    /* Vector of pointers to list elements.  list[0] is ob_item[0], etc. */&#xA;    PyObject **ob_item;&#xA;&#xA;    /* ob_item contains space for &#39;allocated&#39; elements.  The number&#xA;     * currently in use is ob_size.&#xA;     * Invariants:&#xA;     *     0 &amp;lt;= ob_size &amp;lt;= allocated&#xA;     *     len(list) == ob_size&#xA;     *     ob_item == NULL implies ob_size == allocated == 0&#xA;     * list.sort() temporarily sets allocated to -1 to detect mutations.&#xA;     *&#xA;     * Items must normally not be NULL, except during construction when&#xA;     * the list is not yet visible outside the function that builds it.&#xA;     */&#xA;    Py_ssize_t allocated;&#xA;} PyListObject;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2018/01/01/python-internal4-lldb/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Python 2.7 源码 - 字符串对象</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2017/12/28/python-internal3-string-object/</id>
    <content type="html">&lt;h2&gt;Python 的字符串类型和对象&lt;/h2&gt;&#xA;&lt;p&gt;有了之前&lt;a href=&#34;http://www.lyyyuna.com/2017/12/24/python-internal2-integer-object/&#34;&gt;整数对象&lt;/a&gt;的铺垫，研究字符串类型及其对象，当然是先看其对应的类型结构体和对象结构体。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// stringobject.c&#xA;PyTypeObject PyString_Type = {&#xA;    PyVarObject_HEAD_INIT(&amp;amp;PyType_Type, 0)&#xA;    &amp;quot;str&amp;quot;,&#xA;    PyStringObject_SIZE,&#xA;    sizeof(char),&#xA;    string_dealloc,                             /* tp_dealloc */&#xA;    (printfunc)string_print,                    /* tp_print */&#xA;    0,                                          /* tp_getattr */&#xA;    ...&#xA;    ...&#xA;    &amp;amp;PyBaseString_Type,                         /* tp_base */&#xA;    0,                                          /* tp_dict */&#xA;    0,                                          /* tp_descr_get */&#xA;    0,                                          /* tp_descr_set */&#xA;    0,                                          /* tp_dictoffset */&#xA;    0,                                          /* tp_init */&#xA;    0,                                          /* tp_alloc */&#xA;    string_new,                                 /* tp_new */&#xA;    PyObject_Del,                               /* tp_free */&#xA;};&#xA;&#xA;// stringobject.c&#xA;typedef struct {&#xA;    PyObject_VAR_HEAD&#xA;    long ob_shash;&#xA;    int ob_sstate;&#xA;    char ob_sval[1];&#xA;} PyStringObject;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;ob_shash&lt;/code&gt; 是该字符串的哈希值，由于 Python 的字典实现大量使用了哈希值，且字典的健多为 &lt;code&gt;PyStringObject&lt;/code&gt;，预先计算哈希值并保存下来，可以加速字典的运算。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;ob_sstate&lt;/code&gt; 和字符串对象的 intern 机制有关。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;ob_sval&lt;/code&gt; 为什么是长度为 1 的数组？这种定义方法其实符合 C99 标准。&lt;a href=&#34;https://en.wikipedia.org/wiki/Flexible_array_member&#34;&gt;Flexible array member&lt;/a&gt;规定，若要支持柔性数组，可在结构体末尾放置一个不指定长度的数组。而大多数编译器都支持长度为 1 的定义方法，所以就写成 1 了。如果你单独定义 &lt;code&gt;char buf[]&lt;/code&gt;，那必然是会报错的。&lt;/p&gt;&#xA;&lt;h2&gt;创建一个 PyStringObject&lt;/h2&gt;&#xA;&lt;p&gt;最底层的生成字符串的函数为 &lt;code&gt;PyString_FromString&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// stringobject.c&#xA;PyObject *&#xA;PyString_FromString(const char *str)&#xA;{&#xA;    ...&#xA;    size = strlen(str);&#xA;    ...&#xA;&#xA;    /* Inline PyObject_NewVar */&#xA;    op = (PyStringObject *)PyObject_MALLOC(PyStringObject_SIZE + size);&#xA;    if (op == NULL)&#xA;        return PyErr_NoMemory();&#xA;    (void)PyObject_INIT_VAR(op, &amp;amp;PyString_Type, size);&#xA;    op-&amp;gt;ob_shash = -1;&#xA;    op-&amp;gt;ob_sstate = SSTATE_NOT_INTERNED;&#xA;    Py_MEMCPY(op-&amp;gt;ob_sval, str, size+1);  // 将原始C字串的值搬运过来&#xA;&#xA;    ...&#xA;    ...&#xA;    return (PyObject *) op;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;函数是根据原始的 C 语言字符串生成对应的 &lt;code&gt;PyStringObject&lt;/code&gt;。原始字符串被复制到 &lt;code&gt;ob_sval&lt;/code&gt; 中。&lt;/p&gt;&#xA;&lt;h2&gt;intern 机制&lt;/h2&gt;&#xA;&lt;p&gt;和整数对象一样，&lt;code&gt;PyStringObject&lt;/code&gt; 需要优化才堪实用，于是 Python 的设计者便开发了 intern 机制。&lt;/p&gt;&#xA;&lt;p&gt;所谓 intern，即如果两个字符串对象的原始字符串相同，那么其 &lt;code&gt;ob_sval&lt;/code&gt; 共享同一份内存。若程序中出现了 100 次 &lt;code&gt;hello, world&lt;/code&gt;，那么在内存中只会保存一份。&lt;/p&gt;&#xA;&lt;p&gt;intern 机制的核心在于字典 &lt;code&gt;interned&lt;/code&gt;。该字典为 Python 的内建数据结构，可以简单等价于 C++ 的 &lt;code&gt;map&amp;lt;T,R&amp;gt;&lt;/code&gt;。该字典的健值都为字符串本身 &lt;code&gt;pystring:pystring&lt;/code&gt;，所有需 intern 的字符串会缓存到该 &lt;code&gt;interned&lt;/code&gt; 字典中，当在程序中再遇到相同的字符串 &lt;code&gt;pystring&lt;/code&gt;，便可通过字典在 &lt;code&gt;O(1)&lt;/code&gt; 时间内检索出。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// stringobject.c&#xA;PyObject *&#xA;PyString_FromString(const char *str)&#xA;{&#xA;    ...&#xA;    ...&#xA;    /* share short strings */&#xA;    if (size == 0) {&#xA;        PyObject *t = (PyObject *)op;&#xA;        PyString_InternInPlace(&amp;amp;t);&#xA;        op = (PyStringObject *)t;&#xA;        nullstring = op;&#xA;        Py_INCREF(op);&#xA;    } else if (size == 1) {&#xA;        PyObject *t = (PyObject *)op;&#xA;        PyString_InternInPlace(&amp;amp;t);&#xA;        op = (PyStringObject *)t;&#xA;        characters[*str &amp;amp; UCHAR_MAX] = op;&#xA;        Py_INCREF(op);&#xA;    }&#xA;    return (PyObject *) op;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 &lt;code&gt;PyString_FromString&lt;/code&gt; 函数最后，会强制将长度为 0 和 1 的字符串 intern，而这一操作的核心为 &lt;code&gt;PyString_InterInPlace&lt;/code&gt; 函数。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// stringobject.c&#xA;void&#xA;PyString_InternInPlace(PyObject **p)&#xA;{&#xA;    ...&#xA;    ...&#xA;    if (interned == NULL) {&#xA;        interned = PyDict_New();&#xA;        if (interned == NULL) {&#xA;            PyErr_Clear(); /* Don&#39;t leave an exception */&#xA;            return;&#xA;        }&#xA;    }&#xA;    t = PyDict_GetItem(interned, (PyObject *)s);&#xA;    if (t) {&#xA;        Py_INCREF(t);&#xA;        Py_SETREF(*p, t);&#xA;        return;&#xA;    }&#xA;&#xA;    if (PyDict_SetItem(interned, (PyObject *)s, (PyObject *)s) &amp;lt; 0) {&#xA;        PyErr_Clear();&#xA;        return;&#xA;    }&#xA;&#xA;    Py_REFCNT(s) -= 2;&#xA;    PyString_CHECK_INTERNED(s) = SSTATE_INTERNED_MORTAL;&#xA;}&#xA;&#xA;// object.h&#xA;#define Py_SETREF(op, op2)                      \&#xA;    do {                                        \&#xA;        PyObject *_py_tmp = (PyObject *)(op);   \&#xA;        (op) = (op2);                           \&#xA;        Py_DECREF(_py_tmp);                     \&#xA;    } while (0)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;函数的开始会尝试新建 &lt;code&gt;interned&lt;/code&gt; 字典。然后是尝试在 &lt;code&gt;interned&lt;/code&gt; 字典中找该字符串 &lt;code&gt;PyDict_GetItem&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;若找到，就需要增加该健值对上的引用计数，并减去 &lt;code&gt;PyStringObject&lt;/code&gt; 对象的引用计数。&lt;code&gt;PyStringObject&lt;/code&gt; 对象减为 0 后会被回收内存。为啥原对象要被回收？因为后续程序只会通过 &lt;code&gt;interned&lt;/code&gt; 字典引用字符串，原对象留着没啥用处了。&lt;/li&gt;&#xA;&lt;li&gt;若没找到，会尝试在字典中新建健值对 &lt;code&gt;PyDict_SetItem&lt;/code&gt;。新建的健值对需要减去 2 个引用计数。我们的 &lt;code&gt;interned&lt;/code&gt; 字典健值都是原字符串，该 &lt;code&gt;PyStringObject&lt;/code&gt; 无论如何都至少会有两个引用。健值仅仅是作为 Python 虚拟机内部使用，不应影响所运行程序的内存回收，故需减 2。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;单字符字符串的进一步优化&lt;/h2&gt;&#xA;&lt;p&gt;在 &lt;code&gt;PyString_FromString&lt;/code&gt; 函数中，还看到了 &lt;code&gt;characters&lt;/code&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;    else if (size == 1) {&#xA;        PyObject *t = (PyObject *)op;&#xA;        PyString_InternInPlace(&amp;amp;t);&#xA;        op = (PyStringObject *)t;&#xA;        characters[*str &amp;amp; UCHAR_MAX] = op;&#xA;        Py_INCREF(op);&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;单字节的字符串被缓存到了 &lt;code&gt;characters&lt;/code&gt; 数组中。在创建字符串函数时，直接从数组中取出单字节字符串：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;PyObject *&#xA;PyString_FromString(const char *str)&#xA;{&#xA;    register size_t size;&#xA;&#xA;    ...&#xA;    ...&#xA;    if (size == 1 &amp;amp;&amp;amp; (op = characters[*str &amp;amp; UCHAR_MAX]) != NULL) {&#xA;#ifdef COUNT_ALLOCS&#xA;        one_strings++;&#xA;#endif&#xA;        Py_INCREF(op);&#xA;        return (PyObject *)op;&#xA;    }&#xA;    ...&#xA;    ...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;数组比哈希字典效率更高。&lt;/p&gt;&#xA;&lt;h2&gt;字符串拼接所做的优化&lt;/h2&gt;&#xA;&lt;p&gt;字符串虽然是变长对象，但并不是可变对象，创建之后，&lt;code&gt;ob_sval&lt;/code&gt; 数组的长度无法再改变。在拼接两个字符串 s1, s2 时，必须重新生成一个 &lt;code&gt;PyStringObject&lt;/code&gt; 对象来放置 &lt;code&gt;s1-&amp;gt;ob_sval + s2-&amp;gt;sval&lt;/code&gt;。如果要连接 N 个 &lt;code&gt;PyStringObject&lt;/code&gt; 对象，那么就必须进行 N-1 次的内存申请及内存搬运的工作。毫无疑问，这将严重影响 Python 的执行效率。&lt;/p&gt;&#xA;&lt;p&gt;所以官方推荐的做法是使用 &lt;code&gt;join&lt;/code&gt; 函数，该函数一次性分配好所有内存，然后统一搬运。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;s = &amp;quot;-&amp;quot;&#xA;seq = (&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;)&#xA;print s.join( seq )&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;实验&lt;/h2&gt;&#xA;&lt;p&gt;何种字符串会 intern？不同的 Python 版本似乎采取了不同的策略，以我 Mac 上 Python 2.7.10 为例：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; &#39;foo&#39; is &#39;foo&#39;&#xA;True&#xA;&amp;gt;&amp;gt;&amp;gt; &#39;foo!&#39; is &#39;foo!&#39;&#xA;True&#xA;&amp;gt;&amp;gt;&amp;gt; &#39;a&#39;*20 is &#39;a&#39;*20&#xA;True&#xA;&amp;gt;&amp;gt;&amp;gt; &#39;a&#39;*21 is &#39;a&#39;*21&#xA;False&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2017/12/28/python-internal3-string-object/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Python 2.7 源码 - 整数对象</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2017/12/24/python-internal2-integer-object/</id>
    <content type="html">&lt;h2&gt;Python 的面向对象&lt;/h2&gt;&#xA;&lt;p&gt;面向对象编程中，对象是数据以及基于这些数据的操作的集合，实际上在计算机中这只是一堆内存逻辑上的集合，无论这段内存是连续的还是分开的。&lt;/p&gt;&#xA;&lt;p&gt;Python 是由 C 语言写成，描述一段逻辑上结合的内存，直接用结构体 &lt;code&gt;struct&lt;/code&gt; 就可以了。但是 &lt;code&gt;struct&lt;/code&gt; 并不是面向对象中类型的概念，对象还需要成员函数。所以还需要另外一个结构体 &lt;code&gt;struct&lt;/code&gt; 来描述成员函数的集合。&lt;/p&gt;&#xA;&lt;p&gt;上述特点就导致了在 Python 中，实际的类型也是一个对象，这个类型对象的结构体如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct _typeobject {&#xA;    PyObject_VAR_HEAD&#xA;    const char *tp_name; /* For printing, in format &amp;quot;&amp;lt;module&amp;gt;.&amp;lt;name&amp;gt;&amp;quot; */&#xA;    Py_ssize_t tp_basicsize, tp_itemsize; /* For allocation */&#xA;&#xA;    /* Methods to implement standard operations */&#xA;&#xA;    destructor tp_dealloc;&#xA;    printfunc tp_print;&#xA;    getattrfunc tp_getattr;&#xA;    setattrfunc tp_setattr;&#xA;    cmpfunc tp_compare;&#xA;    reprfunc tp_repr;&#xA;&#xA;    /* Method suites for standard classes */&#xA;&#xA;    PyNumberMethods *tp_as_number;&#xA;    PySequenceMethods *tp_as_sequence;&#xA;    PyMappingMethods *tp_as_mapping;&#xA;&#xA;    /* More standard operations (here for binary compatibility) */&#xA;&#xA;    hashfunc tp_hash;&#xA;    ternaryfunc tp_call;&#xA;    reprfunc tp_str;&#xA;    getattrofunc tp_getattro;&#xA;    setattrofunc tp_setattro;&#xA;&#xA;    /* Functions to access object as input/output buffer */&#xA;    PyBufferProcs *tp_as_buffer;&#xA;&#xA;    /* Flags to define presence of optional/expanded features */&#xA;    long tp_flags;&#xA;&#xA;    const char *tp_doc; /* Documentation string */&#xA;&#xA;    /* Assigned meaning in release 2.0 */&#xA;    /* call function for all accessible objects */&#xA;    traverseproc tp_traverse;&#xA;&#xA;    /* delete references to contained objects */&#xA;    inquiry tp_clear;&#xA;&#xA;    /* Assigned meaning in release 2.1 */&#xA;    /* rich comparisons */&#xA;    richcmpfunc tp_richcompare;&#xA;&#xA;    /* weak reference enabler */&#xA;    Py_ssize_t tp_weaklistoffset;&#xA;&#xA;    /* Added in release 2.2 */&#xA;    /* Iterators */&#xA;    getiterfunc tp_iter;&#xA;    iternextfunc tp_iternext;&#xA;&#xA;    /* Attribute descriptor and subclassing stuff */&#xA;    struct PyMethodDef *tp_methods;&#xA;    struct PyMemberDef *tp_members;&#xA;    struct PyGetSetDef *tp_getset;&#xA;    struct _typeobject *tp_base;&#xA;    PyObject *tp_dict;&#xA;    descrgetfunc tp_descr_get;&#xA;    descrsetfunc tp_descr_set;&#xA;    Py_ssize_t tp_dictoffset;&#xA;    initproc tp_init;&#xA;    allocfunc tp_alloc;&#xA;    newfunc tp_new;&#xA;    freefunc tp_free; /* Low-level free-memory routine */&#xA;    inquiry tp_is_gc; /* For PyObject_IS_GC */&#xA;    PyObject *tp_bases;&#xA;    PyObject *tp_mro; /* method resolution order */&#xA;    PyObject *tp_cache;&#xA;    PyObject *tp_subclasses;&#xA;    PyObject *tp_weaklist;&#xA;    destructor tp_del;&#xA;&#xA;    /* Type attribute cache version tag. Added in version 2.6 */&#xA;    unsigned int tp_version_tag;&#xA;&#xA;#ifdef COUNT_ALLOCS&#xA;    /* these must be last and never explicitly initialized */&#xA;    Py_ssize_t tp_allocs;&#xA;    Py_ssize_t tp_frees;&#xA;    Py_ssize_t tp_maxalloc;&#xA;    struct _typeobject *tp_prev;&#xA;    struct _typeobject *tp_next;&#xA;#endif&#xA;} PyTypeObject;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;所以在源码中，Python 最基础的对象表示如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct _object &#xA;{&#xA;    Py_ssize_t ob_refcnt;&#xA;    struct _typeobject *ob_type;&#xA;} PyObject;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;每一个对象都有一个指针指向自己所属的类型对象，而类型对象则有关于这个对象支持的所有操作的信息。&lt;/p&gt;&#xA;&lt;p&gt;仔细看 &lt;code&gt;PyTypeObject&lt;/code&gt; 的头部，&lt;code&gt;PyObject_VAR_HEAD&lt;/code&gt; 即含有 &lt;code&gt;ob_type&lt;/code&gt;，难道还有类型的类型这个概念？是的，这个终极的类型就是元类，即 &lt;code&gt;metaclass&lt;/code&gt;。做个简单的实验。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; class A(object):&#xA;...     pass&#xA;...&#xA;&amp;gt;&amp;gt;&amp;gt;&#xA;&amp;gt;&amp;gt;&amp;gt;&#xA;&amp;gt;&amp;gt;&amp;gt; A.__class__&#xA;&amp;lt;type &#39;type&#39;&amp;gt;&#xA;&amp;gt;&amp;gt;&amp;gt; A.__class__.__class__&#xA;&amp;lt;type &#39;type&#39;&amp;gt;&#xA;&amp;gt;&amp;gt;&amp;gt; type.__class__&#xA;&amp;lt;type &#39;type&#39;&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 Python 中类型是对象，所以类型对象也有类型，而元类的类型就是自己。&lt;/p&gt;&#xA;&lt;h2&gt;Python 的整数类型&lt;/h2&gt;&#xA;&lt;p&gt;整数类型没啥可说的，按照 &lt;code&gt;PyTypeObject&lt;/code&gt; 结构去填充信息即可：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;PyTypeObject PyInt_Type = {&#xA;    PyVarObject_HEAD_INIT(&amp;amp;PyType_Type, 0)&#xA;    &amp;quot;int&amp;quot;,&#xA;    sizeof(PyIntObject),&#xA;    0,&#xA;    (destructor)int_dealloc,                    /* tp_dealloc */&#xA;    (printfunc)int_print,                       /* tp_print */&#xA;    0,                                          /* tp_getattr */&#xA;    0,                                          /* tp_setattr */&#xA;    (cmpfunc)int_compare,                       /* tp_compare */&#xA;    (reprfunc)int_to_decimal_string,            /* tp_repr */&#xA;    &amp;amp;int_as_number,                             /* tp_as_number */&#xA;    0,                                          /* tp_as_sequence */&#xA;    0,                                          /* tp_as_mapping */&#xA;    (hashfunc)int_hash,                         /* tp_hash */&#xA;    0,                                          /* tp_call */&#xA;    (reprfunc)int_to_decimal_string,            /* tp_str */&#xA;    PyObject_GenericGetAttr,                    /* tp_getattro */&#xA;    0,                                          /* tp_setattro */&#xA;    0,                                          /* tp_as_buffer */&#xA;    Py_TPFLAGS_DEFAULT | Py_TPFLAGS_CHECKTYPES |&#xA;        Py_TPFLAGS_BASETYPE | Py_TPFLAGS_INT_SUBCLASS,          /* tp_flags */&#xA;    int_doc,                                    /* tp_doc */&#xA;    0,                                          /* tp_traverse */&#xA;    0,                                          /* tp_clear */&#xA;    0,                                          /* tp_richcompare */&#xA;    0,                                          /* tp_weaklistoffset */&#xA;    0,                                          /* tp_iter */&#xA;    0,                                          /* tp_iternext */&#xA;    int_methods,                                /* tp_methods */&#xA;    0,                                          /* tp_members */&#xA;    int_getset,                                 /* tp_getset */&#xA;    0,                                          /* tp_base */&#xA;    0,                                          /* tp_dict */&#xA;    0,                                          /* tp_descr_get */&#xA;    0,                                          /* tp_descr_set */&#xA;    0,                                          /* tp_dictoffset */&#xA;    0,                                          /* tp_init */&#xA;    0,                                          /* tp_alloc */&#xA;    int_new,                                    /* tp_new */&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;整数对象的内存&lt;/h2&gt;&#xA;&lt;p&gt;再看一眼 PyObject 对象，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct _object &#xA;{&#xA;    Py_ssize_t ob_refcnt;&#xA;    struct _typeobject *ob_type;&#xA;} PyObject;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们看到了 &lt;code&gt;ob_refcnt&lt;/code&gt; 引用计数对象，可以很容易地联想到 Python 虚拟机是以引用计数为基础构建垃圾回收机制。既然如此，那还有没有必要专门讨论整数对象的内存使用,而直接抽象成引用计数归零后释放内存？&lt;/p&gt;&#xA;&lt;p&gt;事实上，为了提高虚拟机的性能，整数对象使用了多种技术。&lt;/p&gt;&#xA;&lt;h3&gt;大整数创建&lt;/h3&gt;&#xA;&lt;p&gt;在 intobject.c 中定义有&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define N_INTOBJECTS    ((BLOCK_SIZE - BHEAD_SIZE) / sizeof(PyIntObject))&#xA;&#xA;struct _intblock {&#xA;    struct _intblock *next;&#xA;    PyIntObject objects[N_INTOBJECTS];&#xA;};&#xA;&#xA;typedef struct _intblock PyIntBlock;&#xA;&#xA;static PyIntBlock *block_list = NULL;&#xA;static PyIntObject *free_list = NULL;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;block_list&lt;/code&gt; 是由一个个 &lt;code&gt;PyIntBlock&lt;/code&gt; 串起来的链表，每一个 &lt;code&gt;PyIntBlock&lt;/code&gt; 是一个整数数组。&lt;code&gt;free_list&lt;/code&gt; 是由空闲的 &lt;code&gt;PyIntObject&lt;/code&gt; 组成的链表，空闲是指这块内存虽然被划分为一个 &lt;code&gt;PyIntObject&lt;/code&gt;，但并没有被用于表示一个真正的整数，即其所存储的信息是无用的。&lt;/p&gt;&#xA;&lt;p&gt;整数创建时，&lt;code&gt;PyObject * PyInt_FromLong(long ival)&lt;/code&gt; 会被调用，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;PyObject *&#xA;PyInt_FromLong(long ival)&#xA;{&#xA;    register PyIntObject *v;&#xA;    ...&#xA;    ...&#xA;    if (free_list == NULL) {&#xA;        if ((free_list = fill_free_list()) == NULL)&#xA;            return NULL;&#xA;    }&#xA;    /* Inline PyObject_New */&#xA;    v = free_list;&#xA;    free_list = (PyIntObject *)Py_TYPE(v);&#xA;    (void)PyObject_INIT(v, &amp;amp;PyInt_Type);&#xA;    v-&amp;gt;ob_ival = ival;&#xA;    return (PyObject *) v;&#xA;}&#xA;&#xA;static PyIntObject *&#xA;fill_free_list(void)&#xA;{&#xA;    PyIntObject *p, *q;&#xA;    /* Python&#39;s object allocator isn&#39;t appropriate for large blocks. */&#xA;    p = (PyIntObject *) PyMem_MALLOC(sizeof(PyIntBlock));&#xA;    if (p == NULL)&#xA;        return (PyIntObject *) PyErr_NoMemory();&#xA;    ((PyIntBlock *)p)-&amp;gt;next = block_list;&#xA;    block_list = (PyIntBlock *)p;&#xA;    /* Link the int objects together, from rear to front, then return&#xA;       the address of the last int object in the block. */&#xA;    p = &amp;amp;((PyIntBlock *)p)-&amp;gt;objects[0];&#xA;    q = p + N_INTOBJECTS;&#xA;    while (--q &amp;gt; p)&#xA;        Py_TYPE(q) = (struct _typeobject *)(q-1);&#xA;    Py_TYPE(q) = NULL;&#xA;    return p + N_INTOBJECTS - 1;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当创建整数的时候，会先尝试从 &lt;code&gt;free_list&lt;/code&gt; 中取，如果没有空闲的，就会尝试 &lt;code&gt;fill_free_list&lt;/code&gt;。这个新的 &lt;code&gt;PyIntBlock&lt;/code&gt; 中，每一个 &lt;code&gt;PyIntObject&lt;/code&gt; 都借用 &lt;code&gt;ob_type&lt;/code&gt; 来连接成链表。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define Py_TYPE(ob) (((PyObject*)(ob))-&amp;gt;ob_type)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这里只是借用，初看源码的朋友不要被这里搞混了。因为此时这块内存并没有存放整数，它的成员自然可以借来他用。&lt;code&gt;free_list&lt;/code&gt; 指向数组的末尾，从后往前链接到数组首部。&lt;/p&gt;&#xA;&lt;h3&gt;大整数销毁&lt;/h3&gt;&#xA;&lt;p&gt;当一个整数销毁时，便会进入 &lt;code&gt;int_dealloc&lt;/code&gt; 函数内。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;static void&#xA;int_dealloc(PyIntObject *v)&#xA;{&#xA;    if (PyInt_CheckExact(v)) {&#xA;        Py_TYPE(v) = (struct _typeobject *)free_list;&#xA;        free_list = v;&#xA;    }&#xA;    else&#xA;        Py_TYPE(v)-&amp;gt;tp_free((PyObject *)v);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这个函数在正常情况下不会走到 &lt;code&gt;else&lt;/code&gt; 分支，意味着所谓的销毁，只是把这个整数的 &lt;code&gt;PyIntObject&lt;/code&gt; 重新放回 &lt;code&gt;free_list&lt;/code&gt; 链表中，并不会释放这块内存。这岂不会造成内存泄漏？只能说，理论上会。整数对象所占用的内存空间，只和这个程序同时拥有的最多的整数数量有关。&lt;/p&gt;&#xA;&lt;p&gt;上述做法也是为了优化性能，虚拟机不再需要频繁的 &lt;code&gt;malloc&lt;/code&gt; 和 &lt;code&gt;free&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h3&gt;小整数&lt;/h3&gt;&#xA;&lt;p&gt;除了普通的整数外，Python 中还存在着一种小整数对象。在之前的 &lt;code&gt;PyInt_FromLong&lt;/code&gt; 函数中，我们略了一部分，现在我们从另一个角度看。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;PyObject *&#xA;PyInt_FromLong(long ival)&#xA;{&#xA;    register PyIntObject *v;&#xA;&#xA;    if (-NSMALLNEGINTS &amp;lt;= ival &amp;amp;&amp;amp; ival &amp;lt; NSMALLPOSINTS) {&#xA;        v = small_ints[ival + NSMALLNEGINTS];&#xA;        Py_INCREF(v);&#xA;    ...&#xA;    ...&#xA;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当想创建的整数在 &lt;code&gt;-NSMALLNEGINTS ~ NSMALLPOSINTS&lt;/code&gt; 之间时，就会从 &lt;code&gt;small_ints&lt;/code&gt; 数组中直接取出。这范围内的整数即为小整数。小整数使用广泛，循环的初始值，终结值，步进值等等，都是数值很小的整数。小整数从 Python 虚拟机运行之初就存在，使用它们既不需要 &lt;code&gt;malloc&lt;/code&gt; 和 &lt;code&gt;free&lt;/code&gt;，甚至连指针操作 &lt;code&gt;free_list&lt;/code&gt; 也不要。效率比大整数更高。&lt;/p&gt;&#xA;&lt;p&gt;而小整数的范围可在编译 Python 时指定，默认为 &lt;code&gt;-5 ~ 257&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h2&gt;实验&lt;/h2&gt;&#xA;&lt;p&gt;改造一下整数打印函数，反映出内存的变化。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;static int values[10];&#xA;static int refcounts[10];&#xA;/* ARGSUSED */&#xA;static int&#xA;int_print(PyIntObject *v, FILE *fp, int flags)&#xA;     /* flags -- not used but required by interface */&#xA;{&#xA;    PyIntObject * intObjectPtr;&#xA;    PyIntBlock * p = block_list;&#xA;    PyIntBlock * last = NULL;&#xA;    int count = 0;&#xA;    int i = 0;&#xA;&#xA;    long int_val = v-&amp;gt;ob_ival;&#xA;    Py_BEGIN_ALLOW_THREADS&#xA;    fprintf(fp, &amp;quot;%ld&amp;quot;, int_val);&#xA;    Py_END_ALLOW_THREADS&#xA;&#xA;    while (p!=NULL)&#xA;    {&#xA;        ++count;&#xA;        last = p;&#xA;        p = p-&amp;gt;next;&#xA;    }&#xA;    intObjectPtr = last-&amp;gt;objects;&#xA;    intObjectPtr += N_INTOBJECTS-1;&#xA;    printf(&amp;quot;\nvalue&#39;s address is @%p\n&amp;quot;, v);&#xA;&#xA;    for (i = 0; i &amp;lt; 10; i++, --intObjectPtr)&#xA;    {&#xA;        values[i] = intObjectPtr-&amp;gt;ob_ival;&#xA;        refcounts[i] = intObjectPtr-&amp;gt;ob_refcnt;&#xA;    }&#xA;    printf(&amp;quot;  value : &amp;quot;);&#xA;    for (i = 0; i &amp;lt; 8; ++i)&#xA;    {&#xA;        printf(&amp;quot;%d\t&amp;quot;, values[i]);&#xA;    }&#xA;    printf(&amp;quot;\n&amp;quot;);&#xA;    printf(&amp;quot;  refcnt : &amp;quot;);&#xA;    for (i = 0; i &amp;lt; 8; ++i)&#xA;    {&#xA;        printf(&amp;quot;%d\t&amp;quot;, refcounts[i]);&#xA;    }&#xA;    printf(&amp;quot;\n&amp;quot;);&#xA;&#xA;    printf(&amp;quot; block_list count : %d\n&amp;quot;, count);&#xA;    printf(&amp;quot; free_list address : %p\n&amp;quot;, free_list);&#xA;    return 0;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;运行重新编译后的 python 虚拟机。&lt;/p&gt;&#xA;&lt;h3&gt;大整数实验&lt;/h3&gt;&#xA;&lt;p&gt;首先是连续创建两个大整数。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; a=1111&#xA;&amp;gt;&amp;gt;&amp;gt; a&#xA;1111&#xA;value&#39;s address is @0x100303888&#xA;  value : -5    -4      -3      -2      -1      0       1       2&#xA;  refcnt : 1    1       1       1       54      389     587     84&#xA; block_list count : 9&#xA; free_list address : 0x1003038a0&#xA;&#xA;&amp;gt;&amp;gt;&amp;gt; b=2222&#xA;&amp;gt;&amp;gt;&amp;gt; b&#xA;2222&#xA;value&#39;s address is @0x1003038a0&#xA;  value : -5    -4      -3      -2      -1      0       1       2&#xA;  refcnt : 1    1       1       1       54      389     587     84&#xA; block_list count : 9&#xA; free_list address : 0x1003038b8&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;第一次的 &lt;code&gt;free_list&lt;/code&gt;，正好是第二次整数的地址。可以看到小整数都至少有一个引用，有些多于一次是因为 python 虚拟机内部使用的缘故。&lt;/p&gt;&#xA;&lt;p&gt;当尝试创建一个相同的大整数时。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; c=2222&#xA;&amp;gt;&amp;gt;&amp;gt; c&#xA;2222&#xA;value&#39;s address is @0x1003038b8&#xA;  value : -5    -4      -3      -2      -1      0       1       2&#xA;  refcnt : 1    1       1       1       54      389     587     84&#xA; block_list count : 9&#xA; free_list address : 0x1003038d0&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看出，虽然值相同，但并不是同一个内存块。&lt;/p&gt;&#xA;&lt;h3&gt;小整数实验&lt;/h3&gt;&#xA;&lt;p&gt;创建两个相同的小整数。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; d=1&#xA;&amp;gt;&amp;gt;&amp;gt; d&#xA;1&#xA;value&#39;s address is @0x100604ce8&#xA;  value : -5    -4      -3      -2      -1      0       1       2&#xA;  refcnt : 1    1       1       1       54      389     591     84&#xA; block_list count : 9&#xA; free_list address : 0x1003038d0&#xA;&#xA;&amp;gt;&amp;gt;&amp;gt; c=1&#xA;&amp;gt;&amp;gt;&amp;gt; c&#xA;1&#xA;value&#39;s address is @0x100604ce8&#xA;  value : -5    -4      -3      -2      -1      0       1       2&#xA;  refcnt : 1    1       1       1       54      389     592     84&#xA; block_list count : 9&#xA; free_list address : 0x100303828&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看出，整数 1 只是增加了引用计数，内存块是同一个。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2017/12/24/python-internal2-integer-object/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Python 2.7 源码 - 开始</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2017/12/19/python-internal1-begin/</id>
    <content type="html">&lt;h2&gt;源码编译&lt;/h2&gt;&#xA;&lt;p&gt;Python 官网可以下载到&lt;a href=&#34;https://www.python.org/downloads/source/&#34;&gt;源码&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;Linux 上编译需要先安装额外模块，例如 Ubuntu&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;sudo apt-get build-dep python&#xA;sudo apt-get install libreadline-dev libsqlite3-dev libbz2-dev libssl-dev libreadline6-dev libsqlite3-dev liblzma-dev libbz2-dev tk8.5-dev blt-dev libgdbm-dev libssl-dev libncurses5-dev zlib1g-dev libncurses5-dev&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Windows 上只需打开 PC/VS9.0/pcbuild.sln，选择最少的模块 python, pythoncore 编译，如果这两个模块编译时报错，只需按照错误提示，钩上所需模块即可。&lt;/p&gt;&#xA;&lt;p&gt;Mac 上只需要&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;./configure&#xA;make&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;本系列文章在 Mac 上完成，但环境本身只影响编译，并不影响分析过程，读者选择方便阅读源码的环境即可。&lt;/p&gt;&#xA;&lt;h2&gt;第一个实验&lt;/h2&gt;&#xA;&lt;p&gt;Mac 上编译完会生成一个 &lt;code&gt;python.exe&lt;/code&gt; 的可执行文件。&lt;/p&gt;&#xA;&lt;p&gt;让我们尝试在 Python 源码中修改整数输出的部分，在每一个 int 打印时，输出 &lt;code&gt;hello, world&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;修改 /Objects/intobject.c，添加 &lt;code&gt;fprintf(fp, &amp;quot;hello, world\n&amp;quot;);&lt;/code&gt;&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;static int&#xA;int_print(PyIntObject *v, FILE *fp, int flags)&#xA;     /* flags -- not used but required by interface */&#xA;{&#xA;    long int_val = v-&amp;gt;ob_ival;&#xA;    Py_BEGIN_ALLOW_THREADS&#xA;    // &#xA;    fprintf(fp, &amp;quot;hello, world\n&amp;quot;);&#xA;    fprintf(fp, &amp;quot;%ld&amp;quot;, int_val);&#xA;    Py_END_ALLOW_THREADS&#xA;    return 0;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;以下是实验结果：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; a=1&#xA;&amp;gt;&amp;gt;&amp;gt; a&#xA;hello, world&#xA;1&#xA;&amp;gt;&amp;gt;&amp;gt; print(1)&#xA;hello, world&#xA;1&#xA;&amp;gt;&amp;gt;&amp;gt; print(&#39;eee&#39;)&#xA;eee&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;改动只影响了整数打印的部分。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2017/12/19/python-internal1-begin/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Python 中的 descriptor</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2017/09/14/python-descriptor/</id>
    <content type="html">&lt;h2&gt;定义&lt;/h2&gt;&#xA;&lt;p&gt;通常，一个 descriptor 是具有“绑定行为”的对象属性。所绑定行为可通过 descriptor 协议被自定义的 &lt;code&gt;__get__()&lt;/code&gt;, &lt;code&gt;__set__()&lt;/code&gt; 和 &lt;code&gt;__delete__()&lt;/code&gt; 方法重写。如果一个对象的上述三个方法任意一个被重写，则就可被称为 descriptor。&lt;/p&gt;&#xA;&lt;p&gt;属性的默认操作是从对象字典中获取、设置和删除一个属性。例如，a.x 有一个查找链，先 &lt;code&gt;a.__dict__[&#39;x&#39;]&lt;/code&gt;，若没有则 &lt;code&gt;type(a).__dict__[&#39;x&#39;]&lt;/code&gt;，若没有增往上查找父类直到元类。如果查找链中，对象被定义了 descriptor 方法，Python 就会覆盖默认行为。&lt;/p&gt;&#xA;&lt;p&gt;Descriptor 是一个强大的工具，虽然开发者不常接触到它，但它其实就是类、属性、函数、方法、静态方法、类方法以及 &lt;code&gt;super()&lt;/code&gt; 背后的运行机制。&lt;/p&gt;&#xA;&lt;h2&gt;Descriptor 协议&lt;/h2&gt;&#xA;&lt;p&gt;三个方法原型如下所示：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;descr.__get__(self, obj, type=None) --&amp;gt; value&#xA;&#xA;descr.__set__(self, obj, value) --&amp;gt; None&#xA;&#xA;descr.__delete__(self, obj) --&amp;gt; None&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;数据 descriptor 是同时具有 &lt;code&gt;__get__()&lt;/code&gt; 和 &lt;code&gt;__set__()&lt;/code&gt; 方法的对象，若只有 &lt;code&gt;__get__()&lt;/code&gt; 方法，则为非数据 descriptor。如果实例字典中有和数据 descriptor 同名的入口，则数据 descriptor 优先级更高。相反，非数据 descriptor 优先级低。&lt;/p&gt;&#xA;&lt;p&gt;让 &lt;code&gt;__set__()&lt;/code&gt; 方法抛出异常，就能创建一个只读数据 descriptor。&lt;/p&gt;&#xA;&lt;h2&gt;调用 descriptor&lt;/h2&gt;&#xA;&lt;p&gt;descriptor 可以直接通过方法名调用。例如，&lt;code&gt;d.__get__(obj)&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;而通过访问对象属性，自动调用 descriptor 才是更通用的做法。例如，如果 &lt;code&gt;d&lt;/code&gt; 定义了方法 &lt;code&gt;__get__()&lt;/code&gt;，则 &lt;code&gt;obj.d&lt;/code&gt; 会调用 &lt;code&gt;d.__get__(obj)&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;对于对象，&lt;code&gt;b.x&lt;/code&gt; 会被转换成 &lt;code&gt;type(b).__dict__[&#39;x&#39;].__get__(b, type(b))&lt;/code&gt;。而对于类（是的，类也可以调用），&lt;code&gt;B.x&lt;/code&gt; 会被转换成 &lt;code&gt;B.__dict__[&#39;x&#39;].__get__(None, B)&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h2&gt;Descriptor 例子&lt;/h2&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class RevealAccess(object):&#xA;    &amp;quot;&amp;quot;&amp;quot;A data descriptor that sets and returns values&#xA;       normally and prints a message logging their access.&#xA;    &amp;quot;&amp;quot;&amp;quot;&#xA;&#xA;    def __init__(self, initval=None, name=&#39;var&#39;):&#xA;        self.val = initval&#xA;        self.name = name&#xA;&#xA;    def __get__(self, obj, objtype):&#xA;        print(&#39;Retrieving&#39;, self.name)&#xA;        return self.val&#xA;&#xA;    def __set__(self, obj, val):&#xA;        print(&#39;Updating&#39;, self.name)&#xA;        self.val = val&#xA;&#xA;&amp;gt;&amp;gt;&amp;gt; class MyClass(object):&#xA;...     x = RevealAccess(10, &#39;var &amp;quot;x&amp;quot;&#39;)&#xA;...     y = 5&#xA;...&#xA;&amp;gt;&amp;gt;&amp;gt; m = MyClass()&#xA;&amp;gt;&amp;gt;&amp;gt; m.x&#xA;Retrieving var &amp;quot;x&amp;quot;&#xA;10&#xA;&amp;gt;&amp;gt;&amp;gt; m.x = 20&#xA;Updating var &amp;quot;x&amp;quot;&#xA;&amp;gt;&amp;gt;&amp;gt; m.x&#xA;Retrieving var &amp;quot;x&amp;quot;&#xA;20&#xA;&amp;gt;&amp;gt;&amp;gt; m.y&#xA;5&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2017/09/14/python-descriptor/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Writing Your Own Windows Debugger - Debug Event</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2017/05/01/write-a-windows-debugger-02-debug-event/</id>
    <content type="html">&lt;p&gt;We have introduced the debug loop last time, in this post, I will talk about various debug events.&lt;/p&gt;&#xA;&lt;h3&gt;RIP_EVENT&lt;/h3&gt;&#xA;&lt;p&gt;I find very few documents about this event, only mentioned with words like &lt;em&gt;system error&lt;/em&gt; or &lt;em&gt;internal error&lt;/em&gt;. So I decide to print a error message and skip it. As my project is not fully tested, I have never&#xA;encountered such a situation.&lt;/p&gt;&#xA;&lt;h3&gt;OUTPUT_DEBUG_STRING_EVENT&lt;/h3&gt;&#xA;&lt;p&gt;When the debuggee calls the &lt;em&gt;OutpuDebugString&lt;/em&gt; function, it will raise this debug event. The following structure describes the detail of this event:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;typedef struct _OUTPUT_DEBUG_STRING_INFO {&#xA;  LPSTR lpDebugStringData;&#xA;  WORD  fUnicode;&#xA;  WORD  nDebugStringLength;&#xA;} OUTPUT_DEBUG_STRING_INFO, *LPOUTPUT_DEBUG_STRING_INFO;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;lpDebugStringData, The debugging string in the calling process&#39;s address space.&lt;/li&gt;&#xA;&lt;li&gt;fUnicode, The format of the debugging string. If this member is zero, the debugging string is ANSI; if it is nonzero, the string is Unicode.&lt;/li&gt;&#xA;&lt;li&gt;nDebugStringLength, The size of the debugging string, in characters. The length includes the string&#39;s terminating null character.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;With ReadProcessMemory function, the debugger can obtain the value of the string:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;void OnOutputDebugString(const OUTPUT_DEBUG_STRING_INFO* pInfo) &#xA;{&#xA;    BYTE* pBuffer = (BYTE*)malloc(pInfo-&amp;gt;nDebugStringLength);&#xA;&#xA;    SIZE_T bytesRead;&#xA;&#xA;    ReadProcessMemory(&#xA;        g_hProcess,&#xA;        pInfo-&amp;gt;lpDebugStringData,&#xA;        pBuffer, &#xA;        pInfo-&amp;gt;nDebugStringLength,&#xA;        &amp;amp;bytesRead);&#xA;&#xA;    int requireLen = MultiByteToWideChar(&#xA;        CP_ACP,&#xA;        MB_PRECOMPOSED,&#xA;        (LPCSTR)pBuffer,&#xA;        pInfo-&amp;gt;nDebugStringLength,&#xA;        NULL,&#xA;        0);&#xA;&#xA;    TCHAR* pWideStr = (TCHAR*)malloc(requireLen * sizeof(TCHAR));&#xA;&#xA;    MultiByteToWideChar(&#xA;        CP_ACP,&#xA;        MB_PRECOMPOSED,&#xA;        (LPCSTR)pBuffer,&#xA;        pInfo-&amp;gt;nDebugStringLength,&#xA;        pWideStr,&#xA;        requireLen);&#xA;&#xA;    std::wcout &amp;lt;&amp;lt; TEXT(&amp;quot;Debuggee debug string: &amp;quot;) &amp;lt;&amp;lt; pWideStr &amp;lt;&amp;lt;  std::endl;&#xA;&#xA;    free(pWideStr);&#xA;    free(pBuffer);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;LOAD_DLL_DEBUG_EVENT&lt;/h3&gt;&#xA;&lt;p&gt;After the debuggee loads a dll, this debug event will be triggered. The following structure describes the detail of this event:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;typedef struct _LOAD_DLL_DEBUG_INFO {&#xA;  HANDLE hFile;&#xA;  LPVOID lpBaseOfDll;&#xA;  DWORD  dwDebugInfoFileOffset;&#xA;  DWORD  nDebugInfoSize;&#xA;  LPVOID lpImageName;&#xA;  WORD   fUnicode;&#xA;} LOAD_DLL_DEBUG_INFO, *LPLOAD_DLL_DEBUG_INFO;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;You may want to use the member &lt;em&gt;lpImageName&lt;/em&gt; to retrieve the dll file name, however, it doesn&#39;t work. According the explaination on MSDN, this member is pointer to the file name of the associated &lt;em&gt;hFile&lt;/em&gt;, it  may, in turn, either be NULL or point to the actual filename. Even it is not NULL, ReadProcessMemory may also return a NULL. As a result, this membor is not reliable.&lt;/p&gt;&#xA;&lt;p&gt;It seems that there is no direct Windows API to get the filename from the file handle. Someone has tried &lt;a href=&#34;http://blog.csdn.net/bodybo/archive/2006/08/28/1131346.aspx&#34;&gt;this way&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h3&gt;UNLOAD_DLL_DEBUG_EVENT&lt;/h3&gt;&#xA;&lt;p&gt;When a dll module is unloaded, this event will be triggered, nothing needs handled, just skip it.&lt;/p&gt;&#xA;&lt;h3&gt;CREATE_PROCESS_DEBUG_EVENT&lt;/h3&gt;&#xA;&lt;p&gt;After the process is created, this is the first debug event. The following structure describes the detail of this event:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;typedef struct _CREATE_PROCESS_DEBUG_INFO {&#xA;  HANDLE                 hFile;&#xA;  HANDLE                 hProcess;&#xA;  HANDLE                 hThread;&#xA;  LPVOID                 lpBaseOfImage;&#xA;  DWORD                  dwDebugInfoFileOffset;&#xA;  DWORD                  nDebugInfoSize;&#xA;  LPVOID                 lpThreadLocalBase;&#xA;  LPTHREAD_START_ROUTINE lpStartAddress;&#xA;  LPVOID                 lpImageName;&#xA;  WORD                   fUnicode;&#xA;} CREATE_PROCESS_DEBUG_INFO, *LPCREATE_PROCESS_DEBUG_INFO;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;We can use this structure to get the symbols of the debuggee program.&lt;/p&gt;&#xA;&lt;h3&gt;EXIT_PROCESS_DEBUG_EVENT&lt;/h3&gt;&#xA;&lt;p&gt;When debuggee process exits, this event will be triggered. The following structure describe the detail of the event:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;typedef struct _EXIT_PROCESS_DEBUG_INFO {&#xA;  DWORD dwExitCode;&#xA;} EXIT_PROCESS_DEBUG_INFO, *LPEXIT_PROCESS_DEBUG_INFO;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;What we can do is to print the exit code.&lt;/p&gt;&#xA;&lt;h3&gt;CREATE_THREAD_DEBUG_EVENT&lt;/h3&gt;&#xA;&lt;p&gt;It is similar to the process create debug event.&lt;/p&gt;&#xA;&lt;h3&gt;EXIT_THREAD_DEBUG_EVENT&lt;/h3&gt;&#xA;&lt;p&gt;It is similar to the process exit debug event.&lt;/p&gt;&#xA;&lt;h3&gt;EXCEPTION_DEBUG_EVENT&lt;/h3&gt;&#xA;&lt;p&gt;It is the most important event of our debugger, I will cover it in the next post.&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2017/05/01/write-a-windows-debugger-02-debug-event/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Writing Your Own Windows Debugger - Overview</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2017/04/27/write-a-windows-debugger-01-overview/</id>
    <content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Debuggers are the apple of the hacker&#39;s eye. We benefit a lot from the debugger, but few of us know the principle of it.&lt;/p&gt;&#xA;&lt;p&gt;In the book &lt;em&gt;Gray Hat Python&lt;/em&gt; , the author has constructed a simple debugger. However, it is too simple, it is only a machine language level debugger, and can only set basic breakpoints and show CPU register information. We also want to know how to&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Show source code&lt;/li&gt;&#xA;&lt;li&gt;Set breakpoint based on lines, not memory address&lt;/li&gt;&#xA;&lt;li&gt;Set Step In, Step Out, Step Over&lt;/li&gt;&#xA;&lt;li&gt;Show stack trace&lt;/li&gt;&#xA;&lt;li&gt;Show global and local variables&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;In this Chinese blog &lt;a href=&#34;http://www.cnblogs.com/zplutor/archive/2011/03/04/1971279.html&#34;&gt;Zplutor&#39;s&lt;/a&gt;, I find a excellent series which has covered most above topics. I decide to write a English blog about it, and I will turn his code into a C++ version.&lt;/p&gt;&#xA;&lt;p&gt;Before getting started, let&#39;s make some limitations:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It is only a user mode debugger.&lt;/li&gt;&#xA;&lt;li&gt;It is only a Windows debugger. Although the principle is quite same, but Windows has offered lots of convenient APIs. The implementation will be different on Linux.&lt;/li&gt;&#xA;&lt;li&gt;It is only a terminal-based debugger.&lt;/li&gt;&#xA;&lt;li&gt;Different from &lt;em&gt;Gray Hat Python&lt;/em&gt; , the debugger will be implemented by C++.&lt;/li&gt;&#xA;&lt;li&gt;The debuggee program is single thread.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;The modified debugger can be found &lt;a href=&#34;https://github.com/lyyyuna/anotherDebugger&#34;&gt;here&lt;/a&gt;. It is only tested under Windows 10 + Visual Studio 2013.&lt;/p&gt;&#xA;&lt;h2&gt;To Start the Debuggee Program&lt;/h2&gt;&#xA;&lt;p&gt;The so-called user mode debugger is to debug the program in user mode. Windows has provided a series of open API for debugging, and they can be devided into three categories:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;API for starting the debuggee program&lt;/li&gt;&#xA;&lt;li&gt;API for handling debug event during debug loop&lt;/li&gt;&#xA;&lt;li&gt;API for inspecing and modifying debuggee program&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;The first thing to do before debugging a program is to start it. On Windows, we use &lt;em&gt;CreateProcess&lt;/em&gt; to start to program:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;STARTUPINFO startupinfo = { 0 };&#xA;startupinfo.cb = sizeof(startupinfo);&#xA;PROCESS_INFORMATION processinfo = { 0 };&#xA;unsigned int creationflags = DEBUG_ONLY_THIS_PROCESS | CREATE_NEW_CONSOLE;&#xA;&#xA;if (CreateProcess(&#xA;    &amp;quot;L:\\git_up\\anotherDebugger\\anotherDebugger\\Debug\\test.exe&amp;quot;,&#xA;    //path,&#xA;    NULL,&#xA;    NULL,&#xA;    NULL,&#xA;    FALSE,&#xA;    creationflags,&#xA;    NULL,&#xA;    NULL,&#xA;    &amp;amp;startupinfo,&#xA;    &amp;amp;processinfo) == FALSE)&#xA;{&#xA;    std::cout &amp;lt;&amp;lt; &amp;quot;CreateProcess failed: &amp;quot; &amp;lt;&amp;lt; GetLastError() &amp;lt;&amp;lt; std::endl;&#xA;    return;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;DEBUG_ONLY_THIS_PROCESS means the subprocess of the debuggee will not be debugged. If you need subprocess, use DEBUG_PROCESS.&lt;/li&gt;&#xA;&lt;li&gt;CREATE_NEW_CONSOLE means the debuggee&#39;s and debugger&#39;s output will be separated in two consoles.&lt;/li&gt;&#xA;&lt;li&gt;If the debugger process exits, the debuggee will also exit.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;Debugger loop&lt;/h2&gt;&#xA;&lt;p&gt;The debugger loop is a bit like Windows GUI message loop, some operations and exceptions will stop the debuggee and send event to the debugger. We always use&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;DEBUG_EVENT debugEvent;&#xA;WaitForDebugEvent(&amp;amp;debugEvent, INFINITE)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;to capture the debug event.&lt;/p&gt;&#xA;&lt;p&gt;There are 9 debug event in total:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;CREATE_PROCESS_DEBUG_EVENT. Reports a create-process debugging event.&lt;/li&gt;&#xA;&lt;li&gt;CREATE_THREAD_DEBUG_EVENT. Reports a create-thread debugging event.&lt;/li&gt;&#xA;&lt;li&gt;EXCEPTION_DEBUG_EVENT. Reports an exception debugging event.&lt;/li&gt;&#xA;&lt;li&gt;EXIT_PROCESS_DEBUG_EVENT. Reports an exit-process debugging event.&lt;/li&gt;&#xA;&lt;li&gt;EXIT_THREAD_DEBUG_EVENT. Reports an exit-thread debugging event.&lt;/li&gt;&#xA;&lt;li&gt;LOAD_DLL_DEBUG_EVENT. Reports a load-dynamic-link-library (DLL) debugging event.&lt;/li&gt;&#xA;&lt;li&gt;OUTPUT_DEBUG_STRING_EVENT. Reports an output-debugging-string debugging event.&lt;/li&gt;&#xA;&lt;li&gt;RIP_EVENT. Reports a RIP-debugging event (system debugging error).&lt;/li&gt;&#xA;&lt;li&gt;UNLOAD_DLL_DEBUG_EVENT. Reports an unload-DLL debugging event.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;If the debug event has been handled correctly, then&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;ContinueDebugEvent(debuggeeprocessID, debuggeethreadID, DBG_CONTINUE);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;to continue the debuggee process. Let&#39;s combine the above to construct the debug loop:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;while (WaitForDebugEvent(&amp;amp;debugEvent, INFINITE) == TRUE)&#xA;{&#xA;    debuggeeprocessID = debugEvent.dwProcessId;&#xA;    debuggeethreadID = debugEvent.dwThreadId;&#xA;    if (dispatchDebugEvent(debugEvent) == TRUE)&#xA;    {&#xA;        ContinueDebugEvent(debuggeeprocessID, debuggeethreadID, FLAG.continueStatus);&#xA;    }&#xA;    else {&#xA;        break;&#xA;    }&#xA;}&#xA;&#xA;bool dispatchDebugEvent(const DEBUG_EVENT &amp;amp; debugEvent)&#xA;{&#xA;    switch (debugEvent.dwDebugEventCode)&#xA;    {&#xA;    case CREATE_PROCESS_DEBUG_EVENT:&#xA;        // TBD&#xA;        break;&#xA;&#xA;    case CREATE_THREAD_DEBUG_EVENT:&#xA;        // TBD&#xA;        break;&#xA;&#xA;    case EXCEPTION_DEBUG_EVENT:&#xA;        // TBD&#xA;        break;&#xA;&#xA;    case EXIT_PROCESS_DEBUG_EVENT:&#xA;        // TBD&#xA;        break;&#xA;&#xA;    case EXIT_THREAD_DEBUG_EVENT:&#xA;        // TBD&#xA;        break;&#xA;&#xA;    case LOAD_DLL_DEBUG_EVENT:&#xA;        // TBD&#xA;        break;&#xA;&#xA;    case UNLOAD_DLL_DEBUG_EVENT:&#xA;        // TBD&#xA;        break;&#xA;&#xA;    case OUTPUT_DEBUG_STRING_EVENT:&#xA;        // TBD&#xA;        break;&#xA;&#xA;    case RIP_EVENT:&#xA;        // TBD&#xA;        break;&#xA;&#xA;    default:&#xA;        cout &amp;lt;&amp;lt; &amp;quot;Unknown debug event.&amp;quot; &amp;lt;&amp;lt; endl;&#xA;        return false;&#xA;        break;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;In the next part of the series, I intend to give a brief introduction about the 9 debug events.&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2017/04/27/write-a-windows-debugger-01-overview/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>分布式 B 站用户信息爬虫</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2017/04/24/bilibili-users-spider/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;上周末写了一个 B 站用户信息爬虫，怎么爬网页实在是没什么好讲的，所以这篇描述一下简单的分布式爬虫。&lt;/p&gt;&#xA;&lt;p&gt;知乎和 B 站用户爬虫极其类似。它们都有两种爬取策略：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;从一个用户开始，爬取关注者和被关注者，将新找到的用户存储下来，然后再从其关注网络中遍历爬取新的用户。这种爬取策略类似广度优先搜素，根据著名的&lt;a href=&#34;http://baike.baidu.com/link?url=w0Tr_YMnE4BHSLk8MN9QBaAlbAUS18BJrlq85ZuhNDYHcN4pQKXg9KIxJ6fMIcW-rr7pQbT3Ya02hlHfiFZVijScjomLbTfhvwwavVAN3XD4GQCjRACiVhza_tndVf0KUjhj1iYrBgvZ6mTe8UCGw_&#34;&gt;六度人脉理论&lt;/a&gt;，我们可以将大部分用户都找出来。不过该方法会增加程序的复杂度，你得维护好已搜索用户和未搜索用户的列表，快速去重等。&lt;/li&gt;&#xA;&lt;li&gt;大部分网站在建立用户时会使用自增字段，或者有一个字段其值会在特定的数字范围内。对于 B 站，每个人的主页就是很好的例子，&lt;a href=&#34;http://space.bilibili.com/8222478/#!/&#34;&gt;http://space.bilibili.com/8222478/#!/&lt;/a&gt;。而对于知乎，这个值藏的比较隐秘。后来我发现，当一个用户关注你之后，便会邮件一个关注者链接给你，例如 &lt;a href=&#34;http://www.zhihu.com/l/G4gQn&#34;&gt;http://www.zhihu.com/l/G4gQn&lt;/a&gt;，最后是一个 16 进制的五位数，大部分用户都是 G，E 等开头的数字。这种链接在知乎正式页面没有发现过，猜测是历史原因保留了这种形式。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;自增数字的方式程序更容易实现。&lt;/p&gt;&#xA;&lt;h2&gt;换代理的痛点&lt;/h2&gt;&#xA;&lt;p&gt;剩下的问题就是反爬虫，简单的换 header 头部就不说了，因为 B 站和知乎都是根据 IP 来反爬，那么我能想到的就只有：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;换代理&lt;/li&gt;&#xA;&lt;li&gt;分布式爬虫&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;从实现方式看，代理也能看作是一个分布式爬虫。根据 HTTP 返回的状态码，可以判断：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;代理是否正常工作（比如连接 timeout），&lt;/li&gt;&#xA;&lt;li&gt;对方服务器是否判定我们访问过于频繁（比如返回 403）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;基于上述判断，可以实现一些复杂的代理切换策略：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;定时去免费代理网站下载新的代理节点，&lt;/li&gt;&#xA;&lt;li&gt;负载均衡，将请求平均分配到每一个节点，保证不会访问过于频繁，&lt;/li&gt;&#xA;&lt;li&gt;代理探活，将不活跃的代理清除。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;不幸的是，免费好用的代理非常难找，使用 scrapy 配上&lt;a href=&#34;https://github.com/lyyyuna/bilibili_papapa/commit/632a8827c187aa051186089d715616db8ae7fd86&#34;&gt;我写的几百行的代理中间件&lt;/a&gt;，也很难维持一个正常的下载速率。&#xA;用 Python 来爬虫几乎是网上教程的标配了 -_-，导致即使找到一个可用代理，其 IP 也早被列入服务器的黑名单。&lt;/p&gt;&#xA;&lt;h2&gt;分布式爬虫&lt;/h2&gt;&#xA;&lt;h3&gt;基于 HTTP 服务器实现分布式&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/lyyyuna/blog_img/raw/master/blog/201704/http_structure.png&#34; alt=&#34;基于 HTTP 服务器的分布式爬虫&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;主从之间通信借助现有的 HTTP 协议。&lt;/li&gt;&#xA;&lt;li&gt;主控 HTTP 服务器生成用户 id，每当有一个新的 GET 请求，自增 id，并返回给客户端。&lt;/li&gt;&#xA;&lt;li&gt;每一个爬虫在这个结构中是一个客户端，当获取到新的 id 后，便去爬取解析网页，将结果以 POST 请求的方式返回给 HTTP 服务器。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;优点是：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;HTTP 协议简单，用 Flask 框架 5 分钟即能快速搭建。&lt;/li&gt;&#xA;&lt;li&gt;客户端数量扩展极其方便，且不需要公网 IP。&lt;/li&gt;&#xA;&lt;li&gt;爬虫下载速率可由每个客户端各自控制。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;缺点是：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;由于 HTTP 是无状态协议，服务器端不能跟踪一个发布的 id 是否已被正确处理。有可能一个客户端只 GET 而不 POST。需要维护另外的队列来存放未完成的任务。&lt;/li&gt;&#xA;&lt;li&gt;HTTP 服务器发布任务是被动的。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这个链接&lt;a href=&#34;https://github.com/lyyyuna/zhihu_user_papapa&#34;&gt;https://github.com/lyyyuna/zhihu_user_papapa&lt;/a&gt;里是用这种思路实现的 B 站用户爬虫。&lt;/p&gt;&#xA;&lt;h3&gt;基于消息队列实现分布式&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/lyyyuna/blog_img/raw/master/blog/201704/messagequeue_structure.png&#34; alt=&#34;基于消息队列实现分布式爬虫&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;采用消息队列后，Producer 主控侧不再是被动地发布任务，而是主动推送任务。上一小节有的优点消息队列同样拥有，同时&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Producer 也能控制任务发布的速率。&lt;/li&gt;&#xA;&lt;li&gt;利用消息队列的持久化能力，可以在意外退出的情况下，记录未能成功发布的任务和未能成功接收的结果。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这种结构的分布式爬虫，同样需要显示地维护一来一回蓝色红色的数据流，还是稍显复杂。&lt;/p&gt;&#xA;&lt;h3&gt;基于 Celery 任务队列实现分布式&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/lyyyuna/blog_img/raw/master/blog/201704/celery_structure.png&#34; alt=&#34;基于 Celery 实现分布式爬虫&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;初看上去，这个结构和上一节没有区别，但是，上图的红色数据流是不需要显示维护的！&lt;/p&gt;&#xA;&lt;p&gt;举一个简单例子。假设在机器 A，有如下的 worker&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from celery import Celery&#xA;&#xA;app = Celery(&#39;tasks&#39;, broker=&#39;pyamqp://guest@localhost//&#39;)&#xA;&#xA;@app.task&#xA;def add(x, y):&#xA;    return x + y&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;那么在另一台机器 B，只要运行&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from tasks import add&#xA;result = add.delay(4, 4)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;就能得到结果。同时&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;这个被 @app.task 修饰过的方法是异步的。机器 A 可以通过 result.ready() 来来获知任务是否被执行完。通过 result.get() 得到执行的结果。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;基于这个思想，我完成了这个分布式爬虫&lt;a href=&#34;https://github.com/lyyyuna/bilibili_papapa&#34;&gt;https://github.com/lyyyuna/bilibili_papapa&lt;/a&gt;。只需要 Celery 的 broker 具有公网 IP，然后把程序扔给朋友让他们帮我跑就行。唯一的不便是 Celery worker 在个人电脑上部署不便，而基于 HTTP 的分布式爬虫，我只要 C# 写个 HTTP 客户端生成 exe 就可以了。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2017/04/24/bilibili-users-spider/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>使用 Supervisor 管理进程</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2017/04/08/supervisor01/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;如果需要让某一个进程长期运行，该怎么做？&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;开一个终端，SSH 连上之后不关机。&lt;/li&gt;&#xA;&lt;li&gt;Shell 命令加一个 &amp;amp;，把进程扔到后台。&lt;/li&gt;&#xA;&lt;li&gt;写一个 daemon 进程。&lt;/li&gt;&#xA;&lt;li&gt;..&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;当终端关闭，终端下所有的进程也会被相应的杀死，即使是被扔到后台执行的 job。然而，要把自己的应用程序专门写成 daemon，会增加开发的负担。这时候，一种万能的、对原应用侵入最小的方法，Supervisor，便走进了我们的视线。&lt;/p&gt;&#xA;&lt;p&gt;Supervisor 可不光具有后台长期执行程序的功能。先举两个实际的例子。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;我所在组的产品是一个邮件网关，内含七八个扫描引擎，每种引擎都会起数个进程。为了监控和管理这些进程，我们写了很多 Shell 脚本，并用一个看门狗进程来监控进程对应的 pid 文件，一旦进程意外死亡，会被看门狗拉起来。&lt;/li&gt;&#xA;&lt;li&gt;上周末为了写一个 Django + celery + redis 的例子，开了四五个终端，由于是在 virtualenv 下开发的，每次开终端都是一堆重复的 activate 过程。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这些都可以通过 Supervisor，以类似 rc.d 脚本的方式，一劳永逸的解决。&lt;/p&gt;&#xA;&lt;h2&gt;安装&lt;/h2&gt;&#xA;&lt;p&gt;Supervisor 是由 Python 写的，安装十分简单。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pip install supervisor&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;目前只支持 Python2 (&amp;gt;2.4)。&lt;/p&gt;&#xA;&lt;p&gt;不过我建议使用包管理器来安装，例如 ubuntu，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;apt install supervisor&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这样安装完以后会有一个默认的配置文件生成在&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;/etc/supervisor/supervisord.conf&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;配置一个后台进程&lt;/h2&gt;&#xA;&lt;p&gt;Supervisor 会按以下顺序搜索配置文件，&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;$CWD/supervisord.conf&lt;/li&gt;&#xA;&lt;li&gt;$CWD/etc/supervisord.conf&lt;/li&gt;&#xA;&lt;li&gt;/etc/supervisord.conf&lt;/li&gt;&#xA;&lt;li&gt;/etc/supervisor/supervisord.conf (since Supervisor 3.3.0)&lt;/li&gt;&#xA;&lt;li&gt;../etc/supervisord.conf (Relative to the executable)&lt;/li&gt;&#xA;&lt;li&gt;../supervisord.conf (Relative to the executable)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;配置文件是 Windows 的 INI 格式，我们撇开其他节，直奔主题 [program:x]&lt;/p&gt;&#xA;&lt;p&gt;假设有一个循环打印 hello 的程序，使用 virtualenv 中的 Python 环境运行，现在需要其在后台常驻运行。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# /root/test/hello.py&#xA;import time&#xA;while True:&#xA;    print &#39;Hello, world.&#39;&#xA;    time.sleep(2)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们添加一个 [program:x] 小节为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;[program:hellotest]&#xA;command = /root/test/venv/bin/python -u hello.py&#xA;directory = /root/test&#xA;user = root&#xA;stdout_logfile = /root/test/hello.log&#xA;redirect_stderr = true&#xA;autostart = false&#xA;autorestart = true&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;注意要添加 -u 启动参数，不然 stdout 上的输出会被一直缓存。首先启动 Supervisor 进程本身，安装的时候其本身已经被添加为 Linux 系统的一个 service&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# service supervisor start&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;然后使用 supervisorctl 工具来启动我们的 hellotest&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# supervisorctl start hellotest&#xA;hellotest: started&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;查询 hellotest 的运行状态&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# supervisorctl status hellotest&#xA;hellotest                        RUNNING   pid 898, uptime 0:02:01&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;查看 stdout 上的输出&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# tailf test/hello.log &#xA;Hello, world.&#xA;Hello, world.&#xA;Hello, world.&#xA;Hello, world.&#xA;Hello, world.&#xA;Hello, world.&#xA;Hello, world.&#xA;Hello, world.&#xA;Hello, world.&#xA;Hello, world.&#xA;Hello, world.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果我们的参数配置错误，还可以查看 Supervisor 自身的 log&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;/var/log/supervisor/supervisor.log&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;配置一组后台进程&lt;/h2&gt;&#xA;&lt;p&gt;配置一组后台进程与之类似，首先我们需要多个 [program:x] 小节&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;[program:hellotest]&#xA;command = /root/test/venv/bin/python -u hello.py&#xA;directory = /root/test&#xA;user = root&#xA;stdout_logfile = /root/test/hello.log&#xA;redirect_stderr = true&#xA;autorestart = true&#xA;autostart = false&#xA;&#xA;[program:hellotest2]&#xA;command = /root/test/venv/bin/python -u hello2.py&#xA;directory = /root/test&#xA;user = root&#xA;stdout_logfile = /root/test/hello.log&#xA;redirect_stderr = true&#xA;autorestart = true&#xA;autostart = false&#xA;&#xA;[group:hellogroup]&#xA;programs = hellotest, hellotest2&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;启动一组中所有进程时，命令有些不同&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;supervisorctl start hellogroup:*&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;一旦一个 program 被加入组中，你就不能再用原先的命令启动&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# supervisorctl start hellotest&#xA;hellotest: ERROR (no such process)&#xA;# supervisorctl start hellogroup:hellotest&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;验证&lt;/h2&gt;&#xA;&lt;p&gt;我们可以看一下进程的 pid 号来验证我们的 hello 进程确实是 Supervisor 的子进程&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# ps -ef | grep 1182&#xA;root      1182     1  0 16:07 ?        00:00:00 /usr/bin/python /usr/bin/supervisord -n -c /etc/supervisor/supervisord.conf&#xA;root      1226  1182  0 16:12 ?        00:00:00 /root/test/venv/bin/python -u hello2.py&#xA;root      1227  1182  0 16:12 ?        00:00:00 /root/test/venv/bin/python -u hello.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;再用 kill 命令验证 Supervisor 具有看门狗功能&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# kill -9 1226&#xA;# ps -ef | grep 1182&#xA;root      1182     1  0 16:07 ?        00:00:00 /usr/bin/python /usr/bin/supervisord -n -c /etc/supervisor/supervisord.conf&#xA;root      1227  1182  0 16:12 ?        00:00:00 /root/test/venv/bin/python -u hello.py&#xA;root      1255  1182  0 16:18 ?        00:00:00 /root/test/venv/bin/python -u hello2.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;hello2.py 已经是新的 pid 号。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2017/04/08/supervisor01/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>c++ 函数重载是如何实现的</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/12/22/insidecppmodel2/</id>
    <content type="html">&lt;p&gt;函数重载是 c++ 的编译时多态的一部分，也就是说，该行为在编译完成后即是确定的。事实上，这是编译器和链接器之间玩的小花招。链接器通过符号（symbol）定位各个函数，所谓符号可以简单理解为一个字符串。&lt;/p&gt;&#xA;&lt;p&gt;编译器会给每个函数名一个符号，在 c 语言中，符号名只和函数名有关。&lt;/p&gt;&#xA;&lt;p&gt;来一个 c 语言程序的例子，使用 Visual Studio 编译&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void add(int a, int b)&#xA;{}&#xA;&#xA;int main()&#xA;{&#xA;&#x9;add(1, 2);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;用 Visual Studio 自带的工具 dumpbin 查看 .obj 文件的符号表&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;017 00000000 SECT4  notype ()    External     | _add&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们换一个函数声明&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void add(double a, double b)&#xA;{}&#xA;&#xA;int main()&#xA;{&#xA;&#x9;add(1, 2);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;再用 dumpbin 查看 .obj 文件的符号表&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;017 00000000 SECT4  notype ()    External     | _add&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;还是同样的符号。所以， c 语言编译器不支持函数重载，函数名相同的话，链接器永远只能看到一个名字。&lt;/p&gt;&#xA;&lt;p&gt;那么，c++ 呢？&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;&#xA;#include &amp;lt;string&amp;gt;&#xA;&#xA;using namespace std;&#xA;&#xA;void add(int a, int b)&#xA;{}&#xA;void add(double a, double b)&#xA;{}&#xA;void add(string a, string b)&#xA;{}&#xA;&#xA;int main()&#xA;{&#xA;&#x9;add(1, 2);&#xA;&#x9;add(1.0, 2.0);&#xA;&#x9;add(string(&amp;quot;1&amp;quot;), string(&amp;quot;2&amp;quot;));&#xA;&#xA;&#x9;return 0;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;再用 dumpbin 查看 .obj 文件的符号表&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;2F3 00000000 SECT87 notype ()    External     | ?add@@YAXHH@Z (void __cdecl add(int,int))&#xA;2F4 00000000 SECT89 notype ()    External     | ?add@@YAXNN@Z (void __cdecl add(double,double))&#xA;2F5 00000000 SECT8B notype ()    External     | ?add@@YAXV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@0@Z (void __cdecl add(class std::basic_string&amp;lt;char,struct std::char_traits&amp;lt;char&amp;gt;,class std::allocator&amp;lt;char&amp;gt; &amp;gt;,class std::basic_string&amp;lt;char,struct std::char_traits&amp;lt;char&amp;gt;,class std::allocator&amp;lt;char&amp;gt; &amp;gt;))&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到，每个符号都不一样啦。这时候的函数声明不仅和函数名有关，也和参数类型有关，但和返回类型无关。符号能唯一确定，编译器自然也能顺利实现重载。&lt;/p&gt;&#xA;&lt;p&gt;顺便可以发现，同一个函数声明在 c 和 c++ 中是完全不一样的。这也是为什么 c 和 c++ 之间动静态库不能直接互相调用的原因。为此 cpp 使用了 extern &amp;quot;C&amp;quot; 语法，强制使用 c++ 编译器使用 c 语言的符号命名方法。&lt;/p&gt;&#xA;&lt;p&gt;我们实验一下&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;&#xA;#include &amp;lt;string&amp;gt;&#xA;&#xA;using namespace std;&#xA;&#xA;extern &amp;quot;C&amp;quot;{&#xA;&#x9;void add(int a, int b)&#xA;&#x9;{}&#xA;}&#xA;void add(double a, double b)&#xA;{}&#xA;void add(string a, string b)&#xA;{}&#xA;&#xA;int main()&#xA;{&#xA;&#x9;add(1, 2);&#xA;&#x9;add(1.0, 2.0);&#xA;&#x9;add(string(&amp;quot;1&amp;quot;), string(&amp;quot;2&amp;quot;));&#xA;&#xA;&#x9;return 0;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;查看 .obj 文件的符号表&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;2F3 00000000 SECTD3 notype ()    External     | _add&#xA;2F4 00000000 SECT87 notype ()    External     | ?add@@YAXNN@Z (void __cdecl add(double,double))&#xA;2F5 00000000 SECT89 notype ()    External     | ?add@@YAXV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@0@Z (void __cdecl add(class std::basic_string&amp;lt;char,struct std::char_traits&amp;lt;char&amp;gt;,class std::allocator&amp;lt;char&amp;gt; &amp;gt;,class std::basic_string&amp;lt;char,struct std::char_traits&amp;lt;char&amp;gt;,class std::allocator&amp;lt;char&amp;gt; &amp;gt;))&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到，第一个函数的符号和 c 语言一致了。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/12/22/insidecppmodel2/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>c++ 虚函数是如何实现的</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/12/21/insidecppmodel1/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;探索 c++ 对象内部的实现是一件非常有趣的事情。c++ 分为编译时多态和运行时多态。运行时多态依赖于虚函数，大部分人或许听说过虚函数是由虚函数表+虚函数指针实现的，但，真的是这样吗？虽然 c++ 规范有着复杂的语言细节，但底层实现机制却任由编译器厂商想象。（没准某种特殊的处理器电路结构原生支持虚函数，没准这个处理器压根不是冯纽曼型，或者将来厂商发明了比虚函数表更有效率的数据结构。）&lt;/p&gt;&#xA;&lt;p&gt;本篇文章就来实际检验一下 Visual Studio 2013 编译器在无优化条件下，虚函数的实现。&lt;/p&gt;&#xA;&lt;h2&gt;虚函数表&lt;/h2&gt;&#xA;&lt;p&gt;封装把实例的数据和操作结合在了一起，但实例本身只有数据，没有函数，同一个类的函数是共享的。我们通过一个例子来间接证明这一点&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;class Base1&#xA;{&#xA;public:&#xA;&#x9;int a;&#xA;&#x9;void func() { cout &amp;lt;&amp;lt; &amp;quot;heel&amp;quot; &amp;lt;&amp;lt; endl; }&#xA;};&#xA;&#xA;Base1 b1;&#xA;cout &amp;lt;&amp;lt; sizeof(b1) &amp;lt;&amp;lt; endl;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;打印&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;4&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果类中有虚函数，则会在对象中加入一个虚函数指针，该指针指向一个虚函数表，表中是各个虚函数的地址。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;+--+       ++&#xA;| pvtbl  |&amp;gt;| vfunc1  |&#xA;+--+       ++&#xA;| data1  |       | vfunc2  |&#xA;+--+       ++&#xA;| ...    |       | ...     |&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当子类继承父类时，会依次覆盖虚函数表中的各个项，如果子类没有重写某项，那该项就保留。当实例化对象后，虚函数指针就作为一个隐藏数据存在于实例中。如果通过父类指针调用普通成员函数，由于普通函数和类型绑定在一起，所以仍会调用父类成员函数；如果通过父类指针调用虚函数，则会通过对象的虚指针找到虚函数表（即子类的虚函数表），定位虚函数项，实现多态。&lt;/p&gt;&#xA;&lt;p&gt;原理是不是很简单？c++ 就是通过这种看似原始的方式实现高级抽象。以上是编译器的通用做法，我手上的 Visual Studio 2013 编译器就是这么做的，为了提高性能，VS 保证虚函数指针存在于对象实例中最前面位置（历史上也有编译器不这么做，好像是 Borland 的？）。&lt;/p&gt;&#xA;&lt;h2&gt;Visual Studio 2013 中的实现&lt;/h2&gt;&#xA;&lt;p&gt;来一个例子（能这么写是因为我已知了 Visual Studio 2013 编译后对象的内存布局）&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;iostream&amp;gt;&#xA;using namespace std;&#xA;&#xA;class Base &#xA;{&#xA;public:&#xA;&#x9;typedef void (*func)();&#xA;&#x9;virtual void func1() { cout &amp;lt;&amp;lt; &amp;quot;Base::func1&amp;quot; &amp;lt;&amp;lt; endl; }&#xA;&#x9;virtual void func2() { cout &amp;lt;&amp;lt; &amp;quot;Base::func2&amp;quot; &amp;lt;&amp;lt; endl; }&#xA;&#x9;virtual void func3() { cout &amp;lt;&amp;lt; &amp;quot;Base::func3&amp;quot; &amp;lt;&amp;lt; endl; }&#xA;};&#xA;&#xA;class Derived: public Base&#xA;{&#xA;public:&#xA;&#x9;virtual void func1() { cout &amp;lt;&amp;lt; &amp;quot;Derived::func1&amp;quot; &amp;lt;&amp;lt; endl; }&#xA;&#x9;virtual void func3() { cout &amp;lt;&amp;lt; &amp;quot;Derived::func3&amp;quot; &amp;lt;&amp;lt; endl; }&#xA;};&#xA;&#xA;int main()&#xA;{&#xA;&#x9;Base b, b1;&#xA;&#x9;int** pvirtualtable1 = (int**)&amp;amp;b;&#xA;&#x9;cout &amp;lt;&amp;lt; &amp;quot;Base object vtbl address: &amp;quot; &amp;lt;&amp;lt; pvirtualtable1[0] &amp;lt;&amp;lt; endl;&#xA;&#x9;int** pvirtualtable11 = (int**)&amp;amp;b1;&#xA;&#x9;cout &amp;lt;&amp;lt; &amp;quot;another Base object vtbl address: &amp;quot; &amp;lt;&amp;lt; pvirtualtable11[0] &amp;lt;&amp;lt; endl;&#xA;&#x9;cout &amp;lt;&amp;lt; &amp;quot;function in virtual table&amp;quot; &amp;lt;&amp;lt; endl;&#xA;&#x9;for (int i = 0; (Base::func)pvirtualtable1[0][i] != NULL; ++i)&#xA;&#x9;{&#xA;&#x9;&#x9;auto p = (Base::func)pvirtualtable1[0][i];&#xA;&#x9;&#x9;p();&#xA;&#x9;}&#xA;&#x9;cout &amp;lt;&amp;lt; endl;&#xA;&#xA;&#x9;Derived d;&#xA;&#x9;int** pvirtualtable2 = (int**)&amp;amp;d;&#xA;&#x9;cout &amp;lt;&amp;lt; &amp;quot;Derived object vtbl address: &amp;quot; &amp;lt;&amp;lt; pvirtualtable2[0] &amp;lt;&amp;lt; endl;&#xA;&#x9;cout &amp;lt;&amp;lt; &amp;quot;function in virtual table&amp;quot; &amp;lt;&amp;lt; endl;&#xA;&#x9;for (int i = 0; (Base::func)pvirtualtable2[0][i] != NULL; ++i)&#xA;&#x9;{&#xA;&#x9;&#x9;auto p = (Base::func)pvirtualtable2[0][i];&#xA;&#x9;&#x9;p();&#xA;&#x9;}&#xA;&#x9;cout &amp;lt;&amp;lt; endl;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;打印&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Base object pvtbl address: 0029DA58&#xA;another Base object pvtbl address: 0029DA58&#xA;function address in virtual table&#xA;Base::func1&#xA;Base::func2&#xA;Base::func3&#xA;&#xA;Derived object pvtbl address: 0029DB20&#xA;function address in virtual table&#xA;Derived::func1&#xA;Base::func2&#xA;Derived::func3&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到，同一类型不同实例的虚函数表是相同的，继承之后，子类有了自己的虚函数表，表也有相应的更新(Derived::func1, Derived::func3)，表中未重写的项还保留为原值(Base::func2)。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/12/21/insidecppmodel1/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Python 访问外围作用域中的变量</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/09/10/python-nonlocal-variable/</id>
    <content type="html">&lt;p&gt;在表达式中引用变量时，Python 会按照如下的顺序遍历各个作用域，寻找该变量：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;当前函数作用域&lt;/li&gt;&#xA;&lt;li&gt;任何外围作用域（比如包含当前函数的其他函数）&lt;/li&gt;&#xA;&lt;li&gt;global 作用域，即代码所在的模块的作用域&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;如果上述作用域内都找不到变量，就会报 NameError 异常。&lt;/p&gt;&#xA;&lt;p&gt;但是对变量赋值时，规则会有所不同。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果当前作用域变量已存在，那么其值会被替换。&lt;/li&gt;&#xA;&lt;li&gt;如果不存在，则会视为在当前作用域定义新变量，而不是向外围作用域中寻找。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;如下函数&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def function():&#xA;    flag = True&#xA;    def helper():&#xA;        flag = False&#xA;    helper()&#xA;    print flag&#xA;&#xA;function()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;由于 helper 中变量是赋值，这里 flag 输出仍为 True。习惯了 c 语言之类静态类型语言，这种设计起初会感到困惑，但其可以有效地防止局部变量污染函数外的环境。&lt;/p&gt;&#xA;&lt;p&gt;需求总是多样的，一定有程序员想在赋值时访问外围作用域。如果是 Python2，他可以这么做&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def function():&#xA;    flag = [True]&#xA;    def helper():&#xA;        flag[0] = False&#xA;    helper()&#xA;    print flag&#xA;&#xA;function()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;先用 flag[0] 是读操作，产生一次变量引用，寻找到外围作用域中 flag，这时候再赋值 flag[0] = False 便不会新定义变量了。&lt;/p&gt;&#xA;&lt;p&gt;如果是 Python3，则可以使用 nonlocal 关键字。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def function():&#xA;    flag = True&#xA;    def helper():&#xA;        nonlocal flag&#xA;        flag = False&#xA;    helper()&#xA;    print flag&#xA;&#xA;function()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/09/10/python-nonlocal-variable/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Robot Framework 模板与数据驱动测试</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/07/29/robotframework-template-and-data-driven/</id>
    <content type="html">&lt;p&gt;Robot Framework 是关键字驱动的测试框架，虽然关键字驱动高度抽象了底层实现，减少维护成本，降低了对测试人员编程水平的需求，但在某些类型的测试中，数据驱动导向的测试用例比重多，比如常见的用户输入框就有海量的输入可能性。Robot Framework 提供了测试模板，可以将其转换为数据驱动的测试。&lt;/p&gt;&#xA;&lt;h2&gt;基本用法&lt;/h2&gt;&#xA;&lt;p&gt;如果有一个接受参数的关键字，那么它就可以被用作模板。下面的例子展示了这一点。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;*** Settings ***&#xA;Test Setup        Prepare&#xA;Test Template     Compare Two Number ${one} ${three}&#xA;&#xA;*** Test Cases ***&#xA;Template test case&#xA;    1    2&#xA;    1    1&#xA;    2    3&#xA;    2    2&#xA;&#xA;*** Keywords ***&#xA;Compare Two Number ${one} ${three}&#xA;    Should Be Equal    ${one}    ${three}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这里展示了比较两个数是否相等的例子，可以看到只需填入输入数据即可。你也可以用 [Template] 为每个 Test Case 单独指定模板。&lt;/p&gt;&#xA;&lt;h2&gt;与循环执行的区别&lt;/h2&gt;&#xA;&lt;p&gt;有人会问，能否运用循环语句来模拟上述行为呢？&lt;/p&gt;&#xA;&lt;p&gt;首先，由于 Robot Framework 是个测试框架，编程能力被弱化不少，模板语法显得简洁 ^_^，然后，在用例中混入过多的执行控制流也不是推荐的行为（或者绝对地说，用例中就不应该有循环、判断语句）。&lt;/p&gt;&#xA;&lt;p&gt;其次，模板是处于 continue on failure 模式中，某一项输入 Fail，还会继续执行其他输入。普通 Case 一旦有个语句 Fail，该 Case 就会 tear down。比如上面给的例子，第一行和第二行就会 Fail，实际执行结果如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# log&#xA;Starting test: Testcases.UI Test.Template test case&#xA;20160729 12:08:56.652 :  FAIL : 1 != 2&#xA;20160729 12:08:56.668 :  FAIL : 2 != 3&#xA;Ending test:   Testcases.UI Test.Template test case&#xA;&#xA;# report&#xA;========================================================&#xA;Testcases                                                                                                                                                                &#xA;========================================================&#xA;Testcases.UI Test                                                                                                                                                        &#xA;========================================================&#xA;Template test case                                                                                                                                               | FAIL |&#xA;Several failures occurred:&#xA;&#xA;1) 1 != 2&#xA;&#xA;2) 2 != 3&#xA;--&#xA;Testcases.UI Test                                                                                                                                                | FAIL |&#xA;1 critical test, 0 passed, 1 failed&#xA;1 test total, 0 passed, 1 failed&#xA;========================================================&#xA;Testcases                                                                                                                                                        | FAIL |&#xA;1 critical test, 0 passed, 1 failed&#xA;1 test total, 0 passed, 1 failed&#xA;========================================================&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;单个输入中的 Fail 不会中断执行流。&lt;/p&gt;&#xA;&lt;h2&gt;一些不足&lt;/h2&gt;&#xA;&lt;p&gt;这些不足是我自己感受，可能并不准确。&lt;/p&gt;&#xA;&lt;p&gt;我自己在自动化测试中使用数据驱动测试方法，只是希望减轻手工编写的工作量，对于执行流上的步骤不想简化。我希望每个输入都能完整地走完一遍 Test Setup | Test Execuation | Test Teardown 过程，遗憾的是好像 Robot Framework 做不到。下面是例子，这里增加了一个 Test Setup。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;*** Settings ***&#xA;Test Setup        Prepare&#xA;Test Template     Compare Two Number ${one} ${three}&#xA;&#xA;*** Test Cases ***&#xA;Template test case&#xA;    1    2&#xA;    1    1&#xA;    2    3&#xA;    2    2&#xA;&#xA;*** Keywords ***&#xA;Compare Two Number ${one} ${three}&#xA;    Should Be Equal    ${one}    ${three}&#xA;&#xA;Prepare&#xA;    Log    hello, world&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到 hello, world 只打印了一次。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Starting test: Testcases.UI Test.Template test case&#xA;20160729 12:08:56.652 :  INFO : hello, world&#xA;20160729 12:08:56.652 :  FAIL : 1 != 2&#xA;20160729 12:08:56.668 :  FAIL : 2 != 3&#xA;Ending test:   Testcases.UI Test.Template test case&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这就使得框架对测试输入有要求：输入数据不能对后续输入有影响。一旦在执行过程中有 Fail 发生，就无法用 Test Teardown 恢复测试环境（Run Keyword And Continue On Failure 关键字可能可以解决该问题，但这样写逻辑上并不清晰）。&lt;/p&gt;&#xA;&lt;p&gt;使用 Library 导入的标准库和外部库也有问题，测试框架会为每个 Case 生成一个库的实例（即 Python, Java 类的实例），模板中每一行输入都共享一个实例，若是类中有全局变量，便会在各个输入之间产生干扰。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/07/29/robotframework-template-and-data-driven/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>基于 BP 神经网络的手写体数字识别 - 优化</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/06/30/handwritten-neural-net04/</id>
    <content type="html">&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xA;MathJax.Hub.Config({&#xA;  TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; } }&#xA;});&#xA;&lt;/script&gt;&#xA;&lt;p&gt;目前为止，我们论述中，似乎手写数字图像本身并没有太多篇幅。这就是神经网络的特点，那 784 个像素点只是神经网络的输入，不需要任何图像处理。&lt;/p&gt;&#xA;&lt;p&gt;95% 的识别率看起来很高了，但还有不少提升空间。本篇文章将介绍多种优化方法。&lt;/p&gt;&#xA;&lt;h2&gt;交叉熵代价函数&lt;/h2&gt;&#xA;&lt;p&gt;理想情况下我们的神经网络能够快速地从错误中学习。但实际过程中却可能学习缓慢。让我们看下面这个例子：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/tikz28.png&#34; alt=&#34;例子&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;我们期望该神经元在输入 1 时输出 0。若神经元权重初始值为 0.6，偏移初始值为 0.9，则初始输出为 0.82，离预期输出还有一段距离。我们选择学习率 $\eta=0.15$，点击 &lt;strong&gt;Run&lt;/strong&gt; 观察输出变化和二次代价函数的变化动画：&lt;/p&gt;&#xA;&lt;script type=&#34;text/javascript&#34; src=&#34;//cdn.bootcss.com/paper.js/0.9.25/paper-full.min.js&#34;&gt;&lt;/script&gt;&#xA;&lt;script type=&#34;text/paperscript&#34; src=&#34;/customjs/saturation1.js&#34; canvas=&#34;saturation1&#34;&gt;&#xA;&lt;/script&gt;&#xA;&lt;center&gt;&#xA;&lt;canvas id=&#34;saturation1&#34; width=&#34;520&#34; height=&#34;300&#34;&gt;&lt;/canvas&gt;&#xA;&lt;/center&gt;&#xA;&lt;p&gt;可以看到，神经元一直在“学习进步”，且“进步”神速，最终的输出也接近于 0。现在将权重初始值和偏移初始值都设为 2.0，再点击 &lt;strong&gt;Run&lt;/strong&gt; 观察动画：&lt;/p&gt;&#xA;&lt;script type=&#34;text/paperscript&#34; src=&#34;/customjs/saturation2.js&#34; canvas=&#34;saturation2&#34;&gt;&#xA;&lt;/script&gt;&#xA;&lt;center&gt;&#xA;&lt;canvas id=&#34;saturation2&#34; width=&#34;520&#34; height=&#34;300&#34;&gt;&lt;/canvas&gt;&#xA;&lt;/center&gt;&#xA;&lt;p&gt;参数未变，结果造成学习速度减慢。仔细观察，开始的 150 个 epoch 权重和偏移几乎保持不变。过了这个点，神经元又变成了“进步”神速的好孩子。&lt;/p&gt;&#xA;&lt;p&gt;我们经常把自学习与人类的学习作比较，这里神经元的学习过程显得反常。当人类发现自己错误的离谱时会学习较快，而大部分未优化的神经元却在错误中踌躇不前。&lt;/p&gt;&#xA;&lt;p&gt;让我们来探究一下问题的缘由。神经元学习慢，等同于权重和偏移变化慢，等同于代价函数的偏导数 $\partial C/\partial w$ 和 $\partial C / \partial b$ 较小。我们的二次代价函数为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;C = \frac{(y-a)^2}{2},&#xA;\label{54}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;其中，$a$ 是当训练输入 $x=1$ 时神经元的输出，$y=0$ 是期望输出。将 $a=\sigma(z), z = wx+b$ 代入上式，并求取偏导数可得&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\frac{\partial C}{\partial w} &amp;amp; = &amp;amp; (a-y)\sigma&#39;(z) x = a \sigma&#39;(z) \label{55}\\&#xA;\frac{\partial C}{\partial b} &amp;amp; = &amp;amp; (a-y)\sigma&#39;(z) = a \sigma&#39;(z),&#xA;\label{56}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;结合我们的 $\sigma$ 函数图像，即 sigmoid 函数图像：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/sigmoid_function.png&#34; alt=&#34;sigmoid 函数&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;当神经元的输出接近于 0 时，曲线变得很平缓，所以 $\sigma&#39;(z)$ 的值很小，结合公式 (\ref{55}) 和 (\ref{56}) 可知，$\partial C/\partial w$ 和 $\partial C / \partial b$ 的值很小。&lt;/p&gt;&#xA;&lt;h3&gt;介绍交叉熵代价函数&lt;/h3&gt;&#xA;&lt;p&gt;假设我们要训练如下的神经元，输入变量为 $x_1, x_2, ...$，对应的权重为 $w_1, w_2, ...$，偏移为 $b$：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/tikz29.png&#34; alt=&#34;多输入神经元&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;其中输出是 $a=\sigma(z), z = \sum_j w_j x_j+b$。对此，我们定义该神经元的交叉熵代价函数为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;C = -\frac{1}{n} \sum_x \left[y \ln a + (1-y ) \ln (1-a) \right],&#xA;\label{57}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;其中，$n$ 是所有训练数据的总和，$x$ 和 $y$ 是相应的输入和期望输出。为什么公式 (\ref{57}) 可以作为代价函数？&lt;/p&gt;&#xA;&lt;p&gt;首先，由于 $a$ 的取值在 0, 1 之间，$y \ln a + (1-y) \ln (1-a)$ 为负，取反后公式 (\ref{57}) 非负。然后，当实际输出 $a$ 接近期望输出 $y$ 时，交叉熵接近于 0。这两点是代价函数的基本条件。将 $a = \sigma(z)$ 代入公式 (\ref{57}) 并计算交叉熵对权重的偏导，得&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\frac{\partial C}{\partial w_j} &amp;amp; = &amp;amp; -\frac{1}{n} \sum_x \left(&#xA;\frac{y }{\sigma(z)} -\frac{(1-y)}{1-\sigma(z)} \right)&#xA;\frac{\partial \sigma}{\partial w_j} \label{58}\\&#xA;&amp;amp; = &amp;amp; -\frac{1}{n} \sum_x \left(&#xA;\frac{y}{\sigma(z)}&#xA;-\frac{(1-y)}{1-\sigma(z)} \right)\sigma&#39;(z) x_j.&#xA;\label{59}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;合并成一个分母，得&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\frac{\partial C}{\partial w_j} &amp;amp; = &amp;amp; \frac{1}{n}&#xA;\sum_x \frac{\sigma&#39;(z) x_j}{\sigma(z) (1-\sigma(z))}&#xA;(\sigma(z)-y).&#xA;\label{60}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;由于 $\sigma&#39;(z) = \sigma(z)(1-\sigma(z))$，上式还可以抵消，进一步简化为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\frac{\partial C}{\partial w_j} =  \frac{1}{n} \sum_x x_j(\sigma(z)-y).&#xA;\label{61}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;权重的学习速率由 $\sigma(z)-y$ 控制，误差越大，学习越快。二次代价函数 (\ref{55}) 中，正是由于 $\sigma&#39;(z)$ 的存在，自学习的速率减慢，而公式 (\ref{61}) 消掉了这一项。同理，可得交叉熵对权重的偏导数为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\frac{\partial C}{\partial b} = \frac{1}{n} \sum_x (\sigma(z)-y).&#xA;\label{62}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;同样，恼人的 $\sigma&#39;(z)$ 也被消掉了。&lt;/p&gt;&#xA;&lt;p&gt;让我们再来看一下之前动画，这次使用交叉熵作为代价函数，且学习率改为 $\eta=0.005$。第一个，权重初始值是 0.6，偏移初始值是 0.9，点击 &lt;strong&gt;Run&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;script type=&#34;text/paperscript&#34; src=&#34;/customjs/saturation3.js&#34; canvas=&#34;saturation3&#34;&gt;&#xA;&lt;/script&gt;&#xA;&lt;center&gt;&#xA;&lt;canvas id=&#34;saturation3&#34; width=&#34;520&#34; height=&#34;300&#34;&gt;&lt;/canvas&gt;&#xA;&lt;/center&gt;&#xA;&lt;p&gt;意料之中，学习速度还是很快。第二个，权重和偏移初始值都为 2，点击 &lt;strong&gt;Run&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;script type=&#34;text/paperscript&#34; src=&#34;/customjs/saturation4.js&#34; canvas=&#34;saturation4&#34;&gt;&#xA;&lt;/script&gt;&#xA;&lt;center&gt;&#xA;&lt;canvas id=&#34;saturation4&#34; width=&#34;520&#34; height=&#34;300&#34;&gt;&lt;/canvas&gt;&#xA;&lt;/center&gt;&#xA;&lt;p&gt;神经元还是学习迅速。你可能注意到了 $\eta$ 的变化，这会不会影响试验结果？其实，我们关心的不是神经元学习的绝对速度，而是学习速度本身的变化。&lt;/p&gt;&#xA;&lt;p&gt;上述结论完全可以推广到多层多神经元的网络，定义交叉熵为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}  C = -\frac{1}{n} \sum_x&#xA;\sum_j \left[y_j \ln a^L_j + (1-y_j) \ln (1-a^L_j) \right].&#xA;\label{63}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;那什么时候该用交叉熵而不是二次代价函数？对于 sigmoid 神经元，交叉熵几乎永远是更优选择，也被实践证明。&lt;/p&gt;&#xA;&lt;h3&gt;柔性最大值传输 softmax&lt;/h3&gt;&#xA;&lt;p&gt;通过将神经网络的输出由 sigmoid 换成 softmax 层可以进一步改善学习缓慢的问题。&lt;/p&gt;&#xA;&lt;p&gt;对于输出层，其权重输入为 $z^L_j = \sum_{k} w^L_{jk} a^{L-1}_k + b^L_j$，施加 softmax 函数，输出层激励为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;a^L_j = \frac{e^{z^L_j}}{\sum_k e^{z^L_k}},&#xA;\label{78}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;其中，分母是所有输出神经元输出之和。又是一个看起来意义不明的函数。如果我们将所有激励相加，会发现其值正好等于 1，&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\sum_j a^L_j &amp;amp; = &amp;amp; \frac{\sum_j e^{z^L_j}}{\sum_k e^{z^L_k}} = 1.&#xA;\label{79}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;当某一个激励增加时，其他的激励必须相应地减少以保证和不变。换句话说，如果将 softmax 作为输出层，神经网络的所有输出符合概率分布。这又是一个方便的特性，尤其对于手写数字识别来说，每个输出代表每个数字的概率，之前 sigmoid 的方案有可能会有如下的输出&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;[0.9, 0.3, 0.4, 0.1, 0.0, 0.4, 0.0, 0.0, 0.0, 0.1]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;每个概率之间并没有联系，sigmoid 输出神经元只是各顾各的训练。而且人们拿到这个结果肯定会非常疑惑，为啥概率相加不等于 1？&lt;/p&gt;&#xA;&lt;h2&gt;过拟合和正则化&lt;/h2&gt;&#xA;&lt;p&gt;诺贝尔物理学奖获得者费米曾经和他的同事讨论一个数学模型。该模型能够很好地解释实验结果，但费米仍有疑虑。他问该模型用了多少个自由变量，同事回答四个。费米回答：“我记得我朋友冯诺依曼曾经说过，四个变量我能描述一头大象，五个变量就能让他转鼻子了”。&lt;/p&gt;&#xA;&lt;p&gt;拥有大量自由变量的模型很容易就描述大部分实验现象。但是不能说符合实验现象的模型就是好模型。有足够自由变量的模型中，几乎可以描述任何给定大小的数据集，但没有抓住现象背后的本质。这种情况下，模型只能适用于现有数据，面对新的情况却束手无策。模型的真正考验，是它有能力对未出现的现象做出预言。&lt;/p&gt;&#xA;&lt;p&gt;费米和诺依曼对四变量的模型就产生了质疑。而我们手写数字识别系统有 30 个隐藏神经元，有将近 24000 个变量！若是 100 个隐藏神经元，那就有近 80000 个变量！这么多变量，不禁要问，结果可信么？会出现费米和诺依曼担心的问题么？&lt;/p&gt;&#xA;&lt;p&gt;让我们来模拟一下这种情况的发生。我们使用 30 个隐藏神经元，但我们不使用 50000 个 MNIST 训练图像，相反，只是用 1000 个训练图像。这样，问题会更显著。训练使用交叉熵函数，学习率 $\eta=0.5$，mini-batch 大小为 10，训练 400 个epochs。让我们用 &lt;a href=&#34;https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network2.py&#34;&gt;network2&lt;/a&gt; 来观察变化。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import mnist_loader &#xA;training_data, validation_data, test_data = mnist_loader.load_data_wrapper()&#xA;import network2 &#xA;net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost) &#xA;net.large_weight_initializer()&#xA;net.SGD(training_data[:1000], 400, 10, 0.5, evaluation_data=test_data, monitor_evaluation_accuracy=True, monitor_training_cost=True)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;首先是代价函数随学习进度的变化图像：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/overfitting1.png&#34; alt=&#34;代价函数变化&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;看起来不错，代价不断减小，似乎说明我们的神经网络一直在进步。但是测试集上识别率却不是那么回事：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/overfitting2.png&#34; alt=&#34;识别率变化&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;280 个 epoch 之后，识别率处于波动稳定状态，且远低于之前达到的 95% 识别率。训练数据的交叉熵和测试集的实际结果截然不同，出现了费米担心的问题。可以说，280 个 epoch 之后的学习完全无用，标准说法是&lt;strong&gt;过拟合 overfitting&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;让我们在做一点更直观的比较：训练集和测试集的交叉熵横向对比，及识别率横向对比。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/overfitting3.png&#34; alt=&#34;测试集交叉熵&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;交叉熵仅仅下降了 15 个 epoch，之后就一路飙高，持续恶化。这是我们模型过拟合的又一个标志。这里有个小疑问，epoch 15 和 epoch 280 哪个属于开始过拟合？从实践的角度看，我们真正的关心的是测试集（更接近真实情况）上的识别率，交叉熵只是算法的附带物，所以我们认为，epoch 280 之后，过拟合开始占据神经网络的学习过程。&lt;/p&gt;&#xA;&lt;p&gt;下面是训练集的识别率变化：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/overfitting4.png&#34; alt=&#34;训练集识别率&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;我们的模型能够 100% 地描述 1000 个训练图像，实际却不能很好地分类测试数字。&lt;/p&gt;&#xA;&lt;p&gt;最明显的检测过拟合的方法是观察测试集上识别率的变化。如果发现测试集识别率不再改善，就应该停止训练。这也是&lt;a href=&#34;http://www.lyyyuna.com/2016/06/25/handwritten-neural-net02/&#34;&gt;之前文章-代码实现&lt;/a&gt;为什么要再引入验证集的原因，毕竟测试集是最终判定结果用的，应该与训练过程彻底分离。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;training_data, validation_data, test_data = mnist_loader.load_data_wrapper()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们一直在讨论 1000 个训练图片的过拟合问题，那 50000 个图片结果还是一样吗？这里给出结果：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/overfitting_full.png&#34; alt=&#34;扩大训练集&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以看到，过拟合不再那么明显了，训练集的识别率只比测试集高 1.5% 左右。这也间接说明，大量训练数据下神经网络难以达到过拟合。不过训练集并不是那么容易获得的。&lt;/p&gt;&#xA;&lt;h3&gt;正则化 Regularization&lt;/h3&gt;&#xA;&lt;p&gt;首先要明确一点，我们并不想减少网络中变量的数目，我们需要这种特性来描述现实世界复杂的变化。&lt;/p&gt;&#xA;&lt;p&gt;正则化方法能够缓解过拟合问题，最常用的是权重衰减法或者叫 $L_2$ 正则化。$L_2$ 正则化只是在原先的代价函数中加入一个正则项：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;C = -\frac{1}{n} \sum_{xj} \left[ y_j \ln a^L_j+(1-y_j) \ln&#xA;(1-a^L_j)\right] + \frac{\lambda}{2n} \sum_w w^2.&#xA;\label{85}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;等式右边第一项是交叉熵，第二项是网络中所有权重的平方和，并乘以系数 $\lambda /2n$，其中 $\lambda &amp;gt; 0$，称作正则化参数。&lt;/p&gt;&#xA;&lt;p&gt;正则化不只适用于交叉熵代价函数，二次代价函数也可以使用：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;C = \frac{1}{2n} \sum_x |y-a^L|^2 +&#xA;\frac{\lambda}{2n} \sum_w w^2.&#xA;\label{86}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;总结下来就是&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&lt;br&gt;&#xA;C = C_0 + \frac{\lambda}{2n}&#xA;\sum_w w^2,&#xA;\label{87}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;其中 $C_0$ 是未正则化的代价函数。观察该式，可以发现正则化逼迫自学习过程选择更小的权重，权重越大，代价也越高。由于代价函数的变换，随机梯度下降法中偏导数的计算也要随之改变：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\frac{\partial C}{\partial w} &amp;amp; = &amp;amp; \frac{\partial C_0}{\partial w} +&#xA;\frac{\lambda}{n} w \label{88}\\&#xA;\frac{\partial C}{\partial b} &amp;amp; = &amp;amp; \frac{\partial C_0}{\partial b}.&#xA;\label{89}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;$\partial C_0 / \partial w$ 和 $\partial C_0 / \partial b$ 仍让可以用&lt;a href=&#34;http://www.lyyyuna.com/2016/06/26/handwritten-neural-net03/&#34;&gt;上一篇&lt;/a&gt;的反向传播算法求得。对偏移的偏导数并没有改变，所以据梯度下降法学习规则仍为：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;b &amp;amp; \rightarrow &amp;amp; b -\eta \frac{\partial C_0}{\partial b}.&#xA;\label{90}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;而权重的自学习规则则变成：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;w &amp;amp; \rightarrow &amp;amp; w-\eta \frac{\partial C_0}{\partial&#xA;w}-\frac{\eta \lambda}{n} w \label{91}\\&#xA;&amp;amp; = &amp;amp; \left(1-\frac{\eta \lambda}{n}\right) w -\eta \frac{\partial&#xA;C_0}{\partial w}.&#xA;\label{92}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;可以看到，权重 $w$ 乘以了一个小于 1 的系数 $1-\frac{\eta \lambda}{n}$，称为权重衰减，有减小权重的趋势。而后一项由于偏导有正有负，所以权重值并不是单调递减，两项相加，彼此制约。&lt;/p&gt;&#xA;&lt;p&gt;以上是梯度下降法，随机梯度下降法也只要做相应的调整：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;w \rightarrow \left(1-\frac{\eta \lambda}{n}\right) w -\frac{\eta}{m}&#xA;\sum_x \frac{\partial C_x}{\partial w},&#xA;\label{93}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;b \rightarrow b - \frac{\eta}{m} \sum_x \frac{\partial C_x}{\partial b},&#xA;\label{94}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;其中，求和是对一个 mini-batch 内所有数据的求和。&lt;/p&gt;&#xA;&lt;p&gt;让我们实验一下。这次在 &lt;a href=&#34;https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network2.py&#34;&gt;network2&lt;/a&gt; 中加入正则化参数 $\lambda=0.1$。对比之前 1000 个训练数据集的结果：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import mnist_loader &#xA;training_data, validation_data, test_data = mnist_loader.load_data_wrapper() &#xA;import network2 &#xA;net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost)&#xA;net.large_weight_initializer()&#xA;net.SGD(training_data[:1000], 400, 10, 0.5, &#xA;        evaluation_data=test_data, lmbda = 0.1, &#xA;        monitor_evaluation_cost=True, monitor_evaluation_accuracy=True, &#xA;        monitor_training_cost=True, monitor_training_accuracy=True)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;训练集的交叉熵代价看来没什么问题：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/regularized1.png&#34; alt=&#34;训练集的代价&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;但这次识别率却是一直在上升：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/regularized2.png&#34; alt=&#34;识别率上升&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;我们在试一下 50000 个训练数据的情况：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/regularized_full.png&#34; alt=&#34;识别率&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;训练集和测试集的识别率只差 1% 左右，而正则化之前这一值是 1.5%。&lt;/p&gt;&#xA;&lt;p&gt;用以下参数&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;net = network2.Network([784, 100, 10], cost=network2.CrossEntropyCost)&#xA;net.large_weight_initializer()&#xA;net.SGD(training_data, 60, 10, 0.1, lmbda=5.0,&#xA;      evaluation_data=validation_data,&#xA;      monitor_evaluation_accuracy=True)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;识别率提高到 98%。你可以认为，由于过拟合的存在，神经网络模型易陷入局部最优解，正则之后，跳出局部最优，滚向全局最优，最终带来识别率的提升。&lt;/p&gt;&#xA;&lt;h3&gt;为什么正则化能抑制过拟合&lt;/h3&gt;&#xA;&lt;p&gt;从正则化的结果来看，似乎权重值越小越能抑制过拟合。&lt;/p&gt;&#xA;&lt;p&gt;让我们看一个经典的例子，假设要对下图所示的点建立一个模型：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/tenpoints1.png&#34; alt=&#34;很多点&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;数一下，有 10 个点，那可以用一个 9 次函数精确地描述它，$y = a_0 x^9 + a_1 x^8 + \ldots + a_9$：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/tenpoints2.png&#34; alt=&#34;九次函数&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;如果允许一些误差，也可以使用一个简单的线性模型：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/tenpoints3.png&#34; alt=&#34;线性模型&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;那么，哪个才是更好的模型？哪个才能描述还未出现的新点？实践表明，允许一定误差的模型更符合实际情况。现实世界伴随着大量不确定性，传感器采集的噪声和仪器本身的精度都会给训练集加入一定的&lt;strong&gt;噪声&lt;/strong&gt;，这样，后一个模型便在预测新点时占据了优势。&lt;/p&gt;&#xA;&lt;p&gt;回到我们的神经网络，当输入因为某些噪声剧烈变化时，较小的权值 $w$ 能够防止网络整体特性改变过大，网络也就不会去“学习”那些没用的噪声信息了。相反，对于手写数字图像那些重复的特征，神经网络在一遍遍的 mini-batch 中，“铭记在心”。&lt;/p&gt;&#xA;&lt;p&gt;人们也称这个思想为&lt;strong&gt;奥卡姆剃刀原理&lt;/strong&gt;：当两个假说具有完全相同的解释力和预测力时，我们以那个较为简单的假说作为讨论依据。&lt;/p&gt;&#xA;&lt;h3&gt;其他抑制过拟合的方法&lt;/h3&gt;&#xA;&lt;p&gt;当然还有很多抑制过拟合的方法，比如：&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;$L_1$ 正则化&lt;/strong&gt;，即换一个正则函数。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;dropout&lt;/strong&gt;：学习过程中随机删去一些神经元。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;人工扩展训练集&lt;/strong&gt;：这也是我比较喜欢的一个方法，可以通过平移、缩放、旋转、elastic distortions 等扩展数据集。扩展数据简单粗暴有效，微软研究院的研究员用 elastic distortions 扩展数据后，就将 MNIST 识别率提高到了 99.3%。&lt;/p&gt;&#xA;&lt;h2&gt;改进权重初始化&lt;/h2&gt;&#xA;&lt;p&gt;我们在初始化权重和偏移时，选择高斯随机，均值为 0，标准差为 1。权重输入为 $z = \sum_j w_j x_j+b$，随着输入神经元数目的增加，标准差也随之增加，例如 1000 个神经元，其正太分布曲线为&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/gauss1.png&#34; alt=&#34;正太分布&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;曲线非常平坦，意味着 $z \gg 1, z \ll -1$ 的可能性都大大增加，输出 $\sigma(z)$ 极有可能饱和，出现过拟合的现象。解决的方法也非常简单，初始化时标准差选为 $1/\sqrt{n_{\rm in}}$。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/gauss2.png&#34; alt=&#34;改进的正太分布&#34;&gt;&lt;/p&gt;&#xA;&lt;h2&gt;代码&lt;/h2&gt;&#xA;&lt;p&gt;以下是 network2.py 的源码（当然我不是写的啦，&lt;a href=&#34;http://michaelnielsen.org/&#34;&gt;Michael Nielsen&lt;/a&gt; 的杰作），所用技术和算法已在上文逐一阐述。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;quot;&amp;quot;&amp;quot;network2.py&#xA;~~~~~~~~~~~~~~&#xA;&#xA;An improved version of network.py, implementing the stochastic&#xA;gradient descent learning algorithm for a feedforward neural network.&#xA;Improvements include the addition of the cross-entropy cost function,&#xA;regularization, and better initialization of network weights.  Note&#xA;that I have focused on making the code simple, easily readable, and&#xA;easily modifiable.  It is not optimized, and omits many desirable&#xA;features.&#xA;&#xA;&amp;quot;&amp;quot;&amp;quot;&#xA;&#xA;#### Libraries&#xA;# Standard library&#xA;import json&#xA;import random&#xA;import sys&#xA;&#xA;# Third-party libraries&#xA;import numpy as np&#xA;&#xA;&#xA;#### Define the quadratic and cross-entropy cost functions&#xA;&#xA;class QuadraticCost(object):&#xA;&#xA;    @staticmethod&#xA;    def fn(a, y):&#xA;        &amp;quot;&amp;quot;&amp;quot;Return the cost associated with an output ``a`` and desired output&#xA;        ``y``.&#xA;&#xA;        &amp;quot;&amp;quot;&amp;quot;&#xA;        return 0.5*np.linalg.norm(a-y)**2&#xA;&#xA;    @staticmethod&#xA;    def delta(z, a, y):&#xA;        &amp;quot;&amp;quot;&amp;quot;Return the error delta from the output layer.&amp;quot;&amp;quot;&amp;quot;&#xA;        return (a-y) * sigmoid_prime(z)&#xA;&#xA;&#xA;class CrossEntropyCost(object):&#xA;&#xA;    @staticmethod&#xA;    def fn(a, y):&#xA;        &amp;quot;&amp;quot;&amp;quot;Return the cost associated with an output ``a`` and desired output&#xA;        ``y``.  Note that np.nan_to_num is used to ensure numerical&#xA;        stability.  In particular, if both ``a`` and ``y`` have a 1.0&#xA;        in the same slot, then the expression (1-y)*np.log(1-a)&#xA;        returns nan.  The np.nan_to_num ensures that that is converted&#xA;        to the correct value (0.0).&#xA;&#xA;        &amp;quot;&amp;quot;&amp;quot;&#xA;        return np.sum(np.nan_to_num(-y*np.log(a)-(1-y)*np.log(1-a)))&#xA;&#xA;    @staticmethod&#xA;    def delta(z, a, y):&#xA;        &amp;quot;&amp;quot;&amp;quot;Return the error delta from the output layer.  Note that the&#xA;        parameter ``z`` is not used by the method.  It is included in&#xA;        the method&#39;s parameters in order to make the interface&#xA;        consistent with the delta method for other cost classes.&#xA;&#xA;        &amp;quot;&amp;quot;&amp;quot;&#xA;        return (a-y)&#xA;&#xA;&#xA;#### Main Network class&#xA;class Network(object):&#xA;&#xA;    def __init__(self, sizes, cost=CrossEntropyCost):&#xA;        &amp;quot;&amp;quot;&amp;quot;The list ``sizes`` contains the number of neurons in the respective&#xA;        layers of the network.  For example, if the list was [2, 3, 1]&#xA;        then it would be a three-layer network, with the first layer&#xA;        containing 2 neurons, the second layer 3 neurons, and the&#xA;        third layer 1 neuron.  The biases and weights for the network&#xA;        are initialized randomly, using&#xA;        ``self.default_weight_initializer`` (see docstring for that&#xA;        method).&#xA;&#xA;        &amp;quot;&amp;quot;&amp;quot;&#xA;        self.num_layers = len(sizes)&#xA;        self.sizes = sizes&#xA;        self.default_weight_initializer()&#xA;        self.cost=cost&#xA;&#xA;    def default_weight_initializer(self):&#xA;        &amp;quot;&amp;quot;&amp;quot;Initialize each weight using a Gaussian distribution with mean 0&#xA;        and standard deviation 1 over the square root of the number of&#xA;        weights connecting to the same neuron.  Initialize the biases&#xA;        using a Gaussian distribution with mean 0 and standard&#xA;        deviation 1.&#xA;&#xA;        Note that the first layer is assumed to be an input layer, and&#xA;        by convention we won&#39;t set any biases for those neurons, since&#xA;        biases are only ever used in computing the outputs from later&#xA;        layers.&#xA;&#xA;        &amp;quot;&amp;quot;&amp;quot;&#xA;        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]&#xA;        self.weights = [np.random.randn(y, x)/np.sqrt(x)&#xA;                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]&#xA;&#xA;    def large_weight_initializer(self):&#xA;        &amp;quot;&amp;quot;&amp;quot;Initialize the weights using a Gaussian distribution with mean 0&#xA;        and standard deviation 1.  Initialize the biases using a&#xA;        Gaussian distribution with mean 0 and standard deviation 1.&#xA;&#xA;        Note that the first layer is assumed to be an input layer, and&#xA;        by convention we won&#39;t set any biases for those neurons, since&#xA;        biases are only ever used in computing the outputs from later&#xA;        layers.&#xA;&#xA;        This weight and bias initializer uses the same approach as in&#xA;        Chapter 1, and is included for purposes of comparison.  It&#xA;        will usually be better to use the default weight initializer&#xA;        instead.&#xA;&#xA;        &amp;quot;&amp;quot;&amp;quot;&#xA;        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]&#xA;        self.weights = [np.random.randn(y, x)&#xA;                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]&#xA;&#xA;    def feedforward(self, a):&#xA;        &amp;quot;&amp;quot;&amp;quot;Return the output of the network if ``a`` is input.&amp;quot;&amp;quot;&amp;quot;&#xA;        for b, w in zip(self.biases, self.weights):&#xA;            a = sigmoid(np.dot(w, a)+b)&#xA;        return a&#xA;&#xA;    def SGD(self, training_data, epochs, mini_batch_size, eta,&#xA;            lmbda = 0.0,&#xA;            evaluation_data=None,&#xA;            monitor_evaluation_cost=False,&#xA;            monitor_evaluation_accuracy=False,&#xA;            monitor_training_cost=False,&#xA;            monitor_training_accuracy=False):&#xA;        &amp;quot;&amp;quot;&amp;quot;Train the neural network using mini-batch stochastic gradient&#xA;        descent.  The ``training_data`` is a list of tuples ``(x, y)``&#xA;        representing the training inputs and the desired outputs.  The&#xA;        other non-optional parameters are self-explanatory, as is the&#xA;        regularization parameter ``lmbda``.  The method also accepts&#xA;        ``evaluation_data``, usually either the validation or test&#xA;        data.  We can monitor the cost and accuracy on either the&#xA;        evaluation data or the training data, by setting the&#xA;        appropriate flags.  The method returns a tuple containing four&#xA;        lists: the (per-epoch) costs on the evaluation data, the&#xA;        accuracies on the evaluation data, the costs on the training&#xA;        data, and the accuracies on the training data.  All values are&#xA;        evaluated at the end of each training epoch.  So, for example,&#xA;        if we train for 30 epochs, then the first element of the tuple&#xA;        will be a 30-element list containing the cost on the&#xA;        evaluation data at the end of each epoch. Note that the lists&#xA;        are empty if the corresponding flag is not set.&#xA;&#xA;        &amp;quot;&amp;quot;&amp;quot;&#xA;        if evaluation_data: n_data = len(evaluation_data)&#xA;        n = len(training_data)&#xA;        evaluation_cost, evaluation_accuracy = [], []&#xA;        training_cost, training_accuracy = [], []&#xA;        for j in xrange(epochs):&#xA;            random.shuffle(training_data)&#xA;            mini_batches = [&#xA;                training_data[k:k+mini_batch_size]&#xA;                for k in xrange(0, n, mini_batch_size)]&#xA;            for mini_batch in mini_batches:&#xA;                self.update_mini_batch(&#xA;                    mini_batch, eta, lmbda, len(training_data))&#xA;            print &amp;quot;Epoch %s training complete&amp;quot; % j&#xA;            if monitor_training_cost:&#xA;                cost = self.total_cost(training_data, lmbda)&#xA;                training_cost.append(cost)&#xA;                print &amp;quot;Cost on training data: {}&amp;quot;.format(cost)&#xA;            if monitor_training_accuracy:&#xA;                accuracy = self.accuracy(training_data, convert=True)&#xA;                training_accuracy.append(accuracy)&#xA;                print &amp;quot;Accuracy on training data: {} / {}&amp;quot;.format(&#xA;                    accuracy, n)&#xA;            if monitor_evaluation_cost:&#xA;                cost = self.total_cost(evaluation_data, lmbda, convert=True)&#xA;                evaluation_cost.append(cost)&#xA;                print &amp;quot;Cost on evaluation data: {}&amp;quot;.format(cost)&#xA;            if monitor_evaluation_accuracy:&#xA;                accuracy = self.accuracy(evaluation_data)&#xA;                evaluation_accuracy.append(accuracy)&#xA;                print &amp;quot;Accuracy on evaluation data: {} / {}&amp;quot;.format(&#xA;                    self.accuracy(evaluation_data), n_data)&#xA;            print&#xA;        return evaluation_cost, evaluation_accuracy, \&#xA;            training_cost, training_accuracy&#xA;&#xA;    def update_mini_batch(self, mini_batch, eta, lmbda, n):&#xA;        &amp;quot;&amp;quot;&amp;quot;Update the network&#39;s weights and biases by applying gradient&#xA;        descent using backpropagation to a single mini batch.  The&#xA;        ``mini_batch`` is a list of tuples ``(x, y)``, ``eta`` is the&#xA;        learning rate, ``lmbda`` is the regularization parameter, and&#xA;        ``n`` is the total size of the training data set.&#xA;&#xA;        &amp;quot;&amp;quot;&amp;quot;&#xA;        nabla_b = [np.zeros(b.shape) for b in self.biases]&#xA;        nabla_w = [np.zeros(w.shape) for w in self.weights]&#xA;        for x, y in mini_batch:&#xA;            delta_nabla_b, delta_nabla_w = self.backprop(x, y)&#xA;            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]&#xA;            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]&#xA;        self.weights = [(1-eta*(lmbda/n))*w-(eta/len(mini_batch))*nw&#xA;                        for w, nw in zip(self.weights, nabla_w)]&#xA;        self.biases = [b-(eta/len(mini_batch))*nb&#xA;                       for b, nb in zip(self.biases, nabla_b)]&#xA;&#xA;    def backprop(self, x, y):&#xA;        &amp;quot;&amp;quot;&amp;quot;Return a tuple ``(nabla_b, nabla_w)`` representing the&#xA;        gradient for the cost function C_x.  ``nabla_b`` and&#xA;        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar&#xA;        to ``self.biases`` and ``self.weights``.&amp;quot;&amp;quot;&amp;quot;&#xA;        nabla_b = [np.zeros(b.shape) for b in self.biases]&#xA;        nabla_w = [np.zeros(w.shape) for w in self.weights]&#xA;        # feedforward&#xA;        activation = x&#xA;        activations = [x] # list to store all the activations, layer by layer&#xA;        zs = [] # list to store all the z vectors, layer by layer&#xA;        for b, w in zip(self.biases, self.weights):&#xA;            z = np.dot(w, activation)+b&#xA;            zs.append(z)&#xA;            activation = sigmoid(z)&#xA;            activations.append(activation)&#xA;        # backward pass&#xA;        delta = (self.cost).delta(zs[-1], activations[-1], y)&#xA;        nabla_b[-1] = delta&#xA;        nabla_w[-1] = np.dot(delta, activations[-2].transpose())&#xA;        # Note that the variable l in the loop below is used a little&#xA;        # differently to the notation in Chapter 2 of the book.  Here,&#xA;        # l = 1 means the last layer of neurons, l = 2 is the&#xA;        # second-last layer, and so on.  It&#39;s a renumbering of the&#xA;        # scheme in the book, used here to take advantage of the fact&#xA;        # that Python can use negative indices in lists.&#xA;        for l in xrange(2, self.num_layers):&#xA;            z = zs[-l]&#xA;            sp = sigmoid_prime(z)&#xA;            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp&#xA;            nabla_b[-l] = delta&#xA;            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())&#xA;        return (nabla_b, nabla_w)&#xA;&#xA;    def accuracy(self, data, convert=False):&#xA;        &amp;quot;&amp;quot;&amp;quot;Return the number of inputs in ``data`` for which the neural&#xA;        network outputs the correct result. The neural network&#39;s&#xA;        output is assumed to be the index of whichever neuron in the&#xA;        final layer has the highest activation.&#xA;&#xA;        The flag ``convert`` should be set to False if the data set is&#xA;        validation or test data (the usual case), and to True if the&#xA;        data set is the training data. The need for this flag arises&#xA;        due to differences in the way the results ``y`` are&#xA;        represented in the different data sets.  In particular, it&#xA;        flags whether we need to convert between the different&#xA;        representations.  It may seem strange to use different&#xA;        representations for the different data sets.  Why not use the&#xA;        same representation for all three data sets?  It&#39;s done for&#xA;        efficiency reasons -- the program usually evaluates the cost&#xA;        on the training data and the accuracy on other data sets.&#xA;        These are different types of computations, and using different&#xA;        representations speeds things up.  More details on the&#xA;        representations can be found in&#xA;        mnist_loader.load_data_wrapper.&#xA;&#xA;        &amp;quot;&amp;quot;&amp;quot;&#xA;        if convert:&#xA;            results = [(np.argmax(self.feedforward(x)), np.argmax(y))&#xA;                       for (x, y) in data]&#xA;        else:&#xA;            results = [(np.argmax(self.feedforward(x)), y)&#xA;                        for (x, y) in data]&#xA;        return sum(int(x == y) for (x, y) in results)&#xA;&#xA;    def total_cost(self, data, lmbda, convert=False):&#xA;        &amp;quot;&amp;quot;&amp;quot;Return the total cost for the data set ``data``.  The flag&#xA;        ``convert`` should be set to False if the data set is the&#xA;        training data (the usual case), and to True if the data set is&#xA;        the validation or test data.  See comments on the similar (but&#xA;        reversed) convention for the ``accuracy`` method, above.&#xA;        &amp;quot;&amp;quot;&amp;quot;&#xA;        cost = 0.0&#xA;        for x, y in data:&#xA;            a = self.feedforward(x)&#xA;            if convert: y = vectorized_result(y)&#xA;            cost += self.cost.fn(a, y)/len(data)&#xA;        cost += 0.5*(lmbda/len(data))*sum(&#xA;            np.linalg.norm(w)**2 for w in self.weights)&#xA;        return cost&#xA;&#xA;    def save(self, filename):&#xA;        &amp;quot;&amp;quot;&amp;quot;Save the neural network to the file ``filename``.&amp;quot;&amp;quot;&amp;quot;&#xA;        data = {&amp;quot;sizes&amp;quot;: self.sizes,&#xA;                &amp;quot;weights&amp;quot;: [w.tolist() for w in self.weights],&#xA;                &amp;quot;biases&amp;quot;: [b.tolist() for b in self.biases],&#xA;                &amp;quot;cost&amp;quot;: str(self.cost.__name__)}&#xA;        f = open(filename, &amp;quot;w&amp;quot;)&#xA;        json.dump(data, f)&#xA;        f.close()&#xA;&#xA;#### Loading a Network&#xA;def load(filename):&#xA;    &amp;quot;&amp;quot;&amp;quot;Load a neural network from the file ``filename``.  Returns an&#xA;    instance of Network.&#xA;&#xA;    &amp;quot;&amp;quot;&amp;quot;&#xA;    f = open(filename, &amp;quot;r&amp;quot;)&#xA;    data = json.load(f)&#xA;    f.close()&#xA;    cost = getattr(sys.modules[__name__], data[&amp;quot;cost&amp;quot;])&#xA;    net = Network(data[&amp;quot;sizes&amp;quot;], cost=cost)&#xA;    net.weights = [np.array(w) for w in data[&amp;quot;weights&amp;quot;]]&#xA;    net.biases = [np.array(b) for b in data[&amp;quot;biases&amp;quot;]]&#xA;    return net&#xA;&#xA;#### Miscellaneous functions&#xA;def vectorized_result(j):&#xA;    &amp;quot;&amp;quot;&amp;quot;Return a 10-dimensional unit vector with a 1.0 in the j&#39;th position&#xA;    and zeroes elsewhere.  This is used to convert a digit (0...9)&#xA;    into a corresponding desired output from the neural network.&#xA;&#xA;    &amp;quot;&amp;quot;&amp;quot;&#xA;    e = np.zeros((10, 1))&#xA;    e[j] = 1.0&#xA;    return e&#xA;&#xA;def sigmoid(z):&#xA;    &amp;quot;&amp;quot;&amp;quot;The sigmoid function.&amp;quot;&amp;quot;&amp;quot;&#xA;    return 1.0/(1.0+np.exp(-z))&#xA;&#xA;def sigmoid_prime(z):&#xA;    &amp;quot;&amp;quot;&amp;quot;Derivative of the sigmoid function.&amp;quot;&amp;quot;&amp;quot;&#xA;    return sigmoid(z)*(1-sigmoid(z))&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;神经网络识别手写数字目录&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/29/handwritten-neural-net/&#34;&gt;基于 BP 神经网络的识别手写体数字 - 神经网络基础&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/06/25/handwritten-neural-net02/&#34;&gt;基于 BP 神经网络的手写体数字识别 - 设计与实现&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/06/26/handwritten-neural-net03/&#34;&gt;基于 BP 神经网络的手写体数字识别 - 反向传播算法&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/06/30/handwritten-neural-net04/&#34;&gt;基于 BP 神经网络的手写体数字识别 - 优化&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/06/30/handwritten-neural-net04/" rel="alternate"></link>
    <summary type="html">常见神经网络优化手段一览。</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>基于 BP 神经网络的手写体数字识别 - 反向传播算法</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/06/26/handwritten-neural-net03/</id>
    <content type="html">&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xA;MathJax.Hub.Config({&#xA;  TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; } }&#xA;});&#xA;&lt;/script&gt;&#xA;&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/06/25/handwritten-neural-net02/&#34;&gt;上一篇文章&lt;/a&gt;使用随机梯度下降法实现神经网络自学习的过程。但仍然留有一个问题，如何快速计算代价函数的梯度？这一篇文章将介绍反向传播算法将之解决。&lt;/p&gt;&#xA;&lt;p&gt;反向传播算法最初是由 &lt;a href=&#34;http://en.wikipedia.org/wiki/David_Rumelhart&#34;&gt;David Rumelhart&lt;/a&gt;, &lt;a href=&#34;http://www.cs.toronto.edu/~hinton/&#34;&gt;Geoffrey Hinton&lt;/a&gt;, 和 &lt;a href=&#34;http://en.wikipedia.org/wiki/Ronald_J._Williams&#34;&gt;Ronald Williams&lt;/a&gt; 在其 1986 的&lt;a href=&#34;http://www.nature.com/nature/journal/v323/n6088/pdf/323533a0.pdf&#34;&gt;论文&lt;/a&gt; 中提出的。在该文中，作者将反向传播算法运用到多种神经网络中，其自学习过程都大大加快，并推动了神经网络算法走向实用。今天，反向传播算法可以说是神经网络算法中的“老黄牛”了。&lt;/p&gt;&#xA;&lt;p&gt;其实反向传播不仅仅是一个快速算法那么简单，其还揭示了权重和偏移是如何影响网络的行为。&lt;/p&gt;&#xA;&lt;h2&gt;热身：利用矩阵快速计算神经网络的输出&lt;/h2&gt;&#xA;&lt;p&gt;在讨论反向传播之前，首先来看一下如何快速计算神经网络的输出。虽然上一篇文章中已经介绍了 feedforward 函数，但还是有必要熟悉反向传播算法中使用的数学符号。&lt;/p&gt;&#xA;&lt;p&gt;首先是明确的权重定义。使用 $w^l_{jk}$ 表示权重，代表连接  $(l-1)^{\rm th}$ 层第 $k^{\rm th}$ 个神经元 和 $l^{\rm th}$ 层第 $j^{\rm th}$ 个神经元的权重。举例来说，第二层第四个神经元和第三层第二个神经元之间的权重连接为&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/tikz16.png&#34; alt=&#34;权重连接&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;对于网络的偏移和激励我们将使用类似的符号。即 $b^l_j$ 是 $l^{\rm th}$ 层第 $j^{\rm th}$ 个神经元的偏移，$a^l_j$ 是 $l^{\rm th}$ 层第 $j^{\rm th}$ 个神经元的激励。如图所示：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/tikz17.png&#34; alt=&#34;偏移和激励&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;有了这些记号，第 $l^{\rm th}$ 层第 $j^{\rm th}$ 个神经元的激励 $a^l_j$ 可以由第 $(l-1)^{\rm th}$ 层的所有激励求得：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;a^{l}&lt;em&gt;j = \sigma\left( \sum_k w^{l}&lt;/em&gt;{jk} a^{l-1}_k + b^l_j \right),&#xA;\label{23}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;其中，求和是对第 $(l-1)^{\rm th}$ 层所有的神经元求和。为了将表达式转换成矩阵的形式，这里为每一层 $l$ 定义一个权重矩阵 $w^l$。该矩阵中第 $j^{\rm th}$ 行第 $k^{\rm th}$ 列的元素为 $w^l_{jk}$。类似的，为每一层定义了一个偏移向量 $b^l$，每一个神经元的偏移为 $b^l_j$。最后，我们定义第 $k$ 层所有的激励 $a^l_j$ 的集合为激励向量 $a^l$。&lt;/p&gt;&#xA;&lt;p&gt;对于公式 (\ref{23})，我们还需要向量化函数 $\sigma$。因为我们不是将整个矩阵作为一个参数传递给函数，而是对矩阵的每一个元素应用相同的函数，即 $\sigma(v)$ 的元素为 $\sigma(v)_j = \sigma(v_j)$。举例来说，假如我们有一个函数 $f(x)=x^2$，那么函数 $f$ 的向量化是：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;f\left(\left[ \begin{array}{c} 2 \ 3 \end{array} \right] \right)&#xA;= \left[ \begin{array}{c} f(2) \ f(3) \end{array} \right]&#xA;= \left[ \begin{array}{c} 4 \ 9 \end{array} \right],&#xA;\label{24}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;有了这些，我们将公式 (\ref{23})重写成下列更紧凑的形式：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;a^{l} = \sigma(w^l a^{l-1}+b^l).&#xA;\label{25}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;这个表达式给了我们更全局的视角：本层的激励是如何与上一层的激励相关联的。计算 $a^l$ 时，会计算出中间结构 $z^l \equiv w^l a^{l-1}+b^l$。这一项我们称之为第 $l$ 层的加权输入。$z^l$ 的每一个元素为 $z^l_j= \sum_k w^l_{jk} a^{l-1}_k+b^l_j$，即 $z^l_j$ 是第 $l$ 层第 $j$ 个神经元激励函数的加权输入。公式 (\ref{25}) 有时也会写作 $a^l =\sigma(z^l)$。&lt;/p&gt;&#xA;&lt;h2&gt;代价函数的两个前提假设&lt;/h2&gt;&#xA;&lt;p&gt;反向传播算法是为了计算代价函数 $C$ 的两个偏导数 $\partial C / \partial w$ 和 $\partial C / \partial b$。&#xA;首先看我们的二次代价函数&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;C = \frac{1}{2n} \sum_x |y(x)-a^L(x)|^2,&#xA;\label{26}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;其中 $n$ 是训练数据的总数，求和是对每一个数据求和，$y=y(x)$ 是相应的期望输出，$L$ 是网络的总层数，$a^L = a^L(x)$ 是实际的网络输出。&lt;/p&gt;&#xA;&lt;p&gt;第一个假设是代价函数可以写作时单个训练数据误差 $C_x =\frac{1}{2} |y-a^L |^2$ 的平均值 $C = \frac{1}{n} \sum_x C_x$。这个假设对于后续介绍的其他代价函数也是成立的。&lt;/p&gt;&#xA;&lt;p&gt;之所以这么假设是因为反向传播算法只能够计算单个训练数据的偏导数 $\partial C_x / \partial w$ 和 $\partial C_x / \partial b$。最后对所有数据求平均值得 $\partial C / \partial w$ 和 $\partial C / \partial b$。&lt;/p&gt;&#xA;&lt;p&gt;第二个假设是误差可以写作神经网络输出的函数：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/tikz18.png&#34; alt=&#34;输出的函数&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;例如，二次代价函数就满足这一要求，单个训练数据 $x$ 的二次误差可以写成：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;C = \frac{1}{2} |y-a^L|^2 = \frac{1}{2} \sum_j (y_j-a^L_j)^2,&#xA;\label{27}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;其中，对单个样本来说，$x$ 是定值，期望输出 $y$ 也是定值，唯一的变量就是网络输出 $a^L$，即满足第二条假设。&lt;/p&gt;&#xA;&lt;h2&gt;反向传播的四个基本公式&lt;/h2&gt;&#xA;&lt;p&gt;反向传播算法基于最基本的线性代数操作，比如向量相加、向量与矩阵相乘等。其中有一个比较少见，假设 $s$ 和 $t$ 是两个同维的向量，我们定义 $s \odot t$ 为两个向量对应分量的乘积。那么其每个元素为 $(s \odot t)_j = s_jt_j$。例如，&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\left[\begin{array}{c} 1 \\ 2 \end{array}\right]&#xA;\odot \left[\begin{array}{c} 3 \\ 4\end{array} \right]&#xA;= \left[ \begin{array}{c} 1 \times 3 \\ 2 \times 4 \end{array} \right]&#xA;= \left[ \begin{array}{c} 3 \\ 8 \end{array} \right].&#xA;\label{28}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;这种元素对元素的乘积也称作 Hadamard 积或者是 Schur 积。Numpy 对这种运算有着良好的优化。&lt;/p&gt;&#xA;&lt;p&gt;然后我们继续引入一个中间变量 $\delta^l_j$，我们称作第 $l$ 层第 $j$ 个神经元的误差。为了形象地理解误差到底是什么，假设在我们的神经网络中有一个小妖精：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/tikz19.png&#34; alt=&#34;网络中的小妖精&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这个妖精坐在 $l$ 层的第 $j$ 个神经元上。当输入到来时，它故意扰乱神经元的正常工作。它在神经元的加权输入中加入了一个小的变化 $\Delta z^l_j$，这样输出变成了 $\sigma(z^l_j+\Delta z^l_j)$。这个变化向后层神经网络传递，最终到输出层导致误差相应地改变为 $\frac{\partial C}{\partial z^l_j} \Delta z^l_j$。&lt;/p&gt;&#xA;&lt;p&gt;现在，我们钦定了这个妖精是个好妖精，在试图帮助我们减小误差。当 $\frac{\partial C}{\partial z^l_j}$ 是个很大的正数（负数）时，通过选择 $\Delta z^l_j$ 为负值（正）即可减小误差。但如果 $\frac{\partial C}{\partial z^l_j}$ 接近于零，那么这时这个好妖精无论做什么都对误差结果影响不大，这时可以认为网络接近最优值。&lt;/p&gt;&#xA;&lt;p&gt;以上说明 $\frac{\partial C}{\partial z^l_j}$ 是一个可以用来量化神经元误差 的量。所以我们定义&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\delta^l_j \equiv \frac{\partial C}{\partial z^l_j}.&#xA;\label{29}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;你可能会奇怪为什么要引入一个新的中间量--加权输入 $z^l_j$，而不是直接使用激励 $a^l_j$？纯粹是因为这个中间量让最后的反向传播表达式更简洁。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;输出层的误差&lt;/strong&gt;，$\delta^L$，该误差分量由下式给出&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\delta^L_j = \frac{\partial C}{\partial a^L_j} \sigma&#39;(z^L_j).&#xA;\tag{BP1}\label{BP1}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;这是一个非常自然的表达式，等式右边第一项为 $\partial C / \partial a^L_j$，反映了误差在第 $j$ 个输出激励影响下变化的速度。若某个特定的输出神经元对误差 $C$ 影响不大，则 $\delta^L_j$ 很小。右边第二项为 $\sigma&#39;(z^L_j)$，反应了 $z^L_j$ 对激励函数 $\delta$ 的影响。&lt;/p&gt;&#xA;&lt;p&gt;公式 (\ref{BP1}) 非常容易计算。加权输入在 feedforward 正向传播时即可顺便计算，而 sigmoid 激励函数和二次代价函数的偏导也易可得。鉴于 (\ref{BP1}) 是以每个元素的形式给出的，有必要改写成矩阵的形式：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\delta^L = \nabla_a C \odot \sigma&#39;(z^L).&#xA;\tag{BP1a}\label{BP1a}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;这里，$\nabla_a C$ 是偏导数 $\partial C / \partial a^L_j$ 组成的向量。你可以认为 $\nabla_a C$ 反映了误差相对于输出激励的变化。由二次代价函数 $C = \frac{1}{2} \sum_j (y_j-a_j)^2$ 的偏导数 $\partial C / \partial a^L_j = (a_j-y_j)$ 可得：$\nabla_a C =(a^L-y)$。最终公式 (\ref{BP1}) 变成&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\delta^L = (a^L-y) \odot \sigma&#39;(z^L).&#xA;\label{30}\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;通过下一层误差可以求本层误差&lt;/strong&gt;，即&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\delta^l = ((w^{l+1})^T \delta^{l+1}) \odot \sigma&#39;(z^l),&#xA;\tag{BP2}\label{BP2}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;初看上去这个公式有点复杂，但其意义显而易见。$l+1$ 层的误差 $\delta^{l+1}$，通过权重矩阵的转置 $(w^{l+1})^T$ 反向转播到第 $l$ 层，然后与 $\sigma&#39;(z^l)$ 做 Hadamard 积即可求得 $l$ 层的误差。&lt;/p&gt;&#xA;&lt;p&gt;通过公式 (\ref{BP1}) 和公式 (\ref{BP2}) 的组合，每一层的误差都能求得。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;误差相对于偏移的变化率&lt;/strong&gt;，即偏导数为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}  \frac{\partial C}{\partial b^l_j} =&#xA;\delta^l_j.&#xA;\tag{BP3}\label{BP3}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;这意味着其偏导数就是误差的值本身，我们也可以简写为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\frac{\partial C}{\partial b} = \delta,&#xA;\label{31}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;误差相对于权重的变化率&lt;/strong&gt;，即偏导数为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\frac{\partial C}{\partial w^l_{jk}} = a^{l-1}_k \delta^l_j.&#xA;\tag{BP4}\label{BP4}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;这意味着我们可以通过上一层的激励和本层的误差来求取偏导数，我们也可以简写为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&lt;br&gt;&#xA;\frac{\partial C}{\partial w} = a_{\rm in} \delta_{\rm out},&#xA;\label{32}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;上一层的激励如果接近于零，$a_{\rm in} \approx 0$，那么 $\partial C / \partial w$ 也会非常小，这种情况下，权重的自学习速度减慢了。&lt;/p&gt;&#xA;&lt;h2&gt;反向传播算法&lt;/h2&gt;&#xA;&lt;p&gt;由公式 (\ref{BP1})-(\ref{BP4}) 即可得反向传播算法的步骤如下：&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;首先，输入一个 mini-batch 量的训练数据。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;然后，对每一个训练数据 $x$ 施加以下步骤：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;正向传播&lt;/strong&gt;：对每一层 $l=2,3,...,L$ 计算 $z^{x,l} = w^l a^{x,l-1}+b^l$ 和 $a^{x,l} = \sigma(z^{x,l})$。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;计算最后一层误差&lt;/strong&gt; $\delta^{x,L}$：计算向量 $\delta^{x,L} = \nabla_a C_x \odot \sigma&#39;(z^{x,L})$。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;反向传播误差&lt;/strong&gt;：对每一层 $l=L-1,L-2,...,2$ 计算 $\delta^{x,l} = ((w^{l+1})^T \delta^{x,l+1})\odot \sigma&#39;(z^{x,l})$。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;**最后，为这个 mini-batch 中的训练数据计算下降的梯度：**对于每一层 $l=L,L-1,...,2$ 更新权重和偏移 $w^l \rightarrow w^l-\frac{\eta}{m} \sum_x \delta^{x,l} (a^{x,l-1})^T, b^l \rightarrow b^l-\frac{\eta}{m}\sum_x \delta^{x,l}$。&lt;/p&gt;&#xA;&lt;p&gt;写成代码即为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;   def backprop(self, x, y):&#xA;        &amp;quot;&amp;quot;&amp;quot;Return a tuple &amp;quot;(nabla_b, nabla_w)&amp;quot; representing the&#xA;        gradient for the cost function C_x.  &amp;quot;nabla_b&amp;quot; and&#xA;        &amp;quot;nabla_w&amp;quot; are layer-by-layer lists of numpy arrays, similar&#xA;        to &amp;quot;self.biases&amp;quot; and &amp;quot;self.weights&amp;quot;.&amp;quot;&amp;quot;&amp;quot;&#xA;        nabla_b = [np.zeros(b.shape) for b in self.biases]&#xA;        nabla_w = [np.zeros(w.shape) for w in self.weights]&#xA;        # feedforward&#xA;        activation = x&#xA;        activations = [x] # list to store all the activations, layer by layer&#xA;        zs = [] # list to store all the z vectors, layer by layer&#xA;        for b, w in zip(self.biases, self.weights):&#xA;            z = np.dot(w, activation)+b&#xA;            zs.append(z)&#xA;            activation = sigmoid(z)&#xA;            activations.append(activation)&#xA;        # backward pass&#xA;        delta = self.cost_derivative(activations[-1], y) * \&#xA;            sigmoid_prime(zs[-1])&#xA;        nabla_b[-1] = delta&#xA;        nabla_w[-1] = np.dot(delta, activations[-2].transpose())&#xA;        # Note that the variable l in the loop below is used a little&#xA;        # differently to the notation in Chapter 2 of the book.  Here,&#xA;        # l = 1 means the last layer of neurons, l = 2 is the&#xA;        # second-last layer, and so on.  It&#39;s a renumbering of the&#xA;        # scheme in the book, used here to take advantage of the fact&#xA;        # that Python can use negative indices in lists.&#xA;        for l in xrange(2, self.num_layers):&#xA;            z = zs[-l]&#xA;            sp = sigmoid_prime(z)&#xA;            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp&#xA;            nabla_b[-l] = delta&#xA;            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())&#xA;        return (nabla_b, nabla_w)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;神经网络识别手写数字目录&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/29/handwritten-neural-net/&#34;&gt;基于 BP 神经网络的识别手写体数字 - 神经网络基础&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/06/25/handwritten-neural-net02/&#34;&gt;基于 BP 神经网络的手写体数字识别 - 设计与实现&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/06/26/handwritten-neural-net03/&#34;&gt;基于 BP 神经网络的手写体数字识别 - 反向传播算法&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/06/30/handwritten-neural-net04/&#34;&gt;基于 BP 神经网络的手写体数字识别 - 优化&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/06/26/handwritten-neural-net03/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>基于 BP 神经网络的手写体数字识别 - 设计与实现</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/06/25/handwritten-neural-net02/</id>
    <content type="html">&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xA;MathJax.Hub.Config({&#xA;  TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; } }&#xA;});&#xA;&lt;/script&gt;&#xA;&lt;h2&gt;手写体数字识别的神经网络结构&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/29/handwritten-neural-net/&#34;&gt;上一篇文章&lt;/a&gt;中我们简单介绍了神经网络，接下来让我们运用到主题中 —— 手写体数字识别。&lt;/p&gt;&#xA;&lt;p&gt;手写数字识别可以分为两大子问题。第一是如何将一串数字分割成单个的数字，第二是识别单个数字。我们将专注于解决第二个问题，因为分割问题并不难，而且和我们的主题——神经网络相差甚远。&lt;/p&gt;&#xA;&lt;p&gt;为了识别单个的数字，我们将使用三层神经网络：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/three-layers.png&#34; alt=&#34;三层神经网络&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;输入层的神经元将对输入的像素值编码。神经网络的训练数据包含了 $28 \times 28$ 像素的扫描图，所以输入层有 $784 = 28 \times 28$ 个神经元。为了简便起见，上图中没有 $784$ 个输入神经元全部画出。每一个像素是灰度值，$0.0$ 代表白色，$1.0$ 代表黑色，两者之间的为逐渐变黑的灰色。&lt;/p&gt;&#xA;&lt;p&gt;第二层是隐藏层。让我们记隐藏层的神经元数量为 $n$，我们将对 $n$ 的不同值实验。上图中，$n=15$。&lt;/p&gt;&#xA;&lt;p&gt;输出层包含 $10$ 个神经元。如果第一个输出被激活了，即 $\mbox{output} \approx 1$，意味着神经网络判定当前数字为 $0$。如果第二个输出神经元被激活，则神经网络认为当前数字很有可能为 $1$。以此类推。最后对 $10$ 个输出神经元进行排序，哪个最高说明神经网络认为其最有可能。比如第 $6$ 个神经元输出最高，则输入图像最有可能是数字 $6$。&lt;/p&gt;&#xA;&lt;p&gt;你可能会想为什么会用十个输出神经元？毕竟我们的目标是判断出每一个图片对应的数字，理论上，四个输出的组合就可以编码，$2^4 = 16$ 完全可以包含 $10$ 个值。要回答这个问题还是得靠实验：我们对两种输出编码方案都做了实验，用 $10$ 个输出的效果更好。让我们做一个启发式的思考，用四个 bit 来唯一确定一个数字，意味着得百分百识别出图像，说一不二。而有些时候字确实写的难以辨认，连人类自己都只能说‘大概是 4 或者 9’这种话，这时候，给出 $10$ 个数字的概率更符合人脑的思维方式。&lt;/p&gt;&#xA;&lt;h2&gt;基于梯度下降法学习&lt;/h2&gt;&#xA;&lt;p&gt;现在我们已经设计出神经网络的结构了，那如何识别出数字呢？第一件事是找到训练集。我们将使用 &lt;a href=&#34;http://yann.lecun.com/exdb/mnist/&#34;&gt;MNIST 数据集&lt;/a&gt;。MNIST 是经过修改的 &lt;a href=&#34;http://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology&#34;&gt;NIST&lt;/a&gt; 数据子集，NIST 即 United States&#39; National Institute of Standards and Technology。以下是部分数据：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/some-samples.png&#34; alt=&#34;部分数据&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;图像已经被分割成单个的数字，而且没有噪点等，不需要做图像预处理。MNIST 数据集包括两部分，第一部分包含 60000 个图像，被用作训练数据。这些图像来自 250 个人，半数来自美国人口普查局的员工，另外半数是高中生。图片是 $28 \times 28$ 的灰度图。第二部分是 10000 张图片的测试集。我们将使用测试集来评估人工神经网络的学习效果。为了取得更好的测试效果，测试集来自另外 250 个人。这样，测试集和训练集的完全不同能够更好验证结果。&lt;/p&gt;&#xA;&lt;p&gt;我们将使用 $x$ 来标记训练输入。虽然图片是一个二维数组，不过我们输入会采用 $28 \times 28 = 784$ 的向量。向量中的每一项为图片每一个像素的灰度值。输出我们将记为输出向量 $y = y(x)$。如果一个训练图片是数字 6，则 $y(x) = (0, 0, 0, 0, 0, 0, 1, 0, 0, 0)^\mathrm{T}$。请注意，$\mathrm{T}$ 是转置操作。&lt;/p&gt;&#xA;&lt;p&gt;算法的目标是找到权重和偏移，对于所有训练输入 $x$，网络都能够输出正确的 $y(x)$。为了量化我们与目标的接近程度，定义以下的代价函数：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}  C(w,b) \equiv&#xA;\frac{1}{2n} \sum_x | y(x) - a|^2.  \label{6}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;这里，记 $w$ 为网络所有的权重集，$b$ 为所有的偏移，$n$ 为训练输入的总数，$a$ 为实际的输出向量，求和是对所有训练输入而言。当然，$a$ 应该是 $x,w,b$ 的函数。记号 $| v |$ 为向量 $v$ 的长度。我们称 $C$ 为二次代价函数，其实就是均方差啦， MSE (mean squared error)。可以看出，该代价函数为非负值，并且，当所有训练数据的 $y(x)$ 接近实际输出 $a$ 时，代价函数 $C(w,b) \approx 0$。所以，当神经网络工作良好的时候，$C(w,b)$ 很小，相反，该值会很大，即训练集中有很大一部分预期输出 $y(x)$ 和实际输出 $a$ 不符。我们训练算法的目标，就是找到一组权重和偏移，让误差尽可能的小。&lt;/p&gt;&#xA;&lt;p&gt;为什么会用二次函数误差？毕竟我们感兴趣的是能被正确分类的图片数量。为什么不直接以图片数量为目标，比如目标是识别的数量最大化？问题是，正确分类图像的数量不是权值和偏置的光滑函数，大部分情况下，变量的变化不会导致识别数量的变化，也就难以调整权重和偏移。&lt;/p&gt;&#xA;&lt;p&gt;你可能还会好奇，二次函数是最好的选择吗？其他的代价函数会不会得到完全不同的权值和偏移，效果更好呢？事实上，确实有更好的代价函数，以后的文章还会继续探讨。不过，本文继续使用二次函数，它对我们理解神经网络的基本自学习过程非常有益。&lt;/p&gt;&#xA;&lt;p&gt;接下来，我们介绍梯度下降法，它可以用来解决最小化问题。&lt;/p&gt;&#xA;&lt;p&gt;假设我们要最小化函数 $C(v), v=v_1,v_2$。该函数图像为：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/func_plot.png&#34; alt=&#34;函数图像&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;我们要找到 $C$ 的全局最小值。一种做法是计算函数的导数，找到各个极值。课本上的导数很好求解。不幸的是，现实生活中，问题所代表的函数经常包含过多的变量。尤其是神经网络中，有数以万计的权值和偏移，不可能直接求取极值。&lt;/p&gt;&#xA;&lt;p&gt;幸好还有其他方法。让我们换种思维方式，对比那个函数图像，将函数看作一个山谷，并假设有一个小球沿着山谷斜坡滑动。直觉告诉我们小球最终会滑向坡底。也许这就能用来找到最小值？我们为“小球”随机选择一个起点，然后模拟“小球”沿斜坡滑动。“小球”运动的方向可以通过偏导数确定，这些偏导数包含了山谷形状的信息。&lt;/p&gt;&#xA;&lt;p&gt;是否需要牛顿力学公式来获取小球的运动，考虑摩擦力和重力呢？并不需要，我们是在制定一个最小化 $C$ 的算法，而不是去精确模拟物理学规律。&lt;/p&gt;&#xA;&lt;p&gt;让我们记球在 $v_1$ 方向移动了很小的量 $\Delta v_1$，在 $v_2$ 的方向移动了 $\Delta v_2$，总的 $C$ 的改变量为：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\Delta C \approx \frac{\partial C}{\partial v_1} \Delta v_1 +&#xA;\frac{\partial C}{\partial v_2} \Delta v_2.&#xA;\label{7}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;我们目标是找到一组 $\Delta v_1$ 和 $\Delta v_2$，使 $\Delta C$ 为负，即使球向谷底滚去。接下来记 $\Delta v \equiv (\Delta v_1, \Delta v_2)^T$ 为 $v$ 的总变化，并且记梯度向量 $\nabla C$ 为：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\nabla C \equiv \left( \frac{\partial C}{\partial v_1},&#xA;\frac{\partial C}{\partial v_2} \right)^T.&#xA;\label{8}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;其中梯度向量符号 $\nabla C$ 会比较抽象，因为它纯粹就是一个数学上的概念。有了梯度符号，我们可以将式 (\ref{8}) 改写为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\Delta C \approx \nabla C \cdot \Delta v.&#xA;\label{9}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;从该式可以看出，梯度向量 $\nabla C$ 将 $v$ 的变化反应到 $C$ 中，且我们也找到了如何让 $\Delta C$ 为负的方法。尤其是当我们选择&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\Delta v = -\eta \nabla C,&#xA;\label{10}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;当 $\eta$ 是一个很小的正参数时（其实该参数就是学习率），公式 (\ref{9}) 表明 $\Delta C \approx -\eta\nabla C \cdot \nabla C = -\eta |\nabla C|^2$。因为 $| \nabla C|^2 \geq 0$，能保证 $\Delta C \leq 0$。这正是我们需要的特性！在梯度下降学习法中，我们使用公式 (\ref{10}) 计算 $\Delta v$，然后移动球到新的位置：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;v \rightarrow v&#39; = v -\eta \nabla C.&#xA;\label{11}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;然后不停使用这一公式计算下一步，直到 $C$ 不再减小为止，即找到了全局最小值。&lt;/p&gt;&#xA;&lt;p&gt;总结一下，首先重复计算梯度 $\nabla C$，然后向相反方向移动，画成图就是&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201606/gradient.png&#34; alt=&#34;梯度学习法&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;请注意，上述梯度下降的规则并没有复制出真正的物理运动。在真实生活中，球有动量，滚向谷底后还会继续滚上去，在摩擦力的作用下才会最终停下。但我们的算法中没这么复杂。&lt;/p&gt;&#xA;&lt;p&gt;为了使算法正常工作，公式 (\ref{9}) 中的学习率 $\eta$ 要尽可能的小，不然最终可能 $\Delta C &amp;gt; 0$。同时学习率不能过小，不然会导致每一次迭代中 $\Delta v$ 过小，算法工作会非常慢。&lt;/p&gt;&#xA;&lt;p&gt;尽管到现在我们一直用两个变量的函数 $C$ 举例。但其实对于多变量的函数，这仍是适用的。假设 $C$ 有 $m$ 个变量，$v_1,..., v_m$，那么变化 $\Delta C$ 为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\Delta C \approx \nabla C \cdot \Delta v,&#xA;\label{12}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;其中 $\Delta v = (\Delta v_1,\ldots, \Delta v_m)^T$，梯度向量 $\nabla C$ 为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\nabla C \equiv \left(\frac{\partial C}{\partial v_1}, \ldots,&#xA;\frac{\partial C}{\partial v_m}\right)^T.&#xA;\label{13}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;梯度下降法虽然简单，但实际上很有效，也是一个经典的最优化方法，在神经网络中我们将用它来寻找代价函数的最小值。&lt;/p&gt;&#xA;&lt;p&gt;同时，人们研究了大量梯度下降法的变种，包括去模拟真实的物理学，但都效果不好。因为这些变种算法不光计算一次偏导数，还需要计算二次偏导，这对计算机来说是巨大的挑战，尤其是有着上百万神经元的神经网络。&lt;/p&gt;&#xA;&lt;p&gt;我们将使用梯度下降法来来找到权重 $w_k$ 和偏移 $b_l$。类比上述的梯度法，这里变量 $v_j$ 即为权重和偏移，而梯度 $\nabla C$ 为 $\partial C / \partial w_k$ 和 $\partial C/ \partial b_l$。梯度下降的更新规则如下：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;w_k &amp;amp; \rightarrow &amp;amp; w_k&#39; = w_k-\eta \frac{\partial C}{\partial w_k} \label{16}\\&#xA;b_l &amp;amp; \rightarrow &amp;amp; b_l&#39; = b_l-\eta \frac{\partial C}{\partial b_l}.&#xA;\label{17}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;重复上述规则，找到代价函数的最小值，实现神经网络的自学习。&lt;/p&gt;&#xA;&lt;p&gt;在适用梯度下降法时仍有一些挑战，比如公式 (\ref{6}) 中代价函数是每一个训练样本的误差 $C_x \equiv \frac{|y(x)-a|^2}{2}$ 的平均值。这意味着计算梯度时，需要每一个训练样本计算梯度。当样本数量很多时，就会造成性能的问题。&lt;/p&gt;&#xA;&lt;p&gt;随机梯度下降法能够解决这一问题，加速学习过程。算法每次随机从训练输入中选取 $m$ 个数据，$X_1, X_2,\ldots, X_m $，记为 mini-batch。当 $m$ 足够大时，$\nabla C_{X_j}$ 将十分接近所有样本的平均值 $\nabla C_x$，即&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\frac{\sum_{j=1}^m \nabla C_{X_{j}}}{m} \approx \frac{\sum_x \nabla C_x}{n} = \nabla C,&#xA;\label{18}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;交换等式两边得&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\nabla C \approx \frac{1}{m} \sum_{j=1}^m \nabla C_{X_{j}},&#xA;\label{19}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;这样，我们把总体的梯度转换成计算随机选取的 mini-batch 的梯度。将随机梯度下降法运用到神经网络中，则权重和偏移为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;w_k  \rightarrow &amp;amp; w_k&#39; = w_k-\frac{\eta}{m}  \sum_j \frac{\partial C_{X_j}}{\partial w_k}&#xA;\label{20}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;b_l  \rightarrow &amp;amp; b_l&#39; = b_l-\frac{\eta}{m}  \sum_j \frac{\partial C_{X_j}}{\partial b_l},&#xA;\label{21}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;其中，求和是对当前 mini-batch 中训练样本 $X_j$ 求和。然后选取下一组 mini-batch 重复上述过程，直到所有的训练输入全部选取完成，训练的一个 epoch 完成。&#xA;接着我们可以开始一个新的 epoch。&lt;/p&gt;&#xA;&lt;p&gt;对于 MNIST 数据集来说，一共有 $n=60000$ 个数据，如果选择 mini-batch 的大小 $m=10$，则计算梯度的速度可以比原先快 $6000$ 倍。当然，加速计算的结果只是近似值，尽管会有一些统计学上的波动，但精确的梯度计算并不重要，只要小球下降的大方向不错就行。为什么我敢这么说，因为实践证明了啊，随机梯度也是大多数自学习算法的基石。&lt;/p&gt;&#xA;&lt;h2&gt;代码实现&lt;/h2&gt;&#xA;&lt;p&gt;我们将官方的 MNIST 数据分成三部分，50000 个训练集，10000 个验证集，10000 个测试集。验证集用于在训练过程中实时观察神经网络正确率的变化，测试集用于测试最终神经网络的正确率。&lt;/p&gt;&#xA;&lt;p&gt;下面介绍一下代码的核心部分。首先是 Network 类的初始化部分：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Network(object):&#xA;&#xA;    def __init__(self, sizes):&#xA;        self.num_layers = len(sizes)&#xA;        self.sizes = sizes&#xA;        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]&#xA;        self.weights = [np.random.randn(y, x) &#xA;                        for x, y in zip(sizes[:-1], sizes[1:])]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;列表 sizes 表示神经网络每一层所包含的神经元个数。比如我们想创建一个 2 个输入神经元，3 个神经元在中间层，一个输出神经元的网络，那么可以&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;net = Network([2, 3, 1])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;偏移和权重都是使用 np.random.randn 函数随机初始化的，平均值为 0，标准差为 1。这种随机初始化并不是最佳方案，后续文章会逐步优化。&lt;/p&gt;&#xA;&lt;p&gt;请注意，偏移和权重被初始化为 Numpy 矩阵。net.weights[1] 代表连接第二和第三层神经元的权重。&lt;/p&gt;&#xA;&lt;p&gt;下面是 sigmoid 函数的定义：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def sigmoid(z):&#xA;    return 1.0/(1.0+np.exp(-z))&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;注意到虽然输入 $z$ 是向量，但 Numpy 能够自动处理，为向量中的每一个元素作相同的 sigmoid 运算。&lt;/p&gt;&#xA;&lt;p&gt;然后是计算 sigmoid 函数的导数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def sigmoid_prime(z):&#xA;    &amp;quot;&amp;quot;&amp;quot;Derivative of the sigmoid function.&amp;quot;&amp;quot;&amp;quot;&#xA;    return sigmoid(z)*(1-sigmoid(z))&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;每一层相对于前一层的输出为&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;a&#39; = \sigma(w a + b).&#xA;\label{22}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;对应的是 feedforward 函数当：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    def feedforward(self, a):&#xA;        &amp;quot;&amp;quot;&amp;quot;Return the output of the network if &amp;quot;a&amp;quot; is input.&amp;quot;&amp;quot;&amp;quot;&#xA;        for b, w in zip(self.biases, self.weights):&#xA;            a = sigmoid(np.dot(w, a)+b)&#xA;        return a&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当然，Network 对象最重要的任务还是自学习。下面的 SGD 函数实现了随机梯度下降法：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    def SGD(self, training_data, epochs, mini_batch_size, eta,&#xA;            test_data=None):&#xA;        &amp;quot;&amp;quot;&amp;quot;Train the neural network using mini-batch stochastic&#xA;        gradient descent.  The &amp;quot;training_data&amp;quot; is a list of tuples&#xA;        &amp;quot;(x, y)&amp;quot; representing the training inputs and the desired&#xA;        outputs.  The other non-optional parameters are&#xA;        self-explanatory.  If &amp;quot;test_data&amp;quot; is provided then the&#xA;        network will be evaluated against the test data after each&#xA;        epoch, and partial progress printed out.  This is useful for&#xA;        tracking progress, but slows things down substantially.&amp;quot;&amp;quot;&amp;quot;&#xA;        if test_data: n_test = len(test_data)&#xA;        n = len(training_data)&#xA;        for j in xrange(epochs):&#xA;            random.shuffle(training_data)&#xA;            mini_batches = [&#xA;                training_data[k:k+mini_batch_size]&#xA;                for k in xrange(0, n, mini_batch_size)]&#xA;            for mini_batch in mini_batches:&#xA;                self.update_mini_batch(mini_batch, eta)&#xA;            if test_data:&#xA;                print &amp;quot;Epoch {0}: {1} / {2}&amp;quot;.format(&#xA;                    j, self.evaluate(test_data), n_test)&#xA;            else:&#xA;                print &amp;quot;Epoch {0} complete&amp;quot;.format(j)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;列表 training_data 是由 (x,y) 元组构成，代表训练集的输入和期望输出。而 test_data 则是验证集（非测试集，这里变量名有些歧义），在每一个 epoch 结束时对神经网络正确率做一下检测。其他变量的含义比较显见，不再赘述。&lt;/p&gt;&#xA;&lt;p&gt;SGD 函数在每一个 epoch 开始时随机打乱训练集，然后按照 mini-batch 的大小对数据分割。在每一步中对一个 mini_batch 计算梯度，在 self.update_mini_batch(mini_batch, eta) 更新权重和偏移：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    def update_mini_batch(self, mini_batch, eta):&#xA;        &amp;quot;&amp;quot;&amp;quot;Update the network&#39;s weights and biases by applying&#xA;        gradient descent using backpropagation to a single mini batch.&#xA;        The &amp;quot;mini_batch&amp;quot; is a list of tuples &amp;quot;(x, y)&amp;quot;, and &amp;quot;eta&amp;quot;&#xA;        is the learning rate.&amp;quot;&amp;quot;&amp;quot;&#xA;        nabla_b = [np.zeros(b.shape) for b in self.biases]&#xA;        nabla_w = [np.zeros(w.shape) for w in self.weights]&#xA;        for x, y in mini_batch:&#xA;            delta_nabla_b, delta_nabla_w = self.backprop(x, y)&#xA;            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]&#xA;            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]&#xA;        self.weights = [w-(eta/len(mini_batch))*nw &#xA;                        for w, nw in zip(self.weights, nabla_w)]&#xA;        self.biases = [b-(eta/len(mini_batch))*nb &#xA;                       for b, nb in zip(self.biases, nabla_b)]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;其中最关键的是&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;            delta_nabla_b, delta_nabla_w = self.backprop(x, y)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这就是反向转播算法，这是一个快速计算代价函数梯度的方法。所以 update_mini_batch 仅仅是计算这些梯度，然后用来更新 self.weights 和 self.biases。这里暂时不介绍它，它牵涉较多内容，下一篇文章会重点阐述。&lt;/p&gt;&#xA;&lt;p&gt;让我们看一下 &lt;a href=&#34;https://github.com/mnielsen/neural-networks-and-deep-learning/tree/master/src&#34;&gt;完整的程序&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#### Libraries&#xA;# Standard library&#xA;import random&#xA;&#xA;# Third-party libraries&#xA;import numpy as np&#xA;&#xA;class Network(object):&#xA;&#xA;    def __init__(self, sizes):&#xA;        &amp;quot;&amp;quot;&amp;quot;The list ``sizes`` contains the number of neurons in the&#xA;        respective layers of the network.  For example, if the list&#xA;        was [2, 3, 1] then it would be a three-layer network, with the&#xA;        first layer containing 2 neurons, the second layer 3 neurons,&#xA;        and the third layer 1 neuron.  The biases and weights for the&#xA;        network are initialized randomly, using a Gaussian&#xA;        distribution with mean 0, and variance 1.  Note that the first&#xA;        layer is assumed to be an input layer, and by convention we&#xA;        won&#39;t set any biases for those neurons, since biases are only&#xA;        ever used in computing the outputs from later layers.&amp;quot;&amp;quot;&amp;quot;&#xA;        self.num_layers = len(sizes)&#xA;        self.sizes = sizes&#xA;        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]&#xA;        self.weights = [np.random.randn(y, x)&#xA;                        for x, y in zip(sizes[:-1], sizes[1:])]&#xA;&#xA;    def feedforward(self, a):&#xA;        &amp;quot;&amp;quot;&amp;quot;Return the output of the network if ``a`` is input.&amp;quot;&amp;quot;&amp;quot;&#xA;        for b, w in zip(self.biases, self.weights):&#xA;            a = sigmoid(np.dot(w, a)+b)&#xA;        return a&#xA;&#xA;    def SGD(self, training_data, epochs, mini_batch_size, eta,&#xA;            test_data=None):&#xA;        &amp;quot;&amp;quot;&amp;quot;Train the neural network using mini-batch stochastic&#xA;        gradient descent.  The ``training_data`` is a list of tuples&#xA;        ``(x, y)`` representing the training inputs and the desired&#xA;        outputs.  The other non-optional parameters are&#xA;        self-explanatory.  If ``test_data`` is provided then the&#xA;        network will be evaluated against the test data after each&#xA;        epoch, and partial progress printed out.  This is useful for&#xA;        tracking progress, but slows things down substantially.&amp;quot;&amp;quot;&amp;quot;&#xA;        if test_data: n_test = len(test_data)&#xA;        n = len(training_data)&#xA;        for j in xrange(epochs):&#xA;            random.shuffle(training_data)&#xA;            mini_batches = [&#xA;                training_data[k:k+mini_batch_size]&#xA;                for k in xrange(0, n, mini_batch_size)]&#xA;            for mini_batch in mini_batches:&#xA;                self.update_mini_batch(mini_batch, eta)&#xA;            if test_data:&#xA;                print &amp;quot;Epoch {0}: {1} / {2}&amp;quot;.format(&#xA;                    j, self.evaluate(test_data), n_test)&#xA;            else:&#xA;                print &amp;quot;Epoch {0} complete&amp;quot;.format(j)&#xA;&#xA;    def update_mini_batch(self, mini_batch, eta):&#xA;        &amp;quot;&amp;quot;&amp;quot;Update the network&#39;s weights and biases by applying&#xA;        gradient descent using backpropagation to a single mini batch.&#xA;        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``&#xA;        is the learning rate.&amp;quot;&amp;quot;&amp;quot;&#xA;        nabla_b = [np.zeros(b.shape) for b in self.biases]&#xA;        nabla_w = [np.zeros(w.shape) for w in self.weights]&#xA;        for x, y in mini_batch:&#xA;            delta_nabla_b, delta_nabla_w = self.backprop(x, y)&#xA;            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]&#xA;            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]&#xA;        self.weights = [w-(eta/len(mini_batch))*nw&#xA;                        for w, nw in zip(self.weights, nabla_w)]&#xA;        self.biases = [b-(eta/len(mini_batch))*nb&#xA;                       for b, nb in zip(self.biases, nabla_b)]&#xA;&#xA;    def backprop(self, x, y):&#xA;        &amp;quot;&amp;quot;&amp;quot;Return a tuple ``(nabla_b, nabla_w)`` representing the&#xA;        gradient for the cost function C_x.  ``nabla_b`` and&#xA;        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar&#xA;        to ``self.biases`` and ``self.weights``.&amp;quot;&amp;quot;&amp;quot;&#xA;        nabla_b = [np.zeros(b.shape) for b in self.biases]&#xA;        nabla_w = [np.zeros(w.shape) for w in self.weights]&#xA;        # feedforward&#xA;        activation = x&#xA;        activations = [x] # list to store all the activations, layer by layer&#xA;        zs = [] # list to store all the z vectors, layer by layer&#xA;        for b, w in zip(self.biases, self.weights):&#xA;            z = np.dot(w, activation)+b&#xA;            zs.append(z)&#xA;            activation = sigmoid(z)&#xA;            activations.append(activation)&#xA;        # backward pass&#xA;        delta = self.cost_derivative(activations[-1], y) * \&#xA;            sigmoid_prime(zs[-1])&#xA;        nabla_b[-1] = delta&#xA;        nabla_w[-1] = np.dot(delta, activations[-2].transpose())&#xA;        # Note that the variable l in the loop below is used a little&#xA;        # differently to the notation in Chapter 2 of the book.  Here,&#xA;        # l = 1 means the last layer of neurons, l = 2 is the&#xA;        # second-last layer, and so on.  It&#39;s a renumbering of the&#xA;        # scheme in the book, used here to take advantage of the fact&#xA;        # that Python can use negative indices in lists.&#xA;        for l in xrange(2, self.num_layers):&#xA;            z = zs[-l]&#xA;            sp = sigmoid_prime(z)&#xA;            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp&#xA;            nabla_b[-l] = delta&#xA;            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())&#xA;        return (nabla_b, nabla_w)&#xA;&#xA;    def evaluate(self, test_data):&#xA;        &amp;quot;&amp;quot;&amp;quot;Return the number of test inputs for which the neural&#xA;        network outputs the correct result. Note that the neural&#xA;        network&#39;s output is assumed to be the index of whichever&#xA;        neuron in the final layer has the highest activation.&amp;quot;&amp;quot;&amp;quot;&#xA;        test_results = [(np.argmax(self.feedforward(x)), y)&#xA;                        for (x, y) in test_data]&#xA;        return sum(int(x == y) for (x, y) in test_results)&#xA;&#xA;    def cost_derivative(self, output_activations, y):&#xA;        &amp;quot;&amp;quot;&amp;quot;Return the vector of partial derivatives \partial C_x /&#xA;        \partial a for the output activations.&amp;quot;&amp;quot;&amp;quot;&#xA;        return (output_activations-y)&#xA;&#xA;#### Miscellaneous functions&#xA;def sigmoid(z):&#xA;    &amp;quot;&amp;quot;&amp;quot;The sigmoid function.&amp;quot;&amp;quot;&amp;quot;&#xA;    return 1.0/(1.0+np.exp(-z))&#xA;&#xA;def sigmoid_prime(z):&#xA;    &amp;quot;&amp;quot;&amp;quot;Derivative of the sigmoid function.&amp;quot;&amp;quot;&amp;quot;&#xA;    return sigmoid(z)*(1-sigmoid(z))&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;让我们来看一下这个最简单的 BP 神经网络在手写数字识别上效果如何。初始化一个含有 30 个神经元的隐藏层。训练 30 个 epoch，mini-batch 大小为 10，学习率 $\eta=3.0$。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import mnist_loader&#xA;training_data, validation_data, test_data = mnist_loader.load_data_wrapper()&#xA;import network&#xA;net = network.Network([784, 30, 10])&#xA;import network&#xA;net = network.Network([784, 30, 10])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;结果为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Epoch 0: 9129 / 10000&#xA;Epoch 1: 9295 / 10000&#xA;Epoch 2: 9348 / 10000&#xA;...&#xA;Epoch 27: 9528 / 10000&#xA;Epoch 28: 9542 / 10000&#xA;Epoch 29: 9534 / 10000&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;看来不错！识别率达到了 95.42%！如果将隐藏层的神经元增加到 100 个，最终识别率达到了 96.59%！&lt;/p&gt;&#xA;&lt;h2&gt;神经网络识别手写数字目录&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/29/handwritten-neural-net/&#34;&gt;基于 BP 神经网络的识别手写体数字 - 神经网络基础&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/06/25/handwritten-neural-net02/&#34;&gt;基于 BP 神经网络的手写体数字识别 - 设计与实现&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/06/26/handwritten-neural-net03/&#34;&gt;基于 BP 神经网络的手写体数字识别 - 反向传播算法&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/06/30/handwritten-neural-net04/&#34;&gt;基于 BP 神经网络的手写体数字识别 - 优化&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/06/25/handwritten-neural-net02/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>基于 BP 神经网络的识别手写体数字 - 神经网络基础</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/05/29/handwritten-neural-net/</id>
    <content type="html">&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xA;MathJax.Hub.Config({&#xA;  TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; } }&#xA;});&#xA;&lt;/script&gt;&#xA;&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;上个月，公司内部举办了机器学习比赛，内容是识别手写体数字。&lt;/p&gt;&#xA;&lt;p&gt;我提交的方案参考 &lt;a href=&#34;http://michaelnielsen.org/&#34;&gt;Michael Nielsen&lt;/a&gt;。以下大部分内容也参考了&lt;a href=&#34;http://neuralnetworksanddeeplearning.com/chap1.html&#34;&gt;他写的深度学习在线电子书&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;人类视觉系统其实非常神奇，恐怕自己都没意识到，考虑以下的手写数字：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/504192.png&#34; alt=&#34;504192&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;大部分人能够识别出数字为 504192。人脑每一半球都有着近 1.4 亿个神经元，之间有数以百亿的连接，能够进行复杂的图像处理。相当于每个人随身携带了一台超级计算机，数百万年的进化让该系统训练有素，能够适应并理解视觉世界。&lt;/p&gt;&#xA;&lt;p&gt;当真正开始编写程序时，就会意识到手写数字中复杂之处。在教小孩认数字 9 时，可能会 “这个数字顶上有个圈，右下角有个垂直的竖线。。”，或者你给他看一眼写的 9，他就能学会了。但这些步骤根本无法用传统的算法来描述，因为一个手写数字有着无限的细节。&lt;/p&gt;&#xA;&lt;p&gt;神经网络算法则用另一种方法来解决问题。首先，会准备如下的训练数据，&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/train_data.png&#34; alt=&#34;训练数据&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;然后，系统便以此为基础&lt;strong&gt;学习&lt;/strong&gt;。换句话说，神经网络能够使用这些训练数据自动推导出识别手写数字的规则。并且，训练集越多，神经网络准确率越高。所以虽然上图只展示了 100 个数字，但如果有上百万个训练集的话，我们的手写数字识别器效果会更好。&lt;/p&gt;&#xA;&lt;p&gt;神经网络是一个简单易实现的算法，不会超过 100 行代码。我们也会在将来探讨更为复杂的深度学习算法。&lt;/p&gt;&#xA;&lt;h2&gt;感知器 Perceptron&lt;/h2&gt;&#xA;&lt;p&gt;什么是神经网络？我们从&lt;strong&gt;感知器&lt;/strong&gt;说起。&lt;/p&gt;&#xA;&lt;p&gt;感知器是上世纪 50 年代，&lt;a href=&#34;http://en.wikipedia.org/wiki/Frank_Rosenblatt&#34;&gt;Frank Rosenblatt&lt;/a&gt; 受 &lt;a href=&#34;http://en.wikipedia.org/wiki/Warren_McCulloch&#34;&gt;Warren McCulloch&lt;/a&gt; 和 &lt;a href=&#34;http://en.wikipedia.org/wiki/Walter_Pitts&#34;&gt;Walter Pitts&lt;/a&gt; &lt;a href=&#34;http://scholar.google.ca/scholar?cluster=4035975255085082870&#34;&gt;工作&lt;/a&gt;的启发，所提出的概念。如今，其他的人工神经元模型更常用，最广泛的是 &lt;strong&gt;sigmoid&lt;/strong&gt; 神经元。现在先让我们看看感知器模型，它将帮助我们了解为什么 sigmoid 神经元更受欢迎。&lt;/p&gt;&#xA;&lt;p&gt;感知器如何工作呢？一个感知器有多个二进制输入，$x_1, x_2, ...$，并只有一个二进制的输出：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/perceptron.png&#34; alt=&#34;感知器模型&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这个例子中，感知器有三个输入，$x_1, x_2, x_3$。通常输入数目由需要而定。Rosenblatt 给每一个输入引入一个权重，$w_1, w_2, ...$，在输出增加一个阈值，超过阈值时才会输出 1，以下为输出与输入的关系：&lt;/p&gt;&#xA;&lt;p&gt;\begin{equation}&lt;br&gt;&#xA;output = \left\{\begin{aligned}&#xA;0, \sum_jw_jx_j \leq threshold \\&#xA;1, \sum_jw_jx_j &amp;gt; threshold&#xA;\end{aligned}\right.&#xA;\end{equation}&lt;/p&gt;&#xA;&lt;p&gt;这个简单的公式就是感知器的工作原理！&lt;/p&gt;&#xA;&lt;p&gt;下面给出一个简单的模型，虽然不是实际例子，但易于理解。假设周末即将来临，你听说自己所在的城市会举办奶酪节。你太喜欢奶酪了，但还是得考虑一下周末的天气情况。你将根据下面三个因素来做决定：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;天气怎样？&lt;/li&gt;&#xA;&lt;li&gt;你的女朋友和你一起去吗？&lt;/li&gt;&#xA;&lt;li&gt;节日举办地驾车方便吗？&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;将这三种因素量化成二进制数 $x_1, x_2, x_3$。比如如果天气好，则 $x_1=1$，否则为 $x_1=0$。其他三种因素同理。现在假设你太喜欢奶酪了，以至于女朋友和交通不遍都不太影响你，但你又怕糟糕的天气弄脏衣服。我们可以将感知器设计为：天气权重$w_1=6$，女朋友权重 $w_2=2$ 和交通状况权重 $w_3=2$。可以看到天气占了很大的权重。最后将感知器阈值设为 5 便得到了我们需要的决策模型。一旦天气不好，感知器输出为 0，天气晴朗就输出 1。而女朋友同去与否和交通状况都没法影响感知器输出。&lt;/p&gt;&#xA;&lt;p&gt;通过改变加权系数和阈值，便能得到不同的决策系统。比如将阈值调整为 3，这样女朋友就对你很重要啦，她要是想去，天气再糟你也得跟着一起受罪。&lt;/p&gt;&#xA;&lt;p&gt;虽然感知器并不是人类决策系统的完整模型，但其能对各种条件做加权。而且似乎越复杂的网路越能做出微妙的决策：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/complex_perceptron.png&#34; alt=&#34;复杂网络&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;在这个网络中，第一列感知器 - 我们也称作感知器第一层，只是简单地对输入做加权。而第二层感知器则对第一层决策的结果再一步加权，做出更复杂更抽象的决定。同样还可以增加神经网络的层数来作出更复杂的决定。&lt;/p&gt;&#xA;&lt;p&gt;顺便提一句，上述定义中，感知器只有一个输出，但是上述网络似乎有多个输出。事实上，这仍然是单输出系统，只是单个输出连接到了下一层的多个输入而已。&lt;/p&gt;&#xA;&lt;p&gt;让我们来简化一下感知器的数学表达式，原来的判断条件 $\sum_jw_jx_j &amp;gt; threshold$ 略显累赘。首先用点积形式简化，记 $w \cdot x \equiv \sum_j w_j x_j$，其中 $w$ 是权重向量，$x$ 是输入向量。然后将阈值移到不等式左边，并用偏移的概念取代它，记 $b \equiv - threshold$。感知器规则可重写如下：&lt;/p&gt;&#xA;&lt;p&gt;\begin{equation}&lt;br&gt;&#xA;output = \left\{\begin{aligned}&#xA;0, w \cdot x + b \leq 0 \\&#xA;1, w \cdot x + b &amp;gt; 0&#xA;\end{aligned}\right.&#xA;\end{equation}&lt;/p&gt;&#xA;&lt;p&gt;偏移的概念可用来度量感知器的“兴奋”程度，假如偏移值很大，那么很小的输入就会在输出端反应出来。但若偏移值很小，则说明感知器比较“迟钝”，输入很大时，输出才有变化。接下来的文章中，都会使用偏移而不是阈值的概念。&lt;/p&gt;&#xA;&lt;h2&gt;sigmoid 神经元&lt;/h2&gt;&#xA;&lt;p&gt;自学习的 idea 听起来太棒了。如何为神经网络设计算法呢？假设我们的神经网络全部由感知器构成，输入为手写体数字扫描图的每一个原始像素点。我们希望神经网络能够自调整权重和偏移值，从而能对手写数字准确分类。为了解自学习过程，我们来做一个思想实验，假设我们在权重或偏移做一个小的改变，我们期望输出也会有相应小的变化：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/neural_net.png&#34; alt=&#34;神经网络&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;比如神经网络错误地将数字 9 认为为数字 8，我们就可以对参数做微调（可能某个人写的 9 像 8），修正输出，不断重复上述过程，从而使输出符合我们的预期。&lt;/p&gt;&#xA;&lt;p&gt;实际中，由感知器组成的神经网络并不如所愿。由于感知器的输出不是连续的，0 到 1 是阶跃变化，上述参数的微调往往带来输出的剧烈变化。这下便导致自学习过程完全不可控，有时一点小小的噪声，输出就天壤之变。&lt;/p&gt;&#xA;&lt;p&gt;针对这个问题，我们可以换用 sigmoid 神经元。sigmoid 神经元和感知器是类似的，但输出是连续且变化缓慢的。这个微小的不同使神经网络算法化成为了可能。&lt;/p&gt;&#xA;&lt;p&gt;好，让我来描述一下 sigmoid 神经元。其结构和感知器一样：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/sigmoid.png&#34; alt=&#34;sigmoid 神经元&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;同样有输入 $x_1, x_2, ...$。不同是，输入可以取 0 到 1 之间的任何值，比如 0.638。sigmoid 对每一个输入有一个权重，$w_1, w_2, ...$，以及全局的偏移 $b$。但是 sigmoid 的输出不再限于 0 和 1，而是&lt;/p&gt;&#xA;&lt;p&gt;\begin{equation}&lt;br&gt;&#xA;\sigma(z) \equiv \frac{1}{1+e^{-z}}.&#xA;\end{equation}&lt;/p&gt;&#xA;&lt;p&gt;将 $z=w \cdot x+b$ 展开，可得&lt;/p&gt;&#xA;&lt;p&gt;\begin{equation}&#xA;\frac{1}{1+\exp(-\sum_j w_j x_j-b)}. \label{eq4}&#xA;\end{equation}&lt;/p&gt;&#xA;&lt;p&gt;初看上去，sigmoid 神经元似乎与感知器有着天壤之别，其代数表达式也显得晦涩难懂。然而他们之间是有很多相似之处的。&lt;/p&gt;&#xA;&lt;p&gt;假设当 $z\equiv w \cdot x + b$ 趋向于正无穷，则 $e^{-z}\approx 0$ 和 $\sigma(z) \approx 1$。换句话说，当输入很大时，sigmoid 神经元的输出趋向于 1，这和感知器是一样的。相反的，当 $z\equiv w \cdot x + b$ 趋向于负无穷，则 $e^{-z} \rightarrow \infty$，且 $\sigma(z) \approx 0$。这和感知器又是一样的。只有当输入不大时，才会与感知器表现不同。&lt;/p&gt;&#xA;&lt;p&gt;让我们看一下 sigmoid 函数和阶跃函数的图像：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/sigmoid_function.png&#34; alt=&#34;sigmoid 函数&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/step_function.png&#34; alt=&#34;阶跃函数&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;如果 $\sigma$ 是阶跃函数，那么 sigmoid 神经元就会退化成感知器，也就是说 sigmoid 神经元是平滑了的感知器。函数 $\sigma$ 的平滑度意味着，权重的微小变化 $\Delta w_j$ 和偏移的微小变化 $\Delta b$ 会在输出有相应的变化 $\Delta \mbox{output}$，运用泰勒公式可得：&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray}&#xA;\Delta \mbox{output} \approx \sum_j \frac{\partial , \mbox{output}}{\partial w_j}&#xA;\Delta w_j + \frac{\partial , \mbox{output}}{\partial b} \Delta b,&#xA;\label{5}&#xA;\end{eqnarray}&lt;/p&gt;&#xA;&lt;p&gt;其中，求和是对所有的权重和偏移变化求和。 $\partial ,\mbox{output} / \partial w_j$ 是 $\mbox{output}$ 对 $w_j$ 的偏导数，$\partial , \mbox{output} /\partial b$ 是 $\mbox{output}$ 对 $b$ 的偏导数。从这个近似表达式可以看出，$\Delta \mbox{ouput}$ 是 $\Delta w_j, \Delta b$ 的线性函数。比起感知器那种非线性的输出输入关系，线性化便于调试，也有利于算法化。&lt;/p&gt;&#xA;&lt;p&gt;如何理解 sigmoid 神经元的输出呢？显然最大的不同是 sigmoid 神经元不只输出 0 或 1，而是 0，1 之间所有的实数，比如 0.4 来指出一幅图片是 9 的概率为 40%，60% 的概率不是 9。&lt;/p&gt;&#xA;&lt;h2&gt;神经网络的结构&lt;/h2&gt;&#xA;&lt;p&gt;神经网络的结构：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/net_structure.png&#34; alt=&#34;神经网络的结构&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;如上所述，最左边的那一层被称做输入层，其中的神经元是输入神经元。最右或者输出层包含了输出神经元，该例中只有一个输出神经元。由于中间的神经元既不是输入也不是输出，中间那层被称为隐藏层。该例中只有一个隐藏层，有些神经网络有多个隐藏层，比如下面这张图中有两个隐藏层：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/multi-layer_net_structure.png&#34; alt=&#34;两个隐藏层&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;神经网络输入输出的设计通常很直接。比如手写数字，假设扫描图是 $28 \times 28=784$ 的灰度图像，输入就有 784 个神经元，输出就是每个数字的概率，一共 10 个输出神经元。&lt;/p&gt;&#xA;&lt;h2&gt;神经网络识别手写数字目录&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/29/handwritten-neural-net/&#34;&gt;基于 BP 神经网络的识别手写体数字 - 神经网络基础&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/06/25/handwritten-neural-net02/&#34;&gt;基于 BP 神经网络的手写体数字识别 - 设计与实现&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/06/26/handwritten-neural-net03/&#34;&gt;基于 BP 神经网络的手写体数字识别 - 反向传播算法&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/06/30/handwritten-neural-net04/&#34;&gt;基于 BP 神经网络的手写体数字识别 - 优化&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/05/29/handwritten-neural-net/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Robot Framework 教程 - 循环，条件判断，字符串和列表（译）</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/05/28/robotframework-tutorial-loops-conditional-execution-and-more/</id>
    <content type="html">&lt;p&gt;目前为止，&lt;a href=&#34;http://robotframework.org/&#34;&gt;Robot Framework&lt;/a&gt;教程一直关注于高阶抽象的概念，所以这次有必要介绍一下框架本身的基础概念。所有这些特性都直接来自于标准库，而本文的例子再安装额外的库。&lt;/p&gt;&#xA;&lt;h2&gt;有关循环的关键字&lt;/h2&gt;&#xA;&lt;p&gt;让我们从循环开始。&lt;a href=&#34;http://robotframework.org/&#34;&gt;Robot Framework&lt;/a&gt;为循环提供了多种方案。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;在一系列元素中循环&lt;/li&gt;&#xA;&lt;li&gt;根据数字的范围来循环&lt;/li&gt;&#xA;&lt;li&gt;重复执行某一个关键字多次&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;最后一个和真正的循环是有差别的，意味着你得将所有操作封装到一个关键字中。并且，在执行结束之前无法退出循环。&lt;/p&gt;&#xA;&lt;p&gt;让我们来看一些例子：&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;测试&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;*** Settings ***&#xA;Library           String&#xA;&#xA;*** Test Cases ***&#xA;For-Loop-In-Range&#xA;    : FOR    ${INDEX}    IN RANGE    1    3&#xA;    \    Log    ${INDEX}&#xA;    \    ${RANDOM_STRING}=    Generate Random String    ${INDEX}&#xA;    \    Log    ${RANDOM_STRING}&#xA;&#xA;For-Loop-Elements&#xA;    @{ITEMS}    Create List    Star Trek    Star Wars    Perry Rhodan&#xA;    :FOR    ${ELEMENT}    IN    @{ITEMS}&#xA;    \    Log    ${ELEMENT}&#xA;    \    ${ELEMENT}    Replace String    ${ELEMENT}    ${SPACE}    ${EMPTY}&#xA;    \    Log    ${ELEMENT}&#xA;&#xA;For-Loop-Exiting&#xA;    @{ITEMS}    Create List    Good Element 1    Break On Me    Good Element 2&#xA;    :FOR    ${ELEMENT}    IN    @{ITEMS}&#xA;    \    Log    ${ELEMENT}&#xA;    \    Run Keyword If    &#39;${ELEMENT}&#39; == &#39;Break On Me&#39;    Exit For Loop&#xA;    \    Log    Do more actions here ...&#xA;&#xA;Repeat-Action&#xA;    Repeat Keyword    2    Log    Repeating this ...&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;strong&gt;输出&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Starting test: StandardLoopDemo.For-Loop-In-Range&#xA;20130426 11:24:14.389 :  INFO : 1&#xA;20130426 11:24:14.390 :  INFO : ${RANDOM_STRING} = B&#xA;20130426 11:24:14.390 :  INFO : B&#xA;20130426 11:24:14.391 :  INFO : 2&#xA;20130426 11:24:14.392 :  INFO : ${RANDOM_STRING} = ih&#xA;20130426 11:24:14.392 :  INFO : ih&#xA;Ending test:   StandardLoopDemo.For-Loop-In-Range&#xA;&#xA;Starting test: StandardLoopDemo.For-Loop-Elements&#xA;20130426 11:24:14.394 :  INFO : @{ITEMS} = [ Star Trek | Star Wars | Perry Rhodan ]&#xA;20130426 11:24:14.395 :  INFO : Star Trek&#xA;20130426 11:24:14.396 :  INFO : ${ELEMENT} = StarTrek&#xA;20130426 11:24:14.396 :  INFO : StarTrek&#xA;20130426 11:24:14.397 :  INFO : Star Wars&#xA;20130426 11:24:14.398 :  INFO : ${ELEMENT} = StarWars&#xA;20130426 11:24:14.398 :  INFO : StarWars&#xA;20130426 11:24:14.399 :  INFO : Perry Rhodan&#xA;20130426 11:24:14.400 :  INFO : ${ELEMENT} = PerryRhodan&#xA;20130426 11:24:14.400 :  INFO : PerryRhodan&#xA;Ending test:   StandardLoopDemo.For-Loop-Elements&#xA;&#xA;Starting test: StandardLoopDemo.For-Loop-Exiting&#xA;20130426 11:24:14.402 :  INFO : @{ITEMS} = [ Good Element 1 | Break On Me | Good Element 2 ]&#xA;20130426 11:24:14.402 :  INFO : Good Element 1&#xA;20130426 11:24:14.403 :  INFO : Do more actions here ...&#xA;20130426 11:24:14.404 :  INFO : Break On Me&#xA;Ending test:   StandardLoopDemo.For-Loop-Exiting&#xA;&#xA;Starting test: StandardLoopDemo.Repeat-Action&#xA;20130426 11:24:14.408 :  INFO : Repeating keyword, round 1/2&#xA;20130426 11:24:14.408 :  INFO : Repeating this ...&#xA;20130426 11:24:14.408 :  INFO : Repeating keyword, round 2/2&#xA;20130426 11:24:14.409 :  INFO : Repeating this ...&#xA;Ending test:   StandardLoopDemo.Repeat-Action   &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;语法非常直接，不需要过多解释。唯一需要注意的是，循环体内的关键字必须用 &#39;&#39; 来进行转义。&lt;/p&gt;&#xA;&lt;h2&gt;有关条件判断的关键字&lt;/h2&gt;&#xA;&lt;p&gt;在测试代码中使用条件判断会带来不少争议。不用担心，唯一应该记住的是，测试实现应该尽可能简单明了，不要混杂过多条件逻辑。&lt;/p&gt;&#xA;&lt;p&gt;在下面的例子中将使用以下相关的关键字。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Run Keyword&lt;/strong&gt; - 这个关键字将其他关键字作为一个变量传入。这意味着，测试能够动态地改变执行时所使用的关键字，比如执行其他函数返回的关键字。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Run Keyword If&lt;/strong&gt; - 在测试复杂结构时非常有用，比如被测的 web 页面在输入不同时会有不同的选项。但是在测试中混有过多的程序结构会使 troubleshooting 变得困难。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Run Keyword And Ignore Error&lt;/strong&gt; - 哈，我还没有找到对应的实际例子。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Run Keyword If Test Failed&lt;/strong&gt; - 如果测试失败了可以用这个打一些 log，或者打一个快照。在 troubleshooting 时有用。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;测试&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;*** Test Cases ***&#xA;Run-Keyword&#xA;    ${MY_KEYWORD}=    Set Variable    Log&#xA;    Run Keyword    ${MY_KEYWORD}    Test&#xA;&#xA;Run-Keyword-If&#xA;    ${TYPE}=    Set Variable    V1&#xA;    Run Keyword If    &#39;${TYPE}&#39; == &#39;V1&#39;    Log     Testing Variant 1&#xA;    Run Keyword If    &#39;${TYPE}&#39; == &#39;V2&#39;    Log    Testing Variant 2&#xA;    Run Keyword If    &#39;${TYPE}&#39; == &#39;V3&#39;    Log    Testing Variant 3&#xA;&#xA;Run-Keyword-Ignore-Error&#xA;    @{CAPTAINS}    Create List    Picard    Kirk    Archer&#xA;    Run Keyword And Ignore Error    Should Be Empty    ${CAPTAINS}&#xA;    Log    Reached this point despite of error&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;strong&gt;输出&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Starting test: Robot Blog.StandardConditionDemo.Run-Keyword&#xA;20130426 13:34:50.840 :  INFO : ${MY_KEYWORD} = Log&#xA;20130426 13:34:50.841 :  INFO : Test&#xA;Ending test:   Robot Blog.StandardConditionDemo.Run-Keyword&#xA;&#xA;Starting test: Robot Blog.StandardConditionDemo.Run-Keyword-If&#xA;20130426 13:34:50.843 :  INFO : ${TYPE} = V1&#xA;20130426 13:34:50.844 :  INFO : Testing Variant 1&#xA;Ending test:   Robot Blog.StandardConditionDemo.Run-Keyword-If&#xA;&#xA;Starting test: Robot Blog.StandardConditionDemo.Run-Keyword-Ignore-Error&#xA;20130426 13:34:50.847 :  INFO : @{CAPTAINS} = [ Picard | Kirk | Archer ]&#xA;20130426 13:34:50.848 :  INFO : Length is 3&#xA;20130426 13:34:50.849 :  FAIL : &#39;[u&#39;Picard&#39;, u&#39;Kirk&#39;, u&#39;Archer&#39;]&#39; should be empty&#xA;20130426 13:34:50.850 :  INFO : Reached this point despite of error&#xA;Ending test:   Robot Blog.StandardConditionDemo.Run-Keyword-Ignore-Error&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;字符串和列表&lt;/h2&gt;&#xA;&lt;p&gt;可以看到，&lt;a href=&#34;http://robotframework.org/&#34;&gt;Robot Framework&lt;/a&gt;框架包含了完整的可编程结构。而一些高级语言特有的字符串和列表也能通过 Collection Library 和 String Library 来实现。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;测试&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;*** Settings ***&#xA;Library           String&#xA;Library           Collections&#xA;&#xA;*** Test Cases ***&#xA;StringsAndLists&#xA;    ${SOME_VALUE}=    Set Variable    &amp;quot;Test Value&amp;quot;&#xA;    Log    ${SOME_VALUE}&#xA;    @{WORDS}=    Split String    ${SOME_VALUE}    ${SPACE}&#xA;    ${FIRST}=    Get From List    ${WORDS}    0&#xA;    Log    ${FIRST}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;strong&gt;输出&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Starting test: Robot Blog.StandardStringsAndListsDemo.StringsAndLists&#xA;20130506 21:21:05.880 :  INFO : ${SOME_VALUE} = &amp;quot;Test Value&amp;quot;&#xA;20130506 21:21:05.881 :  INFO : &amp;quot;Test Value&amp;quot;&#xA;20130506 21:21:05.882 :  INFO : @{WORDS} = [ &amp;quot;Test | Value&amp;quot; ]&#xA;20130506 21:21:05.882 :  INFO : ${FIRST} = &amp;quot;Test&#xA;20130506 21:21:05.883 :  INFO : &amp;quot;Test&#xA;Ending test:   Robot Blog.StandardStringsAndListsDemo.StringsAndLists&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;Robot Framework 教程目录&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.codecentric.de/en/2013/05/robot-framework-tutorial-loops-conditional-execution-and-more/&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/01/07/robotframework-tutorial-overview/&#34;&gt;Robot Framework 教程 - 概览（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/04/09/robotframework-tutorial-a-complete-example/&#34;&gt;Robot Framework 教程 - 一个完整的例子（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/04/30/robotframework-ide-ride-overview/&#34;&gt;Robot Framework 教程 - 集成开发环境 RIDE 概览 (译)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/15/robotframework-tutorial-how-to-structure-a-scalable-and-maintainable-acceptance-test-suite/&#34;&gt;Robot Framework 教程 - 如何组织一个可伸缩可维护的验收测试套件（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/28/robotframework-tutorial-loops-conditional-execution-and-more/&#34;&gt;Robot Framework 教程 - 循环，条件判断，字符串和列表（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/05/28/robotframework-tutorial-loops-conditional-execution-and-more/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Robot Framework 教程 - 如何组织一个可伸缩可维护的验收测试套件（译）</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/05/15/robotframework-tutorial-how-to-structure-a-scalable-and-maintainable-acceptance-test-suite/</id>
    <content type="html">&lt;p&gt;当你在一个 sprint 中开始写自动化验收测试时，你没必要重新测试之前每个 sprint 的结果。但经过几轮自动化测试之后，整个测试看起来不再像一个精心设计过的测试套件，而是乱七八糟。这些你一定经历过。这篇文章将展示一些最佳的模式和经验，让你写出可伸缩可维护的测试结构。&lt;/p&gt;&#xA;&lt;p&gt;我们只考虑测试框架本身，忽略和执行有关的问题，比如日志系统、并发和测试硬件。由于我们一直使用 &lt;a href=&#34;http://robotframework.org/&#34;&gt;Robot Framework&lt;/a&gt; 来实现自动化，所以本文的解决方法会有一些局限性。但其他测试框架的用户也可以参考，比如 FitNesse, Cucumber, Concordion, etc。&lt;/p&gt;&#xA;&lt;p&gt;好，一个单独的，精心设计的验收测试并不会存在太长时间，但如何写一个可维护的测试套件？这里我用测试套件这个术语，意味着并不是单单指测试用例，还包括了库、启动脚本和框架等。&lt;/p&gt;&#xA;&lt;p&gt;由于经常改变项目需求和源码实现，测试套件也需要跟着改变。如何让测试套件尽可能地适应各种变化？显然，需要在其中分离出可变和稳定的部分。&lt;/p&gt;&#xA;&lt;p&gt;稳定的部分是指测试框架本身和附加的库。测试用例也会尽可能作为不变的部分，除非需求改变没理由要改变它们。当然，这里允许添加新的测试用例。这里不经要问了，既然框架和测试用例都为稳定的部分，那什么是可变的部分呢？下图展示了一个可伸缩可维护的测试套件的结构。下面会对图中每一层作详细的解释。简单的说，如果系统的上下两头都需要稳定，那么可变的部分只有中间那层。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/SMAT_structure.png&#34; alt=&#34;测试套件结构&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;不同的颜色代表了 Robot Framework 中不同的文件：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;红色&lt;/strong&gt;：测试用例和套件。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;绿色&lt;/strong&gt;：资源文件。资源文件包括关键字。一个关键字可以是一个方法，或者是其他方法的组合。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;蓝色&lt;/strong&gt;：框架自身的内容。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;在图的左边，你可以看到对每一层稳定性和可变性的度量。在最顶层和最底层，稳定性最高，而在最中间那一层，可变性又变的最高。这意味着中间那层的元素经常改变，而其他相对恒定。&lt;/p&gt;&#xA;&lt;h2&gt;每一层&lt;/h2&gt;&#xA;&lt;h3&gt;测试用例&lt;/h3&gt;&#xA;&lt;p&gt;我们推荐的是 “Given/When/Then” 方式来写用例。这意味着只有当需求变化时，才需要动测试用例。&lt;/p&gt;&#xA;&lt;h3&gt;测试套件&lt;/h3&gt;&#xA;&lt;p&gt;测试用例应该按功能组织为测试套件。开头，我们按照用户需求对测试用例分类。在回顾时，发现当相同的用户需求增多时，得花越来越多的时间搜索特定的用例。所以，对用户需求和分类的用例打上&lt;strong&gt;标签&lt;/strong&gt;，将有利于搜索。&lt;/p&gt;&#xA;&lt;h3&gt;导入&lt;/h3&gt;&#xA;&lt;p&gt;下一层是“导入”。这一层包含了自动化验收测试所需的关键字，能够建立测试用例和资源文件之间的对应关系。既然用例不应经常改变，那么关键字就需要持续重构了。由于测试套件之间包含一些类似的测试用例，它们理应具有相同的导入，这样只需为所有的测试套件写一份资源文件。&lt;/p&gt;&#xA;&lt;h3&gt;聚合对象&lt;/h3&gt;&#xA;&lt;p&gt;聚合对象这层改动最为频繁。比如在测试 web UI 时，会建立页面对象的模式。从一个web页抽象的概念，在这一层如何构建经典的软件设计与工程：结构的灵活性和可维护的代码？&lt;/p&gt;&#xA;&lt;h3&gt;库适配器&lt;/h3&gt;&#xA;&lt;p&gt;我们增加了库适配器层。每一个库都应该由资源文件来导入，这样能保证系统中只有一个库的实例。而且有时候库需要用不同的参数来初始化。并且，我们随时会在适配器层增加关键字来扩展功能，而对上层的测试用例保持黑盒状态。&lt;/p&gt;&#xA;&lt;h3&gt;平台&lt;/h3&gt;&#xA;&lt;p&gt;这一层是指 RObot Framework 框架本身和标准库。&lt;/p&gt;&#xA;&lt;h2&gt;结论&lt;/h2&gt;&#xA;&lt;p&gt;一方面，我们构建测试套件的方法产生了深远的影响。在另一方面，我们继续学习新的东西，我相信新的经验和教训将进一步影响测试用例和套件的结构和设计。希望其他项目能从中受惠。&lt;/p&gt;&#xA;&lt;h2&gt;Robot Framework 教程目录&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.codecentric.de/en/2010/07/how-to-structure-a-scalable-and-maintainable-acceptance-test-suite/&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/01/07/robotframework-tutorial-overview/&#34;&gt;Robot Framework 教程 - 概览（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/04/09/robotframework-tutorial-a-complete-example/&#34;&gt;Robot Framework 教程 - 一个完整的例子（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/04/30/robotframework-ide-ride-overview/&#34;&gt;Robot Framework 教程 - 集成开发环境 RIDE 概览 (译)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/15/robotframework-tutorial-how-to-structure-a-scalable-and-maintainable-acceptance-test-suite/&#34;&gt;Robot Framework 教程 - 如何组织一个可伸缩可维护的验收测试套件（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/28/robotframework-tutorial-loops-conditional-execution-and-more/&#34;&gt;Robot Framework 教程 - 循环，条件判断，字符串和列表（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/05/15/robotframework-tutorial-how-to-structure-a-scalable-and-maintainable-acceptance-test-suite/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>DHT 公网嗅探器实现（DHT 爬虫）</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/05/14/dht-sniffer/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;这里实现的 DHT 嗅探器会在公网捕获种子的 infohash，源码见 &lt;a href=&#34;https://github.com/lyyyuna/DHT_sniffer&#34;&gt;GitHub&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;DHT 协议介绍见 &lt;a href=&#34;http://www.lyyyuna.com/2016/03/26/dht01/&#34;&gt;DHT 协议 - 译&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;其实大部分代码来自了 &lt;a href=&#34;https://github.com/Fuck-You-GFW/simDHT/blob/master/simDHT.py&#34;&gt;simDHT&lt;/a&gt;，我只是改成了 gevent 版本。&lt;/p&gt;&#xA;&lt;p&gt;为什么我没有用 Python 3 的 asyncio 呢？最大的原因是我没有在官方 API 中找到方便使用 UDP 协议的接口。asyncio 底层有着类似 Twisted 的事件驱动编程，对于 TCP 协议，官方又封装了一层 Stream，可以用 await 类似同步的方式异步编程。但不知道为啥就是没有 UDP 的封装，见 &lt;a href=&#34;https://groups.google.com/forum/#!topic/python-tulip/xYgQRXkb83g&#34;&gt;谷歌讨论组&lt;/a&gt;，Guido van Rossum 他自己觉得不需要。然而事件编程我不习惯，在这个项目里要用违反直觉的方式封装，所以还是放弃了 asyncio。&lt;/p&gt;&#xA;&lt;h2&gt;gevent 中的 UDP&lt;/h2&gt;&#xA;&lt;p&gt;使用 gevent，对于原程序改动很小。使用 DatagramServer 作为 UDP server。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from gevent.server import DatagramServer&#xA;&#xA;class DHTServer(DatagramServer): &#xA;     def __init__(self, max_node_qsize, bind_ip): &#xA;         s = &#39;:&#39; + str(bind_ip) &#xA;         self.bind_ip = bind_ip &#xA;         DatagramServer.__init__(self, s) &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;协议相关&lt;/h2&gt;&#xA;&lt;h3&gt;如何捕获 infohash&lt;/h3&gt;&#xA;&lt;p&gt;虽是嗅探，但 DHT 的流量不会无缘故的跑过来，必须把自己伪装成一个客户端才能捕获到 DHT 流量。&lt;/p&gt;&#xA;&lt;p&gt;以下设我们伪造的客户端为 X。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;首先向其他 node 发送 find_node 请求，所发送的 node 可以随机生成，我们的目的只是为了让对方 node 能在其路由表中记录下我们伪造的 X。&lt;/li&gt;&#xA;&lt;li&gt;当其他 node 想要下载 torrent 时，便会向其路由表中最近的 node 依次发送 get_peers/announce_peer 请求。这样其必会向我们伪造的 X 发送 get_peers/announce_peer 请求，即包含真实的 infohash。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;这样，一个真实的 infohash 就到手了。总结就是，不断和其他 node 交朋友，然后等着他们发送 infohash 过来。&lt;/p&gt;&#xA;&lt;p&gt;既然是伪造，意味着不需要实现完整的 DHT 协议。只需要 find_node 和 get_peers/announce_peer 请求即可。&lt;/p&gt;&#xA;&lt;h3&gt;路由表&lt;/h3&gt;&#xA;&lt;p&gt;有必要实现完整的路由表吗？协议中的路由表需要维护一个较复杂的数据结构，监控一个 node 的健康程度，若不活跃则需将其删除。作为 DHT 嗅探器这是多余的，因为原数据结构是要保证路由表中是健康的节点，以提高下载速度。而我们是为了认识更多的节点，向 node 发送一次 find_node 请求之后，即可删除该数据。&lt;/p&gt;&#xA;&lt;p&gt;队列，更符合伪造的客户端对 node 管理的需求。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;self.nodes = deque(maxlen=max_node_qsize)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;其他 node 除了会发送 get_peers 请求来获取 torrent 之外，也会发送 find_node 来获取节点信息。这意味着，其他 node 的 find_node 请求便是我们更新 node 信息的来源。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    def process_find_node_response(self, msg, address):&#xA;        # print &#39;find node&#39; + str(msg)&#xA;        nodes = decode_nodes(msg[&amp;quot;r&amp;quot;][&amp;quot;nodes&amp;quot;])&#xA;        for node in nodes:&#xA;            (nid, ip, port) = node&#xA;            if len(nid) != 20: continue&#xA;            if ip == self.bind_ip: continue&#xA;            if port &amp;lt; 1 or port &amp;gt; 65535: continue&#xA;            n = KNode(nid, ip, port)&#xA;            self.nodes.append(n)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们伪造的 X 从队列中取出一个 node，然后发送 find_node，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    def auto_send_find_node(self):&#xA;&#xA;        wait = 1.0 / self.max_node_qsize / 5.0&#xA;        while True:&#xA;            try:&#xA;                node = self.nodes.popleft()&#xA;                self.send_find_node((node.ip, node.port), node.nid)&#xA;            except IndexError:&#xA;                pass&#xA;            sleep(wait) &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;实际测试表明，运行时队列一直是满的，所以不用担心 node 不够用。&lt;/p&gt;&#xA;&lt;h3&gt;解析 infohash&lt;/h3&gt;&#xA;&lt;p&gt;get_peers 和 announce_peer 请求都含有 infohash。虽然 announce_peer 请求质量更高，但数量少。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    def on_get_peers_request(self, msg, address):&#xA;        try:&#xA;            infohash = msg[&amp;quot;a&amp;quot;][&amp;quot;info_hash&amp;quot;]&#xA;            tid = msg[&amp;quot;t&amp;quot;]&#xA;            nid = msg[&amp;quot;a&amp;quot;][&amp;quot;id&amp;quot;]&#xA;            token = infohash[:TOKEN_LENGTH]&#xA;            print &#39;get peers: &#39; + infohash.encode(&amp;quot;hex&amp;quot;),  address[0], address[1]&#xA;            msg = {&#xA;                &amp;quot;t&amp;quot;: tid,&#xA;                &amp;quot;y&amp;quot;: &amp;quot;r&amp;quot;,&#xA;                &amp;quot;r&amp;quot;: {&#xA;                    &amp;quot;id&amp;quot;: get_neighbor(infohash, self.nid),&#xA;                    &amp;quot;nodes&amp;quot;: &amp;quot;&amp;quot;,&#xA;                    &amp;quot;token&amp;quot;: token&#xA;                }&#xA;            }&#xA;            self.send_krpc(msg, address)&#xA;        except KeyError:&#xA;            pass&#xA;&#xA;    def on_announce_peer_request(self, msg, address):&#xA;        try:&#xA;            print &#39;announce peer&#39;&#xA;            infohash = msg[&amp;quot;a&amp;quot;][&amp;quot;info_hash&amp;quot;]&#xA;            token = msg[&amp;quot;a&amp;quot;][&amp;quot;token&amp;quot;]&#xA;            nid = msg[&amp;quot;a&amp;quot;][&amp;quot;id&amp;quot;]&#xA;            tid = msg[&amp;quot;t&amp;quot;]&#xA;&#xA;            if infohash[:TOKEN_LENGTH] == token:&#xA;                if msg[&amp;quot;a&amp;quot;].has_key(&amp;quot;implied_port&amp;quot;) and msg[&amp;quot;a&amp;quot;][&amp;quot;implied_port&amp;quot;] != 0:&#xA;                    port = address[1]&#xA;                else:&#xA;                    port = msg[&amp;quot;a&amp;quot;][&amp;quot;port&amp;quot;]&#xA;                    if port &amp;lt; 1 or port &amp;gt; 65535: return&#xA;                print &#39;announce peer: &#39; + infohash.encode(&amp;quot;hex&amp;quot;),  address[0], port&#xA;        except Exception:&#xA;            pass&#xA;        finally:&#xA;            self.ok(msg, address)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;对着 &lt;a href=&#34;http://www.lyyyuna.com/2016/03/26/dht01/&#34;&gt;DHT 协议 - 译&lt;/a&gt; 很容易看懂。&lt;/p&gt;&#xA;&lt;h3&gt;嗅探器启动&lt;/h3&gt;&#xA;&lt;p&gt;看到这里，你会发现嗅探器启动时，队列是空的。所以必须先放几个已知的 node。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;BOOTSTRAP_NODES = (&#xA;    (&amp;quot;router.bittorrent.com&amp;quot;, 6881),&#xA;    (&amp;quot;dht.transmissionbt.com&amp;quot;, 6881),&#xA;    (&amp;quot;router.utorrent.com&amp;quot;, 6881)&#xA;)&#xA;&#xA;    def join_DHT(self):&#xA;        for address in BOOTSTRAP_NODES:&#xA;            self.send_find_node(address)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;启动之后，队列就会被其他 node 发送的 find_node 所填满。&lt;/p&gt;&#xA;&lt;h2&gt;结果&lt;/h2&gt;&#xA;&lt;p&gt;公网捕获，一小时 10000 个左右。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/psb.jpg&#34; alt=&#34;效果图&#34;&gt;&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/05/14/dht-sniffer/" rel="alternate"></link>
    <summary type="html">做一个自己的种子爬虫。</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Robot Framework 教程 - 集成开发环境 RIDE 概览 (译)</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/04/30/robotframework-ide-ride-overview/</id>
    <content type="html">&lt;h2&gt;正文&lt;/h2&gt;&#xA;&lt;p&gt;Robot Framework IDE (RIDE) 是该框架本身的集成开发环境。&lt;a href=&#34;http://code.google.com/p/robotframework/&#34;&gt;Robot Framework&lt;/a&gt; 是一个通用的自动化测试框架，&lt;a href=&#34;http://www.lyyyuna.com/2015/12/28/robotframework-quickstartguide/&#34;&gt;这里有其简单介绍&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;改项目原本托管在 &lt;a href=&#34;http://code.google.com/p/robotframework-ride/&#34;&gt;Google Code&lt;/a&gt; 上，现托管在 &lt;a href=&#34;https://github.com/robotframework/RIDE/downloads&#34;&gt;GitHub&lt;/a&gt; 上。&lt;/p&gt;&#xA;&lt;p&gt;下载和安装这种事就不用我再重复了。当你打开 RIDE，导入一个测试套件或者是包含几个测试套件的目录时，就会在编辑器的左方展现一个树形结构。可以针对该树形结构，选择每一个测试套件的每一个测试用例。而且，每一个被引用的资源文件都会自动被装载，并显示在树形结构的 External Resources 中。只要测试套件能够被选中，就能修改其全局属性，例如 Suite-Setuo 和 Suite-Teardown。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/RIDE_1.png&#34; alt=&#34;RIDE 1&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;使用 RIDE 的一个巨大优势是可以从各个方面去配置测试套件。如果什么都是手写的，你很有可能会遗漏某些特性。而且 RIDE 中还自带完整的 Robot Framework 文档，在写关键字的时候很有帮助。当按下编辑按钮时，会弹出新窗口供你编辑。对于一些特殊的语法，比如关键字的参数使用惯导符号分割，不用担心，窗口中都会有文字提示。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/ride_3.png&#34; alt=&#34;argument&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;一旦你适应了如何编辑这些项。。。实际上也很容易。编辑单个测试用例时，你必须从树形结构中选取。每个用例的通用项 - 比如文档和标签 - 可以在编辑器的上方填入。在编辑器下方，是由关键字组成的用例步骤，用表格的形式给出。关键一般写在第一列，第二列开始是对应的参数。如图所示，都比较直观。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/RIDE_7.png&#34; alt=&#34;编辑器&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;接下来是文本编辑器部分，你可以从上方的面板中切换。RIDE 并不适用 HTML 格式来存储用例，而是采用纯粹的文本文件格式。这估计是因为 HTML 源文件难编辑的多的原因。RIDE 内部会对文本解析，展现在可视化编辑区。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/RIDE_2.png&#34; alt=&#34;源文件&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;在文本编辑和可是还编辑之间切换平滑，改动会自动同步。&lt;/p&gt;&#xA;&lt;p&gt;习惯了像 Visual Studio 这么方便的 IDE 的同学，肯定也希望 RIDE 有自动补全功能，当然它有。你只需要在写关键字时按下 &#39;CTRL-Space&#39; 就可以了。在空白处，RIDE 会显示库中所有的可能项。请注意，下面截图的显示并不完整。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/RIDE_33.png&#34; alt=&#34;关键字自动补全&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;对于那些在资源文件中定义的关键字，你可以在测试用例中双击，并跳转到定义的地方。相反的，你还可以看到所有使用该关键字的地方。你可以从菜单栏上选择 &#39;Tools -&amp;gt; Search Keywords -&amp;gt; Find Usages&#39; 来找到它们。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/RIDE_4.png&#34; alt=&#34;关键字所有的引用&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这个功能在重构测试用例时非常有用，通过单击每一项搜索结果，可以直接在编辑器中跳转到相应位置。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/RIDE_51.png&#34; alt=&#34;搜索结果&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;最后来看一下第三个面板，&lt;strong&gt;Run&lt;/strong&gt;。它可以让用户直接运行打开的测试套件中的用例。运行的脚本可以是 pybot, jybot 或者是自定义脚本。对于小型项目，前两个选项够用了。但是大型项目需要额外的运行参数，和更多的独立的启动配置脚本。&lt;/p&gt;&#xA;&lt;p&gt;脚本的运行结果可以在编辑器中看到。下面的例子可以看到，所有的测试用例都没通过:-)。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201605/RIDE_6.png&#34; alt=&#34;测试失败&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;我个人对 RIDE 的评价是，作为集成开发环境，它刚好够格，因为也没别的更好选择。这个工具提供了很多指南和内部文档，对于非技术人员无疑是有利的。&lt;/p&gt;&#xA;&lt;h2&gt;Robot Framework 教程目录&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.codecentric.de/en/2012/01/robot-framework-ide-ride-overview/&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/01/07/robotframework-tutorial-overview/&#34;&gt;Robot Framework 教程 - 概览（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/04/09/robotframework-tutorial-a-complete-example/&#34;&gt;Robot Framework 教程 - 一个完整的例子（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/04/30/robotframework-ide-ride-overview/&#34;&gt;Robot Framework 教程 - 集成开发环境 RIDE 概览 (译)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/15/robotframework-tutorial-how-to-structure-a-scalable-and-maintainable-acceptance-test-suite/&#34;&gt;Robot Framework 教程 - 如何组织一个可伸缩可维护的验收测试套件（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/28/robotframework-tutorial-loops-conditional-execution-and-more/&#34;&gt;Robot Framework 教程 - 循环，条件判断，字符串和列表（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/04/30/robotframework-ide-ride-overview/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Robot Framework 教程 - 一个完整的例子（译）</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/04/09/robotframework-tutorial-a-complete-example/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;用 &lt;a href=&#34;http://code.google.com/p/robotframework/&#34;&gt;Robot Framework&lt;/a&gt; 时有太多的选择：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用 Python, Jython 还是 Java？&lt;/li&gt;&#xA;&lt;li&gt;测试用例使用哪种输入格式（HTML, Text, BDD）？&lt;/li&gt;&#xA;&lt;li&gt;要使用 &lt;a href=&#34;http://www.lyyyuna.com/2016/01/07/robotframework-tutorial-overview/&#34;&gt;Robot IDE(RIDE)&lt;/a&gt; 吗？&lt;/li&gt;&#xA;&lt;li&gt;如何在本地和持续集成环境中运行相同的测试？&lt;/li&gt;&#xA;&lt;li&gt;如何运行所有的测试 (scripting, ANT, Maven)？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;那什么是最好的选择呢？我见过的世面太多了。当然，在 Eclipse 中用 Maven 做 Robot 测试非常酷。BDD 相比较 HTML 更适合敏捷开发。&lt;/p&gt;&#xA;&lt;p&gt;所有这些有着相同的共性：简单！这不仅意味着设置和运行简单，还意味着更容易排错。在不同技术背景的团队合作间，这尤其重要。&lt;/p&gt;&#xA;&lt;p&gt;接下来我们用一个完整的例子展示 Robot Framework 的使用方法。&lt;/p&gt;&#xA;&lt;h2&gt;测试准备&lt;/h2&gt;&#xA;&lt;p&gt;开始测试工程前，首先要想好被测系统需要哪些测试库：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;是测 web 应用？那你可能需要 SeleniumLibrary 或者 Selenium2Library。&lt;/li&gt;&#xA;&lt;li&gt;是测数据库？Python 和 Java 都有相应的数据库测试库。&lt;/li&gt;&#xA;&lt;li&gt;是测试 SSH/SFTP？那你可能需要 SSHLibrary。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这个列表可以继续列下去，直到没有可用的测试库为止。这时候你就需要自己写啦（需要单独写一篇文章来阐述）。&lt;/p&gt;&#xA;&lt;p&gt;为什么如此重要？测试库的选择直接影响到了是使用 Python, Jython 还是 Java 版的 Robot Framework。某些测试库只有 Java 的实现，如果要用纯 Python 来调用此库，则要求其实现 &lt;strong&gt;Remote Library 接口&lt;/strong&gt;。因此，在测之前，需要好好想想。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;本文的代码在 &lt;a href=&#34;https://github.com/lyyyuna/Robot-Framework-Sample-Project&#34;&gt;GitHub&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;我们假设被测系统是一个利用 MySQL 数据库做存储的 web 应用（非常普遍）。浏览器使用 Python 的 SeleniumLibrary，数据库使用 Java 版本的 DatabaseLibrary，并用 &lt;strong&gt;Remote Library 接口&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;h2&gt;测试框架&lt;/h2&gt;&#xA;&lt;p&gt;下图是测试框架的概览：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201604/Sample_Overview1.png&#34; alt=&#34;测试框架概览&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Selenium 需要 Selenium Server。这可以是 Robot Framework 所在的同一台机器，也可以是另一台可通过 TCP/IP 连接的服务器。Database Library Server 同理。虽然 DatabaseLibrary 可以本地使用，但那就意味着必须使用 Jython 来测试了。当然也可以在同一台机器上运行多个服务器。在一些正式的测试环境中，Robot Framework 和 CI (持续集成) 服务器经常部署在一起。然后，Selenium Server 通常跑在 Windows 服务器上，因为需要尽量模拟用户的使用场景。DatabaseLibrary Server 也可以部署在 CI 服务器上。&lt;/p&gt;&#xA;&lt;h2&gt;测试实现和管理&lt;/h2&gt;&#xA;&lt;p&gt;最后让我们来实现该测试。不是每一个细节都会 cover，具体可以看 &lt;a href=&#34;https://github.com/lyyyuna/Robot-Framework-Sample-Project&#34;&gt;GitHub&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;但在此之前，让我们再多做一些常规性考虑。比如用哪种格式来组织测试用例，是否使用 RIDE。而 RIDE 的使用又会直接影响到测试用例的格式。团队成员的技术背景，以及不同团队合作潜在的维护成本，对上述选择都有影响。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Tips: 如果你已经使用 Excel 来管理则是用例，你可以直接复制粘贴进 RIDE。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;要我在本文的例子中选择，我会选择 HTML 格式和 RIDE，理由如下：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;RIDE 相比较于最初版本已经有了十足的进步，支持关键字自动补全，实现 Test Suites 和 Resource Files 也十分便利。&lt;/li&gt;&#xA;&lt;li&gt;使用 RIDE 不用特意考虑 BDD 风格。但其中有一些我不喜欢的语法元素。而且，非技术团队成员编写和维护测试用例比较困难，因为现在机器还不能完全看懂人类语言。并且我认为，如果 BDD 是唯一或者最重要的需求，其他那些只支持 BDD 的测试框架才会有优势。&lt;/li&gt;&#xA;&lt;li&gt;HTML 格式有着简单粗暴的优点。你可以直接在浏览器中可视化这些测试用例，尤其是那些熟悉 Excel 的非技术团队成员，看到这些会感到非常亲切。&lt;/li&gt;&#xA;&lt;li&gt;HTML 格式也有着缺点，在版本管理时，HTML 会带来各种各样的问题。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;在实现测试时最重要的就是能够同时在本地和正式测试环境（CI 服务器）中运行。幸运的是，Robot Framework 支持向关键字传入参数，这样便能轻松切换环境：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;参数为 web 应用的 URL&lt;/li&gt;&#xA;&lt;li&gt;Selenium 服务器的 IP 地址与端口&lt;/li&gt;&#xA;&lt;li&gt;Database Library 所使用的 JDBC 连接字符串&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这些参数可以存储在变量文件中。这些变量文件可以在命令行中传入 Robot Framework。由于在本地测试和 CI 服务器中有不同启动脚本，这样便能实现不同环境的快速切换。&lt;/p&gt;&#xA;&lt;p&gt;这意味着最好以如下的目录树来组织你的测试工程。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201604/Sample_DirectoryStructure2.png&#34; alt=&#34;测试工程目录树&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;定义一个通用的目录树结构有助于工程的复用。上述的目录结构对我来说工作的不错，我很早就开始用啦。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Tips: 所有路径都应该用相对路径。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;首先，我们将所有文件放于顶层文件 robot 中。然后将测试的实现和执行分开存放。在实现这边，testsuites 和 resource 分开存放。当然在一些大型工程中，还需要额外的子目录来更好的组织测试用例。更重要的是，最好用相对路径来引用这些文件。使用相对路径能够更好的在不同系统间移植，项目成员间通过版本管理系统也能更好地共享工程。&lt;/p&gt;&#xA;&lt;p&gt;执行分支这边必须处理不同运行目标环境的问题，比如本地开发环境和正式的 CI 环境。若还有其他的部署环境需要在此目录中实现。scripts 目录用于保存执行用的脚本（robot 本身，Selenium Server, Database Library Remote Server），setting 目录放置特殊的变量文件。请注意，这些脚本写完之后就不应该频繁改动，对于配置文件亦是如此，除非执行环境有变化。&lt;/p&gt;&#xA;&lt;p&gt;最后是 lib 文件夹，这取决于项目是否需要自己编写库文件。&lt;/p&gt;&#xA;&lt;h2&gt;执行测试&lt;/h2&gt;&#xA;&lt;p&gt;当执行测试时，我坚持使用 shell 脚本。易于理解，历史悠久且不出问题，在 CI 环境中使用方便。当然，我们很可能需要两套不同的启动脚本，因为本地测试通常在 Windows 电脑上，而正式的 CI 环境是一些 bash 或者 csh 脚本。但需注意，这些写了“写了一遍就忘记”的脚本，其实并不复杂。&lt;/p&gt;&#xA;&lt;p&gt;在最初，我们需要三个脚本：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;robot 测试的启动脚本&lt;/li&gt;&#xA;&lt;li&gt;Selenium Server 的启动脚本&lt;/li&gt;&#xA;&lt;li&gt;Database Library Remote Server 的启动脚本&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;我们也可以把三个脚本合并成一个，但为什么不这么做呢，因为其实后两个服务器只需启动一次，只有测试才需要重复执行。&lt;/p&gt;&#xA;&lt;h2&gt;整合&lt;/h2&gt;&#xA;&lt;p&gt;首先我们需要在开发机器上安装 Robot Framework 和库。我们假设平台是 Windows，在 Unix 上安装也不会太复杂。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Robot Framework 同时支持 2.x 和 3.x。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;安装如下的工具包：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Python 2.7&lt;/li&gt;&#xA;&lt;li&gt;Robot Framwork&lt;/li&gt;&#xA;&lt;li&gt;wxPython&lt;/li&gt;&#xA;&lt;li&gt;RIDE&lt;/li&gt;&#xA;&lt;li&gt;Selenium2Library&lt;/li&gt;&#xA;&lt;li&gt;Database Library Server&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;按顺序安装，然后配置 PATH 目录为  “C:\Python27;C:\Python27\Scripts”。现在你可以用&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pybot&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;来运行 Robot Framework，用&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;ride&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;来启动 RIDE。示意图如下，&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201604/RF_Ride.png&#34; alt=&#34;测试工程目录树&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Selenium Library 通常会包含一个对应的 Selenium Server JAR 包。为了独立使用不同目录下的 Selenium Server（比如其他小组成员安装的），你需要指定一个新的环境变量 RF_HOME，该变量指向 Python 的安装目录。该变量用于 selenium 服务器的本地启动脚本。&lt;/p&gt;&#xA;&lt;p&gt;对于本地的 MySQL 数据库，其配置&lt;a href=&#34;https://github.com/ThomasJaspers/robotframework-dblibrary/tree/master/sample&#34;&gt;在此&lt;/a&gt;。然后安装 MySQL，创建测试 schema 和相应的用户：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\xampp\mysql\bin&amp;gt;mysql -u root -p&#xA;mysql&amp;gt; create database databaselibrarydemo;&#xA;mysql&amp;gt; create user ‘dblib’@’localhost’ identified by ‘dblib’;&#xA;mysql&amp;gt; grant all privileges on databaselibrarydemo.* to ‘dblib’;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这里是工程的源码 &lt;a href=&#34;https://github.com/lyyyuna/Robot-Framework-Sample-Project&#34;&gt;GitHub&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;在 robot/execution/local/scripts 是执行测试前所有需要运行的脚本。测试的实现在 robot/implementation/testsuites 目录中。测试用例可以直接用 RIDE 打开 implementation 目录，然后直接查看和修改。&lt;/p&gt;&#xA;&lt;p&gt;为了运行测试，必须先启动 Selenium 服务器和 DBLibrary 服务器。然后运行 Testsuite。Windows 的批处理脚本在 robot\execution\local\scripts 目录中。因为都使用相对路径，一切应该按计划顺利运行。这里虽然在被测服务器上部署文件，但本地可以很容易地适配。&lt;/p&gt;&#xA;&lt;h2&gt;结论和感想&lt;/h2&gt;&#xA;&lt;p&gt;我们已经看到，Robot Framework 提供了众多功能和可能，即使同一件事也能用不同方法来完成。所以，在正式开始测试前做些基本分析是很有意义的。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201604/impression_ride1.png&#34; alt=&#34;在 RIDE 中编辑 Testsuites 和 Resource 文件&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;使用 RIDE 使得实现测试功能更简单，尤其是那些非技术团队。简单意味着好维护（不只是 Robot Framework 测试哦 ;-)）。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201604/impression_seleniumserver.png&#34; alt=&#34;Selenium Server 启动和运行&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;顺便说一下，我还没有明确指出过，Robot Framework 的 &lt;strong&gt;报表&lt;/strong&gt; 和 logging 非常棒，在 troubleshooting 时非常有用。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201604/impression_logfile.png&#34; alt=&#34;Robot Framework 的 log 文件，其中含有浏览器屏幕截图&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Robot Framework 在各种不同的测试库中提供大量的测试功能。一旦决定哪个测试库最好用时，大大加速了写测试的过程，提高了生产力。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201604/impression_dbserver.png&#34; alt=&#34;Database Library Server 运行&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;尤其是在许多不同工程工作时，一个通用的工程结构和工具非常有用。在一些公共的资源文件中也需要实现一些产品相关的关键字。&lt;/p&gt;&#xA;&lt;p&gt;希望本文有助于你开始使用 Robot Framework，并有效地组织你的测试工程结构。当然，本例还有许多增强的地方，希望这是一个良好的起点。&lt;/p&gt;&#xA;&lt;h2&gt;Robot Framework 教程目录&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.codecentric.de/en/2012/04/robot-framework-tutorial-a-complete-example/&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/01/07/robotframework-tutorial-overview/&#34;&gt;Robot Framework 教程 - 概览（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/04/09/robotframework-tutorial-a-complete-example/&#34;&gt;Robot Framework 教程 - 一个完整的例子（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/04/30/robotframework-ide-ride-overview/&#34;&gt;Robot Framework 教程 - 集成开发环境 RIDE 概览 (译)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/15/robotframework-tutorial-how-to-structure-a-scalable-and-maintainable-acceptance-test-suite/&#34;&gt;Robot Framework 教程 - 如何组织一个可伸缩可维护的验收测试套件（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/28/robotframework-tutorial-loops-conditional-execution-and-more/&#34;&gt;Robot Framework 教程 - 循环，条件判断，字符串和列表（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/04/09/robotframework-tutorial-a-complete-example/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>用 asyncio 封装文件读写</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/03/27/asyncfileread01/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;和网络 IO 一样，文件读写同样是一个费事的操作。&lt;/p&gt;&#xA;&lt;p&gt;默认情况下，Python 使用的是系统的阻塞读写。这意味着在 asyncio 中如果调用了&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;f = file(&#39;xx&#39;)&#xA;f.read()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;会阻塞事件循环。&lt;/p&gt;&#xA;&lt;p&gt;本篇简述如何用 asyncio.Future 对象来封装文件的异步读写。&lt;/p&gt;&#xA;&lt;p&gt;代码在 &lt;a href=&#34;https://github.com/lyyyuna/script_collection/blob/master/aysncfile/asyncfile.py&#34;&gt;GitHub&lt;/a&gt;。目前仅支持 Linux。&lt;/p&gt;&#xA;&lt;h2&gt;阻塞和非阻塞&lt;/h2&gt;&#xA;&lt;p&gt;首先需要将文件的读写改为非阻塞的形式。在非阻塞情况下，每次调用 read 都会立即返回，如果返回值为空，则意味着文件操作还未完成，反之则是读取的文件内容。&lt;/p&gt;&#xA;&lt;p&gt;阻塞和非阻塞的切换与操作系统有关，所以本篇暂时只写了 Linux 版本。如果有过 Unix 系统编程经验，会发现 Python 的操作是类似的。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;flag = fcntl.fcntl(self.fd, fcntl.F_GETFL) &#xA;if fcntl.fcntl(self.fd, fcntl.F_SETFL, flag | os.O_NONBLOCK) != 0: &#xA;    raise OSError() &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;Future 对象&lt;/h2&gt;&#xA;&lt;p&gt;Future 对象类似 Javascript 中的 Promise 对象。它是一个占位符，其值会在将来被计算出来。我们可以使用&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;result = await future&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 future 得到值之后返回。而使用&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;future.set_result(xxx)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;就可以设置 future 的值，也意味着 future 可以被返回了。await 操作符会自动调用 future.result() 来得到值。&lt;/p&gt;&#xA;&lt;h2&gt;loop.call_soon&lt;/h2&gt;&#xA;&lt;p&gt;通过 loop.call_soon 方法可以将一个函数插入到事件循环中。&lt;/p&gt;&#xA;&lt;p&gt;至此，我们的异步文件读写思路也就出来了。通过 loop.call_soon 调用非阻塞读写文件的函数。若一次文件读写没有完成，则计算剩余所学读写的字节数，并再次插入事件循环直至读写完毕。&lt;/p&gt;&#xA;&lt;p&gt;可以发现其就是把传统 Unix 编程里，非阻塞文件读写的 while 循环换成了 asyncio 的事件循环。&lt;/p&gt;&#xA;&lt;p&gt;下面是这一过程的示意代码。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    def read_step(self, future, n, total):&#xA;        res = self.fd.read(n)&#xA;        if res is None:&#xA;            self.loop.call_soon(self.read_step, future, n, total)&#xA;            return&#xA;        if not res: # EOF&#xA;            future.set_result(bytes(self.rbuffer))&#xA;            return&#xA;        self.rbuffer.extend(res)&#xA;        self.loop.call_soon(self.read_step, future, self.BLOCK_SIZE, total)&#xA;&#xA;    def read(self, n=-1):&#xA;        future = asyncio.Future(loop=self.loop)&#xA;&#xA;        self.rbuffer.clear()&#xA;        self.loop.call_soon(self.read_step, future, min(self.BLOCK_SIZE, n), n)&#xA;&#xA;        return future&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/03/27/asyncfileread01/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>DHT 协议 - 译</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/03/26/dht01/</id>
    <content type="html">&lt;p&gt;BitTorrent 使用“分布式哈希表” (DHT) 来存储种子的 peer 信息，且不需要专门的服务器。这样，每一个 peer 都变成一个 tracker。DHT 协议基于 Kademila，且用 UDP 实现。&lt;/p&gt;&#xA;&lt;p&gt;请注意文档中的术语以免产生误解。peer 实现了 BitTorrent 协议，既是服务器也是客户端，且监听在 TCP 端口。node 实现了 DHT 协议，同样既是服务器也是客户端，监听在 UDP 端口。DHT 由 node 和 peer 的位置信息构成。BitTorrent 客户端有一个 DHT node，用来和 DHT 中的其他 node 通信用，从而获取 peer 的位置。&lt;/p&gt;&#xA;&lt;h2&gt;概览&lt;/h2&gt;&#xA;&lt;p&gt;每一个 node 都有一个全球唯一标识符，称作 node ID。Node ID 是从 160-bit 的空间中随机选取的，这和 BitTorrent 的&#xA;infohashes 一致。距离参数（Distance metric）用来比较两个 node ID 之间的接近程度。Nodes 必须维护一个包含其他 node 联系信息的路由表。对那些和自身接近的其他 Node ID，路由表中会有跟多细节。所以 DHT 中，接近自己的 ID 有很多，远的 ID 则较少。&lt;/p&gt;&#xA;&lt;p&gt;在 Kademila 中，距离参数使用异或计算，结果为无符号整形，即&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;distance(A, B) = | A XOR B |&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;值越小越接近。&lt;/p&gt;&#xA;&lt;p&gt;当一个 node 想要获取种子的其他 peer 时，它先计算种子的 infohash 和路由表中已有 nodes 的距离参数。然后向距离种子最近的 node 询问 peer 信息。如果恰巧该 node 有，则返回给询问的 node。否则，该 node 把自己路由表中离种子最近的 node 信息返回。本 node 拿到返回信息之后，不停重复上述步骤直到没有新 node 信息返回。搜索结束时，客户端将&lt;strong&gt;自己&lt;/strong&gt;的 peer 信息返回给离种子最近的 node。&lt;/p&gt;&#xA;&lt;p&gt;peer 查询的返回值必须包含令牌(token)。如果一个 node 宣称自己拥有的 peer 正在下载种子时，必须使用最近接收到的 token。当本 node 试图下载种子时，被请求的 node 检查 IP 地址对应的 token 是否一致。这么做是为了防止恶意主机从其他主机下载种子。由于 token 仅仅由请求 node 返回给被请求 node，故协议并未规定其实现。token 在分发后一段时间内必须被接受。BitTorrent 使用 IP + secret 的 SHA1 值作为 token，每 5 分钟改变一次，有 10 分钟有效期。&lt;/p&gt;&#xA;&lt;h2&gt;路由表&lt;/h2&gt;&#xA;&lt;p&gt;每一个 node 维护了一个好 node 的路由表。路由表的中 node 被用作查询的起始节点，并返回查询的响应信息。&lt;/p&gt;&#xA;&lt;p&gt;并非所有 node 是等价的，有些是“好”的，有些则不。大部分 node 能够使用 DHT 协议发送查询和接受响应，但却不能响应其他 node 的查询。所以在路由表中，必须只包含好的 node。一个好的 node 被定义为能在 15 分钟内响应查询，或者 15 分钟内曾经响应过。若 15 钟没响应，则是可疑的。若对一系列请求都失去响应，则为坏的 node。已知的好的 node 拥有更高的优先级。&lt;/p&gt;&#xA;&lt;p&gt;路由表覆盖从 0 到 2^160 完整的 node ID 空间。路由表又被分为 bucket，每一个拥有一部分子空间。空的表只有一个 bucket，其 ID 范围为 min=0 到 max=2^160。当 ID 为 N 的 node 插入到表中时，它必须放在 min=0 到 max=2^160 之间。由于空的表只有一个 bucket，所有 node 都在该 bucket 中。每个 bucket 可以存放 K 个 node，目前 K &amp;lt;= 8。当 bucket 存满好的 node 时，不允许再插入，除非其本身就在该 bucket 中。在这种情况下，原 bucket 分裂为两个相同大小的 bucket，比如原始 bucket 分裂为 0 到 2^159，2^159 到 2^160。&lt;/p&gt;&#xA;&lt;p&gt;当 bucket 装满了好的 node，新的 node 会被丢弃。一旦 bucket 中的某个 node 变坏，就会用新的  node 来替换这个坏的 node。如果 bucket 中有在 15 分钟内都没有活跃过的 bucket，则其为可疑的 node，这时我们向最久没有联系的 node 发送 ping。如果有回复，那么我们向下一个可疑的 node 发送 ping，不断这样循环下去，直到有某一个 node 没有给出 ping 的回复，或者当前 bucket 中的所有 node 都是好的 (即都不是可疑节点，且在过去 15 分钟内都有活动)。如果 bucket 中的某个 node 没有对我们的 ping 给出回复，还会再试一次 (再发送一次 ping，也许仍然是活跃的，但由于网络拥塞，所以发生了丢包现象，注意 DHT 的包都是 UDP 的)，而不是立即丢弃该 node 或者直接用新 node 来替代它。这样，路由表中永远是活跃的 node。&lt;/p&gt;&#xA;&lt;p&gt;每个 bucket 都应该维护一个 lastchange 字段来表明自身的&amp;quot;新鲜&amp;quot;程度。当 bucket 中的 node 被 ping 并给出了回复，或者一个 node 被加入到了 bucket，或者有新的 node 替代了旧的，bucket 的 lastchange 字段都应当更新。如果一个 bucket 的 lastchange 在过去的 15 分钟内都没有变化，那么将重更新它。这个重更新为：从这个 bucket 所覆盖的范围中随机选择一个 node ID，并对这个 ID 执行 find_nodes 搜索。请注意，收到请求的 node 通常不需要常常更新自己所在的 bucket。反之，不常常收到请求的 node 才需要周期性地更新所在 bucket。有了上述措施，在 DHT 时，才能有足够多的好的 node。&lt;/p&gt;&#xA;&lt;p&gt;当插入第一个 node 到路由表并启动时，这个 node 应试着查找 DHT 中离自己最近的 node。这个查找工作是通过不断的发出 find_node 消息给越来越近的 node 来完成的，当没有更近的 node 时，搜索停止。路由表应当由客户端软件保存。&lt;/p&gt;&#xA;&lt;h2&gt;BitTorrent 协议扩展&lt;/h2&gt;&#xA;&lt;p&gt;BitTorrent 协议被扩展为可通过 tracker 得到的 peer 之间互换 node 的 UDP 端口号。在这种方式下，当下载种子时，客户端能够自动更新路由表。新安装的客户端在无 tracker 的种子中获取不到路由表，必须在种子文件中找到联系信息。&lt;/p&gt;&#xA;&lt;p&gt;Peers 如果支持 DHT 协议，会将 BitTorrent 协议握手消息的 8 字节保留位的最后一位置为 1。如果 peer 收到一个握手消息，表明对方支持 DHT 协议，则应该发送 PORT 消息。它由字节 0x09 开始，payload 的长度是 2 个字节，包含了这个 peer 的 DHT 所使用的 UDP 端口号。当 peer 收到这样的消息是应当向对方的 IP 和消息中指定的端口号的节点发送 ping。如果收到了 ping 的回复，则将新 node 的联系信息加入到路由表中。&lt;/p&gt;&#xA;&lt;h2&gt;种子文件扩展&lt;/h2&gt;&#xA;&lt;p&gt;无 tracker 的种子文件中不含有 announce 关键字，相反，其包含有 nodes 关键字。该关键字应该包含种子创建者路由表的 K 个最近 node。也可以选择设置成已知的可用 node，比如这个种子的创建者。请不要加入 router.bittorrent.com。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;nodes = [[&amp;quot;&amp;lt;host&amp;gt;&amp;quot;, &amp;lt;port&amp;gt;], [&amp;quot;&amp;lt;host&amp;gt;&amp;quot;, &amp;lt;port&amp;gt;], ...]&#xA;nodes = [[&amp;quot;127.0.0.1&amp;quot;, 6881], [&amp;quot;your.router.node&amp;quot;, 4804]]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;KRPC 协议&lt;/h2&gt;&#xA;&lt;p&gt;KRPC 协议是一个简单的 RPC 通信框架，其在 UDP 上使用 bencoded 编码的字典，包含请求与回复，但没有重试。有三种消息类型：query, response, error。对于 DHT 协议来说，有 4 种 query: ping, find_node, get_peers, announce_peer。&lt;/p&gt;&#xA;&lt;p&gt;KRPC 消息是一个简单字典，包含两个必填关键字，附加的关键字取决于消息类型。第一个必填关键字是 t，这是一个字符串表示的 transaction ID。它由请求 node 产生，且包含在回复中，所以回复有可能对应单个 node 的多个请求。transaction ID 应该被编码成字符串表示的二进制数字，通常是两个字符，这样就能包含 2^16 种请求。另一个必填关键字是 y，其对应值表示消息类型，为 q, r 或 e。&lt;/p&gt;&#xA;&lt;h2&gt;联系信息编码&lt;/h2&gt;&#xA;&lt;p&gt;peer 的联系信息被编码成 6 字节的字符串。4 字节为 IP 地址，2 字节为端口号，均用网络字节序表示。&lt;/p&gt;&#xA;&lt;p&gt;node 的联系信息被编码成 26 字节的字符串。20 字节为 node ID，剩余为 IP 和端口号信息，均用网络字节序表示。&lt;/p&gt;&#xA;&lt;h2&gt;Queries&lt;/h2&gt;&#xA;&lt;p&gt;query 为键值对 y:q，含有两个附加关键字，q 和 a。关键字 q 的值包含了请求类型的字符串表示。关键字 a 的值包含了一个所有返回值的字典。&lt;/p&gt;&#xA;&lt;h2&gt;Responses&lt;/h2&gt;&#xA;&lt;p&gt;response 为键值对 y:r，含有一个附加关键字 r。关键字 r 的值包含了一个所有返回值的字典。&lt;/p&gt;&#xA;&lt;h2&gt;Errors&lt;/h2&gt;&#xA;&lt;p&gt;error 为键值对 y:e，含有一个附加关键字 e。e 为一个列表。第一个元素是整形表示的错误码。第二个元素是字符串表示的错误信息。以下为可能的错误码，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Code        Description &#xA;=======================&#xA;201         Generic Error &#xA;202         Server Error &#xA;203         Protocol Error, such as a malformed &#xA;            packet, invalid arguments, or bad &#xA;            token &#xA;204         Method Unknown &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;示例，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;generic error = {&amp;quot;t&amp;quot;:&amp;quot;aa&amp;quot;, &amp;quot;y&amp;quot;:&amp;quot;e&amp;quot;, &amp;quot;e&amp;quot;:[201, &amp;quot;A Generic Error Ocurred&amp;quot;]}&#xA;bencoded = d1:eli201e23:A Generic Error Ocurrede1:t2:aa1:y1:ee&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;DHT Queries&lt;/h2&gt;&#xA;&lt;p&gt;所有的 query 都有一个键值对 &#39;id:请求 node ID&#39;。所有的 response 也有一个键值对 &#39;id:响应的 node ID&#39;。&lt;/p&gt;&#xA;&lt;h3&gt;ping&lt;/h3&gt;&#xA;&lt;p&gt;最基本的 query 是 ping。这时候 q=ping，id 为 20 字节网络字节序表示的发送者 node ID。该 query 的响应为 id=响应者 node ID。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;arguments:  {&amp;quot;id&amp;quot; : &amp;quot;&amp;lt;querying nodes id&amp;gt;&amp;quot;}&#xA;&#xA;response: {&amp;quot;id&amp;quot; : &amp;quot;&amp;lt;queried nodes id&amp;gt;&amp;quot;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;示例，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;ping Query = {&amp;quot;t&amp;quot;:&amp;quot;aa&amp;quot;, &amp;quot;y&amp;quot;:&amp;quot;q&amp;quot;, &amp;quot;q&amp;quot;:&amp;quot;ping&amp;quot;, &amp;quot;a&amp;quot;:{&amp;quot;id&amp;quot;:&amp;quot;abcdefghij0123456789&amp;quot;}}&#xA;bencoded = d1:ad2:id20:abcdefghij0123456789e1:q4:ping1:t2:aa1:y1:qe&#xA;&#xA;Response = {&amp;quot;t&amp;quot;:&amp;quot;aa&amp;quot;, &amp;quot;y&amp;quot;:&amp;quot;r&amp;quot;, &amp;quot;r&amp;quot;: {&amp;quot;id&amp;quot;:&amp;quot;mnopqrstuvwxyz123456&amp;quot;}}&#xA;bencoded = d1:rd2:id20:mnopqrstuvwxyz123456e1:t2:aa1:y1:re&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;find_node&lt;/h3&gt;&#xA;&lt;p&gt;find_node 被用来查找给定 ID 的 node 的联系信息。这时 q == find_node。find_node 请求包含 2 个参数，第一个参数是 id，包含了请求 node ID。第二个参数是 target，包含了请求者正在查找的 node ID。当一个 node 接收到了 find_node 的 query，他应该给出对应的回复，回复中包含 2 个关键字 id 和 nodes，nodes 是字符串类型，包含了被请求 node 的路由表中最接近目标 node 的 K(8) 个最接近的 node 的联系信息。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;arguments:  {&amp;quot;id&amp;quot; : &amp;quot;&amp;lt;querying nodes id&amp;gt;&amp;quot;, &amp;quot;target&amp;quot; : &amp;quot;&amp;lt;id of target node&amp;gt;&amp;quot;}&#xA;&#xA;response: {&amp;quot;id&amp;quot; : &amp;quot;&amp;lt;queried nodes id&amp;gt;&amp;quot;, &amp;quot;nodes&amp;quot; : &amp;quot;&amp;lt;compact node info&amp;gt;&amp;quot;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;示例，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;find_node Query = {&amp;quot;t&amp;quot;:&amp;quot;aa&amp;quot;, &amp;quot;y&amp;quot;:&amp;quot;q&amp;quot;, &amp;quot;q&amp;quot;:&amp;quot;find_node&amp;quot;, &amp;quot;a&amp;quot;: {&amp;quot;id&amp;quot;:&amp;quot;abcdefghij0123456789&amp;quot;, &amp;quot;target&amp;quot;:&amp;quot;mnopqrstuvwxyz123456&amp;quot;}}&#xA;bencoded = d1:ad2:id20:abcdefghij01234567896:target20:mnopqrstuvwxyz123456e1:q9:find_node1:t2:aa1:y1:qe&#xA;&#xA;Response = {&amp;quot;t&amp;quot;:&amp;quot;aa&amp;quot;, &amp;quot;y&amp;quot;:&amp;quot;r&amp;quot;, &amp;quot;r&amp;quot;: {&amp;quot;id&amp;quot;:&amp;quot;0123456789abcdefghij&amp;quot;, &amp;quot;nodes&amp;quot;: &amp;quot;def456...&amp;quot;}}&#xA;bencoded = d1:rd2:id20:0123456789abcdefghij5:nodes9:def456...e1:t2:aa1:y1:re&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;get_peers&lt;/h3&gt;&#xA;&lt;p&gt;get_peers 与种子文件的 infohash 有关。这时 q=get_peers。get_peers 请求包含 2 个参数。第一个参数是 id，包含了请求 node 的 ID。第二个参数是 info_hash，它代表种子文件的 infohash。如果被请求的 node 有对应 info_hash 的 peers，他将返回一个关键字 values，这是一个列表类型的字符串。每一个字符串包含了 CompactIP-address/portinfo 格式的 peers 信息。如果被请求的 node 没有这个 infohash 的 peers，那么他将返回关键字 nodes，这个关键字包含了被请求 node 的路由表中离 info_hash 最近的 K 个 node，使用 Compactnodeinfo 格式回复。在这两种情况下，关键字 token 都将被返回。之后的 annouce_peer 请求中必须包含 token。token 是一个短的二进制字符串。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;arguments:  {&amp;quot;id&amp;quot; : &amp;quot;&amp;lt;querying nodes id&amp;gt;&amp;quot;, &amp;quot;info_hash&amp;quot; : &amp;quot;&amp;lt;20-byte infohash of target torrent&amp;gt;&amp;quot;}&#xA;&#xA;response: {&amp;quot;id&amp;quot; : &amp;quot;&amp;lt;queried nodes id&amp;gt;&amp;quot;, &amp;quot;token&amp;quot; :&amp;quot;&amp;lt;opaque write token&amp;gt;&amp;quot;, &amp;quot;values&amp;quot; : [&amp;quot;&amp;lt;peer 1 info string&amp;gt;&amp;quot;, &amp;quot;&amp;lt;peer 2 info string&amp;gt;&amp;quot;]}&#xA;&#xA;or: {&amp;quot;id&amp;quot; : &amp;quot;&amp;lt;queried nodes id&amp;gt;&amp;quot;, &amp;quot;token&amp;quot; :&amp;quot;&amp;lt;opaque write token&amp;gt;&amp;quot;, &amp;quot;nodes&amp;quot; : &amp;quot;&amp;lt;compact node info&amp;gt;&amp;quot;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;示例，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;get_peers Query = {&amp;quot;t&amp;quot;:&amp;quot;aa&amp;quot;, &amp;quot;y&amp;quot;:&amp;quot;q&amp;quot;, &amp;quot;q&amp;quot;:&amp;quot;get_peers&amp;quot;, &amp;quot;a&amp;quot;: {&amp;quot;id&amp;quot;:&amp;quot;abcdefghij0123456789&amp;quot;, &amp;quot;info_hash&amp;quot;:&amp;quot;mnopqrstuvwxyz123456&amp;quot;}}&#xA;bencoded = d1:ad2:id20:abcdefghij01234567899:info_hash20:mnopqrstuvwxyz123456e1:q9:get_peers1:t2:aa1:y1:qe&#xA;&#xA;Response with peers = {&amp;quot;t&amp;quot;:&amp;quot;aa&amp;quot;, &amp;quot;y&amp;quot;:&amp;quot;r&amp;quot;, &amp;quot;r&amp;quot;: {&amp;quot;id&amp;quot;:&amp;quot;abcdefghij0123456789&amp;quot;, &amp;quot;token&amp;quot;:&amp;quot;aoeusnth&amp;quot;, &amp;quot;values&amp;quot;: [&amp;quot;axje.u&amp;quot;, &amp;quot;idhtnm&amp;quot;]}}&#xA;bencoded = d1:rd2:id20:abcdefghij01234567895:token8:aoeusnth6:valuesl6:axje.u6:idhtnmee1:t2:aa1:y1:re&#xA;&#xA;Response with closest nodes = {&amp;quot;t&amp;quot;:&amp;quot;aa&amp;quot;, &amp;quot;y&amp;quot;:&amp;quot;r&amp;quot;, &amp;quot;r&amp;quot;: {&amp;quot;id&amp;quot;:&amp;quot;abcdefghij0123456789&amp;quot;, &amp;quot;token&amp;quot;:&amp;quot;aoeusnth&amp;quot;, &amp;quot;nodes&amp;quot;: &amp;quot;def456...&amp;quot;}}&#xA;bencoded = d1:rd2:id20:abcdefghij01234567895:nodes9:def456...5:token8:aoeusnthe1:t2:aa1:y1:re&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;announce_peer&lt;/h3&gt;&#xA;&lt;p&gt;announce_peer 表示某个端口正在下载种子文件。announce_peer 包含 4 个参数。第一个参数是 id，包含了请求 node ID；第二个参数是 info_hash，包含了种子文件的 infohash；第三个参数是 port 包含了整型的端口号，表明 peer 在哪个端口下载；第四个参数是 token，这是在之前的 get_peers 请求中收到的回复中所包含的。收到 announce_peer 请求的 node 必须检查这个 token 与回复的 token 是否相同。如果相同，那么被请求的 node 将记录发送者的 IP 和端口号，记录在 peer 联系信息中对应的 infohash 下。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;arguments:  {&amp;quot;id&amp;quot; : &amp;quot;&amp;lt;querying nodes id&amp;gt;&amp;quot;,&#xA;&amp;quot;implied_port&amp;quot;: &amp;lt;0 or 1&amp;gt;,&#xA;&amp;quot;info_hash&amp;quot; : &amp;quot;&amp;lt;20-byte infohash of target torrent&amp;gt;&amp;quot;,&#xA;&amp;quot;port&amp;quot; : &amp;lt;port number&amp;gt;,&#xA;&amp;quot;token&amp;quot; : &amp;quot;&amp;lt;opaque token&amp;gt;&amp;quot;}&#xA;&#xA;response: {&amp;quot;id&amp;quot; : &amp;quot;&amp;lt;queried nodes id&amp;gt;&amp;quot;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;示例，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;announce_peers Query = {&amp;quot;t&amp;quot;:&amp;quot;aa&amp;quot;, &amp;quot;y&amp;quot;:&amp;quot;q&amp;quot;, &amp;quot;q&amp;quot;:&amp;quot;announce_peer&amp;quot;, &amp;quot;a&amp;quot;: {&amp;quot;id&amp;quot;:&amp;quot;abcdefghij0123456789&amp;quot;, &amp;quot;implied_port&amp;quot;: 1, &amp;quot;info_hash&amp;quot;:&amp;quot;mnopqrstuvwxyz123456&amp;quot;, &amp;quot;port&amp;quot;: 6881, &amp;quot;token&amp;quot;: &amp;quot;aoeusnth&amp;quot;}}&#xA;bencoded = d1:ad2:id20:abcdefghij01234567899:info_hash20:&amp;lt;br /&amp;gt;&#xA;mnopqrstuvwxyz1234564:porti6881e5:token8:aoeusnthe1:q13:announce_peer1:t2:aa1:y1:qe&#xA;&#xA;Response = {&amp;quot;t&amp;quot;:&amp;quot;aa&amp;quot;, &amp;quot;y&amp;quot;:&amp;quot;r&amp;quot;, &amp;quot;r&amp;quot;: {&amp;quot;id&amp;quot;:&amp;quot;mnopqrstuvwxyz123456&amp;quot;}}&#xA;bencoded = d1:rd2:id20:mnopqrstuvwxyz123456e1:t2:aa1:y1:re&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/03/26/dht01/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>asyncio 的 coroutine 与 Future</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/03/20/python-asyncio01/</id>
    <content type="html">&lt;h2&gt;coroutine 与 Future 的关系&lt;/h2&gt;&#xA;&lt;p&gt;看起来两者是一样的，因为都可以用以下的语法来异步获取结果，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;result = await future&#xA;result = await coroutine&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;实际上，coroutine 是生成器函数，它既可以从外部接受参数，也可以产生结果。使用 coroutine 的好处是，我们可以暂停一个函数，然后稍后恢复执行。比如在涉及到网路操作的情况下，能够停下函数直到响应到来。在停下的这段时间内，我们可以切换到其他任务继续执行。&lt;/p&gt;&#xA;&lt;p&gt;而 Future 更像是 Javascript 中的 Promise 对象。它是一个占位符，其值会在将来被计算出来。在上述的例子中，当我们在等待网络 IO 函数完成时，函数会给我们一个容器，Promise 会在完成时填充该容器。填充完毕后，我们可以用回调函数来获取实际结果。&lt;/p&gt;&#xA;&lt;p&gt;Task 对象是 Future 的子类，它将 coroutine 和 Future 联系在一起，将 coroutine 封装成一个 Future 对象。&lt;/p&gt;&#xA;&lt;p&gt;一般会看到两种任务启动方法，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;tasks = asyncio.gather(&#xA;    asyncio.ensure_future(func1()),&#xA;    asyncio.ensure_future(func2())&#xA;)&#xA;loop.run_until_complete(tasks)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;和&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;tasks = [&#xA;    asyncio.ensure_future(func1()),&#xA;    asyncio.ensure_future(func2())&#xA;    ]&#xA;loop.run_until_complete(asyncio.wait(tasks))&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;ensure_future 可以将 coroutine 封装成 Task。asyncio.gather 将一些 Future 和 coroutine 封装成一个 Future。asyncio.wait 则本身就是 coroutine。&lt;/p&gt;&#xA;&lt;p&gt;run_until_complete 既可以接收 Future 对象，也可以是 coroutine 对象，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;BaseEventLoop.run_until_complete(future)&#xA;&#xA;Run until the Future is done.&#xA;If the argument is a coroutine object, it is wrapped by ensure_future().&#xA;Return the Future’s result, or raise its exception.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;Task 任务的正确退出方式&lt;/h2&gt;&#xA;&lt;p&gt;在 asyncio 的任务循环中，如果使用 CTRL-C 退出的话，即使捕获了异常，Event Loop 中的任务会报错，出现如下的错误，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Task was destroyed but it is pending!&#xA;task: &amp;lt;Task pending coro=&amp;lt;kill_me() done, defined at test.py:5&amp;gt; wait_for=&amp;lt;Future pending cb=[Task._wakeup()]&amp;gt;&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;根据官方文档，Task 对象只有在以下几种情况，会认为是退出，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;a result / exception are available, or that the future was cancelled&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Task 对象的 cancel 和其父类 Future 略有不同。当调用 Task.cancel() 后，对应 coroutine 会在事件循环的下一轮中抛出 CancelledError 异常。使用 Future.cancelled() 并不能立即返回 True（用来表示任务结束），只有在上述异常被处理任务结束后才算是 cancelled。&lt;/p&gt;&#xA;&lt;p&gt;故结束任务可以用&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;for task in asyncio.Task.all_tasks():&#xA;    task.cancel()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这种方法将所有任务找出并 cancel。&lt;/p&gt;&#xA;&lt;p&gt;但 CTRL-C 也会将事件循环停止，所以有必要重启事件循环，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    try:&#xA;        loop.run_until_complete(tasks)&#xA;    except KeyboardInterrupt as e:&#xA;        for task in asyncio.Task.all_tasks():&#xA;            task.cancel()&#xA;        loop.run_forever() # restart loop&#xA;    finally:&#xA;        loop.close()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在每个 Task 中捕获异常是必要的，如果不确定，可以使用&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;asyncio.gather(..., return_exceptions=True)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;将异常转换为正常的结果返回。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/03/20/python-asyncio01/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>B站全站直播弹幕收集系统的简单设计</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/03/19/bilibili-danmu02/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;虽然标题是全站，但目前只做了等级 top 100 直播间的全天弹幕收集。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/lyyyuna/bilibili_danmu_colloector&#34;&gt;弹幕收集系统&lt;/a&gt;基于之前的&lt;a href=&#34;https://github.com/lyyyuna/bilibili_danmu&#34;&gt;Python版B站直播弹幕姬&lt;/a&gt;修改而来。具体协议分析可以看&lt;a href=&#34;http://www.lyyyuna.com/2016/03/14/bilibili-danmu01/&#34;&gt;上一篇文章&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;直播弹幕协议是直接基于 TCP 协议，所以如果 B 站对类似我这种行为做反制措施，比较困难。应该有我不知道的技术手段来检测类似我这种恶意行为。&lt;/p&gt;&#xA;&lt;p&gt;我试过同时连接 100 个房间，和连接单个房间 100 次的实验，都没有问题。&amp;gt;150 会被关闭链接。&lt;/p&gt;&#xA;&lt;h2&gt;直播间的选取&lt;/h2&gt;&#xA;&lt;p&gt;现在&lt;a href=&#34;https://github.com/lyyyuna/bilibili_danmu_colloector&#34;&gt;弹幕收集系统&lt;/a&gt;在选取直播间上比较简单，直接选取了等级 top100。&lt;/p&gt;&#xA;&lt;p&gt;以后会修改这部分，改成定时去 http://live.bilibili.com/all 查看新开播的直播间，并动态添加任务。&lt;/p&gt;&#xA;&lt;h2&gt;异步任务和弹幕存储&lt;/h2&gt;&#xA;&lt;p&gt;收集系统仍旧使用了 asyncio 异步协程框架，对于每一个直播间都使用如下方法来加进 loop 中。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;danmuji = bilibiliClient(url, self.lock, self.commentq, self.numq)&#xA;task1 = asyncio.ensure_future(danmuji.connectServer())&#xA;task2 = asyncio.ensure_future(danmuji.HeartbeatLoop())&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;其实若将心跳任务 HeartbeatLoop 放入 connectorServer 中去启动，代码看起来更优雅一些。但这么做是因为我需要维护一个任务列表，后面会有描述。&lt;/p&gt;&#xA;&lt;p&gt;在弹幕存储上我花了些时间选择。&#xA;数据库存储是一个同步 IO 的过程，Insert 的时候会阻塞弹幕收集的任务。虽然有 aiomysql 这种异步接口，但配置数据库太麻烦，我的设想是这个小系统能够方便地部署。&lt;/p&gt;&#xA;&lt;p&gt;最终我选择使用自带的 sqlite3。但 sqlite3 无法做并行操作，故开了一个线程单独进行数据库存储。在另一个线程中，100 * 2 个任务搜集所有的弹幕、人数信息，并塞进队列 commentq, numq 中。存储线程每隔 10s 唤醒一次，将队列中的数据写进 sqlite3 中，并清空队列。&lt;/p&gt;&#xA;&lt;p&gt;在多线程和异步的配合下，网络流量没有被阻塞。&lt;/p&gt;&#xA;&lt;h2&gt;可能的连接失败场景处理&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/03/14/bilibili-danmu01/&#34;&gt;弹幕协议&lt;/a&gt;是直接基于 TCP，位与位直接关联性较强，一旦解析错误，很容易就抛 Exception（个人感觉，虽然 TCP 是可靠传输，但B站服务器自身发生错误也是有可能的）。所以有必要设计一个自动重连机制。&lt;/p&gt;&#xA;&lt;p&gt;在 asyncio 文档中提到，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Done means either that a result / exception are available, or that the future was cancelled.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;函数正常返回、抛出异常或者是被 cancel，都会退出当前任务。可以使用 done() 来判断。&lt;/p&gt;&#xA;&lt;p&gt;每一个直播间对应两个任务，解析任务是最容易挂的，但并不会影响心跳任务，所以必须找出并将对应心跳任务结束。&lt;/p&gt;&#xA;&lt;p&gt;在创建任务的时候使用字典记录每个房间的两个任务，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;self.tasks[url] = [task1, task2]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在运行过程中，每隔 10s 做一次检查，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;for url in self.tasks:&#xA;    item = self.tasks[url]&#xA;    task1 = item[0]&#xA;    task2 = item[1]&#xA;    if task1.done() == True or task2.done() == True:&#xA;        if task1.done() == False:&#xA;            task1.cancel()&#xA;        if task2.done() == False:&#xA;            task2.cancel()&#xA;        danmuji = bilibiliClient(url, self.lock, self.commentq, self.numq)&#xA;        task11 = asyncio.ensure_future(danmuji.connectServer())&#xA;        task22 = asyncio.ensure_future(danmuji.HeartbeatLoop())&#xA;        self.tasks[url] = [task11, task22]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;实际我只见过一次任务失败的场景，是因为主播房间被封了，导致无法进入直播间。&lt;/p&gt;&#xA;&lt;h2&gt;结论&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;B站人数是按照连接弹幕服务器的链接数量统计的。通过操纵链接量，可以&lt;strong&gt;瞬间增加任意人数观看&lt;/strong&gt;，有商机？&lt;/li&gt;&#xA;&lt;li&gt;运行的这几天中，发现即使大部分房间不在直播，也能有 &amp;gt;5 的人数，包括凌晨。我只能猜测也有和我一样的人在 24h 收集弹幕。&lt;/li&gt;&#xA;&lt;li&gt;top100 平均一天 40M 弹幕数据。&lt;/li&gt;&#xA;&lt;li&gt;收集的弹幕能做什么？还没想好，可能可以拿来做用户行为分析 -_^&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/03/19/bilibili-danmu02/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>B站直播弹幕协议详解</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/03/14/bilibili-danmu01/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;B站直播弹幕是在 flash 里做的，所以浏览器的开发工具抓不到包。去年我根据 Wireshark 抓的 TCP 包硬写了一个&lt;a href=&#34;https://github.com/lyyyuna/script_collection/blob/master/bilibli_danmu/11.py&#34;&gt;直播终端版&lt;/a&gt;，不过当时对里面很多二进制位不知所云。&lt;/p&gt;&#xA;&lt;p&gt;上个星期我发现B站官方有专门为 UP 主准备的直播弹幕姬，且是用 C# 写的，于是就逆向了。。&lt;/p&gt;&#xA;&lt;p&gt;这里是最新的 &lt;a href=&#34;https://github.com/lyyyuna/bilibili_danmu&#34;&gt;B 站直播弹幕姬 Python 版&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;本篇将对直播协议做一个完整介绍。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;B站协议和端口是会变的（至少改变过一次），故不能保证本篇所述有向后兼容性。&lt;/li&gt;&#xA;&lt;li&gt;有兴趣去逆向B站直播弹幕姬的朋友，不要使用 ILSpy debug 版本，因为有 C# 5, async/await，debug 版本看起来会非常凌乱。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;总体过程&lt;/h2&gt;&#xA;&lt;p&gt;直播协议首先需要获取 RoomId，获取服务器地址，然后与 B 站服务器建立 TCP 链接并保持，之后就处于监听状态，B 站会连续地将弹幕消息推送过来。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Get RoomId (HTTP) --&amp;gt; Get server address (HTTP) --&amp;gt; Open TCP &amp;amp; wait --&amp;gt; parse json&#xA;                                                           |                |&#xA;                                                           \ -- /&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;其中获取 RoomId 有些费解，一般我们认为一个 UP 主的房间 url 若为 http://live.bilibili.com/44515，则其 RoomId 就应该为 44515，但其实部分 UP 主的 url 和其 RoomId 并不对应。比如神奇陆夫人，其 url 显示为 115，但实际上 RoomId 为 1016。真正的 RoomId 需要去 http://live.bilibili.com/115 的 html 中寻找。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;&#xA;    var ROOMID = 1016;&#xA;    var DANMU_RND = 1457957537;&#xA;    var NEED_VIDEO = 1;&#xA;    var ROOMURL = 115;&#xA;&amp;lt;/script&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这些特别的 UP 主经测试 url 都在 100 左右，猜测他们可能是 B 站老用户，或者他们向 B 站申请过特殊 url。&lt;/p&gt;&#xA;&lt;h3&gt;房间连接过程&lt;/h3&gt;&#xA;&lt;p&gt;获取 RoomId 之后，紧接一个 HTTP 请求 &#39;http://live.bilibili.com/api/player?id=cid:RoomId&#39;，获取 xml 数据,&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;uid&amp;gt;0&amp;lt;/uid&amp;gt;&#xA;&amp;lt;uname&amp;gt;&amp;lt;/uname&amp;gt;&#xA;&amp;lt;login&amp;gt;false&amp;lt;/login&amp;gt;&#xA;&amp;lt;isadmin&amp;gt;false&amp;lt;/isadmin&amp;gt;&#xA;&amp;lt;time&amp;gt;1457954601&amp;lt;/time&amp;gt;&#xA;&amp;lt;rank&amp;gt;&amp;lt;/rank&amp;gt;&#xA;&amp;lt;level&amp;gt;&amp;lt;/level&amp;gt;&#xA;&amp;lt;chatid&amp;gt;1016&amp;lt;/chatid&amp;gt;&#xA;&amp;lt;server&amp;gt;livecmt-1.bilibili.com&amp;lt;/server&amp;gt;&#xA;&amp;lt;user_sheid_keyword&amp;gt;&amp;lt;/user_sheid_keyword&amp;gt;&#xA;&amp;lt;sheid_user&amp;gt;&amp;lt;/sheid_user&amp;gt;&#xA;&amp;lt;block_time&amp;gt;0&amp;lt;/block_time&amp;gt;&#xA;&amp;lt;block_type&amp;gt;0&amp;lt;/block_type&amp;gt;&#xA;&amp;lt;state&amp;gt;LIVE&amp;lt;/state&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;其中 livecmt-1.bilibili.com 为直播弹幕地址。&lt;/p&gt;&#xA;&lt;p&gt;然后向 livecmt-1.bilibili.com:788 开一个 TCP 链接，之后所有的弹幕和心跳包都会发生在此链接上。&lt;/p&gt;&#xA;&lt;p&gt;进入直播间需要发送如下的数据包：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;00000000  00 00 00 35 00 10 00 01  00 00 00 07 00 00 00 01 ...5.... ........&#xA;00000010  7b 22 72 6f 6f 6d 69 64  22 3a 31 30 31 36 2c 22 {&amp;quot;roomid &amp;quot;:1016,&amp;quot;&#xA;00000020  75 69 64 22 3a 31 35 35  39 37 33 36 38 35 37 32 uid&amp;quot;:155 97368572&#xA;00000030  38 31 36 30 7d                                   8160}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;0x35 是一次数据包的长度，0x00100001 不详，0x07 代表请求进入直播间，0x00000001 不详。&#xA;后面跟了一串 json 数据，uid 为客户端随机生成，算法如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;(int)(100000000000000.0 + 200000000000000.0*random.random())&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果进入房间成功，则会返回&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;00 00 00 10 00 10 00 01  00 00 00 08 00 00 00 01&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;目前看来并没有其他特殊含义。&lt;/p&gt;&#xA;&lt;h3&gt;消息种类&lt;/h3&gt;&#xA;&lt;p&gt;如果接收到的数据包为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;00000010  00 00 00 14 00 10 00 01  00 00 00 03 00 00 00 01 ........ ........&#xA;00000020  00 00 3c 49                                      ..&amp;lt;I&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;其中 0x14 为一次数据包的长度，0x0010001 不详，0x03 代表这是一个在线人数数据包，0x00000001 不详，0x3c49 = 15433 为在线人数。根据逆向的源码显示，0x03,0x02,0x01 都代表在线人数数据包，不过我只抓到了 0x03 这一种。&lt;/p&gt;&#xA;&lt;p&gt;如果接收到的数据包为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;00000825  00 00 00 d4 00 10 00 00  00 00 00 05 00 00 00 00 ........ ........&#xA;00000835  7b 22 69 6e 66 6f 22 3a  5b 5b 30 2c 31 2c 32 35 {&amp;quot;info&amp;quot;: [[0,1,25&#xA;00000845  2c 31 36 37 37 37 32 31  35 2c 31 34 35 37 39 35 ,1677721 5,145795&#xA;00000855  38 33 37 34 2c 22 31 34  35 37 39 35 35 36 35 35 8374,&amp;quot;14 57955655&#xA;00000865  22 2c 30 2c 22 61 66 61  39 66 37 32 64 22 2c 30 &amp;quot;,0,&amp;quot;afa 9f72d&amp;quot;,0&#xA;00000875  5d 2c 22 e7 81 ab e6 8a  8a e8 80 90 e4 b9 85 ef ],&amp;quot;..... ........&#xA;00000885  bc 88 30 32 ef bc 89 22  2c 5b 36 31 34 39 34 33 ..02...&amp;quot; ,[614943&#xA;00000895  2c 22 e8 8d 92 e5 b7 9d  e5 90 b9 e6 b0 b4 22 2c ,&amp;quot;...... ......&amp;quot;,&#xA;000008A5  30 2c 30 2c 30 5d 2c 5b  39 2c 22 e7 b2 be e8 8b 0,0,0],[ 9,&amp;quot;.....&#xA;000008B5  b1 22 2c 22 e7 a5 9e e5  a5 87 e9 99 86 e5 a4 ab .&amp;quot;,&amp;quot;.... ........&#xA;000008C5  e4 ba ba 22 2c 31 31 35  2c 31 32 32 32 35 32 35 ...&amp;quot;,115 ,1222525&#xA;000008D5  35 5d 2c 5b 32 31 2c 32  35 38 32 37 5d 2c 5b 5d 5],[21,2 5827],[]&#xA;000008E5  5d 2c 22 63 6d 64 22 3a  22 44 41 4e 4d 55 5f 4d ],&amp;quot;cmd&amp;quot;: &amp;quot;DANMU_M&#xA;000008F5  53 47 22 7d                                      SG&amp;quot;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这是一个弹幕数据包，0xd4 为数据包的长度，0x00100000 不详，0x05 代表这是弹幕，0x00000000 不详。之后就是 json 格式的弹幕消息。&lt;/p&gt;&#xA;&lt;h3&gt;弹幕种类&lt;/h3&gt;&#xA;&lt;p&gt;跟据 json[&#39;cmd&#39;] 的值，可分为：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LIVE 直播中&lt;/li&gt;&#xA;&lt;li&gt;PREPARING 准备中&lt;/li&gt;&#xA;&lt;li&gt;DANMU_MSG 弹幕消息&lt;/li&gt;&#xA;&lt;li&gt;SEND_GIFT 赠送礼物消息&lt;/li&gt;&#xA;&lt;li&gt;WELCOME 欢迎某人进入直播间&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;对于 DANMU_MSG，&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;json[&#39;info&#39;][1] 为弹幕消息主体，为 utf-8 编码&lt;/li&gt;&#xA;&lt;li&gt;json[&#39;info&#39;][2][1] 为发送者昵称，为 utf-8 编码&lt;/li&gt;&#xA;&lt;li&gt;json[&#39;info&#39;][2][2] == &#39;1&#39; 是否是管理员&lt;/li&gt;&#xA;&lt;li&gt;json[&#39;info&#39;][2][3] == &#39;1&#39; 是否是 VIP&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;对于 SEND_GIFT，&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;json[&#39;data&#39;][&#39;giftName&#39;] 为礼物名称&lt;/li&gt;&#xA;&lt;li&gt;json[&#39;data&#39;][&#39;uname&#39;] 为发送者昵称&lt;/li&gt;&#xA;&lt;li&gt;json[&#39;data&#39;][&#39;rcost&#39;] 不详&lt;/li&gt;&#xA;&lt;li&gt;json[&#39;data&#39;][&#39;num&#39;] 为礼物数目&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;对于 WELCOME，&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;json[&#39;data&#39;][&#39;uname&#39;] 为新进入直播间的用户昵称&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;心跳包&lt;/h3&gt;&#xA;&lt;p&gt;心跳包和进入直播间所发送的包仅有些许不同&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;00 00 00 10 00 10 00 01  00 00 00 02 00 00 00 01&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;把 0x07 变为 0x02 即可。心跳间隔为 30s。&lt;/p&gt;&#xA;&lt;h2&gt;结论&lt;/h2&gt;&#xA;&lt;p&gt;以下是我登陆 C菌 直播间抓取的弹幕消息。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201603/bilibili.png&#34; alt=&#34;效果图&#34;&gt;&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/03/14/bilibili-danmu01/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>知乎轮带逛 - 定向爬取轮子哥赞过的妹子图</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/02/28/zhihu-lundaiguang/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;轮带逛，是指跟着轮子哥的知乎动态很容易找到高质量妹子图。然而知乎动态管理和搜索都不友好，如果手工翻阅动态工作量很大，所以写了一个脚本，用于找出那些妹子图片。&lt;/p&gt;&#xA;&lt;p&gt;这是脚本的&lt;a href=&#34;https://github.com/lyyyuna/zhihu_lundaiguang&#34;&gt;源码链接&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;GitHub 上已经有一些知乎的第三方 API，如 &lt;a href=&#34;https://github.com/7sDream/zhihu-py3&#34;&gt;zhihu-py3&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/egrcc/zhihu-python&#34;&gt;zhihu-python&lt;/a&gt; 。&lt;/p&gt;&#xA;&lt;p&gt;但我想用异步写，且定制性高，所以还是从头造个轮子。&lt;/p&gt;&#xA;&lt;h2&gt;页面分析&lt;/h2&gt;&#xA;&lt;h3&gt;知乎登陆过程分析&lt;/h3&gt;&#xA;&lt;p&gt;上述 GitHub 知乎的 API 都是使用邮箱、密码、验证码来登陆的，现在知乎支持只使用邮箱/手机号、密码来登陆。虽然老接口仍然可用，但新方法更便捷。&lt;/p&gt;&#xA;&lt;p&gt;因为登陆过程会有 Redirects，所以建议打开 Firebug 的 Persist，或者是使用 Burpsuite 之类的代理来捕获 https 数据流量。&lt;/p&gt;&#xA;&lt;p&gt;以下是使用邮箱登陆时关键的两个请求。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201602/login1.jpg&#34; alt=&#34;登陆请求&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;以下为提交密码的请求，可以看到 POST 四个参数。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201602/login_post.jpg&#34; alt=&#34;提交账号&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;remember_me 为记住我，而 _xsrf 是在登陆页面 html 代码的隐藏参数。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201602/login_xsrf.jpg&#34; alt=&#34;隐藏参数&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;在获取用户更多动态时需要将 _xsrf 作为参数之一提交。但是这里有个小坑，这里获取的 _xsrf 值并不等于获取动态时提交的 _xsrf。实际上经过测试，在登陆时也根本不需要提交这个 _xsrf 参数。个人猜测这是旧接口的遗留代码。&lt;/p&gt;&#xA;&lt;p&gt;那么之后获取更多动态时的 _xsrf 来自哪呢？它藏在 cookies 中。然而知乎的 cookies 并不是一次性获取完毕，如下图所示，登陆完毕只拿到了五个项。（事先把知乎的 cookies 清空）&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201602/cookies1.jpg&#34; alt=&#34;第一次 cookies&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;而紧接着的第二个 GET 请求，才会拿到这个关键的 _xsrf cookies。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201602/cookies2.jpg&#34; alt=&#34;第二次 cookies&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;至此，登陆完毕。&lt;/p&gt;&#xA;&lt;h3&gt;知乎用户新动态分析&lt;/h3&gt;&#xA;&lt;p&gt;分析可借助浏览器调试工具查看，这里总结如下。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;每个用户动态位于 (&#39;div&#39;, class_=&#39;zm-profile-section-item zm-item clearfix&#39;)；&lt;/li&gt;&#xA;&lt;li&gt;上述 div 标签中，若 &#39;data-type-detail&#39; == &#39;member_voteup_answer&#39;，则为该用户送出的赞；&lt;/li&gt;&#xA;&lt;li&gt;上述 div 标签中，data-time 属性的值需作为获取更多状态时作为 start 提交；&lt;/li&gt;&#xA;&lt;li&gt;每个回答在点击之前&amp;quot;显示全部&amp;quot;之前是隐藏的，位于 (&#39;textarea&#39;, class_=&#39;content hidden&#39;)，隐藏内容被转义过；&lt;/li&gt;&#xA;&lt;li&gt;每个回答的评论链接位于 (&#39;div&#39;, class_=&#39;zm-item-answer&#39;)。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;获取知乎回答的评论&lt;/h3&gt;&#xA;&lt;p&gt;GET 上述的评论链接，会返回一个 json 数据。json[&#39;paging&#39;] 中为评论总数、每页评论数、当前页。json[&#39;data&#39;] 为评论数据。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201602/comments.jpg&#34; alt=&#34;评论 json 数据&#34;&gt;&lt;/p&gt;&#xA;&lt;h3&gt;模拟点击“更多”，获取更多动态&lt;/h3&gt;&#xA;&lt;p&gt;以 cookies 中的 _xsrf 和当前最后一个 data-time 为参数 POST，即可获得更多状态。返会的是 html 代码，然后重复上述步骤直到没有更多状态为止。&lt;/p&gt;&#xA;&lt;h2&gt;程序及算法&lt;/h2&gt;&#xA;&lt;p&gt;其实算法很简单。所有轮带逛的回答评论中都有类似“轮带逛、文明观球、营养快线”等关键字，只要符合这个规律，就可以判断出这条动态是我们的目标。&lt;/p&gt;&#xA;&lt;p&gt;我采用 Python3.5 原生的 asyncio 来实现异步，用 aiohttp 编写了所有的底层 GET/POST 请求。一共分为三个任务：crawl_voteup_answer、download_image、monitor，任务之间通过队列通信。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;        \&#xA;        |                                      |                     |&#xA;crawl_voteup_answer --&amp;gt; 登陆 --&amp;gt; 找到赞 --&amp;gt; 分析评论 --&amp;gt; 获取图片链接 -/&#xA;                                                            |&#xA;                                                       queue.put(url)&#xA;                                                        &#xA;                                    download_image &amp;lt;-- queue.get(url)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;monitor 任务中主要是打印队列中等待的链接个数。另外，大约每隔 200s 会让整个爬虫停止 20s，以避免知乎可能的反爬虫措施。&lt;/p&gt;&#xA;&lt;h2&gt;结论&lt;/h2&gt;&#xA;&lt;p&gt;我用以下的参数，花了两个小时爬完了轮子哥的所有动态。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;more_interval = 1 # 点击更多的时间间隔&#xA;comment_interval = 0.2 # 获取评论的时间间隔&#xA;img_interval = 0.2 # 下载图片的时间间隔 &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;一共找到 3669 个妹子图片，其中有效的估计为 85%。而且根据终端的打印过程粗略分析，轮子个在 2015.6 之前还是很正经的，专注于技术问题，而在 2015.6 之后大约有 3000 个妹子图。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201602/meizi.jpg&#34; alt=&#34;妹子图&#34;&gt;&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/02/28/zhihu-lundaiguang/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>SCons 用户指南第六章 - 依赖</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/01/31/scons6-dependencies/</id>
    <content type="html">&lt;p&gt;目前为止，我们看到的都是 SCons 一次性编译的例子。但编译工具一个最主要的功能是只重新编译源码改变的部分，换句话说，SCons 不应该浪费时间重新编译不该编译的内容。比如之前的 hello 例子，你可以调用 SCons 两次看结果的不同：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;% scons -Q&#xA;scons: `.&#39; is up to date.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;第二次执行时，SCons 意识到 hello 程序对于源码来说已经是最新的了，它会拒绝重新编译。你可以通过命令行显式指定程序名来看的更清楚些：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q hello&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;% scons -Q hello&#xA;scons: `hello&#39; is up to date.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;请注意，SCons 报告的 &amp;quot;...is up to date&amp;quot; 是为了避免混淆输出，且只是针对命令行中显式指定的文件名。&lt;/p&gt;&#xA;&lt;h2&gt;判断输入文件何时改变：Decider 函数&lt;/h2&gt;&#xA;&lt;p&gt;编译工具的一个重要方面是在输入文件改变时能发现并重新编译，从而保证软件实时更新。SCons 默认使用 MD5 签名或校验和来跟踪文件内容，也可以使用修改时间戳来跟踪。你甚至可以指定 Python 函数来决定文件是否改变。&lt;/p&gt;&#xA;&lt;h3&gt;使用 MD5 签名来决定文件是否改变&lt;/h3&gt;&#xA;&lt;p&gt;SCons 默认使用 MD5 签名而不是文件的修改时间来跟踪文件的内容。这意味着，如果你习惯基于文件修改时间来重编译，你会有点不习惯。我们用 touch 命令做个例子：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q hello&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;% touch hello.c&#xA;% scons -Q hello&#xA;scons: `hello&#39; is up to date.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到，即使改过时间，SCons 仍然能够判断出文件内容并没有改变，也就避免了 hello 的再次编译。又比如有人修改了文件，但文件内容没改变，这时候也不会重新编译。但当文件内容真的改变了，SCons 就能够检查到并重新编译：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q hello&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;%     [CHANGE THE CONTENTS OF hello.c]&#xA;% scons -Q hello&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;请注意，如果你愿意，你可以用 Decider 方法来显式地指定默认的行为（比如 MD5 签名）：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello.c&#39;)&#xA;Decider(&#39;MD5&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;你也可以用 &#39;MD5&#39; 的同义词 &#39;content&#39;。&lt;/p&gt;&#xA;&lt;h4&gt;使用 MD5 签名的好处&lt;/h4&gt;&#xA;&lt;p&gt;用 MD5 签名来判定内容是否改变带来一个很大的好处：那就是如果一个源文件重新编译后的二进制文件没有改变，则其下游依赖于此的目标文件就不需要重编译。&lt;/p&gt;&#xA;&lt;p&gt;举例来说，用户如果只是更改了源文件的一个注释，那么重新编译的 hello.o 文件会和之前的完全一致（假设编译器没有做手脚）。SCons 这时候就不会重新编译 hello.o：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q hello&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;%   [CHANGE A COMMENT IN hello.c]&#xA;% scons -Q hello&#xA;cc -o hello.o -c hello.c&#xA;scons: `hello&#39; is up to date.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;本质上，当 SCons 意识到文件没有改变时，会对其他依赖于此的编译行为作“短路”处理。虽然分析目标文件（hello.o）内容会花费一些时间，但相比于漫长的编译时间无疑有很高的性价比。&lt;/p&gt;&#xA;&lt;h3&gt;使用时间戳来判断文件是否改变&lt;/h3&gt;&#xA;&lt;p&gt;你也可以使用时间戳，而不是文件内容来决定是否重编译。SCons 有两种使用时间戳的方法来判断输入文件是否改变。&lt;/p&gt;&#xA;&lt;p&gt;最常用的时间戳判断法和 Make 类似：那就是，如果源文件的修改时间比目标文件更新，就重编译。参照如下的调用 Decider 方法：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Object(&#39;hello.c&#39;)&#xA;Decider(&#39;timestamp-newer&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这种模式下，SCons 有点像 Make，可以用 touch 命令来验证这一点：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q hello.o&#xA;cc -o hello.o -c hello.c&#xA;% touch hello.c&#xA;% scons -Q hello.o&#xA;cc -o hello.o -c hello.c&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;实际上正因为其行为和 Make 类似，你也可以用 &#39;make&#39; 字符串来代替 &#39;timestamp-newer&#39;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Object(&#39;hello.c&#39;)&#xA;Decider(&#39;make&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;类似于 Make 的时间戳方法有一个缺点，那就是如果一个输入文件的修改时间比目标文件早，那么目标文件不会重编译。比如你从备份库中恢复源文件就会触发这种行为。恢复的源文件其内容很有可能发生改变，但由于修改时间早于目标文件，也就自然不会重编译。&lt;/p&gt;&#xA;&lt;p&gt;不过 SCons 能够在每次编译的时候记录源文件的时间戳，只要时间戳不同就会出发重编译。这样即使新的源文件比目标文件还要早，也能轻松应对。你可以使用 &#39;timestamp-match&#39; 参数让 SCons 使用这种模式：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Object(&#39;hello.c&#39;)&#xA;Decider(&#39;timestamp-match&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在这种模式下，只要源文件时间戳改变，就会重编译。所以即使我们用 touch -t 选项来将源文件改成一个老的时间（1989.1.1），SCons 仍然会充编译：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q hello.o&#xA;cc -o hello.o -c hello.c&#xA;% touch -t 198901010000 hello.c&#xA;% scons -Q hello.o&#xA;cc -o hello.o -c hello.c&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;通常，用 timestamp-newer 的唯一理由是，你可能有一些特殊需求：改动会来自老文件。&lt;/p&gt;&#xA;&lt;h3&gt;同时使用 MD 签名和时间戳来判断文件是否改变&lt;/h3&gt;&#xA;&lt;p&gt;处于性能的原因，SCons 提供了折中的方法：只对时间戳改变的文件作 MD5 校验。向 Decider 方法传递 &#39;MD5-timestamp&#39; 参数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello.c&#39;)&#xA;Decider(&#39;MD5-timestamp&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这样配置之后，其行为会类似于 &#39;MD5&#39; 参数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q hello&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;% touch hello.c&#xA;% scons -Q hello&#xA;scons: `hello&#39; is up to date.&#xA;% edit hello.c&#xA;    [CHANGE THE CONTENTS OF hello.c]&#xA;% scons -Q hello&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;不过，可以看到，第二个 SCons 调用仅会查看 hello.c 文件的修改时间，而不需要打开文件并计算 MD5 校验和。这种行为能够显著地加速编译。&lt;/p&gt;&#xA;&lt;p&gt;不过缺点是，如果文件在一秒钟之内完成修改，那么 SCons 就不会去重编译它。当然实际开发编程时，基本不会有人这么快完成源文件的修改动作。不过一些编译脚本或者持续集成工具会自动修改文件，这种行为会非常快，这时候 Decider(&#39;MD5-timestamp&#39;) 就不合适了。&lt;/p&gt;&#xA;&lt;h3&gt;写一个自定义的 Decider 方法&lt;/h3&gt;&#xA;&lt;p&gt;传递给 Decider 方法的不同字符串，会让 SCons 采用各种内置函数来分析目标文件的依赖（通常是源文件）。当然啦，你也可以自己写一个函数来分析依赖有没有发生变化。&lt;/p&gt;&#xA;&lt;p&gt;比如，假设我们有很多特定格式的数据在同一个文件中，用来生成不同的目标文件，但每一个目标文件只是依赖于某几个数据。我们想建立这种特定的依赖行为。然而，由于数据太多，我们只想在时间戳改变的时候才去分析输入文件。这时候我们就可以写一个自定义的 Decider 方法：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello.c&#39;)&#xA;def decide_if_changed(dependency, target, prev_ni):&#xA;    if self.get_timestamp() != prev_ni.timestamp:&#xA;        dep = str(dependency)&#xA;        tgt = str(target)&#xA;        if specific_part_of_file_has_changed(dep, tgt):&#xA;            return True&#xA;    return False&#xA;Decider(decide_if_changed)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;请注意在函数定义中，dependency 是第一个参数，然后是 target。这两个参数都是 SCons 的 Node 节点，紧接会用 str() 函数将其转为字符串。&lt;/p&gt;&#xA;&lt;p&gt;第三个参数 prev_ni 是上次目标文件编译时依赖的签名或时间戳信息。实际上 prev_ni 可以按需求包含各种不同信息。对于普通文件，prev_ni 对象有着以下的属性：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;.csig 是目标文件上次编译时其依赖的内容签名，或称之为 MD5 签名。&lt;/li&gt;&#xA;&lt;li&gt;.size 依赖文件的二进制字节数。&lt;/li&gt;&#xA;&lt;li&gt;.timestamp 依赖文件上次的修改时间。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;请注意，在 Decider 方法中忽略一些参数是常见的做法，且不会影响编译行为。&lt;/p&gt;&#xA;&lt;p&gt;另一事需要注意，在第一次运行 SCons 前，三个属性并不都是初始化过的。比如 .sconsign DB 文件在没有目标文件之前不会存在。所以，你必须每次都检查一下 prev_ni 属性的可用性。&lt;/p&gt;&#xA;&lt;p&gt;最终我们得到一个基于 csig 的决策函数的例子。请注意每次调用，依赖文件的签名信息必须通过 get_csig 函数来初始化（这是手动的！）。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;env = Environment()&#xA;&#xA;def config_file_decider(dependency, target, prev_ni):&#xA;    import os.path&#xA;&#xA;    # We always have to init the .csig value...&#xA;    dep_csig = dependency.get_csig()&#xA;    # .csig may not exist, because no target was built yet...&#xA;    if &#39;csig&#39; not in dir(prev_ni):&#xA;        return True&#xA;    # Target file may not exist yet&#xA;    if not os.path.exists(str(target.abspath)):&#xA;        return True&#xA;    if dep_csig != prev_ni.csig:&#xA;        # Some change on source file =&amp;gt; update installed one&#xA;        return True&#xA;    return False&#xA;&#xA;def update_file():&#xA;    f = open(&amp;quot;test.txt&amp;quot;,&amp;quot;a&amp;quot;)&#xA;    f.write(&amp;quot;some line\n&amp;quot;)&#xA;    f.close()&#xA;&#xA;update_file()&#xA;&#xA;# Activate our own decider function&#xA;env.Decider(config_file_decider)&#xA;&#xA;env.Install(&amp;quot;install&amp;quot;,&amp;quot;test.txt&amp;quot;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;混合使用不同方法来判断一个文件是否改变&lt;/h3&gt;&#xA;&lt;p&gt;上一个例子展现了如何使用全局 Decider 方法来解决依赖问题。有时候你会希望对不同目标文件应用不同的决策方法。这时候你可以使用 env.Decider 方法，这样就只会对特定的编译环境产生影响。&lt;/p&gt;&#xA;&lt;p&gt;举例来说，我们希望在一次编译中使用 MD5 校验，并在另一次编译中对相同的源文件使用时间戳，那么你就可以这样：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;env1 = Environment(CPPPATH = [&#39;.&#39;])&#xA;env2 = env1.Clone()&#xA;env2.Decider(&#39;timestamp-match&#39;)&#xA;env1.Program(&#39;prog-MD5&#39;, &#39;program1.c&#39;)&#xA;env2.Program(&#39;prog-timestamp&#39;, &#39;program2.c&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;假设两次编译都包含了 inc.h 文件，那么更新 inc.h 的修改时间（用 touch 命令）就会触发不同的重编译行为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o program1.o -c -I. program1.c&#xA;cc -o prog-MD5 program1.o&#xA;cc -o program2.o -c -I. program2.c&#xA;cc -o prog-timestamp program2.o&#xA;% touch inc.h&#xA;% scons -Q&#xA;cc -o program2.o -c -I. program2.c&#xA;cc -o prog-timestamp program2.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;决策函数的历史版本&lt;/h2&gt;&#xA;&lt;p&gt;现在的 SCons 版本仍然支持两个曾经主要的决策函数。它们被官方加入 2.0 版本，但现在已经不鼓励使用，因为它们在源文件和目标文件之间建立了一种令人费解的决策行为。现在你只可能在维护旧版本的 SConscript 文件中才会碰到它们。&lt;/p&gt;&#xA;&lt;h3&gt;SourceSignature 方法&lt;/h3&gt;&#xA;&lt;p&gt;SourceSignature 方法非常直接，支持两种决策方法，第一个就是 MD5 签名法：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello.c&#39;)&#xA;SourceSignatures(&#39;MD5&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;另一个是时间戳：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello.c&#39;)&#xA;SourceSignatures(&#39;timestamp&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;它们分别和 Decider(&#39;MD5&#39;) 和 Decider(&#39;timestamp-match&#39;) 很像，但是在这种行为之下，SCons 只能依赖于源文件的变化，即那些不是从其他文件生成的文件。&lt;/p&gt;&#xA;&lt;h3&gt;TargetSignatures 方法&lt;/h3&gt;&#xA;&lt;p&gt;当一个目标文件本身被作为其它目标的文件的依赖时，可以用 TargetSignature 方法来决定 SCons 的行为。也就是说，TargetSignature 方法可以配置那些最终目标依赖的临时二进制文件。&lt;/p&gt;&#xA;&lt;p&gt;TargetSignature 方法同样支持 &#39;MD5&#39; 和 &#39;timestamp&#39; 两个参数，其意义和上节所述是一致的。这个例子中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello.c&#39;)&#xA;TargetSignatures(&#39;MD5&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;hello.o 的 MD5 签名将决定最终程序 hello 是否被重编译。在下面的例子中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello.c&#39;)&#xA;TargetSignatures(&#39;timestamp&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;hello.o 的时间戳将决定最终程序 hello 是否被重编译。&lt;/p&gt;&#xA;&lt;p&gt;TargetSignatures 方法还支持 &#39;source&#39; 和 &#39;build&#39; 两个额外的参数。&#39;source&#39; 参数指定了目标文件和源文件使用同样的决策行为（即和 SourceSignature 一样）。所以在这个例子中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello.c&#39;)&#xA;TargetSignatures(&#39;source&#39;)&#xA;SourceSignatures(&#39;timestamp&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;所有目标和源文件都将使用修改时间戳来判断是否改变。&lt;/p&gt;&#xA;&lt;p&gt;最后，&#39;build&#39; 参数指定了 SCons 必须检察目标文件的编译状态，如果一个目标文件被重编译了，在不检查其内容或时间戳的情况下，所有依赖于此的下游目标文件也应该重编译。如果没有重编译，则使用 SourceSignature 重复上节的行为。&lt;/p&gt;&#xA;&lt;p&gt;这其实是模仿了更早 SCons 版本的 build signatures 行为。build signatures 会合并所有输入文件的签名，这样就不需要计算目标文件的 MD5 签名。虽然在某些配置下能提高性能，但远不如 Decider(&#39;MD5-timestamp&#39;) 高效。&lt;/p&gt;&#xA;&lt;h2&gt;隐式依赖：$CPPPATH 配置变量&lt;/h2&gt;&#xA;&lt;p&gt;假设我们的 &amp;quot;Hello, World!&amp;quot; 程序用 #include 包含了 hello.h 头文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;hello.h&amp;gt;&#xA;int&#xA;main()&#xA;{&#xA;    printf(&amp;quot;Hello, %s!\n&amp;quot;, string);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;hello.h 中内容为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;#define string    &amp;quot;world&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在这个例子中，我们希望 SCons 在发现 hello.h 内容改变时，能重编译。为此，我们需要修改 SConstruct 文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello.c&#39;, CPPPATH = &#39;.&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;$CPPPATH 告诉 SCons 去当前目录寻找源程序包含的头文件。这时候：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q hello&#xA;cc -o hello.o -c -I. hello.c&#xA;cc -o hello hello.o&#xA;% scons -Q hello&#xA;scons: `hello&#39; is up to date.&#xA;%     [CHANGE THE CONTENTS OF hello.h]&#xA;% scons -Q hello&#xA;cc -o hello.o -c -I. hello.c&#xA;cc -o hello hello.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;首先可以注意到，SCons 添加了 $CPPPATH 变量所指定的 -I. 参数，这样编译时能够在本地目录的 hello.h 文件。&lt;/p&gt;&#xA;&lt;p&gt;然后，SCons 会扫描 hello.c 包含的 hello.h 内容来决定是否重编译。SCons 会将这标记为目标文件的隐式依赖，所有依赖于 hello.c 和 hello.h 的文件都会被重编译。&lt;/p&gt;&#xA;&lt;p&gt;像 $LIBPATH 变量那样，$CPPPATH 变量可以是一些目录路径的列表，或者是目录路径分割的字符串（在 POSIX/Linux 上是 &#39;:&#39;，在 Windows 上是 &#39;;&#39;）。这两个方法都能使 SCons 产生正确的编译选项：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello.c&#39;, CPPPATH = [&#39;include&#39;, &#39;/home/project/inc&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 POSIX 或 Linux 系统上：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q hello&#xA;cc -o hello.o -c -Iinclude -I/home/project/inc hello.c&#xA;cc -o hello hello.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 Windows 上：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;scons -Q hello.exe&#xA;cl /Fohello.obj /c hello.c /nologo /Iinclude /I\home\project\inc&#xA;link /nologo /OUT:hello.exe hello.obj&#xA;embedManifestExeCheck(target, source, env)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;缓存隐式依赖&lt;/h2&gt;&#xA;&lt;p&gt;扫描每个 #include 文件会耗费额外的时间。当构建大型系统时，扫描时间只占了一小部分的编译时间。但重编译部分组件时，扫描占据的时间就非常可观，在真正编译前，SCons 会花费大量的时间判断所有依赖是否是最新的。&lt;/p&gt;&#xA;&lt;p&gt;实际中，错误的依赖中会浪费 SCons 扫描时间只是一个小问题。然而，等待时间通常让开发人员不能忍。因此，SCons 允许你缓存依赖关系，下次编译可以直接使用。你只需要在命令行中指定 --implicit-cache 选项：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q --implicit-cache hello&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;% scons -Q hello&#xA;scons: `hello&#39; is up to date.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果你不想每次在命令行指定 --implicit-cache 选项，你可以在 SConscript 文件中设置 implicit_cache ，使其成为默认行为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;SetOption(&#39;implicit_cache&#39;, 1)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;SCons 默认不缓存隐式依赖，因为当依赖发生改变后，SCons 不能及时发现变化。具体来说，在以下情况，--implicit-cache 选项会导致重编译失败：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;当使用 --implicit-cache 选项，SCons 会忽略如 $CPPPATH 或 $LIBPATH 路径中的任何变化，比如不同目录的同名文件。&lt;/li&gt;&#xA;&lt;li&gt;当使用 --implicit-cache 选项，如果一个和之前同名的文件被加入到路径中，SCons 就无法检测到变化。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3&gt;--implicit-deps-changed 选项&lt;/h3&gt;&#xA;&lt;p&gt;在使用隐式依赖关系时，有时你想重新扫描文件以重建缓存。比如说，你项目编译依赖的一个外部库最近有了更新，这时候缓存的隐式依赖就过时了。你可以通过 --implicit-deps-changed 选项来更新缓存：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q --implicit-deps-changed hello&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;% scons -Q hello&#xA;scons: `hello&#39; is up to date.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在这个例子中，SCons 会重新扫描隐式依赖并更新缓存。&lt;/p&gt;&#xA;&lt;h3&gt;--implicit-deps-unchanged 选项&lt;/h3&gt;&#xA;&lt;p&gt;在建立缓存时，SCons 默认会区分那些修改过的文件。然而有时，即使源文件发生变化，你仍然想强制 SCons 使用缓存中的依赖。在 #include 包含的头文件没变化，而只是源文件做了修改的情况下，这可以加速编译过程。在下面这个例子中，你可以使用 --implicit-deps-unchanged 选项：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q --implicit-deps-unchanged hello&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;% scons -Q hello&#xA;scons: `hello&#39; is up to date.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这里，SCons 假设缓存是最新的，且不会去重新扫描文件。但实际是，对于持续的微小代码改动，这样虽然减少了编译时间，但有可能却让产品错过了显著的性能提升。&lt;/p&gt;&#xA;&lt;h2&gt;显式依赖：Depends 方法&lt;/h2&gt;&#xA;&lt;p&gt;有时候，SCons 不能发现文件的依赖。在这种情况下，就需要你显式地定义文件之间的依赖关系，才能在文件改动后触发重编译。这通过 Depends 方法来实现：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;hello = Program(&#39;hello.c&#39;)&#xA;Depends(hello, &#39;other_file&#39;)&#xA;&#xA;% scons -Q hello&#xA;cc -c hello.c -o hello.o&#xA;cc -o hello hello.o&#xA;% scons -Q hello&#xA;scons: `hello&#39; is up to date.&#xA;% edit other_file&#xA;    [CHANGE THE CONTENTS OF other_file]&#xA;% scons -Q hello&#xA;cc -c hello.c -o hello.o&#xA;cc -o hello hello.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;请注意，Depends 的依赖（即第二个参数）也可以是节点对象的列表：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;hello = Program(&#39;hello.c&#39;)&#xA;goodbye = Program(&#39;goodbye.c&#39;)&#xA;Depends(hello, goodbye)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这样，依赖将先于目标文件生成：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q hello&#xA;cc -c goodbye.c -o goodbye.o&#xA;cc -o goodbye goodbye.o&#xA;cc -c hello.c -o hello.o&#xA;cc -o hello hello.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;来自外部文件的依赖：ParseDepends 方法&lt;/h2&gt;&#xA;&lt;p&gt;SCons 对不同语言有不同的内置扫描器。但由于扫描器实现的不足，有时候不能提取出特定的隐式依赖关系。&lt;/p&gt;&#xA;&lt;p&gt;下面是一个扫描 C 语言头文件失败的例子：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;#define FOO_HEADER &amp;lt;foo.h&amp;gt;&#xA;#include FOO_HEADER&#xA;&#xA;int main() {&#xA;    return FOO;&#xA;}&#xA;&#xA;% scons -Q&#xA;cc -o hello.o -c -I. hello.c&#xA;cc -o hello hello.o&#xA;%    [CHANGE CONTENTS OF foo.h]&#xA;% scons -Q&#xA;scons: `.&#39; is up to date.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;很显然扫描器无法分析头文件的依赖。因为不是一个完整的 C 预处理器，扫描器无法展开宏。&lt;/p&gt;&#xA;&lt;p&gt;在这些情况下，你也许会求助编译器来提取隐式依赖关系。ParseDepends 方法能够解析编译器的 Make 风格的输出，并显式地建立起所有依赖项。&lt;/p&gt;&#xA;&lt;p&gt;下面这个例子使用 ParseDepends 来处理编译器产生的依赖文件，而这些依赖文件其实是编译时的副产物：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;obj = Object(&#39;hello.c&#39;, CCFLAGS=&#39;-MD -MF hello.d&#39;, CPPPATH=&#39;.&#39;)&#xA;SideEffect(&#39;hello.d&#39;, obj)&#xA;ParseDepends(&#39;hello.d&#39;)&#xA;Program(&#39;hello&#39;, obj)&#xA;  &#xA;% scons -Q&#xA;cc -o hello.o -c -MD -MF hello.d -I. hello.c&#xA;cc -o hello hello.o&#xA;%    [CHANGE CONTENTS OF foo.h]&#xA;% scons -Q&#xA;cc -o hello.o -c -MD -MF hello.d -I. hello.c&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;解析编译器产生的 .d 依赖文件会导致鸡生蛋-蛋生鸡的问题。也就是不必要的重编译问题：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o hello.o -c -MD -MF hello.d -I. hello.c&#xA;cc -o hello hello.o&#xA;% scons -Q --debug=explain&#xA;scons: rebuilding `hello.o&#39; because `foo.h&#39; is a new dependency&#xA;cc -o hello.o -c -MD -MF hello.d -I. hello.c&#xA;% scons -Q&#xA;scons: `.&#39; is up to date.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在第一次运行时，依赖文件随二进制文件一起产生。因为此时 SCons 并不清楚目标文件依赖于 foo.h。在第二次运行的时候，二进制文件被重编译，因为此时 foo.h 被确认为一个新的依赖。&lt;/p&gt;&#xA;&lt;p&gt;ParseDepends 在启动时立即读入指定的文件，并判断出文件是否存在。而编译过程产生的依赖文件不会再被自动解析。因此，在同一次编译中，编译器提取的依赖关系不会被存入签名数据库中。这个不足导致 ParseDepends 会带来不必要的重编译行为。因此，应只在 SCons 的扫描器不足以应付时使用这个功能。&lt;/p&gt;&#xA;&lt;h2&gt;忽略依赖：Ignore 函数&lt;/h2&gt;&#xA;&lt;p&gt;有时候即使依赖改变也不想重编译程序，你就需要向 SCons 指定要忽略的文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;hello_obj=Object(&#39;hello.c&#39;)&#xA;hello = Program(hello_obj)&#xA;Ignore(hello_obj, &#39;hello.h&#39;)&#xA;&#xA;% scons -Q hello&#xA;cc -c -o hello.o hello.c&#xA;cc -o hello hello.o&#xA;% scons -Q hello&#xA;scons: `hello&#39; is up to date.&#xA;% edit hello.h&#xA;[CHANGE THE CONTENTS OF hello.h]&#xA;% scons -Q hello&#xA;scons: `hello&#39; is up to date.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;现在，上面的例子有点不自然，因为实际开发中很难想象在 hello.h 改变后，不需要重编译 hello。更现实的例子是，hello 所在的目录被不同系统所共享，但每个系统的 stdio.h 头文件都不相同。如果不作设置，那么在切换系统的时候，SCons 就会误以为头文件改变而触发重编译行为。为了避免此问题，可以作如下改动：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;hello = Program(&#39;hello.c&#39;, CPPPATH=[&#39;/usr/include&#39;])&#xA;Ignore(hello, &#39;/usr/include/stdio.h&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Ignore 方法还可以避免默认的编译行为。这是因为目录实际上依赖于其内部内容。如果想避免某个文件被默认编译，可以指定目录忽略特定文件。请注意，当用户在命令行指定需要目标文件时，还是会触发编译行为。或者其他依赖于此该文件的文件被要求编译时，也会编译该文件。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;hello_obj=Object(&#39;hello.c&#39;)&#xA;hello = Program(hello_obj)&#xA;Ignore(&#39;.&#39;,[hello,hello_obj])&#xA;&#xA;% scons -Q&#xA;scons: `.&#39; is up to date.&#xA;% scons -Q hello&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;% scons -Q hello&#xA;scons: `hello&#39; is up to date.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;按序依赖：Requires 方法&lt;/h2&gt;&#xA;&lt;p&gt;偶尔的，你可能需要修改某些文件和目录，且它们被目标文件所依赖，但这些改变对目标文件来说没有影响，你不希望这些改变触发重编译行为。这种关系称为按序依赖，因为只有目标文件之前的依赖关系发生了改变。这样的依赖关系导致的改变并不一定需要传递到目标文件。&lt;/p&gt;&#xA;&lt;p&gt;举例来说，你需要在每次编译时产生一个文件来记录编译时长、版本信息等。很显然这个文件的内容每次都不同。如果你的 SCons 配置成普通的依赖决策，那么每次都会导致重编译行为。为了演示该行为，可以用 Python 生成一个 version.c 文件，然后让原程序链接此文件，最后在生成目标文件时打印其中的字符串：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;import time&#xA;&#xA;version_c_text = &amp;quot;&amp;quot;&amp;quot;&#xA;char *date = &amp;quot;%s&amp;quot;;&#xA;&amp;quot;&amp;quot;&amp;quot; % time.ctime(time.time())&#xA;open(&#39;version.c&#39;, &#39;w&#39;).write(version_c_text)&#xA;&#xA;hello = Program([&#39;hello.c&#39;, &#39;version.c&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果 version.c 是一个实际的源文件那么显然每次 version.o 都会重编译，接着会导致 hello 每次也跟着重编译：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q hello&#xA;cc -o hello.o -c hello.c&#xA;cc -o version.o -c version.c&#xA;cc -o hello hello.o version.o&#xA;% sleep 1&#xA;% scons -Q hello&#xA;cc -o version.o -c version.c&#xA;cc -o hello hello.o version.o&#xA;% sleep 1&#xA;% scons -Q hello&#xA;cc -o version.o -c version.c&#xA;cc -o hello hello.o version.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;（请注意，需要 sleep 一秒钟来正确使用上述这个例子）&lt;/p&gt;&#xA;&lt;p&gt;一个解决方法是使用 Requires 方法，指定 version.o 的改变只有在目标程序需要链接时，才会导致重编译行为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;import time&#xA;&#xA;version_c_text = &amp;quot;&amp;quot;&amp;quot;&#xA;char *date = &amp;quot;%s&amp;quot;;&#xA;&amp;quot;&amp;quot;&amp;quot; % time.ctime(time.time())&#xA;open(&#39;version.c&#39;, &#39;w&#39;).write(version_c_text)&#xA;&#xA;version_obj = Object(&#39;version.c&#39;)&#xA;&#xA;hello = Program(&#39;hello.c&#39;,&#xA;                LINKFLAGS = str(version_obj[0]))&#xA;&#xA;Requires(hello, version_obj)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;请注意，虽然我们不再将 version.c 作为源文件之一，我们还是需要提取文件名作为 $LINKFLAGS 变量，才会触发编译器链接行为。&lt;/p&gt;&#xA;&lt;p&gt;当做出上述改变后，hello 可执行程序只有在 hello.c 改变时才会重编译，而 version.o 的重编译（因为 SConstruct 每次都会改变 version.c 的内容）不会触发最终程序的重编译：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q hello&#xA;cc -o version.o -c version.c&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello version.o hello.o&#xA;% sleep 1&#xA;% scons -Q hello&#xA;cc -o version.o -c version.c&#xA;scons: `hello&#39; is up to date.&#xA;% sleep 1&#xA;%     [CHANGE THE CONTENTS OF hello.c]&#xA;% scons -Q hello&#xA;cc -o version.o -c version.c&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello version.o hello.o&#xA;% sleep 1&#xA;% scons -Q hello&#xA;cc -o version.o -c version.c&#xA;scons: `hello&#39; is up to date.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;AlwaysBuild 方法&lt;/h2&gt;&#xA;&lt;p&gt;最后，还可以通过 AlwaysBuild 方法来影响 SCons 处理依赖的行为。当一个文件被传入 AlwaysBuild 方法：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;hello = Program(&#39;hello.c&#39;)&#xA;AlwaysBuild(hello)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;每次编译目标文件时，该源文件都会被认为是过时的，所有依赖路径上的文件都会被重编译：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;% scons -Q&#xA;cc -o hello hello.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;AlwaysBuild 这个名字有歧义，因为它并不意味着目标文件每次都会重编译。而是说每次在命令行指定该目标文件时，会触发重编译行为。所以假如在命令行指定其他的目标文件，那么它只有在真正过时时才会被重编译：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;% scons -Q hello.o&#xA;scons: `hello.o&#39; is up to date.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/01/31/scons6-dependencies/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>使用 Python 实现一个简单的 HTTP 代理 - GET</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/01/16/http-proxy-get1/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;HTTP 代理是位于服务器与客户端之间的中间实体，在各个端点之间来回传送 HTTP 报文。&lt;/p&gt;&#xA;&lt;p&gt;按照用途分类，HTTP proxy 可以分为&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;内容过滤。&lt;/li&gt;&#xA;&lt;li&gt;科学上网。&lt;/li&gt;&#xA;&lt;li&gt;Web 缓存。维护服务器常用文档的一个副本，增加客户端的访问速度。&lt;/li&gt;&#xA;&lt;li&gt;反向代理。反向代理可以接收发给服务器的真实请求，然后按需交给真实的服务器。类似于路由的功能。&lt;/li&gt;&#xA;&lt;li&gt;...&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;按照代理对客户端的可见性又可以分为&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;透明代理&lt;/li&gt;&#xA;&lt;li&gt;非透明代理&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;本文要实现一个简单的 HTTP 非透明代理，暂时只支持 GET 请求的转发，且不追求性能和错误处理。&lt;/p&gt;&#xA;&lt;h2&gt;HTTP 非透明代理下 GET 请求的不同&lt;/h2&gt;&#xA;&lt;p&gt;除了部分请求头和 URL 之外，在非透明代理下，浏览器发给服务器和发给代理的报文是完全一样的。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;首先浏览器会向非透明代理发送完整的绝对路径 URL。而在普通情况下只会发送相对路径，不需要主机名。&lt;/li&gt;&#xA;&lt;li&gt;浏览器会用 Proxy-Connection 头部代替 Connection 头部。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3&gt;为何要用绝对路径&lt;/h3&gt;&#xA;&lt;p&gt;早期的 HTTP 设计中，客户端只会与单个服务器进行通信，所以一旦 TCP 连接建立起来以后，只需要相对路径。&lt;/p&gt;&#xA;&lt;p&gt;但代理就有问题，客户端首先和代理建立 TCP 连接，但由于传递的请求头中使用相对路径，代理就不知道使用什么 IP 和 端口来向远端的服务器建立 TCP 连接。所以，对于早期的 HTTP 1.0，强制客户端发给代理时使用完整路径，如&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;GET http://www.douban.com/ HTTP /1.0&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;较新的 HTTP 1.1 则规定了必须包含 Host 头部。所以对于 HTTP 1.1 的代理来说，完整 URL 不是必须的。但由于网络上还有大量旧版代理，Host 头部代理或许根本不识别，所以现在浏览器在使用代理时，还是会使用完整 URL。&lt;/p&gt;&#xA;&lt;p&gt;以下是用 nc 监听 8888 端口，火狐配置 nc 8888 为代理时，所发送 GET 请求&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;root@yan:~# nc -lvp 8888&#xA;listening on [any] 8888 ...&#xA;Warning: forward host lookup failed for promote.cache-dns.local: Unknown host&#xA;connect to [192.168.27.128] from promote.cache-dns.local [192.168.27.1] 29798&#xA;GET http://www.douban.com/ HTTP/1.1&#xA;Host: www.douban.com&#xA;User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64; rv:42.0) Gecko/20100101 Firefox/42.0&#xA;Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#xA;Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3&#xA;Accept-Encoding: gzip, deflate&#xA;Cookie: bid=&amp;quot;UwoBYPAPsOE&amp;quot;; ll=&amp;quot;118159&amp;quot;; __utma=30149280.478845192.1452777657.1452777657.1452777657.1; __utmz=30149280.1452777657.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); _pk_id.100001.8cb4=d15426da1038582e.1452777681.1.1452777681.1452777681.&#xA;Connection: keep-alive&#xA;Cache-Control: max-age=0&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看出使用的是完整路径。&lt;/p&gt;&#xA;&lt;h3&gt;为什么要用 Proxy-Connection 头部&lt;/h3&gt;&#xA;&lt;p&gt;Connection 头部是为了减少建立 TCP 连接的次数，复用连接产生的。默认 HTTP 1.1 是 Keepalive，但 1.0 的代理则不识别此头部。对于不认识的头部，代理会直接转发，以保持向后兼容性。&lt;/p&gt;&#xA;&lt;p&gt;假如 Connection: Keep-alive 发给了代理，代理不识别转发给了服务器，而恰巧服务器识别此头部，便会出现严重问题。服务器和浏览器都保持连接，而代理则中断了连接。&lt;/p&gt;&#xA;&lt;p&gt;为解决这个问题，出现了一个新的头部 Proxy-Connection。如果 1.1 的代理，代理会改写为 Connection 头部。如果 1.0 的代理，那么会直接转发此头部，服务器发现 Proxy-Connection 后，就会采用非长连接的方式。&lt;/p&gt;&#xA;&lt;p&gt;Proxy-Connection 头部我实际实验的时候，并不是每个浏览器都会发送。同样是火狐，家里电脑直接发送了 Connection，而单位电脑则是 Proxy-Connection。&lt;/p&gt;&#xA;&lt;h2&gt;实现&lt;/h2&gt;&#xA;&lt;p&gt;我们要做的有&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;替换完整路径为相对路径&lt;/li&gt;&#xA;&lt;li&gt;去掉 Proxy-Connection&lt;/li&gt;&#xA;&lt;li&gt;将 Connection 头部改为 close （为了简单起见）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;我采用 BaseHTTPServer 和 BaseHTTPRequestHandler 来处理浏览器发送的 GET 请求，原始套接字 socket 来转发请求给远端服务器，既没有多线程也没有 IO 复用。采用 urllib 库来解析完整路径 URL，并取出相对路径。&lt;/p&gt;&#xA;&lt;p&gt;代码如下&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer&#xA;    import socket&#xA;    import urllib&#xA;&#xA;    class MyHandler(BaseHTTPRequestHandler):&#xA;&#xA;        def do_GET(self):&#xA;            uri = self.path&#xA;            # print uri&#xA;            proto, rest = urllib.splittype(uri)&#xA;            host, rest = urllib.splithost(rest)&#xA;            # print host&#xA;            path = rest        &#xA;            host, port = urllib.splitnport(host)&#xA;            if port &amp;lt; 0:&#xA;                port = 80&#xA;            # print host&#xA;            host_ip = socket.gethostbyname(host)&#xA;            # print port&#xA;&#xA;            del self.headers[&#39;Proxy-Connection&#39;]&#xA;            self.headers[&#39;Connection&#39;] = &#39;close&#39;&#xA;&#xA;            send_data = &#39;GET &#39; + path + &#39; &#39; + self.protocol_version + &#39;\r\n&#39;&#xA;            head = &#39;&#39;&#xA;            for key, val in self.headers.items():&#xA;                head = head + &amp;quot;%s: %s\r\n&amp;quot; % (key, val)&#xA;            send_data = send_data + head + &#39;\r\n&#39;&#xA;            # print send_data&#xA;            so = socket.socket(socket.AF_INET, socket.SOCK_STREAM)&#xA;            so.connect((host_ip, port))&#xA;            so.sendall(send_data)&#xA;&#xA;            # 因为采用非长连接，所以会关闭连接， recv 会退出&#xA;            data = &#39;&#39;&#xA;            while True:&#xA;                tmp = so.recv(4096)&#xA;                if not tmp:&#xA;                    break&#xA;                data = data + tmp&#xA;&#xA;            # socprint data&#xA;            so.close()&#xA;&#xA;            self.wfile.write(data)&#xA;&#xA;&#xA;        # do_CONNECT = do_GET&#xA;&#xA;    def main():&#xA;        try:&#xA;            server = HTTPServer((&#39;&#39;, 8888), MyHandler)&#xA;            print &#39;Welcome to the machine...&#39;&#xA;            server.serve_forever()&#xA;        except KeyboardInterrupt:&#xA;            print &#39;^C received, shutting down server&#39;&#xA;            server.socket.close()&#xA;&#xA;    if __name__ == &#39;__main__&#39;:&#xA;        main()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/01/16/http-proxy-get1/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Robot Framework 教程 - 概览（译）</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/01/07/robotframework-tutorial-overview/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://code.google.com/p/robotframework/&#34;&gt;Robot Framework&lt;/a&gt; 是一个通用的自动化测试框架。这是本系列的第一篇文章，将会给出一个全面的概述。&lt;/p&gt;&#xA;&lt;p&gt;请注意，第一篇文章几乎不会包含任何&amp;quot;真正实现方面的东西&amp;quot;，而是讲述一些高级别、抽象的概念，来为以后的文章打下坚实的基础。&lt;/p&gt;&#xA;&lt;h2&gt;什么是自动化测试框架&lt;/h2&gt;&#xA;&lt;p&gt;如果你已经有自动化测试的经验（例如，使用过一些自动化测试工具），你可以直接跳过本小节。&lt;/p&gt;&#xA;&lt;p&gt;现在，我想先问一个问题：什么是自动化测试？以及它为何不同于手动执行的测试？Michael Bolton 写的&lt;a href=&#34;http://www.developsense.com/blog/2009/08/testing-vs-checking/&#34;&gt;这篇文章&lt;/a&gt;对这两个问题给出了一个非常好的答案：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;核对是机器干的事，测试则需要智慧。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;然而请注意，当我们下面讨论自动化测试时，会同时使用测试和核对两个术语。&lt;/p&gt;&#xA;&lt;p&gt;让我们来看个具体的例子，比如说一个保险公司的评级引擎。这个引擎会根据输入的某些参数（数字）来计算值。对于这样一个算法已知的系统而言，显然大量（自动化）核对是非常合适的。但检验这个算法正确与否，则需要一些思考。&lt;/p&gt;&#xA;&lt;p&gt;假设我们有一个基于数据库表的接口，和一个批处理程序：从一个表中取出数据，计算后与另一个表中的数据核对结果。&lt;/p&gt;&#xA;&lt;p&gt;首先，我们需要测试脚本语言（取决于个人喜好，可以是 Shell, Perl, Java 等等）。此外我们还要准备一些基本的测试功能。然后访问数据库表，执行一个又一个脚本，测试结果最好以某种报告的形式返回。一旦脚本运行完毕，我们便可以开始核对检查工作。基本上，我们认为，一个典型的自动化测试框架应该提供上述的功能。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/GenericFrameworkView.png&#34; alt=&#34;最简测试框架&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;上图描述了一个非常基本的自动化测试框架。该框架有一个可执行测试的核心系统，可以输出一些报告，并提供接口来插入特定的测试功能。这个插入接口实现会非常简单。&lt;/p&gt;&#xA;&lt;p&gt;这就带来一个基本的问题：当我用这些测试框架时，该用什么编程语言来实现我的测试功能？稍后我们会详细回答这个问题，但现在我们可以说，&lt;strong&gt;Robot Framework&lt;/strong&gt; 测试框架允许使用很多不同的语言。&lt;/p&gt;&#xA;&lt;p&gt;在了解 &lt;strong&gt;Robot Framework&lt;/strong&gt; 的具体体系结构之前，我们先讨论下 &lt;strong&gt;Robot Framework&lt;/strong&gt; 的核心术语，即&lt;strong&gt;关键字驱动测试&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;h2&gt;什么是关键字驱动测试&lt;/h2&gt;&#xA;&lt;p&gt;每当我试图解释什么是关键字的时候，我总会把它称为函数或者方法，其能够用于测试被测系统的一个方面。&lt;/p&gt;&#xA;&lt;p&gt;真正强大的是，一个关键字可以由其关键字来定义。这就是为什么通常说：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;高级别关键字&lt;/strong&gt;：这些关键字用来测试系统业务逻辑。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;低级别关键字&lt;/strong&gt;：为了控制高级别关键字的实现在合适的大小，会将其分割成几个低级别关键字。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;技术性关键字&lt;/strong&gt;：这些关键字提供技术实现细节。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;下面这张图用一个关键字例子描述了这三者的关系。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/Keywords.png&#34; alt=&#34;嵌套的关键字定义&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;通常技术性关键字可以由任何编程语言来实现（好吧，不是真的）。其他的&lt;strong&gt;关键字&lt;/strong&gt;则是由已存在的关键字组合而成。即使本文关注的是抽象的概念，我们还是来看一个具体的关键字定义：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/KeywordGoogleSearch.png&#34; alt=&#34;GoogleS earch 关键字&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这个例子表明， Google Search 这个关键字可以由 &lt;strong&gt;Selenium Library&lt;/strong&gt; 库中的关键字来创建。好消息是已经有大量预定义的关键字，它们的集合称为&lt;strong&gt;测试库&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;好，让我们开始。。。&lt;/p&gt;&#xA;&lt;h2&gt;说好的概览&lt;/h2&gt;&#xA;&lt;p&gt;最后开始我们的主题，&lt;strong&gt;Robot Framework&lt;/strong&gt; 概览。安装 &lt;strong&gt;Robot Framework&lt;/strong&gt; 时，一些标准测试库会随核心框架一起安装。&lt;/p&gt;&#xA;&lt;p&gt;除了&lt;a href=&#34;http://code.google.com/p/robotframework/wiki/TestLibraries&#34;&gt;标准测试库&lt;/a&gt;外，还有很多&lt;a href=&#34;http://code.google.com/p/robotframework/wiki/TestLibraries#External_test_libraries&#34;&gt;额外的外部测试库&lt;/a&gt;。它们通常是社区由不同的目的贡献的。在写特定测试用例的时候，你完全可以混用不同测试库的所有关键字。这意味着，在测试一个 web 应用时，可以用 &lt;strong&gt;Selenium Library&lt;/strong&gt; 来与 web 前端交互，用 &lt;strong&gt;Database Library&lt;/strong&gt; 来检测数据库中数据的正确性。理想情况下，完全不需要编程，只需组合库中的关键字来构成高级别关键字。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/Overview_3.png&#34; alt=&#34;Robot Framework 概览&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Robot Framework 除了核心功能和测试库外，还提供了一个 IDE (RIDE, Robot Integrated Development Environment)，用户可以在此编写和组织自己的测试用例和关键字。请注意，这个 RIDE 不是用来写技术性关键字的。技术性关键字取决于你的开发环境，比如 Eclipse 来开发 Java 写的关键字。&lt;/p&gt;&#xA;&lt;p&gt;上图中尚未包含&lt;strong&gt;资源文件&lt;/strong&gt;。我们测试用例的集合称作&lt;strong&gt;测试套件&lt;/strong&gt;，听起来很有道理。现在为&lt;strong&gt;测试套件&lt;/strong&gt;添加新关键字也是可行的。但最好在外部的&lt;strong&gt;资源文件&lt;/strong&gt;中定义关键字。&lt;/p&gt;&#xA;&lt;p&gt;现在，我们在使用 Robot Framwwork 框架时，有三个重要的概念：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;测试套件&lt;/strong&gt;：这是测试用例（机器的核对工作）的容器。通常每个项目至少有一个&lt;em&gt;测试套件&lt;/em&gt;。在大型工程中，需要根据功能来划分不同的&lt;em&gt;测试套件&lt;/em&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;资源文件&lt;/strong&gt;：为了让测试设计者的角度看，几乎总会定义高级别关键字。反过来说，通常会有自己的资源文件。特别是对产品开发或者一些长期项目而言，肯定能益于&lt;strong&gt;关键字&lt;/strong&gt;，而且还能被其他项目组使用。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;测试库&lt;/strong&gt;：通常不需要编写自己的&lt;strong&gt;技术性关键字&lt;/strong&gt;，除非你在使用特定技术细节，你才需要自己实现一个新的测试库，不过这并不费时。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;需要强调的是，&lt;strong&gt;测试库&lt;/strong&gt;中的关键字和&lt;strong&gt;资源文件&lt;/strong&gt;中组合成的关键字，在使用时没有区别。&lt;/p&gt;&#xA;&lt;h2&gt;自定义测试功能该用什么语言&lt;/h2&gt;&#xA;&lt;p&gt;Robot Framework 自身和其核心库都是由 &lt;a href=&#34;http://www.python.org/&#34;&gt;Python&lt;/a&gt; 实现的。因此，如果熟悉 Python （或者打算开始熟悉 :)），用其写自己的关键字是个好的选择。我一直认为 Python 是个很酷的语言，但如果 Robot Framework 局限于 Python，它不会这么成功。这就是为什么会有 &lt;a href=&#34;http://www.jython.org/&#34;&gt;Jython&lt;/a&gt;。有了 Jython 就可以在 Java 的虚拟机上运行 Python 代码。这使得我们能够用 Java 来编写测试库，甚至是任何编译成 Java Byte Code 的语言。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;在 .NET 系中，IronPython 和 Jython 是类似的。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;这引出了以下的安装堆栈：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/InstallationStacks.png&#34; alt=&#34;Robot Framework 安装堆栈&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Robot Framework 历史上是上图最左边的安装堆栈（在没有 RIDE 的情况下）。早期 Jython 的安装和支持欠佳。然而，现在 Java 已经支持的很好了，只有很少的缺陷。&lt;/p&gt;&#xA;&lt;p&gt;现在还有 JAR 安装方式的 Robot Framework，Python 的测试库和 Jython 都被打包成一个大的 JAR 文件。这有很大的优势，你可以将 JAR 放入版本控制中，或者是放入本地的 Maven 仓库中。这样就能保证团队成员都使用相同版本的 Robot Framework，且能够实时更新。不过也有缺点，这种情况下，RIDE 无法显示 JAR 文件关键字的帮助信息，所以 RIDE 还需要单独安装。&lt;/p&gt;&#xA;&lt;p&gt;好，现在回到我们的主题：用什么语言来实现自己的测试功能。&lt;/p&gt;&#xA;&lt;h2&gt;Remote Libraries&lt;/h2&gt;&#xA;&lt;p&gt;目前为止，无论是本地还是服务器，Robot Framework 都是安装在同一台机器。然后我们也看到可以用 Python, Jython 和纯 Java 语言来开发测试库。&lt;/p&gt;&#xA;&lt;p&gt;用 &lt;a href=&#34;http://code.google.com/p/robotframework/wiki/RemoteLibrary&#34;&gt;Remote Libraries&lt;/a&gt;，可以在其他机器中，用支持 &lt;a href=&#34;http://code.google.com/p/robotframework/wiki/RemoteLibrary&#34;&gt;XML-RPC protocol&lt;/a&gt; 的任何语言来编写测试库。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/RemoteLibrary.png&#34; alt=&#34;Remote Library 用法&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;当在测试用例和资源文件中导入 Remote Library，它们用起来和普通的库没有区别。还有一个优点是，你也可以从 Remote Library 中获取帮助文件。如果对其实现感兴趣，可以看看 Database Library 的源码。需要指出的是，Remote Library 功能本身就是某些测试库的附加功能。&lt;/p&gt;&#xA;&lt;p&gt;Remote Library 作为一个远程的服务器，而 Robot Framework 作为一个客户端。当然这两个库完全能在本地使用。&lt;/p&gt;&#xA;&lt;p&gt;这是绝对不能被低估的一个非常强大的功能。&lt;/p&gt;&#xA;&lt;h2&gt;持续集成&lt;/h2&gt;&#xA;&lt;p&gt;把 Robot Framework 集成到持续集成服务器中非常直接，因为框架本身是用脚本语言写成的。Java 版本当然也可以使用 Maven 集成。&lt;/p&gt;&#xA;&lt;h2&gt;Robot Framework 教程目录&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blog.codecentric.de/en/2012/03/robot-framework-tutorial-overview/&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/01/07/robotframework-tutorial-overview/&#34;&gt;Robot Framework 教程 - 概览（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/04/09/robotframework-tutorial-a-complete-example/&#34;&gt;Robot Framework 教程 - 一个完整的例子（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/04/30/robotframework-ide-ride-overview/&#34;&gt;Robot Framework 教程 - 集成开发环境 RIDE 概览 (译)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/15/robotframework-tutorial-how-to-structure-a-scalable-and-maintainable-acceptance-test-suite/&#34;&gt;Robot Framework 教程 - 如何组织一个可伸缩可维护的验收测试套件（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lyyyuna.com/2016/05/28/robotframework-tutorial-loops-conditional-execution-and-more/&#34;&gt;Robot Framework 教程 - 循环，条件判断，字符串和列表（译）&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/01/07/robotframework-tutorial-overview/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Python 脚本实现读取图片属性信息</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/01/06/exif-info-extract1/</id>
    <content type="html">&lt;p&gt;我之前的这篇文章《&lt;a href=&#34;http://www.lyyyuna.com/2015/11/14/exif-hack/&#34;&gt;暴力修改图片的 GPS 信息&lt;/a&gt;》中，讲述了如何从图片的二进制文件中读取 GPS 信息。&lt;/p&gt;&#xA;&lt;p&gt;这里改用 Python 脚本读取图片信息。有几个说明&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;没有实现错误处理&lt;/li&gt;&#xA;&lt;li&gt;没有读取所有信息，大概只有 GPS 信息、图片分辨率、图片像素、设备商、拍摄设备等&lt;/li&gt;&#xA;&lt;li&gt;简单修改后应该能实现&lt;a href=&#34;http://www.lyyyuna.com/2015/11/14/exif-hack/&#34;&gt;暴力修改图片的 GPS 信息&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;但对于本身没有 GPS 信息的图片，实现则非常复杂，需要仔细计算每个描述符的偏移量&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;脚本运行后，读取结果如下&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/exif_info3.jpg&#34; alt=&#34;脚本读取的信息&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这里和 Windows 属性查看器读到的内容完全一致&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/exif_info1.jpg&#34; alt=&#34;图片信息1&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/exif_info2.jpg&#34; alt=&#34;图片信息2&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;源码如下&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;# -*- coding:utf-8 -*-&#xA;import binascii&#xA;&#xA;class ParseMethod(object):&#xA;    @staticmethod&#xA;    def parse_default(f, count, offset):&#xA;        pass&#xA;&#xA;    @staticmethod&#xA;    def parse_latitude(f, count, offset):&#xA;        old_pos = f.tell()&#xA;        f.seek(12 + offset)&#xA;&#xA;        latitude = [0,0,0]&#xA;        for i in xrange(count):&#xA;            byte = f.read(4)&#xA;            numerator = byte.encode(&#39;hex&#39;)&#xA;&#xA;            byte = f.read(4)&#xA;            denominator = byte.encode(&#39;hex&#39;)&#xA;&#xA;            latitude[i] =  float(int(numerator, 16)) / int(denominator, 16)&#xA;&#xA;&#xA;        print &#39;Latitude:\t%.2f %.2f\&#39; %.2f\&amp;quot;&#39; % (latitude[0], latitude[1], latitude[2])&#xA;        f.seek(old_pos)    &#xA;&#xA;&#xA;    @staticmethod&#xA;    def parse_longtitude(f, count, offset):&#xA;        old_pos = f.tell()&#xA;        f.seek(12 + offset)&#xA;&#xA;        longtitude = [0,0,0]&#xA;        for i in xrange(count):&#xA;            byte = f.read(4)&#xA;            numerator = byte.encode(&#39;hex&#39;)&#xA;&#xA;            byte = f.read(4)&#xA;            denominator = byte.encode(&#39;hex&#39;)&#xA;&#xA;            longtitude[i] =  float(int(numerator, 16)) / int(denominator, 16)&#xA;&#xA;&#xA;        print &#39;Longtitude:\t%.2f %.2f\&#39; %.2f\&amp;quot;&#39; % (longtitude[0], longtitude[1], longtitude[2])&#xA;        f.seek(old_pos) &#xA;&#xA;    @staticmethod&#xA;    def parse_make(f, count, offset):&#xA;        old_pos = f.tell()&#xA;        f.seek(12 + offset)&#xA;        byte = f.read(count)&#xA;        a = byte.encode(&#39;hex&#39;)&#xA;        print &#39;Make:\t\t&#39; + binascii.a2b_hex(a)&#xA;        f.seek(old_pos) &#xA;&#xA;    @staticmethod&#xA;    def parse_model(f, count, offset):&#xA;        old_pos = f.tell()&#xA;        f.seek(12 + offset)&#xA;        byte = f.read(count)&#xA;        a = byte.encode(&#39;hex&#39;)&#xA;        print &#39;Model:\t\t&#39; + binascii.a2b_hex(a)&#xA;        f.seek(old_pos)         &#xA;&#xA;    @staticmethod&#xA;    def parse_datetime(f, count, offset):&#xA;        old_pos = f.tell()&#xA;        f.seek(12 + offset)&#xA;        byte = f.read(count)&#xA;        a = byte.encode(&#39;hex&#39;)&#xA;        print &#39;DateTime:\t&#39; + binascii.a2b_hex(a)&#xA;        f.seek(old_pos)&#xA;&#xA;    # rational data type, 05&#xA;    @staticmethod&#xA;    def parse_xresolution(f, count, offset):&#xA;        old_pos = f.tell()&#xA;        f.seek(12 + offset)&#xA;&#xA;        byte = f.read(4)&#xA;        numerator = byte.encode(&#39;hex&#39;)&#xA;        byte = f.read(4)&#xA;        denominator = byte.encode(&#39;hex&#39;)&#xA;        xre = int(numerator, 16) / int(denominator, 16)&#xA;&#xA;        print &#39;XResolution:\t&#39; + str(xre) + &#39; dpi&#39;&#xA;        f.seek(old_pos)&#xA;&#xA;    @staticmethod&#xA;    def parse_yresolution(f, count, offset):&#xA;        old_pos = f.tell()&#xA;        f.seek(12 + offset)&#xA;&#xA;        byte = f.read(4)&#xA;        numerator = byte.encode(&#39;hex&#39;)&#xA;        byte = f.read(4)&#xA;        denominator = byte.encode(&#39;hex&#39;)&#xA;        xre = int(numerator, 16) / int(denominator, 16)&#xA;&#xA;        print &#39;YResolution:\t&#39; + str(xre) + &#39; dpi&#39;&#xA;        f.seek(old_pos)&#xA;&#xA;    @staticmethod&#xA;    def parse_exif_ifd(f, count, offset):&#xA;        old_pos = f.tell()&#xA;        f.seek(12 + offset)&#xA;&#xA;        byte = f.read(2)&#xA;        a = byte.encode(&#39;hex&#39;)        &#xA;        exif_ifd_number = int(a, 16)&#xA;&#xA;        for i in xrange(exif_ifd_number):&#xA;            byte = f.read(2)&#xA;            tag_id = byte.encode(&#39;hex&#39;)&#xA;            #print tag_id,&#xA;&#xA;            byte = f.read(2)&#xA;            type_n = byte.encode(&#39;hex&#39;)&#xA;            #print type_n,&#xA;&#xA;            byte = f.read(4)&#xA;            count = byte.encode(&#39;hex&#39;)&#xA;            #print count,&#xA;&#xA;            byte = f.read(4)&#xA;            value_offset = byte.encode(&#39;hex&#39;)&#xA;            #print value_offset&#xA;&#xA;            value_offset = int(value_offset, 16)&#xA;            EXIF_IFD_DICT.get(tag_id, ParseMethod.parse_default)(f, count, value_offset)&#xA;&#xA;        f.seek(old_pos)    &#xA;&#xA;    @staticmethod&#xA;    def parse_x_pixel(f, count, value):&#xA;        print &#39;X Pixels:\t&#39; + str(value)&#xA;&#xA;    @staticmethod&#xA;    def parse_y_pixel(f, count, value):&#xA;        print &#39;y Pixels:\t&#39; + str(value)&#xA;&#xA;    @staticmethod&#xA;    def parse_gps_ifd(f, count, offset):&#xA;        old_pos = f.tell()        &#xA;        f.seek(12 + offset)&#xA;        byte = f.read(2)&#xA;        a = byte.encode(&#39;hex&#39;)   &#xA;        gps_ifd_number = int(a, 16)&#xA;&#xA;        for i in xrange(gps_ifd_number):&#xA;            byte = f.read(2)&#xA;            tag_id = byte.encode(&#39;hex&#39;)&#xA;            #print tag_id,&#xA;&#xA;            byte = f.read(2)&#xA;            type_n = byte.encode(&#39;hex&#39;)&#xA;            #print type_n,&#xA;&#xA;            byte = f.read(4)&#xA;            count = byte.encode(&#39;hex&#39;)&#xA;            #print count,&#xA;&#xA;            byte = f.read(4)&#xA;            value_offset = byte.encode(&#39;hex&#39;)&#xA;            #print value_offset&#xA;&#xA;            count = int(count, 16)&#xA;            value_offset = int(value_offset, 16)&#xA;            GPS_IFD_DICT.get(tag_id, ParseMethod.parse_default)(f, count, value_offset)&#xA;&#xA;        f.seek(old_pos)  &#xA;&#xA;IFD_dict = {&#xA;    &#39;010f&#39; : ParseMethod.parse_make ,&#xA;    &#39;0110&#39; : ParseMethod.parse_model ,&#xA;    &#39;0132&#39; : ParseMethod.parse_datetime ,&#xA;    &#39;011a&#39; : ParseMethod.parse_xresolution ,&#xA;    &#39;011b&#39; : ParseMethod.parse_yresolution ,&#xA;    &#39;8769&#39; : ParseMethod.parse_exif_ifd ,&#xA;    &#39;8825&#39; : ParseMethod.parse_gps_ifd&#xA;}&#xA;&#xA;EXIF_IFD_DICT = {&#xA;    &#39;a002&#39; : ParseMethod.parse_x_pixel ,&#xA;    &#39;a003&#39; : ParseMethod.parse_y_pixel&#xA;}&#xA;&#xA;GPS_IFD_DICT = {&#xA;    &#39;0002&#39; : ParseMethod.parse_latitude ,&#xA;    &#39;0004&#39; : ParseMethod.parse_longtitude&#xA;}&#xA;&#xA;&#xA;with open(&#39;image.jpg&#39;, &#39;rb&#39;) as f:&#xA;    byte = f.read(2)&#xA;    a = byte.encode(&#39;hex&#39;)&#xA;    print &#39;SOI Marker:\t&#39; + a&#xA;&#xA;    byte = f.read(2)&#xA;    a = byte.encode(&#39;hex&#39;)&#xA;    print &#39;APP1 Marker:\t&#39; + a&#xA;&#xA;    byte = f.read(2)&#xA;    a = byte.encode(&#39;hex&#39;)&#xA;    print &#39;APP1 Length:\t&#39; + str(int(a, 16)) + &#39; .Dec&#39;&#xA;&#xA;    byte = f.read(4)&#xA;    a = byte.encode(&#39;hex&#39;)&#xA;    print &#39;Identifier:\t&#39; + binascii.a2b_hex(a)&#xA;&#xA;    byte = f.read(2)&#xA;    a = byte.encode(&#39;hex&#39;)&#xA;    print &#39;Pad:\t\t&#39; + a &#xA;&#xA;    print &#xA;&#xA;    print &#39;Begin to print Header.... &#39;&#xA;    print &#39;APP1 Body: &#39;&#xA;&#xA;    byte = f.read(2)&#xA;    a = byte.encode(&#39;hex&#39;)&#xA;    print &#39;Byte Order:\t&#39; + a    &#xA;&#xA;    byte = f.read(2)&#xA;    a = byte.encode(&#39;hex&#39;)&#xA;    print &#39;42:\t\t&#39; + a  &#xA;&#xA;    byte = f.read(4)&#xA;    a = byte.encode(&#39;hex&#39;)&#xA;    print &#39;0th IFD Offset:\t&#39; + a  &#xA;&#xA;    print &#39;Finish print Header&#39;&#xA;&#xA;    print &#39;Begin to print 0th IFD....&#39;&#xA;    print&#xA;    #print &#39;Total: &#39;,&#xA;    byte = f.read(2)&#xA;    a = byte.encode(&#39;hex&#39;)&#xA;    interoperability_number = int(a, 16)&#xA;    #print interoperability_number&#xA;    &#xA;&#xA;    for i in xrange(interoperability_number):&#xA;        byte = f.read(2)&#xA;        tag_id = byte.encode(&#39;hex&#39;)&#xA;        #print tag_id,&#xA;&#xA;        byte = f.read(2)&#xA;        type_n = byte.encode(&#39;hex&#39;)&#xA;        #print type_n,&#xA;&#xA;        byte = f.read(4)&#xA;        count = byte.encode(&#39;hex&#39;)&#xA;        #print count,&#xA;&#xA;        byte = f.read(4)&#xA;        value_offset = byte.encode(&#39;hex&#39;)&#xA;        #print value_offset&#xA;&#xA;        count = int(count, 16)&#xA;        value_offset = int(value_offset, 16)&#xA;        &#xA;        # simulate switch&#xA;        IFD_dict.get(tag_id, ParseMethod.parse_default)(f, count, value_offset)&#xA;&#xA;&#xA;    print&#xA;    print &#39;Finish print 0th IFD....&#39;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/01/06/exif-info-extract1/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>一个简单的公司自动订餐脚本实现</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/01/04/cdcfan-auto-order/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;因为食堂难吃，公司推出了集体外卖订餐服务，员工需要每天去指定网页提交订餐。&lt;/p&gt;&#xA;&lt;p&gt;由于经常忘了订餐，便诞生了下面这个脚本。&lt;/p&gt;&#xA;&lt;p&gt;该系统功能是工作日每天定时订餐，并发送邮件告知用户订餐结果。&lt;/p&gt;&#xA;&lt;h2&gt;登陆过程分析&lt;/h2&gt;&#xA;&lt;p&gt;打开 http://cdcfan/ 便可见到登陆页面，登陆时只需输入自己英文名即可。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/cdcfan_logon.jpg&#34; alt=&#34;cdcfan 登陆页面&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这里点击“进入”会发送 GET 请求，然后获得员工的各种信息，比如 ID，部门编号等。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/cdcfan_logon_get.jpg&#34; alt=&#34;cdcfan 登陆 GET&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;登陆结果如下&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/cdcfan_ehuaile.jpg&#34; alt=&#34;cdcfan 登陆结果&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;当用户点击“下单”，这时候才会发送 POST 参数，请求参数主要为之前 GET 请求获得的部门号和员工 id。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/cdcfan_order-new.jpg&#34; alt=&#34;cdcfan 下单请求&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;请求会返回一个 json 数据。代表你是否成功订餐，还是已经订过餐。比如已经订过后，exceed_count 为 1，其余为 0.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/cdcfan_order_result.jpg&#34; alt=&#34;cdcfan 下单结果&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;而页面则显示&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/cdcfan_chipangle.jpg&#34; alt=&#34;cdcfan 吃胖了&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;回过头来看登陆过程，如图 2，每一步 GET 请求，都会附上一个隐含参数 &#39;_=1451880513702&#39;，参数值会逐次递增 1。这个值有什么用我还没研究出来，用 Burp Suite 代理修改了也依然能返回正确结果。不过实际上不需要去分析这个值是由服务器还是客户端产生，因为最关键的下单 POST 请求与这个毫无关系。&lt;/p&gt;&#xA;&lt;p&gt;于是一切就变得简单了，实测这个系统其实并不依赖于会话机制，员工输入的姓名只是用来获得对应的员工 id 和部门号。那意味着，实现自动化订餐时，&lt;strong&gt;并不需要模拟登陆过程&lt;/strong&gt;，只要向 /api/order-new POST 自己的 id 和 部门号，就能完成订餐。&lt;/p&gt;&#xA;&lt;h2&gt;自动化订餐&lt;/h2&gt;&#xA;&lt;p&gt;首先定义数据库表，&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;create table cdcuser&#xA;{&#xA;    id integer primary key,&#xA;    psid varchar,&#xA;    depcode varchar,&#xA;    email varchar    &#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;然后只需要遍历取出的每个记录，分别发送 POST 请求即可。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;for user in r:&#xA;    psid = user[2]&#xA;    depcode = user[3]&#xA;    email = user[4]&#xA;&#xA;    post_data = {&#39;order&#39;:&#39;e-1&#39;, &#39;psid&#39;:psid, &#39;depcode&#39;:depcode}&#xA;    post_data_urlencode = urllib.urlencode(post_data)&#xA;&#xA;    req_url = &#39;http://cdcfan/api/order-new&#39;&#xA;    req = urllib2.Request(url = req_url, data = post_data_urlencode)&#xA;&#xA;    res_data = urllib2.urlopen(req)&#xA;    res_json = res_data.read()&#xA;    print res_json&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;定时任务和发送邮件&lt;/h2&gt;&#xA;&lt;p&gt;得益于公司内部 MTA 的转发策咯，任意邮件域名不作检查，除恶意邮件外，其他直接被转发。这意味着可以自己搭建 MTA 发送邮件。&lt;/p&gt;&#xA;&lt;p&gt;MTA 可以直接使用 Postfix，在 Debian 8 上默认配置即可工作。Python 有非常方便的 smtplib 模块用于连接 MTA 并发送邮件&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;server = smtplib.SMTP(&#39;localhost&#39;)&#xA;server.set_debuglevel(1)&#xA;server.sendmail(fromaddr, toaddrs, msg)&#xA;server.quit()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;不过我偷懒，直接解析 json 结果后，调用系统的 mail 命令&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;res = json.loads(res_json)&#xA;if (res[&#39;succeed_count&#39;] == 0):&#xA;    cmd = &amp;quot;echo &#39;ding can shi bai, nin ke neng yi jing ding guo le. DO NOT REPLY&#39; | mail -s cdcfanauto &amp;quot; + email&#xA;    # print cmd&#xA;    os.system(cmd)&#xA;else:&#xA;    cmd = &amp;quot;echo &#39;ding can cheng gong. DO NOT REPLY&#39; | mail -s cdcfanauto &amp;quot; + email&#xA;    os.system(cmd)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;最后就是在每周工作日定时调用，这里直接使用 crontab 的定时任务&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;10 10 * * 1-5 python /root/cdcfan/cdc.py &amp;gt;/dev/null 2&amp;gt;&amp;amp;1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;问题&lt;/h3&gt;&#xA;&lt;p&gt;实际测试时遇到了邮件不能发送的问题，原因我没有仔细研究。&lt;/p&gt;&#xA;&lt;p&gt;（大概是 crontab 在定时时会向系统管理员发送邮件，而由于上述的 python /root/cdcfan/cdc.py &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 其实是 crontab 的子进程？？？，查看了 Postfix 的 maillog 之后发现，这两个进程之间的发送邮件会相互干扰。）&lt;/p&gt;&#xA;&lt;p&gt;（比如 Postfix 的默认配置下，邮件域名为 @debian.com。所以默认管理员邮箱会向这个邮件域名发送。但这个域名是不存在，作为发送方，可以伪造，因为协议并没有强制要求。但作为接收方，伪造的邮件域名必然会不可达，最终被退回。）&lt;/p&gt;&#xA;&lt;p&gt;（不过按理说不应该啊，不知道为什么管理员邮件发送失败会造成我调用 mail 失败。我又按照网上说的把 crontab 的发送邮件关闭，现象依旧，maillog 显示邮件被“自己的 MTA”退回。）&lt;/p&gt;&#xA;&lt;h2&gt;http 服务器&lt;/h2&gt;&#xA;&lt;p&gt;由于之前所述的我不能解释的问题，我只能另辟蹊径。让 crontab 定时发送 GET 请求到本地的一个 http 服务器，本地 http 服务器收到请求后再执行上述的订餐任务。本地 http 服务器和 crontab 完全是两个不相关的进程，不存在相互干扰的问题。&lt;/p&gt;&#xA;&lt;p&gt;crontab 修改为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;10 10 * * 1-5 curl http://127.0.0.1:5000/cdc/ &amp;gt;/dev/null 2&amp;gt;&amp;amp;1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;服务器可以用 Flask 简单搭一个&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;from flask import Flask&#xA;import cdc&#xA;&#xA;app = Flask(__name__)&#xA;&#xA;@app.route(&#39;/cdc/&#39;)&#xA;def submit():&#xA;    cdc.submitcdcfan()&#xA;    return &amp;quot;haha&amp;quot;&#xA;&#xA;if __name__ == &#39;__main__&#39;:&#xA;    app.run()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;最终结果&lt;/h2&gt;&#xA;&lt;p&gt;成功收到订餐成功的提示邮件&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/cdcfan_success.jpg&#34; alt=&#34;cdcfan 邮箱结果&#34;&gt;&lt;/p&gt;&#xA;&lt;h2&gt;彩蛋&lt;/h2&gt;&#xA;&lt;p&gt;大概因为是安全公司的内部系统，所以在页面源码里看到了如下的注释&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/cdcfan_hack.jpg&#34; alt=&#34;js 源码&#34;&gt;&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/01/04/cdcfan-auto-order/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>解决 GitHub 禁百度爬虫，并自动 ping 搜索引擎</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/01/03/sitemap-baidu-autosubmit-1/</id>
    <content type="html">&lt;p&gt;本篇包含两个内容。&lt;/p&gt;&#xA;&lt;h2&gt;DNSPod 双解析&lt;/h2&gt;&#xA;&lt;p&gt;用百度站长工具测试时，才发现 GitHub 禁了百度爬虫，解决方法也比较简单。&lt;/p&gt;&#xA;&lt;p&gt;首先更换你的 DNS 解析服务器，推荐使用免费的 DNSPod 解析。它支持多路解析，可以专为百度搜索，解析到另一个服务器。&lt;/p&gt;&#xA;&lt;p&gt;国内的 GitCafe 并不屏蔽百度，在 GitCafe 建立 Page 的过程是类似的。然后只需要在 hexo 的 _config.yml 上配置两个 repo 即可，如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;deploy:&#xA;- type: git&#xA;repository: git@github.com:lyyyuna/lyyyuna.github.io.git&#xA;branch: master&#xA;- type: git&#xA;repository: git@gitcafe.com:lyyyuna/lyyyuna.git&#xA;branch: gitcafe-pages&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;你需要在你的域名提供商那修改 DNS 服务器为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;f1g1ns1.dnspod.net&#xA;f1g1ns2.dnspod.net&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 DNSPod 配置面板上：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201601/dnspod.jpg&#34; alt=&#34;DNSPod&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;大概需要等待 1-2 天，全球的解析才会恢复正常。而这时候，百度也应该能够正常抓取网页了。&lt;/p&gt;&#xA;&lt;h2&gt;自动 ping 搜素引擎&lt;/h2&gt;&#xA;&lt;p&gt;大部分搜索引擎都提供了 ping 服务，当你有新的文章发布时，可以 ping 一下搜索引擎让其来抓取。&lt;/p&gt;&#xA;&lt;p&gt;这里，在上一篇自动提交 sitemap.xml 功能的基础上，再添加自动 ping 百度和必应的功能。&lt;/p&gt;&#xA;&lt;h3&gt;ping 必应&lt;/h3&gt;&#xA;&lt;p&gt;必应的接口比较简单，只需要 POST 自己的 sitemap.xml 即可。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;sitemap_url = &#39;http://www.lyyyuna.com/sitemap.xml&#39;&#xA;bing_ping = &#39;http://www.bing.com/webmaster/ping.aspx?siteMap=&#39; + sitemap_url&#xA;&#xA;get = urllib2.urlopen(bing_ping)&#xA;result = get.read()&#xA;print result&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;ping 百度&lt;/h3&gt;&#xA;&lt;p&gt;百度的接口稍显复杂，需要 POST XML 结构的数据。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;RPC端点： http://ping.baidu.com/ping/RPC2&#xA;调用方法名： weblogUpdates.extendedPing&#xA;参数： (应按照如下所列的相同顺序传送)&#xA;博客名称&#xA;博客首页地址&#xA;新发文章地址&#xA;博客rss地址 &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;提交的 XML 格式为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;&#xA;&amp;lt;methodCall&amp;gt;&#xA;    &amp;lt;methodName&amp;gt;weblogUpdates.extendedPing&amp;lt;/methodName&amp;gt;&#xA;    &amp;lt;params&amp;gt;&#xA;        &amp;lt;param&amp;gt;&#xA;            &amp;lt;value&amp;gt;&amp;lt;string&amp;gt;百度的空间&amp;lt;/string&amp;gt;&amp;lt;/value&amp;gt;&#xA;        &amp;lt;/param&amp;gt;&#xA;        &amp;lt;param&amp;gt;&#xA;            &amp;lt;value&amp;gt;&amp;lt;string&amp;gt;http://hi.baidu.com/baidu/&amp;lt;/string&amp;gt;&amp;lt;/value&amp;gt;&#xA;        &amp;lt;/param&amp;gt;&#xA;        &amp;lt;param&amp;gt;&#xA;            &amp;lt;value&amp;gt;&amp;lt;string&amp;gt;http://baidu.com/blog/example.html&amp;lt;/string&amp;gt;&amp;lt;/value&amp;gt;&#xA;        &amp;lt;/param&amp;gt;&#xA;        &amp;lt;param&amp;gt;&#xA;            &amp;lt;value&amp;gt;&amp;lt;string&amp;gt;http://hi.baidu.com/baidu/rss&amp;lt;/string&amp;gt;&amp;lt;/value&amp;gt;&#xA;        &amp;lt;/param&amp;gt;&#xA;    &amp;lt;/params&amp;gt;&#xA;&amp;lt;/methodCall&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;好在 Python 处理 XML 方便，将新发文章地址作为参数，如下&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;root = ET.Element(&amp;quot;methodCall&amp;quot;)&#xA;methodname = ET.SubElement(root, &amp;quot;methodName&amp;quot;).text = &#39;weblogUpdates.extendedPing&#39;&#xA;params = ET.SubElement(root, &amp;quot;params&amp;quot;)&#xA;&#xA;param = ET.SubElement(params, &amp;quot;param&amp;quot;)&#xA;value = ET.SubElement(param, &#39;value&#39;)&#xA;string = ET.SubElement(value, &#39;string&#39;).text = u&#39;lyyyuna 的小花园&#39;&#xA;&#xA;param = ET.SubElement(params, &amp;quot;param&amp;quot;)&#xA;value = ET.SubElement(param, &#39;value&#39;)&#xA;string = ET.SubElement(value, &#39;string&#39;).text = u&#39;http://www.lyyyuna.com/&#39;&#xA;&#xA;param = ET.SubElement(params, &amp;quot;param&amp;quot;)&#xA;value = ET.SubElement(param, &#39;value&#39;)&#xA;string = ET.SubElement(value, &#39;string&#39;).text = url&#xA;&#xA;param = ET.SubElement(params, &amp;quot;param&amp;quot;)&#xA;value = ET.SubElement(param, &#39;value&#39;)&#xA;string = ET.SubElement(value, &#39;string&#39;).text = u&#39;http://www.lyyyuna.com/atom.xml&#39;&#xA;&#xA;# tree = ET.ElementTree(root)&#xA;xmlstr = ET.tostring(root, encoding=&#39;utf8&#39;, method=&#39;xml&#39;)&#xA;# print xmlstr&#xA;# print&#xA;&#xA;baidu_pingRPC = &#39;http://ping.baidu.com/ping/RPC2&#39;&#xA;req = urllib2.Request(baidu_pingRPC, xmlstr)&#xA;response = urllib2.urlopen(req)&#xA;the_page = response.read()&#xA;&#xA;print the_page&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;对代码进行了整合，可以同时提交 sitemap.xml 并 ping。代码见 &lt;a href=&#34;https://github.com/lyyyuna/script_collection/blob/master/baidu_url_auto_submit/1.py&#34;&gt;我的GitHub&lt;/a&gt;。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/01/03/sitemap-baidu-autosubmit-1/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>SCons 用户指南第五章 - 节点对象</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2016/01/03/scons5-node-objects/</id>
    <content type="html">&lt;p&gt;SCons 在内部把文件和目录都表示成节点。灵活运用内部对象（非二进制文件），可以让你的 SConscript 脚本文件更容易移植且易读。&lt;/p&gt;&#xA;&lt;h2&gt;5.1 编译方法会返回目标文件节点的列表&lt;/h2&gt;&#xA;&lt;p&gt;所有编译方法都会返回节点对象的列表，它们代表了即将被编译的目标文件。这些的节点对象又可以被当作参数传给其他的编译方法。&lt;/p&gt;&#xA;&lt;p&gt;举例来说，假如我们想使用不同选项来编译由两个二进制文件所构成的程序。那意味着，我们会对每一个源文件指定不同选项，调用 Object 编译方法：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Object(&#39;hello.c&#39;, CCFLAGS=&#39;-DHELLO&#39;)&#xA;Object(&#39;goodbye.c&#39;, CCFLAGS=&#39;-DGOODBYE&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;接着，会调用 Program 编译方法来生成最终程序。在调用时，我们会在参数中列出二进制文件的名字：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Object(&#39;hello.c&#39;, CCFLAGS=&#39;-DHELLO&#39;)&#xA;Object(&#39;goodbye.c&#39;, CCFLAGS=&#39;-DGOODBYE&#39;)&#xA;Program([&#39;hello.o&#39;, &#39;goodbye.o&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;问题来了，我们在 SConstruct 文件中直接用字符串中硬编码了文件名称，这回使得脚本在不同操作系统间缺乏移植性。比如在 Windows 系统中，第一步生成的二进制文件名称为 hello.obj 和 goodbye.obj，而不是 hello.o 和 goodbye.o。&lt;/p&gt;&#xA;&lt;p&gt;一个更好的解决方案是将 Object 编译方法返回的目标列表存储在变量中，然后将变量直接用于 Program 方法：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;hello_list = Object(&#39;hello.c&#39;, CCFLAGS=&#39;-DHELLO&#39;)&#xA;goodbye_list = Object(&#39;goodbye.c&#39;, CCFLAGS=&#39;-DGOODBYE&#39;)&#xA;Program(hello_list + goodbye_list)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这样，我们的 SConstruct 文件具备了可移植性，在 Linux 系统上编译输出如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o goodbye.o -c -DGOODBYE goodbye.c&#xA;cc -o hello.o -c -DHELLO hello.c&#xA;cc -o hello hello.o goodbye.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 Windows 上如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;scons -Q&#xA;cl /Fogoodbye.obj /c goodbye.c -DGOODBYE&#xA;cl /Fohello.obj /c hello.c -DHELLO&#xA;link /nologo /OUT:hello.exe hello.obj goodbye.obj&#xA;embedManifestExeCheck(target, source, env)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在本指南余下例子里，我们都会使用编译方法返回的节点列表。&lt;/p&gt;&#xA;&lt;h2&gt;5.2 显示创建文件和目录列表&lt;/h2&gt;&#xA;&lt;p&gt;值得一提的是，在 SCons 中，表示文件和目录的节点之间有着显著的区别。SCons 分别支持用 File 和 Dir 方法返回一个文件和目录节点：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;hello_c = File(&#39;hello.c&#39;)&#xA;Program(hello_c)&#xA;&#xA;classes = Dir(&#39;classes&#39;)&#xA;Java(classes, &#39;src&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;通常你不需要直接调用 File 和 Dir。那是因为在调用编译方法时会自动将文件和目录的字符串转换。而当你需要显示地查询传递到编译方法的节点属性，或是无歧义的指定目录中的一个文件的时候，你就需要 File 和 Dir 方法了。&lt;/p&gt;&#xA;&lt;p&gt;有时候，你在不知道是文件还是目录的前提下，需要一个文件系统的入口点。这时候你就可以使用 Entry 方法，它可以返回文件或是目录的节点:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;xyzzy = Entry(&#39;xyzzy&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;返回的 xyzzy 节点一旦传入编译方法或其他需要节点的方法中，就会转换成对应的文件和目录节点。&lt;/p&gt;&#xA;&lt;h2&gt;5.3 打印节点文件名&lt;/h2&gt;&#xA;&lt;p&gt;节点最常用的就是打印其对应的文件名称。请记住，编译方法返回的是节点的列表，所以必须从列表中把单个节点逐一取出。例如如下的 SConstruct 文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;object_list = Object(&#39;hello.c&#39;)&#xA;program_list = Program(object_list)&#xA;print &amp;quot;The object file is:&amp;quot;, object_list[0]&#xA;print &amp;quot;The program file is:&amp;quot;, program_list[0]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;就会在 POSIX 系统上打印如下的文件名：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;The object file is: hello.o&#xA;The program file is: hello&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;而在 Windows 系统上是：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;scons -Q&#xA;The object file is: hello.obj&#xA;The program file is: hello.exe&#xA;cl /Fohello.obj /c hello.c /nologo&#xA;link /nologo /OUT:hello.exe hello.obj&#xA;embedManifestExeCheck(target, source, env)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;请注意，以上的例子中，object_list[0] 取出了列表的一个节点对象，Python 的 print 函数将对象转化为字符串以打印。&lt;/p&gt;&#xA;&lt;h2&gt;5.4 将节点文件名作为字符串&lt;/h2&gt;&#xA;&lt;p&gt;之所以上一小节能够直接打印节点名打印出来，是因为节点相应的字符串对应了文件名。假如你不只是要打印文件名，你可以用 Python 内置的 str 函数将文件名取出。比如，你可以用 Python 的 os.path.exists 来判断一个文件是否存在：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;import os.path&#xA;program_list = Program(&#39;hello.c&#39;)&#xA;program_name = str(program_list[0])&#xA;if not os.path.exists(program_name):&#xA;    print program_name, &amp;quot;does not exist!&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 POSIX 系统中执行结果如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;hello does not exist!&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o     &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;5.5 GetBuildPath: 从节点或字符串中获取路径&lt;/h2&gt;&#xA;&lt;p&gt;env.GetBuildPath(file_or_list) 可以返回节点的路径，或是字符串所表示的路径。它甚至可以输入节点或字符串列表，输出对应路径的列表。如果传入单个节点，结果和调用 str(node) 相同。这些字符串可以有内嵌的构造变量，能够使用环境变量来展开。这些路径可以是文件也可以是目录，而且不需要存在。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;env=Environment(VAR=&amp;quot;value&amp;quot;)&#xA;n=File(&amp;quot;foo.c&amp;quot;)&#xA;print env.GetBuildPath([n, &amp;quot;sub/dir/$VAR&amp;quot;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;将会打印如下的文件名：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;[&#39;foo.c&#39;, &#39;sub/dir/value&#39;]&#xA;scons: `.&#39; is up to date.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;同时，存在着不需要 Environment 变量，就能调用的 GetBuildPath 函数。它使用了 SCons 默认的 Environment 环境，来作字符串参数的替代。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2016/01/03/scons5-node-objects/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>向百度收录自动推送链接</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2015/12/29/sitemap-baidu-autosubmit/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;相比较三个搜索引擎，必应对我站点的收录居然是最快的，而百度的抓取确实很慢，至今未收录。研究了下百度的站长工具，里面提到可以通过发送 POST http://data.zz.baidu.com/urls?site=www.lyyyuna.com&amp;amp;token=XXXXXXXXXXXXX&amp;amp;type=original 请求，提交希望百度抓取的链接。不过百度没有给 Python 的例子，于是我准备自己写一个。&lt;/p&gt;&#xA;&lt;h2&gt;自动推送设计思路&lt;/h2&gt;&#xA;&lt;p&gt;整个流程比较简单，毕竟只有一个 POST 请求。公司的电脑常年开机，上面跑了虚拟机，可以作为自动推送机。&lt;/p&gt;&#xA;&lt;p&gt;由于每天允许最大推送链接数只有 500 条，所以我计划每天定时推送一次，且每次只推送新产生的链接。&lt;/p&gt;&#xA;&lt;p&gt;定时任务可以直接使用 crontab 完成。&lt;/p&gt;&#xA;&lt;p&gt;对于如何找到新链接，一开始我想的是是用爬虫爬一遍，虽然我的网站是全静态的，但写爬虫真的麻烦。后来我想到，sitemap.xml 会随 hexo g 自动产生，我只需要去 sitemap.xml 找新链接即可。在我本地的自动推送机上，使用 Python 自带的 sqlite3 数据库保存已推送过的链接。&lt;/p&gt;&#xA;&lt;h2&gt;自动推送链接的实现&lt;/h2&gt;&#xA;&lt;h3&gt;crontab 定时触发脚本&lt;/h3&gt;&#xA;&lt;p&gt;crontab 设置成每天 1:10 AM 推送。如何设置可以谷歌或参照自带帮助说明。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;10 1 * * * python /root/sitemap_auto_push/1.py &amp;gt;/dev/null 2&amp;gt;&amp;amp;1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;sqlite3 数据库&lt;/h3&gt;&#xA;&lt;p&gt;更简单了，只需要一个表。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;create table urls&#xA;{&#xA;    id integer primary key autoincrement,&#xA;    url varchar(200)    &#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;XML 解析&lt;/h3&gt;&#xA;&lt;p&gt;sitemap.xml 是 XML 标记的，可以直接使用 Python 的 xml 模块来解析。我个人主页的 sitemap.xml 树结构如下&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;urlset xmlns=&amp;quot;http://www.sitemaps.org/schemas/sitemap/0.9&amp;quot;&amp;gt;&#xA;&#xA;&amp;lt;url&amp;gt;&#xA;    &amp;lt;loc&amp;gt;http://www.lyyyuna.com/2015/12/28/robotframework-quickstartguide/&amp;lt;/loc&amp;gt;&#xA;    &amp;lt;lastmod&amp;gt;2015-12-28T15:06:00.354Z&amp;lt;/lastmod&amp;gt;&#xA;&amp;lt;/url&amp;gt;&#xA;&amp;lt;url&amp;gt;&#xA;    &amp;lt;loc&amp;gt;http://www.lyyyuna.com/2015/12/25/scons4-building-and-linking-with-libraries/&amp;lt;/loc&amp;gt;&#xA;    &amp;lt;lastmod&amp;gt;2015-12-25T13:30:14.968Z&amp;lt;/lastmod&amp;gt;&#xA;&amp;lt;/url&amp;gt;    &#xA;...&#xA;...&#xA;...&#xA;&amp;lt;/urlset&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;所以简单遍历一下就可以取出所有链接，再与数据库中的内容比较即可&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;loc_string = &#39;{http://www.sitemaps.org/schemas/sitemap/0.9}loc&#39;&#xA;for url in root:&#xA;    for attr in url:&#xA;        if attr.tag == loc_string:&#xA;            if not check_if_exist(attr.text):&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;POST 请求&lt;/h3&gt;&#xA;&lt;p&gt;每行一个链接 POST 即可，没有键-值，不需要 urlencode。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;baidu_zhanzhang_url = &#39;http://data.zz.baidu.com/urls?site=www.lyyyuna.com&amp;amp;token=XXXXXXXXXXXXX&amp;amp;type=original&#39;&#xA;# values = &#39;http://www.lyyyuna.com/2015/12/28/robotframework-quickstartguide/&#39;&#xA;&#xA;req = urllib2.Request(baidu_zhanzhang_url, values)&#xA;response = urllib2.urlopen(req)&#xA;the_page = response.read()      &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;完整源代码&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;# -*- coding: utf-8 -*-&#xA;&#xA;import urllib&#xA;import urllib2&#xA;&#xA;def check_if_exist(url):&#xA;    for cached_url in all_urls:&#xA;        ascii_cached_url = cached_url[1].encode(&#39;ascii&#39;)&#xA;        # print ascii_cached_url&#xA;        if url == ascii_cached_url:&#xA;            return True&#xA;    return False&#xA;    &#xA;sitemap_url = &#39;http://www.lyyyuna.com/sitemap.xml&#39;&#xA;get = urllib2.urlopen(sitemap_url)&#xA;xml_string = get.read()&#xA;&#xA;import sqlite3&#xA;import xml.etree.ElementTree as ET&#xA;root = ET.fromstring(xml_string)&#xA;&#xA;cx = sqlite3.connect(&#39;sitemap.db3&#39;)&#xA;cur = cx.cursor()&#xA;cur.execute(&#39;select * from urls&#39;)&#xA;all_urls = cur.fetchall()&#xA;# print all_urls[0][1]&#xA;&#xA;values = &#39;&#39;&#xA;loc_string = &#39;{http://www.sitemaps.org/schemas/sitemap/0.9}loc&#39;&#xA;for url in root:&#xA;    for attr in url:&#xA;        if attr.tag == loc_string:&#xA;            if not check_if_exist(attr.text):&#xA;                # print attr.text&#xA;                cur.execute(&amp;quot;insert into urls (url) values (&#39;&amp;quot; + attr.text + &amp;quot;&#39;)&amp;quot;)&#xA;                values = values + attr.text + &#39;\n&#39;&#xA;&#xA;cx.commit()&#xA;&#xA;print values&#xA;&#xA;baidu_zhanzhang_url = &#39;http://data.zz.baidu.com/urls?site=www.lyyyuna.com&amp;amp;token=XXXXXXXXXXXXX&amp;amp;type=original&#39;&#xA;# values = &#39;http://www.lyyyuna.com/2015/12/28/robotframework-quickstartguide/&#39;&#xA;&#xA;req = urllib2.Request(baidu_zhanzhang_url, values)&#xA;response = urllib2.urlopen(req)&#xA;the_page = response.read()&#xA;&#xA;print the_page&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;若看到&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;{&amp;quot;remain&amp;quot;:496,&amp;quot;success&amp;quot;:2}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;你就成功了。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2015/12/29/sitemap-baidu-autosubmit/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>Robot Framework 快速入门指南</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2015/12/28/robotframework-quickstartguide/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;h3&gt;关于本指南&lt;/h3&gt;&#xA;&lt;p&gt;《Robot Framework 快速入门指南》介绍了 &lt;a href=&#34;http://robotframework.org/&#34;&gt;Robot Framework&lt;/a&gt; 的一些最重要的特性。你不仅可以打开并浏览这些例子，而且你也可以把本指南当成一个 &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/blob/master/QuickStart.rst#executing-this-guide&#34;&gt;可执行的演示程序&lt;/a&gt;。所有这些特性在《&lt;a href=&#34;http://robotframework.org/robotframework/#user-guide&#34;&gt;Robot Framework 用户指南&lt;/a&gt;》中有详细的介绍。&lt;/p&gt;&#xA;&lt;h3&gt;Robot Framework 概览&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://robotframework.org/&#34;&gt;Robot Framework&lt;/a&gt; 是一个通用的开源自动化测试框架，常被用作验收测试 (acceptance testing) 和验收测试驱动开发 (acceptance test-driven development, ATDD)。它有着易用的表格测试数据语法，并且采用了关键字驱动的测试方法。你可以使用 Python 或者 Java 编写的测试库莱扩展框架的测试能力，而且用户可以使用和测试用例相同的语法，来创建新的高级关键字。&lt;/p&gt;&#xA;&lt;p&gt;Robot Framework 独立于操作系统和应用。核心框架采用 Python 编写，同样能够在 Jython (JVM) 和 IronPython (.NET) 上运行。该框架有着丰富的生态系统，包含多种多样独立开发的通用测试库和工具。&lt;/p&gt;&#xA;&lt;p&gt;有关 Robot Framework 极其生态系统更多的信息，你可以浏览 &lt;a href=&#34;http://robotframework.org/&#34;&gt;http://robotframework.org/&lt;/a&gt;。在那，你可以看到更多丰富的文档，演示程序，测试库和其他的工具列表，等等。&lt;/p&gt;&#xA;&lt;h3&gt;演示程序&lt;/h3&gt;&#xA;&lt;p&gt;在本指南中的示例应用程序是一个经典的登录示例的变体：这是用 Python 编写的基于命令行的身份验证服务器。该应用程序允许用户做三件事：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;用有效的密码创建一个新账户；&lt;/li&gt;&#xA;&lt;li&gt;使用有效的账户和密码登陆；&lt;/li&gt;&#xA;&lt;li&gt;用已有的账户改变密码。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;应用程序本身是文件 &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/blob/master/sut/login.py&#34;&gt;sut/login.py&lt;/a&gt; 中，可以直接执行命令 python sut/login.py。如果试图用一个不存在的用户帐户，或者无效的密码登陆，都会显示如下的错误消息：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; python sut/login.py login nobody P4ssw0rd&#xA;Access Denied&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当创建一个有效帐户和密码，并登录成功后：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; python sut/login.py create fred P4ssw0rd&#xA;SUCCESS&#xA;&#xA;&amp;gt; python sut/login.py login fred P4ssw0rd&#xA;Logged In&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当使用无效凭据更改密码，显示的错误消息和之前相同。新密码会进行有效性验证，如果无效，则给出如下错误消息：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;&amp;gt; python sut/login.py change-password fred wrong NewP4ss&#xA;Changing password failed: Access Denied&#xA;&#xA;&amp;gt; python sut/login.py change-password fred P4ssw0rd short&#xA;Changing password failed: Password must be 7-12 characters long&#xA;&#xA;&amp;gt; python sut/login.py change-password fred P4ssw0rd NewP4ss&#xA;SUCCESS &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;该应用程序使用一个简单的数据库文件来追踪用户状态。该文件位于操作系统相关的临时目录。&lt;/p&gt;&#xA;&lt;h2&gt;执行演示程序&lt;/h2&gt;&#xA;&lt;p&gt;这些说明会解释如何自己运行本指南的演示程序，如果你不感兴趣，你仍然可以查看 &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/blob/master/QuickStart.rst#viewing-results&#34;&gt;在线结果&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;h3&gt;安装&lt;/h3&gt;&#xA;&lt;p&gt;推荐使用 &lt;a href=&#34;http://python.org/&#34;&gt;Python&lt;/a&gt; 的 &lt;a href=&#34;http://pip-installer.org/&#34;&gt;pip&lt;/a&gt; 工具来安装 Robot Framework。你可以直接运行：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pip install robotframework&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;你可以查看 &lt;a href=&#34;https://github.com/robotframework/robotframework/blob/master/INSTALL.rst&#34;&gt;Robot Framework 安装指南&lt;/a&gt;，了解更多的安装方法，和有关安装的更多一般信息。&lt;/p&gt;&#xA;&lt;p&gt;这个示例是使用 &lt;a href=&#34;http://docutils.sourceforge.net/rst.html&#34;&gt;reStructuredText&lt;/a&gt; 标记语言书写，采用框架的代码块中的测试数据。想要用这种格式执行本测试需要安装 [docutils](Robot Framework test data in code blocks) 模块：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pip install docutils&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;请注意，目前官方还不支持 Python3。请查阅 &lt;a href=&#34;https://github.com/robotframework/robotframework/blob/master/INSTALL.rst&#34;&gt;安装指南&lt;/a&gt; 了解非官方的 Python3 移植，极其最近的支持程度。&lt;/p&gt;&#xA;&lt;h3&gt;执行&lt;/h3&gt;&#xA;&lt;p&gt;安装完以后，你还需要获取演示实例。最方便的方法就是下载一个 &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/releases&#34;&gt;发布版本&lt;/a&gt; 或者获取 &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/archive/master.zip&#34;&gt;最新版本&lt;/a&gt; 后在任意位置解压，你也可以直接克隆这个 &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide&#34;&gt;仓库&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;当你安装完，并获取一切必要条件之后，你可以用 pybot 命令运行本演示：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pybot QuickStart.rst&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;你还可以配置各种命令行选项来执行：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pybot --log custom_log.html --name Custom_Name QuickStart.rst&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;运行 pybot --help 来获取可用的选项列表。&lt;/p&gt;&#xA;&lt;h3&gt;查看结果&lt;/h3&gt;&#xA;&lt;p&gt;运行演示程序将会生成以下三个结果文件。这些文件被在线链接到可用的预执行文件，但运行演示程序时会在本地创建它们。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://robotframework.org/QuickStartGuide/report.html&#34;&gt;report.html&lt;/a&gt; 测试报告&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://robotframework.org/QuickStartGuide/log.html&#34;&gt;log.html&lt;/a&gt; 详细的测试执行 log&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://robotframework.org/QuickStartGuide/output.xml&#34;&gt;output.xml&lt;/a&gt; XML 格式的机读报告&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2&gt;测试用例&lt;/h2&gt;&#xA;&lt;h3&gt;工作流测试&lt;/h3&gt;&#xA;&lt;p&gt;Robot Framework 测试用例是使用简单的表格语法创建。例如，下面的表有两个测试：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;用户能够创建账户并登录&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;用户不能使用错误的密码登录&lt;/p&gt;&#xA;&lt;p&gt;*** Test Cases ***&#xA;User can create an account and log in&#xA;Create Valid User    fred    P4ssw0rd&#xA;Attempt to Login with Credentials    fred    P4ssw0rd&#xA;Status Should Be    Logged In&lt;/p&gt;&#xA;&lt;p&gt;User cannot log in with bad password&#xA;Create Valid User    betty    P4ssw0rd&#xA;Attempt to Login with Credentials    betty    wrong&#xA;Status Should Be    Access Denied&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;请注意，这些测试读起来就像是用英语书写的手动测试步骤，而并不像是自动化测试。这是因为 Robot Framework 采用关键字驱动的测试方法，使得编写测试时能够使用自然语言，来描述过程的步骤和预期结果。测试用例是由关键字和其可能的参数构成。&lt;/p&gt;&#xA;&lt;h3&gt;高级别测试&lt;/h3&gt;&#xA;&lt;p&gt;测试用例也可以使用更抽象的关键字创建，这些例子没有任何位置参数。这允许使用更自由的文字，甚至方便那些不懂技术的客户或其他项目利益相关者互相交流。在 &lt;a href=&#34;http://en.wikipedia.org/wiki/Acceptance_test-driven_development&#34;&gt;验证测试驱动开发&lt;/a&gt; 或其他变体中这种方法尤其重要。&lt;/p&gt;&#xA;&lt;p&gt;Robot Framework 并不强制要求测试用例的格式。一个常见的风格是使用 given-when-then 风格，即 &lt;a href=&#34;http://en.wikipedia.org/wiki/Behavior_driven_development&#34;&gt;行为驱动开发&lt;/a&gt; (behavior-driven development, BDD)。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;*** Test Cases ***&#xA;User can change password&#xA;    Given a user has a valid account&#xA;    When she changes her password&#xA;    Then she can log in with the new password&#xA;    And she cannot use the old password anymore&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;数据驱动测试&lt;/h3&gt;&#xA;&lt;p&gt;我们经常会碰到这种情况，测试用例相似仅仅是输入或输出数据不同。在这种情况下_数据驱动测试_允许不同的测试数据，而无需重复工作流。在 Robot Framework 中使用 [Template] 设置，可以将用例转换为数据驱动的测试，而用例中定义的数据作为模板关键字运行：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;*** Test Cases ***&#xA;Invalid password&#xA;    [Template]    Creating user with invalid password should fail&#xA;    abCD5            ${PWD INVALID LENGTH}&#xA;    abCD567890123    ${PWD INVALID LENGTH}&#xA;    123DEFG          ${PWD INVALID CONTENT}&#xA;    abcd56789        ${PWD INVALID CONTENT}&#xA;    AbCdEfGh         ${PWD INVALID CONTENT}&#xA;    abCD56+          ${PWD INVALID CONTENT}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;除了在单独的测试中使用 [Template] 设置，也可以在之后介绍的 &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/blob/master/QuickStart.rst#setups-and-teardowns&#34;&gt;启动和卸载&lt;/a&gt; 的设置表格中使用 Test Template 选项。在本例中，模板能够避免为了过长或过短密码，再去创建其他无效的用例。如果不使用模板，你就不得不为每一个输入输出创建一个用例，而使用模板只要一个用例。&lt;/p&gt;&#xA;&lt;p&gt;请注意，上述例子的错误消息是使用 &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/blob/master/QuickStart.rst#variables&#34;&gt;变量&lt;/a&gt; 来指定。&lt;/p&gt;&#xA;&lt;h2&gt;关键字&lt;/h2&gt;&#xA;&lt;p&gt;测试用例的关键字有两种来源。&lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/blob/master/QuickStart.rst#library-keywords&#34;&gt;库关键字&lt;/a&gt; 来自导入的测试库，所谓的 &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/blob/master/QuickStart.rst#user-keywords&#34;&gt;用户关键字&lt;/a&gt; 可由和创建测试用例相同的表格语法来书写。&lt;/p&gt;&#xA;&lt;h3&gt;库关键字&lt;/h3&gt;&#xA;&lt;p&gt;所有在测试库中定义的低级关键字都是由标准编程语言实现的，通常是 Python 或者 Java。Robot Framework 有着丰富的 &lt;a href=&#34;http://robotframework.org/#test-libraries&#34;&gt;测试库&lt;/a&gt;，它们被分成_标准库_，&lt;em&gt;外部库_和_自定义库&lt;/em&gt;。标准库分布于核心框架和一些通用库中，比如 OperatingSystem, Screenshot 和 BuiltIn 中。 这些库比较特别，当安装完框架后便是可用的。而如用于网络测试的 &lt;a href=&#34;https://github.com/rtomac/robotframework-selenium2library/#readme&#34;&gt;Selenium2Library&lt;/a&gt;，必须单独安装。如果这些库还不够用， &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/blob/master/QuickStart.rst#creating-test-libraries&#34;&gt;创建自定义库&lt;/a&gt; 是非常简单的。&lt;/p&gt;&#xA;&lt;p&gt;为了使用一个测试库提供的关键字，必须先导入该库。本指南中的测试需要 OperatingSystem 库 (如 Remove File) 和自定义库 LoginLibrary 库 (如 Attempt to login with credentials)。它们都在如下的设置表格中导入：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;*** Settings ***&#xA;Library           OperatingSystem&#xA;Library           lib/LoginLibrary.py&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;用户关键字&lt;/h3&gt;&#xA;&lt;p&gt;Robot Framework 最强大的特性是允许用户使用已有关键字来创建新的高级关键字。这种语法被称作_用户自定义关键字_，或者简称为_用户关键字_。关键字语法和创建测试用例是类似的。上述例子中所有的高级关键字都在如下的关键字表格中创建：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;*** Keywords ***&#xA;Clear login database&#xA;    Remove file    ${DATABASE FILE}&#xA;&#xA;Create valid user&#xA;    [Arguments]    ${username}    ${password}&#xA;    Create user    ${username}    ${password}&#xA;    Status should be    SUCCESS&#xA;&#xA;Creating user with invalid password should fail&#xA;    [Arguments]    ${password}    ${error}&#xA;    Create user    example    ${password}&#xA;    Status should be    Creating user failed: ${error}&#xA;&#xA;Login&#xA;    [Arguments]    ${username}    ${password}&#xA;    Attempt to login with credentials    ${username}    ${password}&#xA;    Status should be    Logged In&#xA;&#xA;# Keywords below used by higher level tests. Notice how given/when/then/and&#xA;# prefixes can be dropped. And this is a commend.&#xA;&#xA;A user has a valid account&#xA;    Create valid user    ${USERNAME}    ${PASSWORD}&#xA;&#xA;She changes her password&#xA;    Change password    ${USERNAME}    ${PASSWORD}    ${NEW PASSWORD}&#xA;    Status should be    SUCCESS&#xA;&#xA;She can log in with the new password&#xA;    Login    ${USERNAME}    ${NEW PASSWORD}&#xA;&#xA;She cannot use the old password anymore&#xA;    Attempt to login with credentials    ${USERNAME}    ${PASSWORD}&#xA;    Status should be    Access Denied&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;用户自定义关键字可以包含其他用户关键字，或者是库关键字。正如你在本例中看到的那样，用户自定义关键字可以包含参数。它们还可以返回值，甚至是包括 FOR 循环。现在，重要的是，用户自定义关键字使得测试作者能过复用之前相同的步骤序列。用户自定义关键字也使得测试作者保持测试用例具有高可读性，并在不同场景下使用合适的抽象级别。&lt;/p&gt;&#xA;&lt;h2&gt;变量&lt;/h2&gt;&#xA;&lt;h3&gt;定义变量&lt;/h3&gt;&#xA;&lt;p&gt;变量是 Robot Framework 的一个组成部分。通常在测试中使用的任何数据，如有更改，最好定义为变量。变量的定义语法非常简单，如下变量表所示：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;*** Variables ***&#xA;${USERNAME}               janedoe&#xA;${PASSWORD}               J4n3D0e&#xA;${NEW PASSWORD}           e0D3n4J&#xA;${DATABASE FILE}          ${TEMPDIR}${/}robotframework-quickstart-db.txt&#xA;${PWD INVALID LENGTH}     Password must be 7-12 characters long&#xA;${PWD INVALID CONTENT}    Password must be a combination of lowercase and uppercase letters and numbers&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;变量还可以由命令行给出，这对不同环境中执行测试用例是非常有用的。例如，可以如下执行演示程序：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pybot --variable USERNAME:johndoe --variable PASSWORD:J0hnD0e QuickStart.rst&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;除用户定义的变量外，有一些是始终可用的内置变量。这些变量包括 ${TEMPDIR} 和 ${/}，这在上述示例中被使用。&lt;/p&gt;&#xA;&lt;h3&gt;使用变量&lt;/h3&gt;&#xA;&lt;p&gt;变量可以在测试数据的大多数地方使用。他们最常被用作关键字的参数，像下面的测试用例演示的那样。返回值分配给变量和以后使用。例如，如下的 Database Should Contain &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/blob/master/QuickStart.rst#user-keywords&#34;&gt;用户关键字&lt;/a&gt;，将数据库内容设置在 ${database} 变量中，然后使用 &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/blob/master/QuickStart.rst#user-keywords&#34;&gt;BuiltIn&lt;/a&gt; 关键字 Should Contain 来验证内容的正确性。库和用户关键字都能返回值。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;*** Test Cases ***&#xA;User status is stored in database&#xA;    [Tags]    variables    database&#xA;    Create Valid User    ${USERNAME}    ${PASSWORD}&#xA;    Database Should Contain    ${USERNAME}    ${PASSWORD}    Inactive&#xA;    Login    ${USERNAME}    ${PASSWORD}&#xA;    Database Should Contain    ${USERNAME}    ${PASSWORD}    Active&#xA;&#xA;*** Keywords ***&#xA;Database Should Contain&#xA;    [Arguments]    ${username}    ${password}    ${status}&#xA;    ${database} =     Get File    ${DATABASE FILE}&#xA;    Should Contain    ${database}    ${username}\t${password}\t${status}\n&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;组织测试用例&lt;/h2&gt;&#xA;&lt;h3&gt;测试套件&lt;/h3&gt;&#xA;&lt;p&gt;测试用例的集合被称为 Robot Framework 中的测试套件。每个输入文件，该文件包含测试用例构成一个测试套件。当 &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/blob/master/QuickStart.rst#executing-this-guide&#34;&gt;执行本指南&lt;/a&gt;，你可以看到控制台输出的 QuickStart。这个名字就是从文件名中生成的，在报告和日志中也可以看到。&lt;/p&gt;&#xA;&lt;p&gt;也可以通过层次结构来组织测试用例，将测试用例文件放入目录，再将这些目录放置到其他目录中。所有这些目录会自动创建高级测试套件，目录名即为测试套件的名字。由于测试套件只是文件和目录，它们可以很方便地放置在任何版本控制系统中。&lt;/p&gt;&#xA;&lt;h3&gt;安装和卸载&lt;/h3&gt;&#xA;&lt;p&gt;如果要在每个测试用例想在之前或之后要执行的某些关键字，可以在 Test Setup 和 Test Teardown 中设置。同样的，如果要在测试套件之前或之后执行某些关键字，你只需要在 Suite Setup 和 Suite Teardown 中设置。 单个测试也可以通过测试用例表格的 [Setup] 和 [Teardown] 使用自定义安装或卸载。这和之前 &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/blob/master/QuickStart.rst#data-driven-tests&#34;&gt;数据驱动测试&lt;/a&gt; 使用 [Template] 的方法是相同的。&lt;/p&gt;&#xA;&lt;p&gt;在本演示中我们要确保在开始执行之前，每个测试之后，数据库被清除：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;*** Settings ***&#xA;Suite Setup       Clear Login Database&#xA;Test Teardown     Clear Login Database&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;使用标签&lt;/h3&gt;&#xA;&lt;p&gt;Robot Framework 允许设置测试用例标签，赋予其元数据。标签可以 Force Tags  和  Default Tags 为文件中所有测试用例强制设置，如下表中的所有测试用例。还可以通过 [Tags] 为单个测试用例设置，比如 &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/blob/master/QuickStart.rst#using-variables&#34;&gt;之前&lt;/a&gt; 的 User status is stored in database 测试。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;*** Settings ***&#xA;Force Tags        quickstart&#xA;Default Tags      example    smoke&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当你在执行完后查看报告，你可以看到每个测试用例有指定的标签，也可以看到针对每个标签生成的统计信息。标签也可以用于许多其他用途，其中最重要的是有选择地执行测试。你可以试试，比如下列命令：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pybot --include smoke QuickStart.rst&#xA;pybot --exclude database QuickStart.rst&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;创建测试库&lt;/h2&gt;&#xA;&lt;p&gt;Robot Framework 提供了一个简单的 API 来使用 Python 或 Java 创建测试库，一些远程库接口还允许使用其他编程语言。《&lt;a href=&#34;http://robotframework.org/robotframework/#user-guide&#34;&gt;Robot Framework 用户指南&lt;/a&gt;》包含有关库 API 的详细说明。&lt;/p&gt;&#xA;&lt;p&gt;举例来说，我们来看一下本例中的 LoginLibrary 测试库。库位于 &lt;a href=&#34;https://github.com/robotframework/QuickStartGuide/blob/master/lib/LoginLibrary.py&#34;&gt;lib/LoginLibrary.py&lt;/a&gt;，源代码如下。通过源代码可以看到，关键字 Create User 如何映射到实际的执行方法 create_user。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;import os.path&#xA;import subprocess&#xA;import sys&#xA;&#xA;&#xA;class LoginLibrary(object):&#xA;&#xA;    def __init__(self):&#xA;        self._sut_path = os.path.join(os.path.dirname(__file__),&#xA;                                    &#39;..&#39;, &#39;sut&#39;, &#39;login.py&#39;)&#xA;        self._status = &#39;&#39;&#xA;&#xA;    def create_user(self, username, password):&#xA;        self._run_command(&#39;create&#39;, username, password)&#xA;&#xA;    def change_password(self, username, old_pwd, new_pwd):&#xA;        self._run_command(&#39;change-password&#39;, username, old_pwd, new_pwd)&#xA;&#xA;    def attempt_to_login_with_credentials(self, username, password):&#xA;        self._run_command(&#39;login&#39;, username, password)&#xA;&#xA;    def status_should_be(self, expected_status):&#xA;        if expected_status != self._status:&#xA;            raise AssertionError(&amp;quot;Expected status to be &#39;%s&#39; but was &#39;%s&#39;.&amp;quot;&#xA;                                % (expected_status, self._status))&#xA;&#xA;    def _run_command(self, command, *args):&#xA;        command = [sys.executable, self._sut_path, command] + list(args)&#xA;        process = subprocess.Popen(command, stdout=subprocess.PIPE,&#xA;                                stderr=subprocess.STDOUT)&#xA;        self._status = process.communicate()[0].strip()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2015/12/28/robotframework-quickstartguide/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>SCons 用户指南第四章 - 编译和链接库</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2015/12/25/scons4-building-and-linking-with-libraries/</id>
    <content type="html">&lt;p&gt;在大型软件工程中，经常将部分软件合并成一个或多个库文件。SCons 在创建和使用库文件方面非常简单易用。&lt;/p&gt;&#xA;&lt;h2&gt;4.1 编译库&lt;/h2&gt;&#xA;&lt;p&gt;你可以代替 Program 使用 Library 来生成你自己的库文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Library(&#39;foo&#39;, [&#39;f1.c&#39;, &#39;f2.c&#39;, &#39;f3.c&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;SCons 会自动根据你的系统使用合适的库文件前缀和后缀。所以在 POSIX 或 Linux 系统上，上面的例子编译过程如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o f1.o -c f1.c&#xA;cc -o f2.o -c f2.c&#xA;cc -o f3.o -c f3.c&#xA;ar rc libfoo.a f1.o f2.o f3.o&#xA;ranlib libfoo.a&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 Windows 系统上，上述例子的编译过程如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;scons -Q&#xA;cl /Fof1.obj /c f1.c /nologo&#xA;cl /Fof2.obj /c f2.c /nologo&#xA;cl /Fof3.obj /c f3.c /nologo&#xA;lib /nologo /OUT:foo.lib f1.obj f2.obj f3.obj&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;目标库文件的命名规则类似于直接生成程序：如果你没有显示指定目标库文件名称，SCons 会从第一个指定的源文件名字中推导出，并且 SCons 会加上合适的文件前缀和后缀。&lt;/p&gt;&#xA;&lt;h3&gt;4.1.1 从源码或二进制文件编译库&lt;/h3&gt;&#xA;&lt;p&gt;上一个例子战士了如何从一系列源码中编译出库文件，然而你也可以在 Library 调用中放置二进制文件，它会自动分析出这些是二进制文件。事实上，你也可以在源队列中混合使用源代码文件和二进制文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Library(&#39;foo&#39;, [&#39;f1.c&#39;, &#39;f2.o&#39;, &#39;f3.c&#39;, &#39;f4.o&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;SCons 能够意识到在生成最终库文件前需要编译哪些源文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o f1.o -c f1.c&#xA;cc -o f3.o -c f3.c&#xA;ar rc libfoo.a f1.o f2.o f3.o f4.o&#xA;ranlib libfoo.a&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;当然，在这个例子中，必须先编译出这些二进制文件。请查看第五章，如何显示编译自己的二进制文件并包含在自己的库文件中。&lt;/p&gt;&#xA;&lt;h3&gt;4.1.2 编译静态库：使用 StaticLibrary 方法&lt;/h3&gt;&#xA;&lt;p&gt;Library 方法能够编译一个传统的静态库文件。如果你想明确地控制库文件的类型，你可以使用 StaticLibrary 方法来代替 Library：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;StaticLibrary(&#39;foo&#39;, [&#39;f1.c&#39;, &#39;f2.c&#39;, &#39;f3.c&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在功能上它们之间没有区别。&lt;/p&gt;&#xA;&lt;h3&gt;4.1.3 编译动态库（DLL）：使用 SharedLibrary 方法&lt;/h3&gt;&#xA;&lt;p&gt;如果你像编译在 POSIX 系统或者 Windows 系统上编译动态库文件，你应该使用 SharedLibrary 方法：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;SharedLibrary(&#39;foo&#39;, [&#39;f1.c&#39;, &#39;f2.c&#39;, &#39;f3.c&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 POSIX 系统上输出为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o f1.os -c f1.c&#xA;cc -o f2.os -c f2.c&#xA;cc -o f3.os -c f3.c&#xA;cc -o libfoo.so -shared f1.os f2.os f3.os&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 Windows 系统上输出为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;scons -Q&#xA;cl /Fof1.obj /c f1.c /nologo&#xA;cl /Fof2.obj /c f2.c /nologo&#xA;cl /Fof3.obj /c f3.c /nologo&#xA;link /nologo /dll /out:foo.dll /implib:foo.lib f1.obj f2.obj f3.obj&#xA;RegServerFunc(target, source, env)&#xA;embedManifestDllCheck(target, source, env)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;你可以注意到 SCons 能够正确处理输出文件的过程，在 POSIX 系统上假设 -shared 选项，在 Windows 系统上加上 /dll 选项。&lt;/p&gt;&#xA;&lt;h2&gt;4.2 链接库&lt;/h2&gt;&#xA;&lt;p&gt;通常，你之所以编译库文件是为了在多个程序中链接它。为了链接库，你只需要在 $LIBS 构造变量中指定库，在 $LIBPATH 构造变量中指定库文件所在的目录：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Library(&#39;foo&#39;, [&#39;f1.c&#39;, &#39;f2.c&#39;, &#39;f3.c&#39;])&#xA;Program(&#39;prog.c&#39;, LIBS=[&#39;foo&#39;, &#39;bar&#39;], LIBPATH=&#39;.&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;很显然可以注意到，你不需要指定库的前缀（比如 lib）或者后缀（比如 .a 或 .lib）。SCons 能够为当前的系统使用正确的前缀和后缀。&lt;/p&gt;&#xA;&lt;p&gt;在类 POSIX 系统中，以上例子的编译过程为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o f1.o -c f1.c&#xA;cc -o f2.o -c f2.c&#xA;cc -o f3.o -c f3.c&#xA;ar rc libfoo.a f1.o f2.o f3.o&#xA;ranlib libfoo.a&#xA;cc -o prog.o -c prog.c&#xA;cc -o prog prog.o -L. -lfoo -lbar&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 Windows 系统上，以上例子的编译过程为：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;scons -Q&#xA;cl /Fof1.obj /c f1.c /nologo&#xA;cl /Fof2.obj /c f2.c /nologo&#xA;cl /Fof3.obj /c f3.c /nologo&#xA;lib /nologo /OUT:foo.lib f1.obj f2.obj f3.obj&#xA;cl /Foprog.obj /c prog.c /nologo&#xA;link /nologo /OUT:prog.exe /LIBPATH:. foo.lib bar.lib prog.obj&#xA;embedManifestExeCheck(target, source, env)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;像之前一样，可以注意到 SCons 能够正确地构造命令行，以确保在各个系统上能够链接正确的库。&lt;/p&gt;&#xA;&lt;p&gt;并且，如果你只有一个库需要链接，你可以用单个字符串，来代替 Python 的列表，即：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;prog.c&#39;, LIBS=&#39;foo&#39;, LIBPATH=&#39;.&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这和以下是等价的：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;prog.c&#39;, LIBS=[&#39;foo&#39;], LIBPATH=&#39;.&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这和 SCons 在处理单个源文件中既可以使用字符串或者列表，是类似的。&lt;/p&gt;&#xA;&lt;h2&gt;4.3 寻找库：$LIBPATH 构造变量&lt;/h2&gt;&#xA;&lt;p&gt;链接器默认只在系统指定的路径中寻找库文件。当你指定了 $LIBPATH 构造变量，SCons 知道如何寻找库文件。$LIBPATH 由一系列目录路径构成，如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;prog.c&#39;, LIBS = &#39;m&#39;, LIBPATH = [&#39;/usr/lib&#39;, &#39;/usr/local/lib&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;推荐使用 Python 列表，因为这具有可移植性。你也可以将所有目录名字放在一个字符串中。在 POSIX 系统中，使用冒号来分割目录路径：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;LIBPATH = &#39;/usr/lib:/usr/local/lib&#39;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;或者在 Windows 系统上使用分号来分割：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;LIBPATH = &#39;C:\\lib;D:\\lib&#39;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;（注意到，在 Windows 系统上必须对反斜杠进行转义。）&lt;/p&gt;&#xA;&lt;p&gt;当链接器执行时，SCons 会生成合适的标志位，这样链接器就将去寻找 SCons 指定的路径。所以在 POSIX 系统上，上述例子的编译过程如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o prog.o -c prog.c&#xA;cc -o prog prog.o -L/usr/lib -L/usr/local/lib -lm&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;或者在 Windows 系统上，上述例子的编译过程如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;scons -Q&#xA;cl /Foprog.obj /c prog.c /nologo&#xA;link /nologo /OUT:prog.exe /LIBPATH:\usr\lib /LIBPATH:\usr\local\lib m.lib prog.obj&#xA;embedManifestExeCheck(target, source, env)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;注意到 SCons 能够正确地根据系统生成合适的命令行参数。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2015/12/25/scons4-building-and-linking-with-libraries/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>小米路由器 mini 刷机记录</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2015/12/19/xiaomiluyou01/</id>
    <content type="html">&lt;h2&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;以前并没有玩过路由器，但是单片机嵌入式玩过不少，很多概念都是相通的。&lt;/p&gt;&#xA;&lt;p&gt;刷新路由器的固件，其实也就是烧写 flash 的过程，有些系统也可能将程序存储在 EEPROM 中。很多网上的路由器资料中都会提到什么 TTL, JTAG, uboot 烧写等等，他们有什么区别呢。&lt;/p&gt;&#xA;&lt;h3&gt;flash 种类&lt;/h3&gt;&#xA;&lt;p&gt;我知道的 flash 分为两种，一种是类似 norflash，自带数据总线和地址总线，代码可以直接在 flash 运行，不需要像 PC 那样将程序从硬盘 copy 到内存中。在单片机中，大部分都是这种结构。&lt;/p&gt;&#xA;&lt;p&gt;第二种是类似 nandflash，只有数据总线，cpu 无法寻址，代码必须先从 flash 拷贝到 ram 中，才能真正开始执行代码。&lt;/p&gt;&#xA;&lt;h3&gt;代码的启动方式&lt;/h3&gt;&#xA;&lt;p&gt;首先明确一点，cpu 必须通过数据总线和地址总线寻址到代码，才能启动。对于 norflash 这种，非常方便，只要将 flash 地址配置到 cpu 上电后的第一条指令所在的范围即可。在早期的嵌入式设计中，经常在系统中同时配有 norflash 和 nandflash，norflash 比较贵且容量较小，所以里边一般只放置搬运代码。cpu 从 norflash启动后，执行里面的搬运代码将 nandflash 中真正的大段产品代码搬运到 ram 中。&lt;/p&gt;&#xA;&lt;p&gt;而 nandflash 启动就需要处理器支持。现在的 cpu 会在内部自带上述的搬运代码，比如三星的 ARM11 S3C6410，假如配置成 nandflash 启动（通过某些引脚的高低电平），会自动将 nandflash 前 4K 代码 copy 到 ram 中。&lt;/p&gt;&#xA;&lt;p&gt;我知道有较新的 cpu 支持从 sd 卡启动，这其实和 nandflash 启动原理类似。比如树莓派。&lt;/p&gt;&#xA;&lt;h3&gt;flash 烧写方式&lt;/h3&gt;&#xA;&lt;p&gt;最暴力原始的烧写方式，就是自制烧录器。比如一些 flash 的接口是 SPI，通过单片机将 PC 的串口数据转成 SPI 数据写进 flash。&lt;/p&gt;&#xA;&lt;p&gt;但路由器板子上 flash 已经焊死，很多人并不会焊接，这时就可以借助 JTAG 接口。我知道的 JTAG 是一种调试处理器的接口，一些编程器实现了该接口，比如 j-link。通过 j-link 可以直接操纵 cpu 对 flash 进行烧写。但实际上 j-link 烧写支持的 flash 种类是有限的，据我所知对 nandflash 支持一般（或者没有支持？）。而且正版的 j-link 非常昂贵（&amp;gt; 1000$）。&lt;/p&gt;&#xA;&lt;p&gt;除了以上两种烧录方式，其他都得借助 BootLoader。&lt;/p&gt;&#xA;&lt;h3&gt;BootLoader&lt;/h3&gt;&#xA;&lt;p&gt;首先在逻辑上对 flash 内容分区，其中 cpu 上电后执行的第一分区放入 BootLoader，将读到的 TTL，网口，USB 等等数据烧录到另一分区中，实现自我烧写，烧写完成后跳入另一分区中执行产品代码。有了 BootLoader，只要不破坏这一段分区内容，就能一直烧录。&lt;/p&gt;&#xA;&lt;p&gt;经典的 BootLoader 有 uboot。显然 BootLoader 的出现极大的方便了路由器的开发，节省了成本。一个好的 BootLoader 完全可以同时支持 TTL，网口，USB，sd卡。&lt;/p&gt;&#xA;&lt;h2&gt;小米路由器刷固件过程&lt;/h2&gt;&#xA;&lt;p&gt;小米路由器的 BootLoader 支持 usb 刷固件。系统启动后，可以从管理员页面刷新固件。&lt;/p&gt;&#xA;&lt;p&gt;因为不清楚小米官方 BootLoader 会不会对固件有限制，我打算将 BootLoader 和 固件 全部刷新。&lt;/p&gt;&#xA;&lt;h3&gt;获取 root 权限和 ssh&lt;/h3&gt;&#xA;&lt;p&gt;首先要根据 &lt;a href=&#34;https://d.miwifi.com/rom/ssh&#34;&gt;官方指南&lt;/a&gt; 在网页管理员页面刷成开发板固件，然后绑定小米账号获取 ssh 开发工具，再从 usb 烧录 ssh 开发工具。&lt;/p&gt;&#xA;&lt;p&gt;ssh 登陆后，首先查看系统的分区。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;    root@XiaoQiang:~# cat /proc/mtd&#xA;&#xA;    dev:    size        erasesize   name&#xA;    mtd0:   01000000    00010000    &amp;quot;ALL&amp;quot;&#xA;    mtd1:   00030000    00010000    &amp;quot;Bootloader&amp;quot;&#xA;    mtd2:   00010000    00010000    &amp;quot;Config&amp;quot;&#xA;    mtd3:   00010000    00010000    &amp;quot;Factory&amp;quot;&#xA;    mtd4:   00c80000    00010000    &amp;quot;OS1&amp;quot;&#xA;    mtd5:   00b19a3b    00010000    &amp;quot;rootfs&amp;quot;&#xA;    mtd6:   00200000    00010000    &amp;quot;OS2&amp;quot;&#xA;    mtd7:   00100000    00010000    &amp;quot;overlay&amp;quot;&#xA;    mtd8:   00010000    00010000    &amp;quot;crash&amp;quot;&#xA;    mtd9:   00010000    00010000    &amp;quot;reserved&amp;quot;&#xA;    mtd10:  00010000    00010000    &amp;quot;Bdata&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以将一些分区备份至 U 盘中。比如 Bdata 分区应该有 sn 信息，如果你对保修比较在意。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;    root@XiaoQiang:~# dd if=/dev/mtd1 of=/extdisks/sda1/xiaomi-bootloader.bin&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;刷 BootLoader&lt;/h3&gt;&#xA;&lt;p&gt;我选择 hackpascal 开发的 &lt;a href=&#34;http://www.right.com.cn/forum/thread-161906-1-1.html&#34;&gt;Breed&lt;/a&gt; 作为我的 BootLoader，它支持 LAN 口，更方便。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;    root@XiaoQiang:~# wget -O /tmp/breed.bin http://breed.hackpascal.net/latest/breed-mt7620-xiaomi-mini.bin&#xA;    root@XiaoQiang:~# mtd -r write /tmp/breed.bin Bootloader&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;按照 &lt;a href=&#34;http://www.right.com.cn/forum/thread-161906-1-1.html&#34;&gt;Breed&lt;/a&gt; 的说明运行 BreedEnter.exe 后，重启路由器。这时路由器和 PC 通过网线直连。按照 hackpascal 所说，Breed 是带 dhcp 的，实际测试没有成功，我手动配置了电脑的 ip 为 192.168.1.2，打开网页 http://192.168.1.1。&lt;/p&gt;&#xA;&lt;h3&gt;刷固件&lt;/h3&gt;&#xA;&lt;p&gt;有了 Breed 之后，刷固件就简单多了。下载 &lt;a href=&#34;http://downloads.openwrt.org.cn/PandoraBox/Xiaomi-Mini-R1CM/stable/PandoraBox-ralink-mt7620-xiaomi-mini-squashfs-sysupgrade-r1024-20150608.bin&#34;&gt;PandoraBox_xiaomi_20150608&lt;/a&gt;。按照 http://192.168.1.1 的指示上传即可。对于小米的固件_可能_需要_配置一下固件的启动方式_。&lt;/p&gt;&#xA;&lt;p&gt;你也可以从后台&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;    root@XiaoQiang:~# mtd -r write /tmp/PandoraBox-ralink-mt7620-xiaomi-mini-squashfs-sysupgrade-r1024-20150608.bin OS1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;但有了 Breed 减少了你手抖刷错变砖的几率。&lt;/p&gt;&#xA;&lt;p&gt;重启完后，路由器就是 PandoraBox 系统了。分区的名称也变了。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;    _______________________________________________________________ &#xA;     |    ____                 _                 ____               |&#xA;     |   |  _ \ __ _ _ __   __| | ___  _ __ __ _| __ )  _____  __   |&#xA;     |   | |_) / _` | &#39;_ \ / _` |/ _ \| &#39;__/ _` |  _ \ / _ \ \/ /   |&#xA;     |   |  __/ (_| | | | | (_| | (_) | | | (_| | |_) | (_) &amp;gt;  &amp;lt;    |&#xA;     |   |_|   \__,_|_| |_|\__,_|\___/|_|  \__,_|____/ \___/_/\_\   |&#xA;     |                                                              |&#xA;     |                  PandoraBox SDK Platform                     |&#xA;     |                  The Core of SmartRouter                     |&#xA;     |       Copyright 2013-2015 D-Team Technology Co.,Ltd.SZ       |&#xA;     |                http://www.pandorabox.org.cn                  |&#xA;     |______________________________________________________________|&#xA;      Base on OpenWrt BARRIER BREAKER (14.09, r1024)&#xA;    [root@PandoraBox:/root]#cat /proc/mtd&#xA;    dev:    size   erasesize  name&#xA;    mtd0: 00030000 00010000 &amp;quot;u-boot&amp;quot;&#xA;    mtd1: 00010000 00010000 &amp;quot;u-boot-env&amp;quot;&#xA;    mtd2: 00010000 00010000 &amp;quot;Factory&amp;quot;&#xA;    mtd3: 01000000 00010000 &amp;quot;fullflash&amp;quot;&#xA;    mtd4: 00f80000 00010000 &amp;quot;firmware&amp;quot;&#xA;    mtd5: 001230fb 00010000 &amp;quot;kernel&amp;quot;&#xA;    mtd6: 00e3cf05 00010000 &amp;quot;rootfs&amp;quot;&#xA;    mtd7: 00860000 00010000 &amp;quot;rootfs_data&amp;quot;&#xA;    mtd8: 00020000 00010000 &amp;quot;panic_oops&amp;quot;&#xA;    mtd9: 00010000 00010000 &amp;quot;culiang-crash&amp;quot;&#xA;    mtd10: 00010000 00010000 &amp;quot;culiang-reserved&amp;quot;&#xA;    mtd11: 00010000 00010000 &amp;quot;culiang-Bdata&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2015/12/19/xiaomiluyou01/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>SCons 用户指南第三章-让 SCons 编译更简单</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2015/12/03/scons3-less-simple-things-to-do-with-builds/</id>
    <content type="html">&lt;p&gt;在本章中，你将看到一些使用 SCons 编译配置的简单例子。这些例子表明，在不同系统和不同语言上使用 SCons 都是非常易用的。&lt;/p&gt;&#xA;&lt;h2&gt;3.1 指定目标文件的名称&lt;/h2&gt;&#xA;&lt;p&gt;在前几章的例子中，你已经看到了使用 Program 编译方法生成的目标文件名称和源文件相同。也就是说，如下的命令在 POSIX 系统上将生成可执行文件 hello，而在 Windows 上将生成 hello.exe。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello.c&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果你想要自定义名称，你只需要在调用时在源文件左侧指定就行：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;new_hello&#39;, &#39;hello.c&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;（SCons 要求目标文件的名称放在第一个，然后是源文件的名称，因此这个顺序模仿了大部分编程语言中的赋值顺序，包括 Python: &amp;quot;program = source files&amp;quot;）&lt;/p&gt;&#xA;&lt;p&gt;如下的命令将在 POSIX 系统上生成一个可执行程序 new_hello：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o hello.o -c hello.c&#xA;cc -o new_hello hello.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如下的命令将在 Windows 系统上生成可执行程序 new_hello.exe：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;scons -Q&#xA;cl /Fohello.obj /c hello.c /nologo&#xA;link /nologo /OUT:new_hello.exe hello.obj&#xA;embedManifestExeCheck(target, source, env)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;3.2 编译多个源文件&lt;/h2&gt;&#xA;&lt;p&gt;你已经看到了如何使用 SCons 从单个源文件编译的例子。在实际开发过程中，更多的是编译多个源文件的例子。为此，你只需要将源文件放在 Python list 中即可，如下所示：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program([&#39;prog.c&#39;, &#39;file1.c&#39;, &#39;file2.c&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;编译过程如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o file1.o -c file1.c&#xA;cc -o file2.o -c file2.c&#xA;cc -o prog.o -c prog.c&#xA;cc -o prog prog.o file1.o file2.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到，SCons 自动从列表的第一个源文件名推导出可执行程序的名字。由于第一个源文件名为 prog.c，SCons 会将生成文件命名为 prog （或者在 Windows 上是 prog.exe）。如果你想指定不同的名字，你只需要将源文件列表放在第二个参数，在第一个参数放置可执行程序名：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;program&#39;, [&#39;prog.c&#39;, &#39;file1.c&#39;, &#39;file2.c&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 Linux 上，编译过程如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o file1.o -c file1.c&#xA;cc -o file2.o -c file2.c&#xA;cc -o prog.o -c prog.c&#xA;cc -o program prog.o file1.o file2.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 Windows 上：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;scons -Q&#xA;cl /Fofile1.obj /c file1.c /nologo&#xA;cl /Fofile2.obj /c file2.c /nologo&#xA;cl /Foprog.obj /c prog.c /nologo&#xA;link /nologo /OUT:program.exe prog.obj file1.obj file2.obj&#xA;embedManifestExeCheck(target, source, env)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;3.3 用 Glob 函数生成文件列表&lt;/h2&gt;&#xA;&lt;p&gt;你也可以使用 Glob 函数来匹配出所有符合特定模式的源文件。模式可以是标准 shell 的模式匹配格式，比如 *, ?, [abc], [!abc]。这种方法使得在写多源文件时变得非常容易。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;program&#39;, Glob(&#39;*.c&#39;))&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;3.4 指定单个文件 Vs. 文件列表&lt;/h2&gt;&#xA;&lt;p&gt;我们已经展示了两种指定程序源文件的方法，第一种是使用文件的列表：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello&#39;, [&#39;file1.c&#39;, &#39;file2.c&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;第二种是使用单个文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello&#39;, &#39;hello.c&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;你实际上也可以将单个文件名放入一个列表中。这样你的脚本格式能够保持一致：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello&#39;, [&#39;hello.c&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;SCons 函数能够接受以上任何一种形式。实际上 SCons 将输入都看作是文件列表，但是允许你在输入单个源文件时省略方括号。&lt;/p&gt;&#xA;&lt;h3&gt;重要&lt;/h3&gt;&#xA;&lt;p&gt;虽然 SCons 函数不严格区分字符串和列表，但 Python 本身对这两者严格区分。所以在 SCons 允许既可以字符串和列表时：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# The following two calls both work correctly:&#xA;Program(&#39;program1&#39;, &#39;program1.c&#39;)&#xA;Program(&#39;program2&#39;, [&#39;program2.c&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果对混有字符串和列表的情况做一些 Python 的操作，可能会导致发生错误和不正确的结果：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;common_sources = [&#39;file1.c&#39;, &#39;file2.c&#39;]&#xA;&#xA;# THE FOLLOWING IS INCORRECT AND GENERATES A PYTHON ERROR&#xA;# BECAUSE IT TRIES TO ADD A STRING TO A LIST:&#xA;Program(&#39;program1&#39;, common_sources + &#39;program1.c&#39;)&#xA;&#xA;# The following works correctly, because it&#39;s adding two&#xA;# lists together to make another list.&#xA;Program(&#39;program2&#39;, common_sources + [&#39;program2.c&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;3.5 让文件列表更容易阅读&lt;/h2&gt;&#xA;&lt;p&gt;使用 Python 列表的一打缺点就是每个源文件名都必须包含在引号之间。当文件名很长时，就会显得累赘且不易阅读。幸运的是，SCons 和 Python 都提供了多种方式来简化 SConstruct 的阅读。&lt;/p&gt;&#xA;&lt;p&gt;为了使长文件列表易于处理，SCons 提供了 Split 函数来处理被引号包含且用空格或其他空白字符分隔的文件名，处理之后将转换成文件列表。对前一个例子使用 Split 函数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;program&#39;, Split(&#39;main.c file1.c file2.c&#39;))&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;（你如果熟悉 Python, 你应该已经意识到这和 string 模块中的 split() 函数非常相似。和 split() 成员函数不同的是， Split 函数并不要求输入一定是一个字符串，并将列表中单个字符串包起来。如果对象已经是一个列表，则直接原样返回不变。对于任意值传递到 SCons 函数中，这是一个方便的方法，这有就无需手工检查该变量的类型。）&lt;/p&gt;&#xA;&lt;p&gt;将 Split 函数放在 Program 调用中仍然显得笨拙。一个易读的方法是将 Split 调用的输出赋值给一个变量，然后将变量传递给 Program 函数：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;src_files = Split(&#39;main.c file1.c file2.c&#39;)&#xA;Program(&#39;program&#39;, src_files)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;最后需说明的是，Split 函数并不关心文件名之间空格的长度，这样你可以创建跨越多行的文件列表字符串，更容易编辑：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;src_files = Split(&amp;quot;&amp;quot;&amp;quot;main.c&#xA;                     file1.c&#xA;                     file2.c&amp;quot;&amp;quot;&amp;quot;)&#xA;Program(&#39;program&#39;, src_files)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;（这个例子中使用了 Python 的三重引号表示法，使得字符串能跨越多行，这里既可以是单引号也可以是双引号。）&lt;/p&gt;&#xA;&lt;h2&gt;3.6 关键字参数&lt;/h2&gt;&#xA;&lt;p&gt;SCons 也允许你使用 Python 的关键字参数来指定输出文件和输入源文件。输出文件是 target，输入文件是 source。Python 语法如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;src_files = Split(&#39;main.c file1.c file2.c&#39;)&#xA;Program(target = &#39;program&#39;, source = src_files)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;由于关键字显示指定了参数，所以实际上如果你喜欢，你可以颠倒它们的顺序：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;src_files = Split(&#39;main.c file1.c file2.c&#39;)&#xA;Program(source = src_files, target = &#39;program&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;至于你是否用关键字参数纯属个人喜好，SCons 函数的执行效果完全相同。&lt;/p&gt;&#xA;&lt;h2&gt;3.7 编译多个程序&lt;/h2&gt;&#xA;&lt;p&gt;为了能够在下单个 SConstruct 文件中编译多个程序， 你只需要调用 Program 方法多次即可，每一个输出程序对应一个调用。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;foo.c&#39;)&#xA;Program(&#39;bar&#39;, [&#39;bar1.c&#39;, &#39;bar2.c&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;SCons 的编译输出如下：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o bar1.o -c bar1.c&#xA;cc -o bar2.o -c bar2.c&#xA;cc -o bar bar1.o bar2.o&#xA;cc -o foo.o -c foo.c&#xA;cc -o foo foo.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;注意到 SCons 编译的顺序和 SConstruct 文件中指定的顺序并不相同。实际上 SCons 能够自动识别出单个二进制文件的编译顺序。我们将在下面的“&lt;em&gt;依赖&lt;/em&gt;”章节中详细阐述。&lt;/p&gt;&#xA;&lt;h2&gt;3.8 在多个编译程序中共享源文件&lt;/h2&gt;&#xA;&lt;p&gt;在多个编译程序中共享源文件是常见的复用代码的方法。其中一个方法就是根据常用的源文件生成库，然后让最终生成程序都链接该库。（创建库将在第 4 章，生成和链接库 中详述。）&lt;/p&gt;&#xA;&lt;p&gt;更直接，可能稍微麻烦的方法是将共同的源文件都放入各自的源文件列表中：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(Split(&#39;foo.c common1.c common2.c&#39;))&#xA;Program(&#39;bar&#39;, Split(&#39;bar1.c bar2.c common1.c common2.c&#39;))&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;即使 common1.c 和 common2.c 生成的二进制文件被链接了两次，SCons 也能够自动识别出它们只需要分别编译一次即可：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons -Q&#xA;cc -o bar1.o -c bar1.c&#xA;cc -o bar2.o -c bar2.c&#xA;cc -o common1.o -c common1.c&#xA;cc -o common2.o -c common2.c&#xA;cc -o bar bar1.o bar2.o common1.o common2.o&#xA;cc -o foo.o -c foo.c&#xA;cc -o foo foo.o common1.o common2.o&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果两个或多个程序共享了大量的源文件，那么重复输入源文件名会带来维护上的问题。你可以使用另外一个 Python 列表来存储共同源文件名，然后使用 Python 的 + 运算符进行链接：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;common = [&#39;common1.c&#39;, &#39;common2.c&#39;]&#xA;foo_files = [&#39;foo.c&#39;] + common&#xA;bar_files = [&#39;bar1.c&#39;, &#39;bar2.c&#39;] + common&#xA;Program(&#39;foo&#39;, foo_files)&#xA;Program(&#39;bar&#39;, bar_files)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这和上一个例子功能完全相同。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2015/12/03/scons3-less-simple-things-to-do-with-builds/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>修改图片的 GPS 信息</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2015/11/14/exif-hack/</id>
    <content type="html">&lt;h2&gt;序&lt;/h2&gt;&#xA;&lt;p&gt;在一些应用中上传图片可以显示拍摄地信息，这是因为使用带 GPS 功能的照相机或者是智能手机拍照后，会在图片中含有拍摄地的 GPS 信息。查看图片的详细信息之后，你会发现如下图所示记录了经度、纬度和海拔。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/1.png&#34; alt=&#34;属性查看&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;在 Windows 上，详细信息中的时间等可以直接修改，但唯独 GPS 信息是不可修改。本着研究探索的精神，我打算试试能不能直接修改二进制文件的方法来修改 GPS，将任意一幅图片修改为在北京拍摄。通过谷歌，了解到图片信息是由一种 Exchangeable image file format (Exif) 的格式来描述。网上我能查到的最新 specification 版本为 2012 年的 Exif v2.3 版本。&lt;a href=&#34;http://www.cipa.jp/std/documents/e/DC-008-2012_E.pdf&#34;&gt;Exif 规格书链接&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3&gt;Exif 规范的图片&lt;/h3&gt;&#xA;&lt;p&gt;Exif 规范其实包含了图片和音频两部分内容，这里我们只关心图片。整个图片的结构如下：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;File Header&lt;/li&gt;&#xA;&lt;li&gt;0th IFD&lt;/li&gt;&#xA;&lt;li&gt;0th IFD Value&lt;/li&gt;&#xA;&lt;li&gt;1st IFD&lt;/li&gt;&#xA;&lt;li&gt;1st IFD Value&lt;/li&gt;&#xA;&lt;li&gt;1st (Thumbnail) Image Data&lt;/li&gt;&#xA;&lt;li&gt;0th (Primary) Image Data&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/2.png&#34; alt=&#34;图片文件结构&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以看到，IFD 记录了如图片长宽的信息，EXIF IFD 记录图片的拍摄信息，GPS IFD 则记录了 GPS。&lt;/p&gt;&#xA;&lt;h3&gt;IFD 结构&lt;/h3&gt;&#xA;&lt;p&gt;一个 IFD 由四部分组成，每一个 IFD 都是固定的 12 个字节，分别是&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Bytes 0-1   Tag&lt;/li&gt;&#xA;&lt;li&gt;Bytes 2-3   Type&lt;/li&gt;&#xA;&lt;li&gt;Bytes 4-7   Count&lt;/li&gt;&#xA;&lt;li&gt;Bytes 8-11  Value Offset&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;em&gt;Tag&lt;/em&gt; 是标记这个 IFD 的类别。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Type&lt;/em&gt; 是指数据的类型，有 BYTE(1, 8-bit), ASCII(2, 8-bit), SHORT(3, 2-byte), LONG(4, 4-byte), RATIONAL(5, 2-long) 等。其中 RATIONAL 的第一个 long 是分子，第二个 long 是分母。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Count&lt;/em&gt; 是指数据的数量，比如纬度就用度、分、秒三个数来描述。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;Value Offset&lt;/em&gt; 是指真实数据所在的偏移地址（相对于 File header），而且需要注意的是，这里记录的值小于 4 个字节，则数据左对齐。&lt;/p&gt;&#xA;&lt;h3&gt;Exif IFD 结构&lt;/h3&gt;&#xA;&lt;p&gt;EXif IFD Pointer&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Tag     = 34665(8769.H)&#xA;Type    = LONG &#xA;Count   = 1&#xA;Default = None&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;GPS IFD Pointer&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Tag     = 34853(8825.H)&#xA;Type    = LONG &#xA;Count   = 1 &#xA;Default = None&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;GPS 属性信息&lt;/h3&gt;&#xA;&lt;p&gt;我们这边只关心 GPS 的经纬度，与之相关的一些 Tag 信息如下。&lt;/p&gt;&#xA;&lt;p&gt;GPSLatitudeRef&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Tag     = 1&#xA;Type    = ASCII  &#xA;Count   = 2&#xA;Default = None &#xA;&#39;N&#39;     = North latitude&#xA;&#39;S&#39;     = South latitude &#xA;Other   = reserved&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;GPSLatitude&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Tag     = 2&#xA;Type    = RATIONAL&#xA;Count   = 3 &#xA;Default = None&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;GPSLongtitudeRef&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Tag     = 3&#xA;Type    = ASCII  &#xA;Count   = 2&#xA;Default = None &#xA;&#39;E&#39;     = East longtitude&#xA;&#39;W&#39;     = West longtitude&#xA;Other   = reserved&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;GPSLongtitude&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Tag     = 4&#xA;Type    = RATIONAL&#xA;Count   = 3 &#xA;Default = None&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;实战&lt;/h2&gt;&#xA;&lt;h3&gt;寻找头部&lt;/h3&gt;&#xA;&lt;p&gt;用二进制编辑器打开手机拍摄的图片。阅读了 Specification 之后，我们了解到图片文件开始处所包含的信息为 SOI Marker(FFD8.H), APP1 Marker(FFE1.H), APP1 Length(xxxx.H), Identifier(&#39;Exif&#39;), Pad(00.H), APP1 Body(File Header, 0th IFD, 0th IFD Value, ...)。&lt;/p&gt;&#xA;&lt;p&gt;查看一下二进制，&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/3.png&#34; alt=&#34;图片起始&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以看到真的有 FFD8.H, FFE1.H, 后面的 45.H, 78.H, 69.H, 66.H，则正好是 &#39;Exif&#39; 的 ASCII 值。&lt;/p&gt;&#xA;&lt;p&gt;接下来 8 个字节，分别是 Byte Order(4D4D.H), 42(002A.H), 0th IFD Offset(00000008.H) 和 Number of Interoperability(000B.H)。让我们检察一下二进制文件。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/4.png&#34; alt=&#34;APP1 Body&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;接下来就是各种 IFD 的信息，我们需要先找到我们关心的 GPS IFD Pointer, 其 Tag = 8825.H。搜索一下，找到啦，在地址 0000008e.H 处。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/5.png&#34; alt=&#34;GPS IFD Pointer&#34;&gt;&lt;/p&gt;&#xA;&lt;h3&gt;修改 GPS&lt;/h3&gt;&#xA;&lt;p&gt;按照之前描述的 IFD 结构，我们将接下来的 10 个字节如图分割，可以看到其指出真正的 GPS 信息位于地址 03EC.H 处。由于这里的地址是相对于 File Header (也就是地址 000C.H)，所以真实的地址为 03EC.H + 000C.H = 03F8.H。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/6.png&#34; alt=&#34;偏移地址&#34;&gt;&lt;/p&gt;&#xA;&lt;h4&gt;第一个 IFD&lt;/h4&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/7.png&#34; alt=&#34;GPSLatitudeRef&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;开始两个字节为 GPS IFD Number，忽略。接下来的 4 个 IFD 就是我们需要修改的 GPS 信息。我们可以看出这是一个 GPSLatitudeRef，其中 4E000000.H 是 &#39;N&#39; 的 ASCII 码值，而且之前说过数据必须左对齐。这个我们不需要修改。&lt;/p&gt;&#xA;&lt;h4&gt;第二个 IFD&lt;/h4&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/8.png&#34; alt=&#34;N&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;我们可以看出这是一个 GPSLatitude, 其指出真正 GPS 纬度信息存放在地址 049A.H + 000C.H = 04A6.H 处。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/9.png&#34; alt=&#34;纬度&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;1F.H / 01.H = 31, 1D.H / 01.H = 29, 0C71.H / 64.H = 31。计算结果与 Windows 右键属性查看的完全一致。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/10.png&#34; alt=&#34;原纬度值&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;谷歌搜索得知北京天安门位于北纬 39(27.H) 度 54(36.H) 分，那我们只需要修改对应位就行。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/11.png&#34; alt=&#34;修改后纬度值&#34;&gt;&lt;/p&gt;&#xA;&lt;h4&gt;第三/四个 IFD&lt;/h4&gt;&#xA;&lt;p&gt;我们可以找到并修改经度信息。04B2.H + 0C.H = 04BE.H&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/12.png&#34; alt=&#34;原经度值&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;北京天安门位于东经 116 度 23 分。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/13.png&#34; alt=&#34;现经度值&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;再用 Windows 右键属性查看一下。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/14.png&#34; alt=&#34;属性查看&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;已经在北京了。&lt;/p&gt;&#xA;&lt;p&gt;我们可以用 QQ 上传照片的功能验证一下。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/15.png&#34; alt=&#34;QQ&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;确实在北京天安门附近。&lt;/p&gt;&#xA;&lt;h2&gt;Conclusion&lt;/h2&gt;&#xA;&lt;p&gt;对于不带 GPS 信息的图片怎么办呢，那就比较麻烦了，因为其本身不含 GPS IFD，要手动插入 IFD，计算各个偏移量，再将后面的 jpeg 数据整体后移。&lt;/p&gt;&#xA;&lt;p&gt;该研究起初源于我想恶作剧在空间传照片时显示任意地点，结果等我弄完后发现其实 QQ 支持在上传添加地点时候乱填 -_-&lt;/p&gt;&#xA;&lt;p&gt;最后是我用来实验的图片，摄于江南大学，2015.2.11，iphone 5c.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;/img/blog/201511/IMG_0596.JPG&#34; alt=&#34;flower&#34;&gt;&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2015/11/14/exif-hack/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>SCons 用户指南第二章-简单编译</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2015/11/02/scons2-simple-build/</id>
    <content type="html">&lt;p&gt;在本章中，你将会看到使用 SCons 作配置的简单编译的例子。这些例子表现了使用 SCons 作为不同语言不同系统编译构建工具是非常简单的。&lt;/p&gt;&#xA;&lt;h2&gt;2.1 编译简单的 C/C++ 程序&lt;/h2&gt;&#xA;&lt;p&gt;以下是著名的 C 语言 &amp;quot;Hello, World!&amp;quot;：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;int&#xA;main()&#xA;{&#xA;    printf(&amp;quot;Hello, world!\n&amp;quot;);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;接下来是如何使用 SCons 进行编译。只要在名为 SConstruct 的文件中输入：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Program(&#39;hello.c&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这个最小的配置文件告诉 SCons 两个信息：你想编译成什么（一个可执行的程序），和你的源文件（hello.c）。Program 是一个 builder_method，这是一个 Python 的调用，用来告诉 SCons 你想生成一个可执行的程序。&lt;/p&gt;&#xA;&lt;p&gt;好了。现在使用 scons 命令来编译程序。在一个 POSIX 兼容的系统上，比如 Linux/UNIX，你将会看到如下的输出：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons&#xA;scons: Reading SConscript files ...&#xA;scons: done reading SConscript files.&#xA;scons: Building targets ...&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;scons: done building targets.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在使用 Microsoft Visual C++ 编译器的 Windows 系统上，你会看到如下的输出：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;scons&#xA;scons: Reading SConscript files ...&#xA;scons: done reading SConscript files.&#xA;scons: Building targets ...&#xA;cl /Fohello.obj /c hello.c /nologo&#xA;link /nologo /OUT:hello.exe hello.obj&#xA;embedManifestExeCheck(target, source, env)&#xA;scons: done building targets.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;首先注意到，你只需要指出源文件的名字，SCons 就会正确推导出 object 和可执行文件的名字。&lt;/p&gt;&#xA;&lt;p&gt;然后注意到，相同的 SConstruct 文件，不用修改就可以在不同系统生成正确的输出：在 POSIX 系统上生成 hello.o 和 hello，在 Windows 系统上生成 hello.obj 和 hello.exe。这是一个非常简单的例子，展示了 SCons 能够很容易地编写可移植的软件编译系统。&lt;/p&gt;&#xA;&lt;p&gt;（注意到在本指南中，并不是每个例子都给出了 POSIX 和 Windows 的输出，然而除非特别声明，这些例子在每个系统上都应该是可工作的。）&lt;/p&gt;&#xA;&lt;h2&gt;2.2 编译目标文件&lt;/h2&gt;&#xA;&lt;p&gt;Program 编译方法只是 SCons 提供的众多编译方法的一种，他们可用来编译成各种文件。其中另外一个就是 Object 编译方法，能使 SCons 从指定的源文件编译成相应的目标文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Object(&#39;hello.c&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;现在你只要运行 scons 命令编译程序，就能在 POSIX 系统上得到名为 hello.o 的目标文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons&#xA;scons: Reading SConscript files ...&#xA;scons: done reading SConscript files.&#xA;scons: Building targets ...&#xA;cc -o hello.o -c hello.c&#xA;scons: done building targets.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在使用 Microsoft Visual C++ 编译器的 Windows 系统上，你会得到：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;scons&#xA;scons: Reading SConscript files ...&#xA;scons: done reading SConscript files.&#xA;scons: Building targets ...&#xA;cl /Fohello.obj /c hello.c /nologo&#xA;scons: done building targets.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;2.3 简单 Java 编译&lt;/h2&gt;&#xA;&lt;p&gt;SCons 也使得编译 Java 及其简单。然而不像 Program 和 Object 编译方法，Java编译方法需要你指定生成的 class 文件的目标路径，和你 .java 文件的源路径：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Java(&#39;classes&#39;, &#39;src&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果 src 目录只包含一个 hello.java 文件，那么使用 scons 命令的输出结果将是（POSIX）：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons&#xA;scons: Reading SConscript files ...&#xA;scons: done reading SConscript files.&#xA;scons: Building targets ...&#xA;javac -d classes -sourcepath src src/hello.java&#xA;scons: done building targets.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;我们将在第 26 章讲述更多关于 Java 编译的内容，包括 .jar 和其他类型文件。&lt;/p&gt;&#xA;&lt;h2&gt;2.4 在编译之后清理&lt;/h2&gt;&#xA;&lt;p&gt;当使用 SCons 编译完成之后，不需要特别的命令来清理。相反，你只需要 -c 或者 --clean 选项，SCons 就会自动清理相关的编译生成文件。如果在上面的例子之后，我们调用 scons -c 命令，在 POSIX 系统上就会输出：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons&#xA;scons: Reading SConscript files ...&#xA;scons: done reading SConscript files.&#xA;scons: Building targets ...&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;scons: done building targets.&#xA;% scons -c&#xA;scons: Reading SConscript files ...&#xA;scons: done reading SConscript files.&#xA;scons: Cleaning targets ...&#xA;Removed hello.o&#xA;Removed hello&#xA;scons: done cleaning targets.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 Windows 上就会输出：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;scons&#xA;scons: Reading SConscript files ...&#xA;scons: done reading SConscript files.&#xA;scons: Building targets ...&#xA;cl /Fohello.obj /c hello.c /nologo&#xA;link /nologo /OUT:hello.exe hello.obj&#xA;embedManifestExeCheck(target, source, env)&#xA;scons: done building targets.&#xA;C:\&amp;gt;scons -c&#xA;scons: Reading SConscript files ...&#xA;scons: done reading SConscript files.&#xA;scons: Cleaning targets ...&#xA;Removed hello.obj&#xA;Removed hello.exe&#xA;scons: done cleaning targets.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;注意到 SCons 用 Cleaning targets ... 和 done cleaning targets 来告诉你清理过程。&lt;/p&gt;&#xA;&lt;h2&gt;2.5 SConstruct 文件&lt;/h2&gt;&#xA;&lt;p&gt;如果你曾经使用过类似 Make 的编译系统，你可能会想 SConstruct 文件是否等同于 Makefile 文件。是的，SConstruct 文件是 SCons 用来控制编译过程的。&lt;/p&gt;&#xA;&lt;h3&gt;2.5.1 SConstruct 文件是 Python 脚本文件&lt;/h3&gt;&#xA;&lt;p&gt;然而 SConstruct 文件和 Makefile 文件一个重要的区别就是：SConstruct 文件实际上就是一个 Python 脚本文件。如果你还不熟悉 Python，不要着急。本用户指南会介绍一下基本的 Python 语法来有效地使用 SCons。而且，Python 非常容易学习。&lt;/p&gt;&#xA;&lt;p&gt;使用 Python 脚本语言的一方面就是你可以在 SConstruct 文件中使用 Python 的注释，那就是 &#39;#&#39;，该行之后的都会被忽略：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# Arrange to build the &amp;quot;hello&amp;quot; program.&#xA;Program(&#39;hello.c&#39;)    # &amp;quot;hello.c&amp;quot; is the source file.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;你可以在本指南剩余部分看到，一个真正的脚本语言，可以使用极简单的方法来满足现实世界的复杂需求。&lt;/p&gt;&#xA;&lt;h3&gt;2.5.2 SCons 函数是顺序无关的&lt;/h3&gt;&#xA;&lt;p&gt;SConstruct 文件更像 Makefile 文件也是区别于普通 Python 脚本的重要一点就是，SCons 函数的调用顺序并不影响实际编译过程中目标文件的编译顺序。换句话说，当你调用 Program 编译方法（或者其他编译方法）时，你并不是告诉在此立即编译程序。相反，你只是告诉你需要编译的程序，举例来说，如果你想编译 hello.c，完全由 SCons 来决定何时编译程序。（我们将在第六章-依赖中学习 SCons 何时编译和重新编译）。&lt;/p&gt;&#xA;&lt;p&gt;当 SCons 读入 SConstruct 文件和实际编译程序的时候， SCons 通过在输出的状态信息中反映出调用编译方法如 Program 和实际编译程序过程的区别。这能够反映出 SCons 到底是在执行 Python 语句还是在执行编译命令。&lt;/p&gt;&#xA;&lt;p&gt;让我们来用一个例子说明这一点。Python 有一个 print 语句能够在将字符串打印在屏幕上。如果 print 语句放在 Program 编译方法之间：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;print &amp;quot;Calling Program(&#39;hello.c&#39;)&amp;quot;&#xA;Program(&#39;hello.c&#39;)&#xA;print &amp;quot;Calling Program(&#39;goodbye.c&#39;)&amp;quot;&#xA;Program(&#39;goodbye.c&#39;)&#xA;print &amp;quot;Finished calling Program()&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;然后当我们调用 SCons 时，我们能够看到打印的 print 语句，指示出这些语句是何时执行的：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;% scons&#xA;scons: Reading SConscript files ...&#xA;Calling Program(&#39;hello.c&#39;)&#xA;Calling Program(&#39;goodbye.c&#39;)&#xA;Finished calling Program()&#xA;scons: done reading SConscript files.&#xA;scons: Building targets ...&#xA;cc -o goodbye.o -c goodbye.c&#xA;cc -o goodbye goodbye.o&#xA;cc -o hello.o -c hello.c&#xA;cc -o hello hello.o&#xA;scons: done building targets.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;注意到尽管我们先调用了 Program(&#39;hello&#39;)，但是 goodbye 程序先被编译了，&lt;/p&gt;&#xA;&lt;h2&gt;2.6 使 SCons 输出更简洁&lt;/h2&gt;&#xA;&lt;p&gt;你已经看见了 SCons 在实际编译指令周围使用了一些信息来指示出它当前执行的动作：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;scons&#xA;scons: Reading SConscript files ...&#xA;scons: done reading SConscript files.&#xA;scons: Building targets ...&#xA;cl /Fohello.obj /c hello.c /nologo&#xA;link /nologo /OUT:hello.exe hello.obj&#xA;embedManifestExeCheck(target, source, env)&#xA;scons: done building targets.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这些信息强调了 SCons 工作的顺序：所有的配置文件（大部分是 SConscript 文件）首先被读入和执行，然后是编译目标文件。除了其他好处，这些信息还帮助区分是读入配置错误还是编译过程中发生的错误。&lt;/p&gt;&#xA;&lt;p&gt;一个显而易见的缺点是这些信息混淆了输出。幸运的是你可以使用 -Q 选项来取消它们：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;scons -Q&#xA;cl /Fohello.obj /c hello.c /nologo&#xA;link /nologo /OUT:hello.exe hello.obj&#xA;embedManifestExeCheck(target, source, env)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;因为本指南想注重于 SCons de 实际工作过程，我们将在剩余的例子中继续使用 -Q 选项来移除这些信息。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2015/11/02/scons2-simple-build/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>SCons 用户指南第一章-编译和安装 SCons</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2015/10/17/scons1-building-and-installing-scons/</id>
    <content type="html">&lt;p&gt;本章会告诉你在你系统上安装 SCons 的基本步骤，或者是在没有预编译包的情况下自己编译 SCons (有些人会倾向于自己编译的灵活性)。在此之前，本章也会涉及到一些安装 Python 的步骤，因为这是 SCons 的依赖。幸运的是，安装 SCons 和 Python 非常简单，而且有些系统已经自带 Python 环境。&lt;/p&gt;&#xA;&lt;h2&gt;1.1 安装 Python&lt;/h2&gt;&#xA;&lt;p&gt;由于 SCons 是由 Python 写成的，所以必须先安装 Python。在安装 Python 之前，首先得确定你是否已经安装过 Python 了。你只需要在你系统令行输入 python -v 或者是 python --version 。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ python -V&#xA;Python 2.5.1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在 Windows 系统上，输出结果类似：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;C:\&amp;gt;python -V&#xA;Python 2.5.1&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果系统没有安装 Python，你就会看到类似的错误信息，比如 &amp;quot;command no found&amp;quot; (UNIX/Linux) 或者是 &amp;quot;&#39;python&#39; is not recognized as an internal or external command, operable program or batch file&amp;quot; (Windows)。在这种情况下，你就需要先安装 Python。&lt;/p&gt;&#xA;&lt;p&gt;官方的下载和安装 Python 的地址如下：&#xA;&lt;a href=&#34;http://www.python.org/download/&#34;&gt;Python 官网&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;SCons 支持 2.7 以来的所有 2.x 版本的 Python，3.x 版本的还不支持。我们建议你安装最新的 2.x 版本 Python。最新的 Python 可以显著地提高 SCons 的性能。&lt;/p&gt;&#xA;&lt;h2&gt;1.2 从预编译包中安装 SCons&lt;/h2&gt;&#xA;&lt;p&gt;在很多系统上，SCons 都有现成的预编译包可直接安装，包括 Windows 和 Linux。本小节你不需要完全阅读，你只需要阅读你对应的系统。&lt;/p&gt;&#xA;&lt;h3&gt;1.2.1 在 Red Hat (和基于RPM) 的 Linux 系统上安装 SCons&lt;/h3&gt;&#xA;&lt;p&gt;SCons 有 RPM (Red Hat Package Manager) 格式的预编译报，可以安装于 Red Hat Linux, Fedora 或者其他使用 RPM 的 Linux 发行版。你的发行版可能已经有一个预编译 SCons RPM，比如 SUSE, Mandrake 和 Fedora。你可以在你发行版下载服务器上搜索 SCons RPM，或者是一些 RPM 搜索站：http://www.rpmfind.net/, http://rpm.pbone.net/。&lt;/p&gt;&#xA;&lt;p&gt;如果你的发行版支持 yum 安装，你可以直接运行以下命令安装 SCons：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# yum install scons&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;如果你的Linux发行版没有包含一个特定的 SCons RPM 文件，你可以下载SCons项目提供的通用的RPM来安装。这会安装SCons脚本到 /usr/bin 目录，安装 SCons 库模块到 /usr/lib/scons。&lt;/p&gt;&#xA;&lt;p&gt;下载合适的.rpm文件，从命令行安装：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;#rpm -Uvh scons-2.1.0-1.noarch.rpm&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;或者，你可使用图形包管理器，查询你的包管理器应用文档，找到如何安装下载的 RPM 的特殊指令。&lt;/p&gt;&#xA;&lt;h3&gt;1.2.2 在 Debian Linux 系统上安装 SCons&lt;/h3&gt;&#xA;&lt;p&gt;Debian Linux 使用另一个包管理器，而且安装 SCons 也非常方便。&lt;/p&gt;&#xA;&lt;p&gt;如果你的系统联网，则可以运行以下命令来获取最新的 Debian 包：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# apt-get install scons&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3&gt;1.2.3 在 Windows 系统里安装 SCons&lt;/h3&gt;&#xA;&lt;p&gt;SCons 的 Windows 安装包使得安装极其简单。只需要在 &lt;a href=&#34;http://www.scons.org/download.php&#34;&gt;下载页面&lt;/a&gt; 下载 scons-2.4.0.win32.exe 文件，然后你需要做的就是打开后不停的下一步。&lt;/p&gt;&#xA;&lt;h2&gt;1.3 在任何系统上编译和安装 SCons&lt;/h2&gt;&#xA;&lt;p&gt;如果你的系统上没有预编译的报，那么仍然能够通过 Python 原生的 distutils 包轻易地编译和安装 SCons。&lt;/p&gt;&#xA;&lt;p&gt;首先第一步是去&lt;a href=&#34;http://www.scons.org/download.html&#34;&gt;下载页面&lt;/a&gt;下载 scons-2.4.0.tar.gz 或者 scons-2.4.0.zip。&lt;/p&gt;&#xA;&lt;p&gt;然后解压压缩包，在 Linux/UNIX 上使用 tar，在 Windows 上使用 WinZip。解压之后会在你的本地目录创建一个 scons-2.4.0 临时目录。然后切换你的工作目录到临时目录中执行下列命令：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# cd scons-2.4.0&#xA;# python setup.py install&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这会编译 SCons，然后将 scons 脚本安装在执行 setup.py 脚本的目录中 (/usr/local/bin 或者 c:\Python25\Scripts)，然后将 SCons 的编译构建引擎放置在 python 的库目录中 (/usr/local/lib/scons 或者 C:\Python25\scons)。因为这些都是系统目录，所以你可能需要 root (Linux/UNIX) 或者 Administrator (Windows) 权限。&lt;/p&gt;&#xA;&lt;h3&gt;1.3.1 编译并同时安装多个版本的 SCons&lt;/h3&gt;&#xA;&lt;p&gt;SCons 的 setup.py 脚本有一些扩展选项，支持在多个地方安装多个版本的 SCons。举例来说，当你在决定使用哪个版本的 SCons 时，这能让你轻易的下载并实验不同版本的 SCons。&lt;/p&gt;&#xA;&lt;p&gt;在安装时可以通过  --version-lib 选项来制定安装版本的位置：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# python setup.py install --version-lib&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这会将 SCons 的引擎安装在 /usr/lib/scons-2.4.0 或者是 C:\Python25\scons-2.4.0 目录下。&lt;/p&gt;&#xA;&lt;p&gt;如果你第一次安装 SCons 时指定了 --version-lib 选项，你之后每一次安装新版本时就无需指定。 SCons 的 setup.py 脚本会自动检测版本的特殊位置名，并且假设你每个版本都安装在不同的位置。当然，你也可以指定 --standalone-lib 选项来消除这个假设。&lt;/p&gt;&#xA;&lt;h3&gt;1.3.2 安装 SCons 于其他位置&lt;/h3&gt;&#xA;&lt;p&gt;你可以指定 --prefix= 选项将 SCons 安装在非默认位置，例如：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;# python setup.py install --prefix=/opt/scons&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这会将 scons 脚本安装在 /opt/scons/bin 和将编译构建引擎安装在 /opt/scons/lib/scons 中。&lt;/p&gt;&#xA;&lt;p&gt;现在你也可以同时指定 --prefix= 和 --version-lib 选项。setup.py 脚本会根据特定 prefix 将引擎安装在特定版本的目录。这样会将编译引擎安装在 /opt/scons/lib/scons-2.4.0。&lt;/p&gt;&#xA;&lt;h3&gt;1.3.3 在无管理员权限的情况下编译和安装 SCons&lt;/h3&gt;&#xA;&lt;p&gt;如果你没有权限将 SCons 安装到系统目录中，那你可以使用 --prefix= 选项安装到你指定的目录中。例如，你可以将 SCons 安装到相对于用户的 $HOME 中，将 scons 脚本安装在 $HOME/bin，并将引擎安装在 $HOME/lib/scons:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;$ python setup.py install --prefix=$HOME&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;你当然可以安装你选择的任何地方，并使用 --version-lib 来指定特定版本的目录。&lt;/p&gt;&#xA;&lt;p&gt;这可以在你已有 SCons 的情况下实验最新的 SCons 版本。当然，你必须在 PATH 环境变量中将最新版本的 SCons 目录放置在旧版本 SCons 目录之前。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2015/10/17/scons1-building-and-installing-scons/" rel="alternate"></link>
    <summary type="html"></summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
  <entry>
    <title>shellcode学习-绕过条件判断</title>
    <updated>2026-01-21T10:28:30+08:00</updated>
    <id>https://www.lyyyuna.com/2015/08/30/shellcode1/</id>
    <content type="html">&lt;p&gt;shellcode学习第一个例子。&lt;/p&gt;&#xA;&lt;p&gt;以下有一段c语言编写的命令行程序，检验用户输入的数字，并判断是否合法。这里用户的输入被放在了函数的缓冲区里，但程序没有对缓冲区长度做检查，留下了漏洞。这里可以利用该漏洞绕过数字检察，使得任意输入都会被判定为正确。&#xA;在 &lt;em&gt;validate_serial&lt;/em&gt; 中，&lt;em&gt;do_valid_stuff&lt;/em&gt; 的地址溢出到函数的返回值上，就可实现。&lt;/p&gt;&#xA;&lt;h2&gt;源程序&lt;/h2&gt;&#xA;&lt;pre&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;&#xA;#include &amp;lt;stdlib.h&amp;gt;&#xA;#include &amp;lt;string.h&amp;gt;&#xA;&#xA;int valid_serial(char * psz)&#xA;{&#xA;    size_t len = strlen(psz);&#xA;    unsigned total = 0;&#xA;    size_t i;&#xA;&#xA;    if (len&amp;lt;10)&#xA;        return 0;&#xA;&#xA;    for (i = 0; i &amp;lt; len; i++)&#xA;    {&#xA;        if ((psz[i]&amp;lt;&#39;0&#39;) || (psz[i]&amp;gt;&#39;z&#39;))&#xA;            return 0;&#xA;        total += psz[i];&#xA;    }&#xA;&#xA;    if (total % 853 == 83)&#xA;        return 1;&#xA;&#xA;    return 0;    &#xA;}&#xA;&#xA;int valildate_serial()&#xA;{&#xA;    char serial[24];&#xA;&#xA;    fscanf(stdin, &amp;quot;%s&amp;quot;, serial);&#xA;&#xA;    if (valid_serial(serial))&#xA;        return 1;&#xA;    else&#xA;        return 0;&#xA;}&#xA;&#xA;int do_valid_stuff()&#xA;{&#xA;    printf(&amp;quot;the serial number is valid!\n&amp;quot;);&#xA;    exit(0);&#xA;}&#xA;&#xA;int do_invalid_stuff()&#xA;{&#xA;    printf(&amp;quot;invalid serial number!\nexiting\n&amp;quot;);&#xA;    exit(1);&#xA;}&#xA;&#xA;int main(int argc, char * argv[])&#xA;{&#xA;    if (valildate_serial())&#xA;        do_valid_stuff();&#xA;    else&#xA;        do_invalid_stuff();&#xA;&#xA;    return 0;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2&gt;反汇编main&lt;/h2&gt;&#xA;&lt;pre&gt;&lt;code&gt;(gdb) disass main&#xA;Dump of assembler code for function main:&#xA;   0x0804861a &amp;lt;+0&amp;gt;:     push   %ebp&#xA;   0x0804861b &amp;lt;+1&amp;gt;:     mov    %esp,%ebp&#xA;   0x0804861d &amp;lt;+3&amp;gt;:     call   0x804859f &amp;lt;valildate_serial&amp;gt;&#xA;   0x08048622 &amp;lt;+8&amp;gt;:     test   %eax,%eax&#xA;   0x08048624 &amp;lt;+10&amp;gt;:    je     0x804862d &amp;lt;main+19&amp;gt;&#xA;   0x08048626 &amp;lt;+12&amp;gt;:    call   0x80485de &amp;lt;do_valid_stuff&amp;gt;&#xA;   0x0804862b &amp;lt;+17&amp;gt;:    jmp    0x8048632 &amp;lt;main+24&amp;gt;&#xA;   0x0804862d &amp;lt;+19&amp;gt;:    call   0x80485fc &amp;lt;do_invalid_stuff&amp;gt;&#xA;   0x08048632 &amp;lt;+24&amp;gt;:    mov    $0x0,%eax&#xA;   0x08048637 &amp;lt;+29&amp;gt;:    pop    %ebp&#xA;   0x08048638 &amp;lt;+30&amp;gt;:    ret&#xA;End of assembler dump.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可得到 &lt;em&gt;do_valid_stuff&lt;/em&gt; 的地址为 0x08048626。&lt;em&gt;validate_serial&lt;/em&gt; 的返回地址为 0x08048622。下面就通过溢出修改返回地址。&lt;/p&gt;&#xA;&lt;h2&gt;缓冲区溢出&lt;/h2&gt;&#xA;&lt;p&gt;源码中，缓冲区长度为24，理论上只要覆盖24+2处的数据就可以了。我们需要检验一下，在fscanf处打断点，观察堆栈内容。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;Breakpoint 1, valildate_serial () at serial.c:31&#xA;31          fscanf(stdin, &amp;quot;%s&amp;quot;, serial);&#xA;(gdb) x/20x $esp&#xA;0xbffff6bc:     0x0804869b      0x00000001      0xbffff794      0xbffff79c&#xA;0xbffff6cc:     0xbffff6e8      0xb7e987f5      0xb7ff0590      0x0804865b&#xA;0xbffff6dc:     0xb7fc7ff4      0xbffff6e8      0x08048622      0xbffff768&#xA;0xbffff6ec:     0xb7e7fe46      0x00000001      0xbffff794      0xbffff79c&#xA;0xbffff6fc:     0xb7fe0860      0xb7ff6821      0xffffffff      0xb7ffeff4&#xA;(gdb)c&#xA;AAAAAAAAAABBBBBBBBBBCCCCCCCC1234&#xA;&#xA;Breakpoint 2, valildate_serial () at serial.c:33&#xA;33          if (valid_serial(serial))&#xA;(gdb) x/20x $esp&#xA;0xbffff6bc:     0xb7fc8440      0x080486d0      0xbffff6c8      0x41414141&#xA;0xbffff6cc:     0x41414141      0x42424141      0x42424242      0x42424242&#xA;0xbffff6dc:     0x43434343      0x43434343      0x34333231      0xbffff700&#xA;0xbffff6ec:     0xb7e7fe46      0x00000001      0xbffff794      0xbffff79c&#xA;0xbffff6fc:     0xb7fe0860      0xb7ff6821      0xffffffff      0xb7ffeff4&#xA;(gdb)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;可以看到“1234”对应的ascii码“0x34333231”已经被写入了返回值&amp;quot;0x08048622&amp;quot;原来所在的地方。&#xA;接下来把“1234”换成我们需要的返回地址。&lt;/p&gt;&#xA;&lt;p&gt;我们回到shell中实验一下&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;lyyyuna@yan:~/Desktop/shellcode/validate_serial$ printf &amp;quot;AAAAAAAAAABBBBBBBBBBCCCCCCCC\x26\x86\x04\x08&amp;quot; | ./serial&#xA;the serial number is valid!&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;成功绕过了程序的检验机制。&lt;/p&gt;&#xA;</content>
    <link href="https://www.lyyyuna.com/2015/08/30/shellcode1/" rel="alternate"></link>
    <summary type="html">shellcode 管窥。</summary>
    <author>
      <name>lyyyuna</name>
      <email>lyyyuna@outlook.com</email>
    </author>
  </entry>
</feed>